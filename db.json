{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/icarus/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/icarus/source/js/insight.js","path":"js/insight.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/css/images/avatar.png","path":"css/images/avatar.png","modified":0,"renderable":1},{"_id":"themes/icarus/source/css/images/logo.png","path":"css/images/logo.png","modified":0,"renderable":1},{"_id":"themes/icarus/source/css/images/logo2.png","path":"css/images/logo2.png","modified":0,"renderable":1},{"_id":"themes/icarus/source/css/images/thumb-default-small.png","path":"css/images/thumb-default-small.png","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/justified-gallery/jquery.justifiedGallery.min.js","path":"vendor/justified-gallery/jquery.justifiedGallery.min.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/justified-gallery/justifiedGallery.min.css","path":"vendor/justified-gallery/justifiedGallery.min.css","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/styles.css","path":"vendor/open-sans/styles.css","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/source-code-pro/styles.css","path":"vendor/source-code-pro/styles.css","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/font-awesome/css/font-awesome.css","path":"vendor/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/font-awesome/css/font-awesome.min.css","path":"vendor/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/css/lg-fb-comment-box.css","path":"vendor/lightgallery/css/lg-fb-comment-box.css","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/css/lg-fb-comment-box.css.map","path":"vendor/lightgallery/css/lg-fb-comment-box.css.map","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/css/lg-fb-comment-box.min.css","path":"vendor/lightgallery/css/lg-fb-comment-box.min.css","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/css/lg-transitions.css","path":"vendor/lightgallery/css/lg-transitions.css","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/css/lg-transitions.css.map","path":"vendor/lightgallery/css/lg-transitions.css.map","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/css/lg-transitions.min.css","path":"vendor/lightgallery/css/lg-transitions.min.css","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/css/lightgallery.css","path":"vendor/lightgallery/css/lightgallery.css","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/css/lightgallery.css.map","path":"vendor/lightgallery/css/lightgallery.css.map","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/css/lightgallery.min.css","path":"vendor/lightgallery/css/lightgallery.min.css","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/fonts/lg.eot","path":"vendor/lightgallery/fonts/lg.eot","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/fonts/lg.svg","path":"vendor/lightgallery/fonts/lg.svg","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/fonts/lg.ttf","path":"vendor/lightgallery/fonts/lg.ttf","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/fonts/lg.woff","path":"vendor/lightgallery/fonts/lg.woff","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/img/loading.gif","path":"vendor/lightgallery/img/loading.gif","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/img/video-play.png","path":"vendor/lightgallery/img/video-play.png","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/img/vimeo-play.png","path":"vendor/lightgallery/img/vimeo-play.png","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/img/youtube-play.png","path":"vendor/lightgallery/img/youtube-play.png","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-autoplay.js","path":"vendor/lightgallery/js/lg-autoplay.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-autoplay.min.js","path":"vendor/lightgallery/js/lg-autoplay.min.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-fullscreen.js","path":"vendor/lightgallery/js/lg-fullscreen.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-fullscreen.min.js","path":"vendor/lightgallery/js/lg-fullscreen.min.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-hash.js","path":"vendor/lightgallery/js/lg-hash.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-hash.min.js","path":"vendor/lightgallery/js/lg-hash.min.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-pager.js","path":"vendor/lightgallery/js/lg-pager.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-pager.min.js","path":"vendor/lightgallery/js/lg-pager.min.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-share.js","path":"vendor/lightgallery/js/lg-share.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-share.min.js","path":"vendor/lightgallery/js/lg-share.min.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-thumbnail.js","path":"vendor/lightgallery/js/lg-thumbnail.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-thumbnail.min.js","path":"vendor/lightgallery/js/lg-thumbnail.min.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-video.js","path":"vendor/lightgallery/js/lg-video.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-video.min.js","path":"vendor/lightgallery/js/lg-video.min.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-zoom.js","path":"vendor/lightgallery/js/lg-zoom.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lightgallery.js","path":"vendor/lightgallery/js/lightgallery.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lightgallery.min.js","path":"vendor/lightgallery/js/lightgallery.min.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-zoom.min.js","path":"vendor/lightgallery/js/lg-zoom.min.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/59ZRklaO5bWGqF5A9baEERJtnKITppOI_IvcXXDNrsc.woff2","path":"vendor/open-sans/fonts/59ZRklaO5bWGqF5A9baEERJtnKITppOI_IvcXXDNrsc.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/K88pR3goAWT7BTt32Z01mxJtnKITppOI_IvcXXDNrsc.woff2","path":"vendor/open-sans/fonts/K88pR3goAWT7BTt32Z01mxJtnKITppOI_IvcXXDNrsc.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/LWCjsQkB6EMdfHrEVqA1KRJtnKITppOI_IvcXXDNrsc.woff2","path":"vendor/open-sans/fonts/LWCjsQkB6EMdfHrEVqA1KRJtnKITppOI_IvcXXDNrsc.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNShWV49_lSm1NYrwo-zkhivY.woff2","path":"vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNShWV49_lSm1NYrwo-zkhivY.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSj0LW-43aMEzIO6XUTLjad8.woff2","path":"vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSj0LW-43aMEzIO6XUTLjad8.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSpX5f-9o1vgP2EXwfjgl7AY.woff2","path":"vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSpX5f-9o1vgP2EXwfjgl7AY.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSq-j2U0lmluP9RWlSytm3ho.woff2","path":"vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSq-j2U0lmluP9RWlSytm3ho.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSqaRobkAwv3vxw3jMhVENGA.woff2","path":"vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSqaRobkAwv3vxw3jMhVENGA.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSugdm0LZdjqr5-oayXSOefg.woff2","path":"vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSugdm0LZdjqr5-oayXSOefg.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSv8zf_FOSsgRmwsS7Aa9k2w.woff2","path":"vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSv8zf_FOSsgRmwsS7Aa9k2w.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/RjgO7rYTmqiVp7vzi-Q5URJtnKITppOI_IvcXXDNrsc.woff2","path":"vendor/open-sans/fonts/RjgO7rYTmqiVp7vzi-Q5URJtnKITppOI_IvcXXDNrsc.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/cJZKeOuBrn4kERxqtaUH3VtXRa8TVwTICgirnJhmVJw.woff2","path":"vendor/open-sans/fonts/cJZKeOuBrn4kERxqtaUH3VtXRa8TVwTICgirnJhmVJw.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/u-WUoqrET9fUeobQW7jkRRJtnKITppOI_IvcXXDNrsc.woff2","path":"vendor/open-sans/fonts/u-WUoqrET9fUeobQW7jkRRJtnKITppOI_IvcXXDNrsc.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBiYE0-AqJ3nfInTTiDXDjU4.woff2","path":"vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBiYE0-AqJ3nfInTTiDXDjU4.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBjTOQ_MqJVwkKsUn0wKzc2I.woff2","path":"vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBjTOQ_MqJVwkKsUn0wKzc2I.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBjUj_cnvWIuuBMVgbX098Mw.woff2","path":"vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBjUj_cnvWIuuBMVgbX098Mw.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBkbcKLIaa1LC45dFaAfauRA.woff2","path":"vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBkbcKLIaa1LC45dFaAfauRA.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBmo_sUJ8uO4YLWRInS22T3Y.woff2","path":"vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBmo_sUJ8uO4YLWRInS22T3Y.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBo4P5ICox8Kq3LLUNMylGO4.woff2","path":"vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBo4P5ICox8Kq3LLUNMylGO4.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBr6up8jxqWt8HVA3mDhkV_0.woff2","path":"vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBr6up8jxqWt8HVA3mDhkV_0.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xozscpT2726on7jbcb_pAhJtnKITppOI_IvcXXDNrsc.woff2","path":"vendor/open-sans/fonts/xozscpT2726on7jbcb_pAhJtnKITppOI_IvcXXDNrsc.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasD9V_2ngZ8dMf8fLgjYEouxg.woff2","path":"vendor/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasD9V_2ngZ8dMf8fLgjYEouxg.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasDy2Q8seG17bfDXYR_jUsrzg.woff2","path":"vendor/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasDy2Q8seG17bfDXYR_jUsrzg.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/font-awesome/fonts/FontAwesome.otf","path":"vendor/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/font-awesome/fonts/fontawesome-webfont.eot","path":"vendor/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/font-awesome/fonts/fontawesome-webfont.woff","path":"vendor/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/font-awesome/fonts/fontawesome-webfont.woff2","path":"vendor/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/jquery/2.1.3/jquery.min.js","path":"vendor/jquery/2.1.3/jquery.min.js","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/font-awesome/fonts/fontawesome-webfont.ttf","path":"vendor/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/icarus/source/vendor/font-awesome/fonts/fontawesome-webfont.svg","path":"vendor/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"themes/icarus/.gitignore","hash":"542aaea07afe90211c6a45c90b7d6879a4503043","modified":1475249797797},{"_id":"themes/icarus/LICENSE","hash":"df00918fa95de563927fd92b26f14c7affdc3052","modified":1475249797797},{"_id":"themes/icarus/README.md","hash":"25c75503f044b817297995a96621c92ce037a098","modified":1475249797797},{"_id":"themes/icarus/_config.yml","hash":"1b0c7dfb85cec3033adc0609924bfbca328165fa","modified":1475252087027},{"_id":"themes/icarus/package.json","hash":"1bc52ef10a33df23e56bd73c927f605019c87d41","modified":1475249797803},{"_id":"source/_posts/About.md","hash":"a582164cc3aaba47582eb413136dc31abaf0f8a6","modified":1475251658315},{"_id":"source/_posts/hello-world.md","hash":"8a02477044e2b77f1b262da2c48c01429e4a32e4","modified":1475249661260},{"_id":"themes/icarus/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1475249797787},{"_id":"themes/icarus/.git/config","hash":"d29e0b80e29cd924161a73c63bac11af41d2631c","modified":1475249797787},{"_id":"themes/icarus/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1475249779720},{"_id":"themes/icarus/.git/index","hash":"711967a6e626fef38e7a8c91fc07311079812169","modified":1475249797837},{"_id":"themes/icarus/.git/packed-refs","hash":"dcc71ca22f0255184d0f0e406207a4103e43e355","modified":1475249797787},{"_id":"themes/icarus/.github/ISSUE_TEMPLATE.md","hash":"9393fd3dbc943f1544facb66af7fd8b7a5b9ddbb","modified":1475249797797},{"_id":"themes/icarus/languages/en.yml","hash":"ade241498b85503a8953a1deca963222f47067a7","modified":1475249797797},{"_id":"themes/icarus/languages/es.yml","hash":"d7432219be5bee4cb569331378ade61b749688e0","modified":1475249797797},{"_id":"themes/icarus/languages/fr.yml","hash":"cb3e597cbec7e8f458858c457bafd1f3a225083d","modified":1475249797797},{"_id":"themes/icarus/languages/id.yml","hash":"70ec9ab2ac04cf882e81377ca5ad15bf8adceca8","modified":1475249797797},{"_id":"themes/icarus/languages/ja.yml","hash":"ff972961e5f468a695d80d21b62c3e9032cdf561","modified":1475249797797},{"_id":"themes/icarus/languages/ko.yml","hash":"7c4ad4577dc0577ad2ca1c0410507f5e5fadf530","modified":1475249797797},{"_id":"themes/icarus/languages/pt-BR.yml","hash":"3c5d5293575593705b9a2dfa9d97b017eb4bc8c3","modified":1475249797797},{"_id":"themes/icarus/languages/ru.yml","hash":"d1aab2b0c939d0c6020f881d664b660a01ee7327","modified":1475249797797},{"_id":"themes/icarus/languages/tr.yml","hash":"8b7eb6aec264db50dbabea89f680acca256f4cd1","modified":1475249797797},{"_id":"themes/icarus/languages/zh-CN.yml","hash":"3dc8ec524805afd090438be717908750da439204","modified":1475249797797},{"_id":"themes/icarus/languages/zh-TW.yml","hash":"d8d96a0a17c20af11919ce036e87379a6b163db9","modified":1475249797797},{"_id":"themes/icarus/layout/archive.ejs","hash":"c1ecf667f40f34d61ab33eed46bab143eb1af36d","modified":1475249797797},{"_id":"themes/icarus/layout/categories.ejs","hash":"aa95629b770cff8cca9d663aeb6b17928f070de5","modified":1475249797797},{"_id":"themes/icarus/layout/category.ejs","hash":"1d407f9176db84e83062c52ad4755aaea9e74401","modified":1475249797797},{"_id":"themes/icarus/layout/index.ejs","hash":"43e971ebc35657b18e08a049559790348a16666f","modified":1475249797800},{"_id":"themes/icarus/layout/layout.ejs","hash":"6f01b3d46d184a820297f9542497808b152bb09e","modified":1475249797800},{"_id":"themes/icarus/layout/page.ejs","hash":"50170783bac99946ae8af483920568de9b2d9801","modified":1475249797800},{"_id":"themes/icarus/layout/post.ejs","hash":"50170783bac99946ae8af483920568de9b2d9801","modified":1475249797800},{"_id":"themes/icarus/layout/tag.ejs","hash":"f6c220d4e5c231028bc71ddc11aec97d7b5a9943","modified":1475249797800},{"_id":"themes/icarus/layout/tags.ejs","hash":"b0fcea68d7c11e5899bf0375d80997685111653f","modified":1475249797800},{"_id":"themes/icarus/scripts/meta.js","hash":"1993754a2f3dffa283fa0538eb8f056385b69ad4","modified":1475249797803},{"_id":"themes/icarus/scripts/thumbnail.js","hash":"e667a611f9baac270281b765832020d50bf8fb7f","modified":1475249797803},{"_id":"themes/icarus/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1475249779716},{"_id":"themes/icarus/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1475249779716},{"_id":"themes/icarus/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1475249779716},{"_id":"themes/icarus/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1475249779716},{"_id":"themes/icarus/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1475249779716},{"_id":"themes/icarus/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1475249779716},{"_id":"themes/icarus/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1475249779716},{"_id":"themes/icarus/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1475249779716},{"_id":"themes/icarus/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1475249779716},{"_id":"themes/icarus/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1475249779716},{"_id":"themes/icarus/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1475249779720},{"_id":"themes/icarus/.git/logs/HEAD","hash":"787036cb351211783c7e4761b95ee9259d882b72","modified":1475249797787},{"_id":"themes/icarus/_source/about/index.md","hash":"2847759c65295fdc47685cc32e10ae30b2f022ae","modified":1475249797797},{"_id":"themes/icarus/_source/categories/index.md","hash":"55bee2cb88da438a2e8b1f29b1d7e954c07a9e60","modified":1475249797797},{"_id":"themes/icarus/_source/tags/index.md","hash":"e999413d6392c34156b5c6e9273f9069f9e6d92d","modified":1475249797797},{"_id":"themes/icarus/layout/comment/counter.ejs","hash":"e109d3256b004b027d029bd5bd67feeb72dc5388","modified":1475249797797},{"_id":"themes/icarus/layout/comment/disqus.ejs","hash":"1b32a90f400dc580f4b8298de75b94429ca6de68","modified":1475249797797},{"_id":"themes/icarus/layout/comment/duoshuo.ejs","hash":"ce46d7410a99b57704da32e9d09071cef6c9fa93","modified":1475249797797},{"_id":"themes/icarus/layout/comment/index.ejs","hash":"d45635e78a3fc40e424a401e983f2c8eef6ebcfd","modified":1475249797797},{"_id":"themes/icarus/layout/comment/scripts.ejs","hash":"8a9a20f72ba0923afa776396fb67d8c5d446a666","modified":1475249797797},{"_id":"themes/icarus/layout/comment/youyan.ejs","hash":"6fe807992832939caf6c3e7651d052df9520d88e","modified":1475249797800},{"_id":"themes/icarus/layout/common/article.ejs","hash":"9aee307b2387f6762ff6e8226ade2c1c31251132","modified":1475249797800},{"_id":"themes/icarus/layout/common/footer.ejs","hash":"cbfe560fcab445d42ceeb5d1beba5957d5be5eaa","modified":1475249797800},{"_id":"themes/icarus/layout/common/head.ejs","hash":"cad8b2aec0ae4304bddd5c7c0f41f8d6e6dfa691","modified":1475249797800},{"_id":"themes/icarus/layout/common/header.ejs","hash":"738c6a923b2a6de6a81c4892c8a47e03d8b34f88","modified":1475249797800},{"_id":"themes/icarus/layout/common/profile.ejs","hash":"0d5a9622d490652599e3ba3e4077a7d6bb2eb38e","modified":1475249797800},{"_id":"themes/icarus/layout/common/scripts.ejs","hash":"c0a1a9e53f89440c42c325d5bd8c7234652c8937","modified":1475249797800},{"_id":"themes/icarus/layout/common/sidebar.ejs","hash":"6e80fa52d23c9c39bfa357a1e00c26fc8b851b82","modified":1475249797800},{"_id":"themes/icarus/layout/common/thumbnail.ejs","hash":"1b70f8a98cd8650b159bda858dbee38dbdb7f0c5","modified":1475249797800},{"_id":"themes/icarus/layout/common/timeline.ejs","hash":"6420e34e0332c9b6670011519f341340db989343","modified":1475249797800},{"_id":"themes/icarus/layout/plugin/baidu-analytics.ejs","hash":"6a7bee18e666e627e62541a5e30906f87ba1bfe8","modified":1475249797800},{"_id":"themes/icarus/layout/plugin/google-analytics.ejs","hash":"349f08b6521a16e79046b1f94f04317ac74f556e","modified":1475249797800},{"_id":"themes/icarus/layout/plugin/scripts.ejs","hash":"a3c92f1f299e7ba11f2660457d8dcd41acf74640","modified":1475249797800},{"_id":"themes/icarus/layout/search/baidu.ejs","hash":"3e603a702d20c53fd3bcbeb570a16a86d54781ce","modified":1475249797800},{"_id":"themes/icarus/layout/search/index-mobile.ejs","hash":"50a727ac1dfe3073eb6fa6699ba01e66f4ac41c0","modified":1475249797800},{"_id":"themes/icarus/layout/search/index.ejs","hash":"24935e32e61d4706454b174ea3bed0726ae7fb34","modified":1475249797800},{"_id":"themes/icarus/layout/search/insight.ejs","hash":"130fe3d33ac71da0b50f7fee6a87979f30938a1b","modified":1475249797800},{"_id":"themes/icarus/layout/search/swiftype.ejs","hash":"379e66d2c13526e72e4120c443f95fccf4edef71","modified":1475249797800},{"_id":"themes/icarus/layout/share/addtoany.ejs","hash":"ac180c4c84b73a04d61b17e7dc18c257e20bf59f","modified":1475249797800},{"_id":"themes/icarus/layout/share/bdshare.ejs","hash":"a1e772c5a6f174d585b0c1e574058f75dc8e2898","modified":1475249797800},{"_id":"themes/icarus/layout/share/default.ejs","hash":"ebfb919dc525b3ed61a6a5ee05ee71410eedc541","modified":1475249797800},{"_id":"themes/icarus/layout/share/index.ejs","hash":"2a2c0095b95b11e5692bd8ad6a2337aa644189a2","modified":1475249797800},{"_id":"themes/icarus/layout/share/jiathis.ejs","hash":"21ebaa51e828cba2cefbeeaccb01514643565755","modified":1475249797800},{"_id":"themes/icarus/layout/widget/archive.ejs","hash":"d9ebbb7f6ce2f25df5ae25e4a1fef3c08f7054b9","modified":1475249797800},{"_id":"themes/icarus/layout/widget/category.ejs","hash":"583bda80cf15b3ef11fefbd1b502897dfff40100","modified":1475249797803},{"_id":"themes/icarus/layout/widget/links.ejs","hash":"aad118699718b62c0d3f3cfd6f17a181139a76af","modified":1475249797803},{"_id":"themes/icarus/layout/widget/recent_posts.ejs","hash":"2ca923465275fb38a7ac7d67211d6e94a977e957","modified":1475249797803},{"_id":"themes/icarus/layout/widget/tag.ejs","hash":"3b8ae5953990436893da9d68f910ebe592005659","modified":1475249797803},{"_id":"themes/icarus/layout/widget/tagcloud.ejs","hash":"ca8c7bf555fb6ce4904f2c59160548405c2c8a82","modified":1475249797803},{"_id":"themes/icarus/source/css/_extend.styl","hash":"9a5c72663c0da1b32ecb6a75773a5ccfb8c467ca","modified":1475249797803},{"_id":"themes/icarus/source/css/_variables.styl","hash":"d62af931be6612ec8c3a917836379a8cd92fbce1","modified":1475249797810},{"_id":"themes/icarus/source/css/style.styl","hash":"865de42ad496af928252d5bcfa0e0bbb534b0df5","modified":1475249797810},{"_id":"themes/icarus/source/js/insight.js","hash":"6ee84c42c2b230ff9e9bf605a444bd671d44f9e3","modified":1475249797810},{"_id":"themes/icarus/source/js/main.js","hash":"a70daacbd0c0099aae0763b29a7fec20ce222d7a","modified":1475249797810},{"_id":"themes/icarus/.git/objects/pack/pack-b7308fab8d01d38b964bda5e14f5428fc7763456.idx","hash":"d310382e4929ffcb1de10ef0af6ff69badcd8e05","modified":1475249797573},{"_id":"themes/icarus/.git/refs/heads/master","hash":"8e2a78329d7baf8a2144d0c5a43bf0476fdc2c9b","modified":1475249797787},{"_id":"themes/icarus/layout/common/post/banner.ejs","hash":"47ced3f03525698c79c6b1c07b48383fb6c496b2","modified":1475249797800},{"_id":"themes/icarus/layout/common/post/category.ejs","hash":"75c9dda2e7ec041943855ca163a6b1c4c8b4f260","modified":1475249797800},{"_id":"themes/icarus/layout/common/post/date.ejs","hash":"45cb0bcad461036cdd1fe2e3fbb5f2f19940025c","modified":1475249797800},{"_id":"themes/icarus/layout/common/post/gallery.ejs","hash":"659f019761116313169148ec61773e7b84abb739","modified":1475249797800},{"_id":"themes/icarus/layout/common/post/nav.ejs","hash":"d7cd611e642327f33dff3963ef869c2b46824a11","modified":1475249797800},{"_id":"themes/icarus/layout/common/post/tag.ejs","hash":"2e966216256321aa0c76fe1b9be689601c76ef31","modified":1475249797800},{"_id":"themes/icarus/layout/common/post/title.ejs","hash":"669ddb46fefa100856588351a7a2d30ad996b755","modified":1475249797800},{"_id":"themes/icarus/source/css/_partial/archive.styl","hash":"d35088c83ddd7a197d6d94e16a2ce3a7e29fa1dc","modified":1475249797807},{"_id":"themes/icarus/source/css/_partial/article.styl","hash":"5dda40a3767646502722bcf810e289f89f1fd998","modified":1475249797807},{"_id":"themes/icarus/source/css/_partial/comment.styl","hash":"784646796184d4f27918c22395288a2fafbf9554","modified":1475249797807},{"_id":"themes/icarus/source/css/_partial/footer.styl","hash":"484776654e4c1691dc844e6e93786a08855c1c99","modified":1475249797807},{"_id":"themes/icarus/source/css/_partial/header.styl","hash":"1e351f741144135871a3373fe7e969dc961b65e7","modified":1475249797810},{"_id":"themes/icarus/source/css/_partial/insight.styl","hash":"19833cd127f26ad90b06c115f8a96a30e0c0e53b","modified":1475249797810},{"_id":"themes/icarus/source/css/_partial/profile.styl","hash":"fb0170075dc2a41e01dd11bbfdbccbed544c479a","modified":1475249797810},{"_id":"themes/icarus/source/css/_partial/sidebar.styl","hash":"f528ca7064d9fcecd737b9b71c9c54601365d7d3","modified":1475249797810},{"_id":"themes/icarus/source/css/_partial/timeline.styl","hash":"c813b98f4fc45b64d2e07e5d944745a654c8c943","modified":1475249797810},{"_id":"themes/icarus/source/css/_highlight/agate.styl","hash":"601eb70448a16b918df132f6fc41e891ae053653","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/androidstudio.styl","hash":"65d09f1b0e81c6a182f549fd3de51e59823c97ae","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/arduino-light.styl","hash":"15e8572585cd708221c513dea4bdd89d8fe56c10","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/arta.styl","hash":"1a5accc115f41d1b669ed708ac6a29abac876599","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/ascetic.styl","hash":"32cff3bef6fac3760fe78f203096477052a90552","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-cave-dark.styl","hash":"bc647b2c1d971d7cc947aa1ed66e9fd115261921","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-cave-light.styl","hash":"a5be0744a7ecf4a08f600ade4cfd555afc67bc15","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-dune-dark.styl","hash":"df50a85a4b14c7ca6e825d665594b91229d0e460","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-dune-light.styl","hash":"931435fbc6f974e8ce9e32722680035d248a9dc1","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-estuary-dark.styl","hash":"d84382bc8298f96730757391d3e761b7e640f406","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-estuary-light.styl","hash":"344276ca9b27e51d4c907f76afe5d13cf8e60bdf","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-forest-dark.styl","hash":"57c154c6045a038dc7df0a25927853e10bf48c4a","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-forest-light.styl","hash":"95228d9f2102fad425536aac44b80b2cba1f5950","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-heath-dark.styl","hash":"b0cf13b2233e7bc38342032d2d7296591a4c2bcf","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-heath-light.styl","hash":"8c8c2e445abef85273be966d59770e9ced6aac21","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-lakeside-dark.styl","hash":"bb0a8c4ad0dd8e3e7de7122ddf268fc42aa94acb","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-lakeside-light.styl","hash":"2c54cb9bdb259ae3b5b29f63ac2469ed34b08578","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-plateau-dark.styl","hash":"09c64f1a7052aec9070c36c0431df25216afaea1","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-plateau-light.styl","hash":"d1a05fdd1ededc9063d181ab25bad55a164aeb4a","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-savanna-dark.styl","hash":"a16c919a1ccf2f845488078fb341381bec46b1f3","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-savanna-light.styl","hash":"f8244c93711c7cb59dd79d2df966806b30d171ea","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-seaside-dark.styl","hash":"ce233a101daea7124cbfcd34add43ccfe2e1e1c7","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-seaside-light.styl","hash":"0597342da6e2d0c5bdcc7d42dabb07322b1a4177","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-sulphurpool-dark.styl","hash":"414b0cfc142f70afe359c16450b651e28bf7325a","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/atelier-sulphurpool-light.styl","hash":"efa52713efc468abeeb2b9299704371583b857de","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/brown-paper.styl","hash":"c2326ba20a5020a66ca7895258d18833327d4334","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/brown-papersq.png","hash":"3a1332ede3a75a3d24f60b6ed69035b72da5e182","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/codepen-embed.styl","hash":"f4dcc84d8e39f9831a5efe80e51923fc3054feb0","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/color-brewer.styl","hash":"2a439d6214430e2f45dd4939b4dfe1fe1a20aa0f","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/dark.styl","hash":"71ce56d311cc2f3a605f6e2c495ccd7236878404","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/darkula.styl","hash":"ad0d5728d21645039c9f199e7a56814170ed3bab","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/docco.styl","hash":"b1c176378bb275f2e8caa759f36294e42d614bf1","modified":1475249797803},{"_id":"themes/icarus/source/css/_highlight/far.styl","hash":"d9928010ffe71e80b97a5afcba1a4975efdd7372","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/foundation.styl","hash":"bf8ddc94b4ad995b8b8805b5a4cf95004553fdac","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/github-gist.styl","hash":"48211a03d33e7f7ada0b261162bea06676155a71","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/github.styl","hash":"3336aeba324c6d34a6fd41fef9b47bc598f7064c","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/googlecode.styl","hash":"bda816beee7b439814b514e6869dc678822be1bc","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/grayscale.styl","hash":"bf37d8b8d1e602126c51526f0cc28807440228ed","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/highlightjs.styl","hash":"0e198b7a59191c7a39b641a4ddd22c948edb9358","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/hopscotch.styl","hash":"b374c6550b89b4751aedc8fbc3cf98d95bd70ead","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/hybrid.styl","hash":"ea8d7ddc258b073308746385f5cb85aabb8bfb83","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/idea.styl","hash":"a02967cb51c16a34e0ee895d33ded2b823d35b21","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/index.styl","hash":"002d5596f6379cc87dbd43d9145bc764aa666be1","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/ir-black.styl","hash":"693078bbd72a2091ed30f506cc55949600b717af","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/kimbie.dark.styl","hash":"45dbb168f22d739d0109745d2decd66b5f94e786","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/kimbie.light.styl","hash":"61f8baed25be05288c8604d5070afbcd9f183f49","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/magula.styl","hash":"16d323f989b1420a0f72ef989242ece9bf17a456","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/mono-blue.styl","hash":"4c89a6ae29de67c0700585af82a60607e85df928","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/monokai-sublime.styl","hash":"25aa2fc1dbe38593e7c7ebe525438a39574d9935","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/monokai.styl","hash":"5a4fe9f957fd7a368c21b62a818403db4270452f","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/obsidian.styl","hash":"55572bbcfee1de6c31ac54681bb00336f5ae826d","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/paraiso-dark.styl","hash":"f1537bd868579fa018ecdbfd2eb922dcf3ba2cac","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/paraiso-light.styl","hash":"d224d1df0eb3395d9eea1344cee945c228af2911","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/pojoaque.jpg","hash":"c5fe6533b88b21f8d90d3d03954c6b29baa67791","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/pojoaque.styl","hash":"77dae9dc41945359d17fe84dbd317f1b40b2ee33","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/railscasts.styl","hash":"acd620f8bb7ff0e3fe5f9a22b4433ceef93a05e6","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/rainbow.styl","hash":"ce73b858fc0aba0e57ef9fb136c083082746bc1d","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/school-book.png","hash":"711ec983c874e093bb89eb77afcbdf6741fa61ee","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/school-book.styl","hash":"d43560fe519a931ce6da7d57416d7aa148441b83","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/solarized-dark.styl","hash":"702b9299a48c90124e3ac1d45f1591042f2beccc","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/solarized-light.styl","hash":"aa0dd3fd25c464183b59c5575c9bee8756b397f2","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/sunburst.styl","hash":"a0b5b5129547a23865d400cfa562ea0ac1ee3958","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/tomorrow-night-blue.styl","hash":"8b3087d4422be6eb800935a22eb11e035341c4ba","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/tomorrow-night-bright.styl","hash":"0ac6af6ecb446b5b60d6226748e4a6532db34f57","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/tomorrow-night-eighties.styl","hash":"fa57b3bb7857a160fc856dbe319b31e30cc5d771","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/tomorrow-night.styl","hash":"19b3080d4b066b40d50d7e7f297472482b5801fd","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/tomorrow.styl","hash":"15779cf6846725c7c35fc56cac39047d7e0aec1c","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/vs.styl","hash":"959a746f4b37aacb5d1d6ff1d57e0c045289d75d","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/xcode.styl","hash":"5e8532ae8366dcf6a4ef5e4813dc3d42ab3d0a50","modified":1475249797807},{"_id":"themes/icarus/source/css/_highlight/zenburn.styl","hash":"fc5ec840435dad80964d04519d3f882ddc03746a","modified":1475249797807},{"_id":"themes/icarus/source/css/_util/grid.styl","hash":"93fb6f1e2f40cd7d88ad0d56dd73d3f9a7bc853e","modified":1475249797810},{"_id":"themes/icarus/source/css/_util/mixin.styl","hash":"c8e1ddfc0fe9108bab592c7a73b73ce9344991fd","modified":1475249797810},{"_id":"themes/icarus/source/css/images/avatar.png","hash":"0d8236dcca871735500e9d06bbdbe0853ed6775b","modified":1475249797810},{"_id":"themes/icarus/source/css/images/logo.png","hash":"126af1efa8ce41cd6dd11cac345faa824b05f7e7","modified":1475250980579},{"_id":"themes/icarus/source/css/images/logo2.png","hash":"e606a0584f98268b2fe92303f3254520862ef659","modified":1475249797810},{"_id":"themes/icarus/source/css/images/thumb-default-small.png","hash":"e8403b97ed9251f9f5207765b0ce796c5000b4ba","modified":1475249797810},{"_id":"themes/icarus/source/vendor/justified-gallery/jquery.justifiedGallery.min.js","hash":"b2683e7a872bc109b1756a65188a37cef7d0bd5c","modified":1475249797827},{"_id":"themes/icarus/source/vendor/justified-gallery/justifiedGallery.min.css","hash":"13fbcba5e97aa88b748d94d3efc4718475279907","modified":1475249797827},{"_id":"themes/icarus/source/vendor/open-sans/styles.css","hash":"5ca6e111046232bde112d33201a60532aee7d3c4","modified":1475249797837},{"_id":"themes/icarus/source/vendor/source-code-pro/styles.css","hash":"93c308012738728f906cd4c5cfdb34189e0c712b","modified":1475249797837},{"_id":"themes/icarus/.git/logs/refs/heads/master","hash":"787036cb351211783c7e4761b95ee9259d882b72","modified":1475249797787},{"_id":"themes/icarus/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1475249797787},{"_id":"themes/icarus/source/vendor/font-awesome/css/font-awesome.css","hash":"b5020c3860669185ba3f316fa7332cdf5c06f393","modified":1475249797810},{"_id":"themes/icarus/source/vendor/font-awesome/css/font-awesome.min.css","hash":"7cd5a3384333f95c3d37d9488ad82cd6c4b03761","modified":1475249797810},{"_id":"themes/icarus/source/vendor/lightgallery/css/lg-fb-comment-box.css","hash":"844ce27b8488968bccb3e50bb49184ba2aae0625","modified":1475249797827},{"_id":"themes/icarus/source/vendor/lightgallery/css/lg-fb-comment-box.css.map","hash":"51e9df39edf0faa3f38c1bab0c1fa6c922b9edcb","modified":1475249797827},{"_id":"themes/icarus/source/vendor/lightgallery/css/lg-fb-comment-box.min.css","hash":"05830fadb8454f39dcc98c8686eb4d5c24b71fc0","modified":1475249797827},{"_id":"themes/icarus/source/vendor/lightgallery/css/lg-transitions.css","hash":"7871c28498d74451d6aa438c8d3a1817810a1e19","modified":1475249797827},{"_id":"themes/icarus/source/vendor/lightgallery/css/lg-transitions.css.map","hash":"50c3348638b4d82fa08a449c690e8d2bb593005d","modified":1475249797827},{"_id":"themes/icarus/source/vendor/lightgallery/css/lg-transitions.min.css","hash":"5c22e2073a4c96d6212c72135391b599e8d1359f","modified":1475249797827},{"_id":"themes/icarus/source/vendor/lightgallery/css/lightgallery.css","hash":"bef55316a32e512d5a8940e5d0bfe8bf7a9c5c61","modified":1475249797827},{"_id":"themes/icarus/source/vendor/lightgallery/css/lightgallery.css.map","hash":"3175b4107078674d25798979f7666f4daf31e624","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/css/lightgallery.min.css","hash":"c9a2e19c932b56f4a2ce30c98910d10b74edb38a","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/fonts/lg.svg","hash":"9a732790adc004b22022cc60fd5f77ec4c8e3e5a","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/img/loading.gif","hash":"607810444094b8619fa4efa6273bc2a7e38dd4b4","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/img/video-play.png","hash":"3ea484cdc04d2e4547f80cbf80001dcf248c94ef","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/img/vimeo-play.png","hash":"6190254f2804904a4a1fa1eb390dfd334e416992","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/img/youtube-play.png","hash":"fea6df9d9d43151f9c9d15f000adb30eb3e26fc4","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-autoplay.js","hash":"426bb78b93acfc39d533ea2bab1cec8dc289cf24","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-autoplay.min.js","hash":"d845741bcaf961579622880eb2a445257efad1ac","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-fullscreen.js","hash":"65c47ac65362854ba44b00a010bb01e3630209d8","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-fullscreen.min.js","hash":"b6b9e4022700b7faf2a5a175ba44a3bd938fdd20","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-hash.js","hash":"15d16516c5642d3de1566ff8fc9160136ccaa405","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-hash.min.js","hash":"43f1e1e720ab0e241c19b83aa26bd6848eab8edc","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-pager.js","hash":"8092c692b244bb26343eb03b91bd97deb9dafc9c","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-pager.min.js","hash":"25caa6ff65b1c6dee09941e795ae2633bdbab211","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-share.js","hash":"b7fb5f6474911060a351b0a6fe9dbb9ac3fb22aa","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-share.min.js","hash":"39c615f07c5d3aaa65a2c3068a30fdd6dd5c372d","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-thumbnail.js","hash":"3a6476b6df1d2bef4a21861a78776282a7a11ef1","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-thumbnail.min.js","hash":"18dd7d2909d1bfd6852f031d03e774b4428c512b","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-video.js","hash":"4f99b598f6bb18de9eca8c45c5b4373a03962367","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-video.min.js","hash":"032c001ab045a69856f9c3ed4a2a3bf12a8e310f","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-zoom.js","hash":"a758e2c8fcf710f9ff761da0eea0ab9321f3484d","modified":1475249797830},{"_id":"themes/icarus/source/vendor/lightgallery/js/lightgallery.js","hash":"3cd19b33ba99efd5ba1d167da91720566d274b2c","modified":1475249797833},{"_id":"themes/icarus/source/vendor/lightgallery/js/lightgallery.min.js","hash":"956ef9b706755318da69ad0b5d7786339d831251","modified":1475249797833},{"_id":"themes/icarus/source/vendor/lightgallery/js/lg-zoom.min.js","hash":"15b49f9728439819ece15e4295cce254c87a4f45","modified":1475249797830},{"_id":"themes/icarus/source/vendor/open-sans/fonts/59ZRklaO5bWGqF5A9baEERJtnKITppOI_IvcXXDNrsc.woff2","hash":"c4248ea800bd5608344ce163f5658b57e7ef9410","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/K88pR3goAWT7BTt32Z01mxJtnKITppOI_IvcXXDNrsc.woff2","hash":"e0350190d720a8fec0557ab47b318ec4e4486448","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/LWCjsQkB6EMdfHrEVqA1KRJtnKITppOI_IvcXXDNrsc.woff2","hash":"2c5b039b57f62625e88226a938679ec937431ad1","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNShWV49_lSm1NYrwo-zkhivY.woff2","hash":"22413bb8bfb78608c1e25aa1ed5c1f38557df79f","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSj0LW-43aMEzIO6XUTLjad8.woff2","hash":"63eb74ef040aade256f2274a7f31a914edddb0ea","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSpX5f-9o1vgP2EXwfjgl7AY.woff2","hash":"328a22fe3eec71ad9e5ece4d67dd62e79dab6b7f","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSq-j2U0lmluP9RWlSytm3ho.woff2","hash":"4dc6d7174ea6d89f4c45e43e1bfc3e03d8ffebaf","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSqaRobkAwv3vxw3jMhVENGA.woff2","hash":"415eee05976ab8b2471602a5ddb78a6c58fc21aa","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSugdm0LZdjqr5-oayXSOefg.woff2","hash":"a0b0c389cf46d63c850e61fed572485ff0b68183","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSv8zf_FOSsgRmwsS7Aa9k2w.woff2","hash":"c5f29fed6632efe0aa83318369f0d8c4061b775b","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/RjgO7rYTmqiVp7vzi-Q5URJtnKITppOI_IvcXXDNrsc.woff2","hash":"be201d32a9aa5d186723ebb3c538be691aa8c53a","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/cJZKeOuBrn4kERxqtaUH3VtXRa8TVwTICgirnJhmVJw.woff2","hash":"afc44700053c9a28f9ab26f6aec4862ac1d0795d","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/u-WUoqrET9fUeobQW7jkRRJtnKITppOI_IvcXXDNrsc.woff2","hash":"113978181dcac77baecef6115a9121d8f6e4fc3a","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBiYE0-AqJ3nfInTTiDXDjU4.woff2","hash":"5067c81462c15422853c94d21a1726865a61634f","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBjTOQ_MqJVwkKsUn0wKzc2I.woff2","hash":"b366f2fda2e524eb5ef50058eefff249a3b96e6c","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBjUj_cnvWIuuBMVgbX098Mw.woff2","hash":"d22904914469be735490e3c8cb093c7862896dd5","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBkbcKLIaa1LC45dFaAfauRA.woff2","hash":"ae80fb3cd16339aa7b5da280ab53975523dcaac2","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBmo_sUJ8uO4YLWRInS22T3Y.woff2","hash":"b85efde42fa3a03c32b1d31c6cd74c622fc7916c","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBo4P5ICox8Kq3LLUNMylGO4.woff2","hash":"e75607ba1417181397c700775b84303d5a2957b9","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xjAJXh38I15wypJXxuGMBr6up8jxqWt8HVA3mDhkV_0.woff2","hash":"d0b40a7848703556c6631f24e961a98ca5829255","modified":1475249797833},{"_id":"themes/icarus/source/vendor/open-sans/fonts/xozscpT2726on7jbcb_pAhJtnKITppOI_IvcXXDNrsc.woff2","hash":"be365eca44760ce3fc9b377c43d4634958479c69","modified":1475249797837},{"_id":"themes/icarus/source/vendor/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasD9V_2ngZ8dMf8fLgjYEouxg.woff2","hash":"942addaec4d3a60af33947a84a3d85f926015947","modified":1475249797837},{"_id":"themes/icarus/source/vendor/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasDy2Q8seG17bfDXYR_jUsrzg.woff2","hash":"b0e0bb5ef78db8b15d430d0b9be9d4329289a310","modified":1475249797837},{"_id":"themes/icarus/source/vendor/font-awesome/fonts/FontAwesome.otf","hash":"1b22f17fdc38070de50e6d1ab3a32da71aa2d819","modified":1475249797813},{"_id":"themes/icarus/source/vendor/font-awesome/fonts/fontawesome-webfont.eot","hash":"965ce8f688fedbeed504efd498bc9c1622d12362","modified":1475249797813},{"_id":"themes/icarus/source/vendor/font-awesome/fonts/fontawesome-webfont.woff","hash":"6d7e6a5fc802b13694d8820fc0138037c0977d2e","modified":1475249797823},{"_id":"themes/icarus/source/vendor/font-awesome/fonts/fontawesome-webfont.woff2","hash":"97e438cc545714309882fbceadbf344fcaddcec5","modified":1475249797823},{"_id":"themes/icarus/source/vendor/jquery/2.1.3/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1475249797827},{"_id":"themes/icarus/.git/logs/refs/remotes/origin/HEAD","hash":"787036cb351211783c7e4761b95ee9259d882b72","modified":1475249797787},{"_id":"themes/icarus/source/vendor/font-awesome/fonts/fontawesome-webfont.ttf","hash":"61d8d967807ef12598d81582fa95b9f600c3ee01","modified":1475249797823},{"_id":"themes/icarus/source/vendor/font-awesome/fonts/fontawesome-webfont.svg","hash":"c0522272bbaef2acb3d341912754d6ea2d0ecfc0","modified":1475249797820},{"_id":"themes/icarus/.git/objects/pack/pack-b7308fab8d01d38b964bda5e14f5428fc7763456.pack","hash":"14d7042e992eb7866f99fc36f993959de6b69b40","modified":1475249797573},{"_id":"themes/icarus/source/about/index.md","hash":"2847759c65295fdc47685cc32e10ae30b2f022ae","modified":1475249797797},{"_id":"themes/icarus/source/categories/index.md","hash":"55bee2cb88da438a2e8b1f29b1d7e954c07a9e60","modified":1475249797797},{"_id":"themes/icarus/source/tags/index.md","hash":"e999413d6392c34156b5c6e9273f9069f9e6d92d","modified":1475249797797},{"_id":"source/_posts/1970-01-01-creating-customized-images.md","hash":"75751186cfa3fe8765ebeb9ce39be635c1dd8b79","modified":1475252511722},{"_id":"source/_posts/1970-01-01-solving-keyboard-interrrupt-error-in-centos7-0.md","hash":"d60485e605cea7805671a4107782db5430b9bb73","modified":1474996420000},{"_id":"source/_posts/2015-03-03-megam_install_ruby.md","hash":"0ce7905b441739e98ce37074e3fcb1795cf799e5","modified":1474996420000},{"_id":"source/_posts/2015-03-12-git-for-newbies.md","hash":"0933e4a7c7d435f3cdc12ad9752d3e32295aeae2","modified":1474996420000},{"_id":"source/_posts/2015-03-13-chef-setup.md","hash":"510d3db26fb446d25730975430121ac2c49251a7","modified":1474996426000},{"_id":"source/_posts/2015-03-13-how-to-use-oauth-in-ror.md","hash":"9ce1532b1b7629cb647e709c4bae313a16335ea9","modified":1474996448000},{"_id":"source/_posts/2015-03-13-setting-up-golang.md","hash":"34d46df99a9345a5e5971b0571f336135759a865","modified":1474996438000},{"_id":"source/_posts/2015-03-14-how-to-contribute-to-a-git-repository.md","hash":"a7a54f59af046dd3ad786e04cee70e6fdac63af6","modified":1474996440000},{"_id":"source/_posts/2015-03-16-setting-up-scala-sbt-play-akka.md","hash":"36a7a2d9851e921dd6e8d90328100f3d8b3383b0","modified":1474996448000},{"_id":"source/_posts/2015-03-18-rest_api_playframework.md","hash":"69e1eeccb308fcc75d12f4ee16382b3ccb092ca9","modified":1474996452000},{"_id":"source/_posts/2015-03-26-haddop_spark_multinode_setup.md","hash":"ca7cefc29e64680d3fb7a034f683eb043fb23a49","modified":1474996440000},{"_id":"source/_posts/2015-03-27-ceph-in-a-single-node.md","hash":"993b70c893ced7b875dbfcd4c12a412aefe5403d","modified":1474996434000},{"_id":"source/_posts/2015-03-27-concurrency-in-go.md","hash":"9bb485756d925d54fbac7a30752433bd3ff3b69b","modified":1474996448000},{"_id":"source/_posts/2015-03-27-playing-with-configuration-in-gotsuru.md","hash":"bc889f809d460819ee076ccd5423678ad2136914","modified":1474996448000},{"_id":"source/_posts/2015-05-25-docker-introduction.md","hash":"fdc6e8d0db1c6b12cf6845f83bdd7e1428924f2e","modified":1474996444000},{"_id":"source/_posts/2015-05-25-rust.md","hash":"2264b6687717a81c2f3da32f10af6ec346b83aa6","modified":1474996420000},{"_id":"source/_posts/2015-07-08-design-technique-for-building-an-api-using-scalaz.md","hash":"0777c5f03aa540bdce0854efe12c479f952e55ef","modified":1474996434000},{"_id":"source/_posts/2015-08-26-docker-swarm.md","hash":"ed7d5a5825709b4e83efe6772565e73cfd288c60","modified":1474996434000},{"_id":"source/_posts/2015-08-27-rabbitmq-cluster.md","hash":"d5eec7b64171dcbb819384db8c91db3d9a7f95f1","modified":1474996440000},{"_id":"source/_posts/2015-08-27-riak-cluster.md","hash":"5d44c54ba2c44d6af544cc8767203657b0355c72","modified":1474996426000},{"_id":"source/_posts/2015-09-08-mysql-master-slave-replication.md","hash":"63963121458a2834ebd9b8b21b6cf5fd4c780c0e","modified":1474996448000},{"_id":"source/_posts/2015-09-10-codebox-installation-procedure.md","hash":"bfe095e76ce2cfbc645c02643b881b1c9eb7f038","modified":1474996448000},{"_id":"source/_posts/2015-09-16-localization-of-nilavu.md","hash":"d358534f7dde2aae05d184c9d9f7b25b870a1876","modified":1474996440000},{"_id":"source/_posts/2015-09-30-ch.md","hash":"6b6512b28b67bd3c127999a52d6239ca02f0e78a","modified":1474996444000},{"_id":"source/_posts/2015-10-13-ceph-gateway.md","hash":"6d9eddd4f628922e33a5c86f14729fb26f07947c","modified":1474996426000},{"_id":"source/_posts/2015-11-27-datacenter-using-opennebula-federation.md","hash":"3e31e8934dba9fc30de43976311044aeb4786411","modified":1474996444000},{"_id":"source/_posts/2015-12-08-gradle-for-scala.md","hash":"bf4be3b482ffd517ea91b4d991ed9ca8aaa9d6e3","modified":1474996452000},{"_id":"source/_posts/2015-12-08-how-to-build-a-gem.md","hash":"5e838afa8a4a28fe0610f10418cfa0e4dab73b46","modified":1474996432000},{"_id":"source/_posts/2015-12-15-hetzner-networking-in-ubuntu-host.md","hash":"41f3cc0704ef3d4e6482f3a4202cc80df802055d","modified":1474996440000},{"_id":"source/_posts/2015-12-26-nsqd-messaging-server.md","hash":"37e6e2948d5de5976044628614d5694241bdc3ad","modified":1474996452000},{"_id":"source/_posts/2016-02-02-getting-started-with-spark-jobserver.md","hash":"7cbd5c90b36bc0c048e9488b9b39916c6bab7b3b","modified":1474996448000},{"_id":"source/_posts/2016-02-05-build-and-release-management-for-gogodep.md","hash":"b5aa913cb0cda9bc2e3ff57d87c5ecc7d48fea0f","modified":1474996444000},{"_id":"source/_posts/2016-02-05-getting-more-native-welcome-scylladb.md","hash":"0d23df121e46966e1b422e99132a349f638a193a","modified":1474996434000},{"_id":"source/_posts/2016-02-06-chef-vs-urknall.md","hash":"05b76c71e244de71996ab53d6c5bddd7d47e416b","modified":1474996444000},{"_id":"source/_posts/2016-02-06-package-upgrade-from-trusty-to-jessie.md","hash":"76b24e3a8cee95e103517ec7ba5911e6043ac2b2","modified":1474996448000},{"_id":"source/_posts/2016-02-08-spark-notebook-for-developer.md","hash":"d592262708e188989e15ec3e5a54ca9ffff1b470","modified":1474996426000},{"_id":"source/_posts/2016-03-01-packet-net-networking-for-opennebula-host.md","hash":"108e5fe1a6b91dfcf654bd0b4699c0b1eedaf3b1","modified":1474996440000},{"_id":"source/_posts/2016-05-09-how-to-launch-centos.md","hash":"d7a6b47fd5f5d3a0238deda676f3d50e35a57de1","modified":1474996426000},{"_id":"source/_posts/2016-05-09-how-to-launch-debian-jessie.md","hash":"1d6fb0523622cc69c253d0bae13bd0285d867f9e","modified":1474996426000},{"_id":"source/_posts/2016-05-09-how-to-launch-spring-webflow.md","hash":"20d9e1d51180ef9f85b5927c3de65404058cf785","modified":1474996420000},{"_id":"source/_posts/2016-05-09-launch-ubuntu.md","hash":"a3747ede2b276230dab9232c5c5cd0dba7c52daa","modified":1474996420000},{"_id":"source/_posts/2016-05-09-launching-jenkins.md","hash":"f32a25a3b4ff43409eae67ba4f0f672a366d131b","modified":1474996434000},{"_id":"source/_posts/2016-05-10-how-to-launch-postageapp-in-php.md","hash":"84e6ed9afee0aa4da4ef80e47b2497f617c2ca44","modified":1474996446000},{"_id":"source/_posts/2016-05-10-how-to-launch-sdk-using-cc-python.md","hash":"ec16505a45e69782ff2134ea2f0e2b1360a829c9","modified":1474996452000},{"_id":"source/_posts/2016-05-11-how-to-launch-etherpad-lite.md","hash":"a2ca05cf40e1befe87f806c61d90246c42f49085","modified":1474996444000},{"_id":"source/_posts/2016-05-11-how-to-launch-mysql.md","hash":"d06611c80a142f9e3d0b3e1b7b3061c1fd8135b7","modified":1474996426000},{"_id":"source/_posts/2016-05-11-how-to-launch-opsworks-php-simple-demo-app.md","hash":"9763d2e7d7300a233a02f99eecbb386d5274e421","modified":1474996448000},{"_id":"source/_posts/2016-05-11-how-to-launch-redis.md","hash":"b9e6a2f535f328b522a7eeb8d66b9e58d63ab832","modified":1474996452000},{"_id":"source/_posts/2016-05-11-how-to-launch-travis-web.md","hash":"f8bbfb3b7b62ef513a9f98293695dd432785d8c5","modified":1474996434000},{"_id":"source/_posts/2016-05-11-open-web-analytics-installer.md","hash":"15416f1f7754861040142f55a03fc10b697962d7","modified":1474996444000},{"_id":"source/_posts/2016-05-26-how-to-launch-wordpress.md","hash":"98f64fafb716ebe57fe01478c108364ba9ecc719","modified":1474996456000},{"_id":"source/_posts/2016-05-27-how-to-install-docker-container.md","hash":"2d488cd10c87e4c520c33828420c73478af94ffc","modified":1474996444000},{"_id":"source/_posts/2016-05-27-how-to-launch-dockercontainer-in-megamafrica.md","hash":"c11043fde5cee199ac6d2d7e9a2293f52b7e9337","modified":1474996440000},{"_id":"source/_posts/2016-05-27-how-to-launch-ubuntu.md","hash":"0f7f90eac47cb71681a773ec2587717e34185875","modified":1474996420000},{"_id":"source/_posts/2016-05-27-how-to-launch.md","hash":"690208b5e828f7862acd1f8f4c935912b023ad58","modified":1474996434000},{"_id":"source/_posts/2016-06-02-ceph-object-gateway-using-jewel.md","hash":"8dd9f84bcbe58a1da4e372d22d578ec57e0ffe22","modified":1474996444000},{"_id":"source/_posts/2016-06-10-private-registry-along-with-ceph.md","hash":"b191c27784a5f5f8c3111d9c9dc38926302f3e33","modified":1474996420000},{"_id":"source/_posts/2016-06-16-atharva-ceph-windows.md","hash":"df5692cdd94e6b46ac783f28223d494ed83441d4","modified":1474996444000},{"_id":"source/_posts/2016-06-17-getting-started-atharva-storage-in-megamafrica.md","hash":"7325949325c4e15c00ecdc40c6cc71e920fdf438","modified":1474996426000},{"_id":"source/_posts/2016-06-27-cloud-backup-megamafrica.md","hash":"f6b3a5aa2d907a68fac9c73f3577f3d3ea02b20d","modified":1474996452000},{"_id":"source/_posts/2016-06-30-secure-docker-container-using-kvm.md","hash":"bc94b691b855408be35a7bd26e7b46365f4e6326","modified":1474996434000},{"_id":"source/_posts/2016-07-14-how-to-create-a-cassandra-replication.md","hash":"409936220a6a6dc43600be2ed7377269a6a42d15","modified":1474996440000},{"_id":"source/_posts/page-index.md","hash":"27ccc69e8520bb4014c4d2c7368bc43d39c22991","modified":1474996424000}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"Building your own VM Image (Dockerfile for VMs)","slug":"1970-01-01-creating-customized-images","date_published":"1969-12-31T18:30:00.000Z","date_updated":"2016-06-30T23:43:42.859Z","draft":true,"_content":"\n##Introduction\n  \n   Lets the system have installed centos operating system.In my purpose, when preparing an OpenNebula installation is the creation of Virtual Machine images for base Operating Systems or appliances.\n   \n   Some of these images can be downloaded from the marketplace but you may need an OS that is not in the marketplace or the images must be customized in some other way. \n   \n   Now i am going to describe an automated way to customize the base images.It provided by linux distribution using software tool libguestfs.\n\n####Libguestfs\n  This tool can be used to create and modify the virtual machine images in number of format that qemu understands.Some of these utilities let us add or delete files inside the images or execute scripts using the image filesystem as root.\n    \n  To install libguestfs,\n  \n       \n       yum install libguestfs-tools\n   \n#####Base image\n\n Next step download the base Isoimage like ubuntu \n \n   wget http://cloud-images.ubuntu.com/releases/14.04/release/ubuntu-14.04-server-cloudimg-amd64-disk1.img\n\n\n####Install Onecontext\n  One of the customizations we have to do to this image is uninstall the cloud-init package that comes by default with that image and install OpenNebula context package. \n  \n    wget https://github.com/OpenNebula/addon-context-linux/releases/download/v4.14.4/one-context_4.14.4.rpm\n    \n    \n  To create the CDROM image we can use genisoimage. Remember to add a label so its easier to mount. Here we are going to use the label PACKAGES:\n\ni) Copy the onecontext packages to a directory, for example packages \n\nii) Execute genisoimage to create the iso that contains those files:\n\n    $ genisoimage -o packages.iso -R -J -V PACKAGES packages/\n    \n    \n  Now we need to prepare a script with the customizations to be done in the image. For example:\n  \n    \n    \n    \n    mount LABEL=PACKAGES /mnt\n\n    # Install opennebula context package\n     apt-get install -y unzip\n     unzip /mnt/v4.14.4*zip\n     \n    # Install growpart and upgrade util-linux, used for filesystem resizing\n    apt-get install -y epel-release --nogpgcheck\n    apt-get install -y cloud-utils-growpart --nogpgcheck\n    apt-get upgrade -y util-linux --nogpgcheck\n    \n    #nginx install\n     apt-get -y update\n    apt-get install -y nginx\n    ceph_user=\"megam\"\n    ceph_password=\"1234pass\"\n    ceph_group=\"megam\"\n    user_home=\"/home/megam\"\n    if ! getent group $ceph_group > /dev/null 2>&1;  then\n    groupadd --system $ceph_group\n    fi\n    if ! getent passwd $ceph_user > /dev/null 2>&1; then\n    useradd -d $user_home -m -g $ceph_group $ceph_user -s /bin/bash\n        #Set passwordsudo echo -e \"$ceph_password\\n$ceph_password\\n\" | sudo passwd $ceph_user\n    else\n       user_home=`getent passwd $ceph_user | cut -f6 -d:`\n\n    # Renable user (give him a shell)\n    usermod --shell /bin/bash $ceph_user\n    # Make sure MEGAMHOME exists, might have been removed on previous purge\n    mkdir -p $user_home\n    fi\n\n\nInstead of modifying the original image downloaded we can use a feature of qcow2 image that is creating a new image that is based on another one.\n \n To copy the image from original image\n \n    $ qemu-img create -f qcow2 -b ubuntu-14.04-server-cloudimg-amd64-disk1.img ubuntu.qcow2\n    \n  Now all is prepared to customize the image. The command we are going to use is virt-customize.\n  \n  It can do a lot of modifications to the image but we are only going to do two. The command is this one:  \n  \n    virt-customize -v -x --attach packages.iso --format qcow2 -a ubuntu.qcow2 --run script.sh --root-password password:centos\n    \n   It attaches two images, the iso image with the packages and the OS hard disk, executes script.sh\n   \n   After the command is run the image centos.qcow2 contains the modifications we did to the original image. \n   \n   Now we can convert it to any other format we need (for example vmdk) or to a full qcow2 image, that it, does not depend on any other one. \n   \n     qemu-img convert -f qcow2 -O qcow2 -o compat=0.10 ubuntu.qcow2 ubuntu-final.qcow2\n     \n    qemu-img convert -f qcow2 -O vmdk ubuntu.qcow2 ubuntu-final.vmdk\n    \n \n","source":"_posts/1970-01-01-creating-customized-images.md","raw":"---\ntitle: Building your own VM Image (Dockerfile for VMs)\nslug: creating-customized-images\ndate_published: 1970-01-01T00:00:00.000Z\ndate_updated:   2016-07-01T05:13:42.859Z\ndraft: true\n---\n\n##Introduction\n  \n   Lets the system have installed centos operating system.In my purpose, when preparing an OpenNebula installation is the creation of Virtual Machine images for base Operating Systems or appliances.\n   \n   Some of these images can be downloaded from the marketplace but you may need an OS that is not in the marketplace or the images must be customized in some other way. \n   \n   Now i am going to describe an automated way to customize the base images.It provided by linux distribution using software tool libguestfs.\n\n####Libguestfs\n  This tool can be used to create and modify the virtual machine images in number of format that qemu understands.Some of these utilities let us add or delete files inside the images or execute scripts using the image filesystem as root.\n    \n  To install libguestfs,\n  \n       \n       yum install libguestfs-tools\n   \n#####Base image\n\n Next step download the base Isoimage like ubuntu \n \n   wget http://cloud-images.ubuntu.com/releases/14.04/release/ubuntu-14.04-server-cloudimg-amd64-disk1.img\n\n\n####Install Onecontext\n  One of the customizations we have to do to this image is uninstall the cloud-init package that comes by default with that image and install OpenNebula context package. \n  \n    wget https://github.com/OpenNebula/addon-context-linux/releases/download/v4.14.4/one-context_4.14.4.rpm\n    \n    \n  To create the CDROM image we can use genisoimage. Remember to add a label so its easier to mount. Here we are going to use the label PACKAGES:\n\ni) Copy the onecontext packages to a directory, for example packages \n\nii) Execute genisoimage to create the iso that contains those files:\n\n    $ genisoimage -o packages.iso -R -J -V PACKAGES packages/\n    \n    \n  Now we need to prepare a script with the customizations to be done in the image. For example:\n  \n    \n    \n    \n    mount LABEL=PACKAGES /mnt\n\n    # Install opennebula context package\n     apt-get install -y unzip\n     unzip /mnt/v4.14.4*zip\n     \n    # Install growpart and upgrade util-linux, used for filesystem resizing\n    apt-get install -y epel-release --nogpgcheck\n    apt-get install -y cloud-utils-growpart --nogpgcheck\n    apt-get upgrade -y util-linux --nogpgcheck\n    \n    #nginx install\n     apt-get -y update\n    apt-get install -y nginx\n    ceph_user=\"megam\"\n    ceph_password=\"1234pass\"\n    ceph_group=\"megam\"\n    user_home=\"/home/megam\"\n    if ! getent group $ceph_group > /dev/null 2>&1;  then\n    groupadd --system $ceph_group\n    fi\n    if ! getent passwd $ceph_user > /dev/null 2>&1; then\n    useradd -d $user_home -m -g $ceph_group $ceph_user -s /bin/bash\n        #Set passwordsudo echo -e \"$ceph_password\\n$ceph_password\\n\" | sudo passwd $ceph_user\n    else\n       user_home=`getent passwd $ceph_user | cut -f6 -d:`\n\n    # Renable user (give him a shell)\n    usermod --shell /bin/bash $ceph_user\n    # Make sure MEGAMHOME exists, might have been removed on previous purge\n    mkdir -p $user_home\n    fi\n\n\nInstead of modifying the original image downloaded we can use a feature of qcow2 image that is creating a new image that is based on another one.\n \n To copy the image from original image\n \n    $ qemu-img create -f qcow2 -b ubuntu-14.04-server-cloudimg-amd64-disk1.img ubuntu.qcow2\n    \n  Now all is prepared to customize the image. The command we are going to use is virt-customize.\n  \n  It can do a lot of modifications to the image but we are only going to do two. The command is this one:  \n  \n    virt-customize -v -x --attach packages.iso --format qcow2 -a ubuntu.qcow2 --run script.sh --root-password password:centos\n    \n   It attaches two images, the iso image with the packages and the OS hard disk, executes script.sh\n   \n   After the command is run the image centos.qcow2 contains the modifications we did to the original image. \n   \n   Now we can convert it to any other format we need (for example vmdk) or to a full qcow2 image, that it, does not depend on any other one. \n   \n     qemu-img convert -f qcow2 -O qcow2 -o compat=0.10 ubuntu.qcow2 ubuntu-final.qcow2\n     \n    qemu-img convert -f qcow2 -O vmdk ubuntu.qcow2 ubuntu-final.vmdk\n    \n \n","published":1,"date":"2016-09-30T16:21:51.822Z","updated":"2016-09-30T16:21:51.722Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaiqj0000drgbhhdayx3l","content":"<p>##Introduction</p>\n<p>   Lets the system have installed centos operating system.In my purpose, when preparing an OpenNebula installation is the creation of Virtual Machine images for base Operating Systems or appliances.</p>\n<p>   Some of these images can be downloaded from the marketplace but you may need an OS that is not in the marketplace or the images must be customized in some other way. </p>\n<p>   Now i am going to describe an automated way to customize the base images.It provided by linux distribution using software tool libguestfs.</p>\n<p>####Libguestfs<br>  This tool can be used to create and modify the virtual machine images in number of format that qemu understands.Some of these utilities let us add or delete files inside the images or execute scripts using the image filesystem as root.</p>\n<p>  To install libguestfs,</p>\n<pre><code>yum install libguestfs-tools\n</code></pre><p>#####Base image</p>\n<p> Next step download the base Isoimage like ubuntu </p>\n<p>   wget <a href=\"http://cloud-images.ubuntu.com/releases/14.04/release/ubuntu-14.04-server-cloudimg-amd64-disk1.img\" target=\"_blank\" rel=\"external\">http://cloud-images.ubuntu.com/releases/14.04/release/ubuntu-14.04-server-cloudimg-amd64-disk1.img</a></p>\n<p>####Install Onecontext<br>  One of the customizations we have to do to this image is uninstall the cloud-init package that comes by default with that image and install OpenNebula context package. </p>\n<pre><code>wget https://github.com/OpenNebula/addon-context-linux/releases/download/v4.14.4/one-context_4.14.4.rpm\n</code></pre><p>  To create the CDROM image we can use genisoimage. Remember to add a label so its easier to mount. Here we are going to use the label PACKAGES:</p>\n<p>i) Copy the onecontext packages to a directory, for example packages </p>\n<p>ii) Execute genisoimage to create the iso that contains those files:</p>\n<pre><code>$ genisoimage -o packages.iso -R -J -V PACKAGES packages/\n</code></pre><p>  Now we need to prepare a script with the customizations to be done in the image. For example:</p>\n<pre><code>mount LABEL=PACKAGES /mnt\n\n# Install opennebula context package\n apt-get install -y unzip\n unzip /mnt/v4.14.4*zip\n\n# Install growpart and upgrade util-linux, used for filesystem resizing\napt-get install -y epel-release --nogpgcheck\napt-get install -y cloud-utils-growpart --nogpgcheck\napt-get upgrade -y util-linux --nogpgcheck\n\n#nginx install\n apt-get -y update\napt-get install -y nginx\nceph_user=&quot;megam&quot;\nceph_password=&quot;1234pass&quot;\nceph_group=&quot;megam&quot;\nuser_home=&quot;/home/megam&quot;\nif ! getent group $ceph_group &gt; /dev/null 2&gt;&amp;1;  then\ngroupadd --system $ceph_group\nfi\nif ! getent passwd $ceph_user &gt; /dev/null 2&gt;&amp;1; then\nuseradd -d $user_home -m -g $ceph_group $ceph_user -s /bin/bash\n    #Set passwordsudo echo -e &quot;$ceph_password\\n$ceph_password\\n&quot; | sudo passwd $ceph_user\nelse\n   user_home=`getent passwd $ceph_user | cut -f6 -d:`\n\n# Renable user (give him a shell)\nusermod --shell /bin/bash $ceph_user\n# Make sure MEGAMHOME exists, might have been removed on previous purge\nmkdir -p $user_home\nfi\n</code></pre><p>Instead of modifying the original image downloaded we can use a feature of qcow2 image that is creating a new image that is based on another one.</p>\n<p> To copy the image from original image</p>\n<pre><code>$ qemu-img create -f qcow2 -b ubuntu-14.04-server-cloudimg-amd64-disk1.img ubuntu.qcow2\n</code></pre><p>  Now all is prepared to customize the image. The command we are going to use is virt-customize.</p>\n<p>  It can do a lot of modifications to the image but we are only going to do two. The command is this one:  </p>\n<pre><code>virt-customize -v -x --attach packages.iso --format qcow2 -a ubuntu.qcow2 --run script.sh --root-password password:centos\n</code></pre><p>   It attaches two images, the iso image with the packages and the OS hard disk, executes script.sh</p>\n<p>   After the command is run the image centos.qcow2 contains the modifications we did to the original image. </p>\n<p>   Now we can convert it to any other format we need (for example vmdk) or to a full qcow2 image, that it, does not depend on any other one. </p>\n<pre><code> qemu-img convert -f qcow2 -O qcow2 -o compat=0.10 ubuntu.qcow2 ubuntu-final.qcow2\n\nqemu-img convert -f qcow2 -O vmdk ubuntu.qcow2 ubuntu-final.vmdk\n</code></pre>","excerpt":"","more":"<p>##Introduction</p>\n<p>   Lets the system have installed centos operating system.In my purpose, when preparing an OpenNebula installation is the creation of Virtual Machine images for base Operating Systems or appliances.</p>\n<p>   Some of these images can be downloaded from the marketplace but you may need an OS that is not in the marketplace or the images must be customized in some other way. </p>\n<p>   Now i am going to describe an automated way to customize the base images.It provided by linux distribution using software tool libguestfs.</p>\n<p>####Libguestfs<br>  This tool can be used to create and modify the virtual machine images in number of format that qemu understands.Some of these utilities let us add or delete files inside the images or execute scripts using the image filesystem as root.</p>\n<p>  To install libguestfs,</p>\n<pre><code>yum install libguestfs-tools\n</code></pre><p>#####Base image</p>\n<p> Next step download the base Isoimage like ubuntu </p>\n<p>   wget <a href=\"http://cloud-images.ubuntu.com/releases/14.04/release/ubuntu-14.04-server-cloudimg-amd64-disk1.img\">http://cloud-images.ubuntu.com/releases/14.04/release/ubuntu-14.04-server-cloudimg-amd64-disk1.img</a></p>\n<p>####Install Onecontext<br>  One of the customizations we have to do to this image is uninstall the cloud-init package that comes by default with that image and install OpenNebula context package. </p>\n<pre><code>wget https://github.com/OpenNebula/addon-context-linux/releases/download/v4.14.4/one-context_4.14.4.rpm\n</code></pre><p>  To create the CDROM image we can use genisoimage. Remember to add a label so its easier to mount. Here we are going to use the label PACKAGES:</p>\n<p>i) Copy the onecontext packages to a directory, for example packages </p>\n<p>ii) Execute genisoimage to create the iso that contains those files:</p>\n<pre><code>$ genisoimage -o packages.iso -R -J -V PACKAGES packages/\n</code></pre><p>  Now we need to prepare a script with the customizations to be done in the image. For example:</p>\n<pre><code>mount LABEL=PACKAGES /mnt\n\n# Install opennebula context package\n apt-get install -y unzip\n unzip /mnt/v4.14.4*zip\n\n# Install growpart and upgrade util-linux, used for filesystem resizing\napt-get install -y epel-release --nogpgcheck\napt-get install -y cloud-utils-growpart --nogpgcheck\napt-get upgrade -y util-linux --nogpgcheck\n\n#nginx install\n apt-get -y update\napt-get install -y nginx\nceph_user=&quot;megam&quot;\nceph_password=&quot;1234pass&quot;\nceph_group=&quot;megam&quot;\nuser_home=&quot;/home/megam&quot;\nif ! getent group $ceph_group &gt; /dev/null 2&gt;&amp;1;  then\ngroupadd --system $ceph_group\nfi\nif ! getent passwd $ceph_user &gt; /dev/null 2&gt;&amp;1; then\nuseradd -d $user_home -m -g $ceph_group $ceph_user -s /bin/bash\n    #Set passwordsudo echo -e &quot;$ceph_password\\n$ceph_password\\n&quot; | sudo passwd $ceph_user\nelse\n   user_home=`getent passwd $ceph_user | cut -f6 -d:`\n\n# Renable user (give him a shell)\nusermod --shell /bin/bash $ceph_user\n# Make sure MEGAMHOME exists, might have been removed on previous purge\nmkdir -p $user_home\nfi\n</code></pre><p>Instead of modifying the original image downloaded we can use a feature of qcow2 image that is creating a new image that is based on another one.</p>\n<p> To copy the image from original image</p>\n<pre><code>$ qemu-img create -f qcow2 -b ubuntu-14.04-server-cloudimg-amd64-disk1.img ubuntu.qcow2\n</code></pre><p>  Now all is prepared to customize the image. The command we are going to use is virt-customize.</p>\n<p>  It can do a lot of modifications to the image but we are only going to do two. The command is this one:  </p>\n<pre><code>virt-customize -v -x --attach packages.iso --format qcow2 -a ubuntu.qcow2 --run script.sh --root-password password:centos\n</code></pre><p>   It attaches two images, the iso image with the packages and the OS hard disk, executes script.sh</p>\n<p>   After the command is run the image centos.qcow2 contains the modifications we did to the original image. </p>\n<p>   Now we can convert it to any other format we need (for example vmdk) or to a full qcow2 image, that it, does not depend on any other one. </p>\n<pre><code> qemu-img convert -f qcow2 -O qcow2 -o compat=0.10 ubuntu.qcow2 ubuntu-final.qcow2\n\nqemu-img convert -f qcow2 -O vmdk ubuntu.qcow2 ubuntu-final.vmdk\n</code></pre>"},{"title":"Solving keyboard interrupt error in CentOS7.0","slug":"1970-01-01-solving-keyboard-interrrupt-error-in-centos7-0","date_published":"1969-12-31T18:30:00.000Z","date_updated":"2016-06-30T23:42:21.691Z","draft":true,"_content":"\n#Introduction\n     \n  when we launched the vm by using image centos7.0. In vm , I tried to install the git  **yum install git** that keyboard interrupt error is raised on the screen.To solve this error, first we install deltarpm package.          \n       \n   Delta RPM packages contain the difference between an old and a new version of an RPM package. This means the whole new RPM does not have to be downloaded saving bandwidth.\n\nTo use delta RPMs install the deltarpm package\n            \n            yum install deltarpm\n            yum provides */applydeltarpm\n \n next we go to update this package\n \n            yum update\n            \n Finally install git ,\n \n            yum install git\n            \n  Now the git installed successfully.The keyboard interrupt error is solved.\n  \n           \n           \n          \n","source":"_posts/1970-01-01-solving-keyboard-interrrupt-error-in-centos7-0.md","raw":"---\ntitle: Solving keyboard interrupt error in CentOS7.0\nslug: solving-keyboard-interrrupt-error-in-centos7-0\ndate_published: 1970-01-01T00:00:00.000Z\ndate_updated:   2016-07-01T05:12:21.691Z\ndraft: true\n---\n\n#Introduction\n     \n  when we launched the vm by using image centos7.0. In vm , I tried to install the git  **yum install git** that keyboard interrupt error is raised on the screen.To solve this error, first we install deltarpm package.          \n       \n   Delta RPM packages contain the difference between an old and a new version of an RPM package. This means the whole new RPM does not have to be downloaded saving bandwidth.\n\nTo use delta RPMs install the deltarpm package\n            \n            yum install deltarpm\n            yum provides */applydeltarpm\n \n next we go to update this package\n \n            yum update\n            \n Finally install git ,\n \n            yum install git\n            \n  Now the git installed successfully.The keyboard interrupt error is solved.\n  \n           \n           \n          \n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaiqq0001drgbubd4rxsd","content":"<p>#Introduction</p>\n<p>  when we launched the vm by using image centos7.0. In vm , I tried to install the git  <strong>yum install git</strong> that keyboard interrupt error is raised on the screen.To solve this error, first we install deltarpm package.          </p>\n<p>   Delta RPM packages contain the difference between an old and a new version of an RPM package. This means the whole new RPM does not have to be downloaded saving bandwidth.</p>\n<p>To use delta RPMs install the deltarpm package</p>\n<pre><code>yum install deltarpm\nyum provides */applydeltarpm\n</code></pre><p> next we go to update this package</p>\n<pre><code>yum update\n</code></pre><p> Finally install git ,</p>\n<pre><code>yum install git\n</code></pre><p>  Now the git installed successfully.The keyboard interrupt error is solved.</p>\n","excerpt":"","more":"<p>#Introduction</p>\n<p>  when we launched the vm by using image centos7.0. In vm , I tried to install the git  <strong>yum install git</strong> that keyboard interrupt error is raised on the screen.To solve this error, first we install deltarpm package.          </p>\n<p>   Delta RPM packages contain the difference between an old and a new version of an RPM package. This means the whole new RPM does not have to be downloaded saving bandwidth.</p>\n<p>To use delta RPMs install the deltarpm package</p>\n<pre><code>yum install deltarpm\nyum provides */applydeltarpm\n</code></pre><p> next we go to update this package</p>\n<pre><code>yum update\n</code></pre><p> Finally install git ,</p>\n<pre><code>yum install git\n</code></pre><p>  Now the git installed successfully.The keyboard interrupt error is solved.</p>\n"},{"title":"Install Ruby 2.2.2","slug":"2015-03-03-megam_install_ruby","date_published":"2015-03-03T06:00:18.267Z","date_updated":"2016-02-15T05:14:20.856Z","_content":"\nWe recommend you install *git*, *curl* before you get started.\n\nIn Ubuntu\n\n\tsudo apt-get install git curl\n    \n#Pre-reqs\n\nMake your current non-root user as a sudoer. To do so, write a file /etc/sudoers.d/USERNAME\n\t\n    USERNAME  ALL = (root) NOPASSWD:ALL\n    \nMake it as only readable\n\t\n    $ chmod 0440 /etc/sudoers.d/USERNAME\n    \n`NOTE` Please avoid using superuser(root) from here. Run all the below commands as `USERNAME`\n\n#Install RVM\n\nRVM is a command-line tool which allows you to easily install, manage, and work with multiple ruby environments from interpreters to sets of gems. \n\nIf your current `.gnupg/` folder is in root permission, then change the permission to `USERNAME` with the command `sudo chown -R USERNAME:USERNAME ~/.gnupg/`\n\n\t$ gpg --keyserver hkp://keys.gnupg.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3\n\n\t$ \\curl -sSL -ip4 https://get.rvm.io | bash -s stable\n\nto run rvm from anywhere\n\n\t$ source ~/.rvm/scripts/rvm\n\nOnce you have rvm installed, go ahead and  install ruby 2.2.2\n\n\n\t$ rvm install ruby-2.2.2\n\n\nThis will download and install and setup ruby for ya. !\n\nset the installed ruby as default\n\n\t$ rvm use ruby-2.2.2 --default\n\n## Using Ruby\n\n\t$ rvm list\n    \n\trvm rubies\n\n\t=\\* ruby-2.2.2 [ x86_64 ]\n\n\t=> - current\n\t=* - current && default\n\t * - default  ``\n\n##Ruby on Rails\nIf you wish to work on a ruby on rails project like [Nilavu](https://github.com/megamsys/nilavu.git)\n\nits quite simple.\n\n\t$ git clone https://github.com/megamsys/nilavu.git\n\n\t$ cd nilavu\n\n\t$ bundle update\n\n\t$ bundle install\n\n\t$ rails s\n\n\nVoila! we covered installing ruby and using it to run a RoR application. \n\nYou can use **[Megam - Cloud Management](https://www.megam.io)** to launch a Ruby on Rails App in minutes.. \n\n\n","source":"_posts/2015-03-03-megam_install_ruby.md","raw":"---\ntitle: Install Ruby 2.2.2\nslug: megam_install_ruby\ndate_published: 2015-03-03T11:30:18.267Z\ndate_updated:   2016-02-15T10:44:20.856Z\ntags: ruby\n---\n\nWe recommend you install *git*, *curl* before you get started.\n\nIn Ubuntu\n\n\tsudo apt-get install git curl\n    \n#Pre-reqs\n\nMake your current non-root user as a sudoer. To do so, write a file /etc/sudoers.d/USERNAME\n\t\n    USERNAME  ALL = (root) NOPASSWD:ALL\n    \nMake it as only readable\n\t\n    $ chmod 0440 /etc/sudoers.d/USERNAME\n    \n`NOTE` Please avoid using superuser(root) from here. Run all the below commands as `USERNAME`\n\n#Install RVM\n\nRVM is a command-line tool which allows you to easily install, manage, and work with multiple ruby environments from interpreters to sets of gems. \n\nIf your current `.gnupg/` folder is in root permission, then change the permission to `USERNAME` with the command `sudo chown -R USERNAME:USERNAME ~/.gnupg/`\n\n\t$ gpg --keyserver hkp://keys.gnupg.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3\n\n\t$ \\curl -sSL -ip4 https://get.rvm.io | bash -s stable\n\nto run rvm from anywhere\n\n\t$ source ~/.rvm/scripts/rvm\n\nOnce you have rvm installed, go ahead and  install ruby 2.2.2\n\n\n\t$ rvm install ruby-2.2.2\n\n\nThis will download and install and setup ruby for ya. !\n\nset the installed ruby as default\n\n\t$ rvm use ruby-2.2.2 --default\n\n## Using Ruby\n\n\t$ rvm list\n    \n\trvm rubies\n\n\t=\\* ruby-2.2.2 [ x86_64 ]\n\n\t=> - current\n\t=* - current && default\n\t * - default  ``\n\n##Ruby on Rails\nIf you wish to work on a ruby on rails project like [Nilavu](https://github.com/megamsys/nilavu.git)\n\nits quite simple.\n\n\t$ git clone https://github.com/megamsys/nilavu.git\n\n\t$ cd nilavu\n\n\t$ bundle update\n\n\t$ bundle install\n\n\t$ rails s\n\n\nVoila! we covered installing ruby and using it to run a RoR application. \n\nYou can use **[Megam - Cloud Management](https://www.megam.io)** to launch a Ruby on Rails App in minutes.. \n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaiqu0002drgbefooftgx","content":"<p>We recommend you install <em>git</em>, <em>curl</em> before you get started.</p>\n<p>In Ubuntu</p>\n<pre><code>sudo apt-get install git curl\n</code></pre><p>#Pre-reqs</p>\n<p>Make your current non-root user as a sudoer. To do so, write a file /etc/sudoers.d/USERNAME</p>\n<pre><code>USERNAME  ALL = (root) NOPASSWD:ALL\n</code></pre><p>Make it as only readable</p>\n<pre><code>$ chmod 0440 /etc/sudoers.d/USERNAME\n</code></pre><p><code>NOTE</code> Please avoid using superuser(root) from here. Run all the below commands as <code>USERNAME</code></p>\n<p>#Install RVM</p>\n<p>RVM is a command-line tool which allows you to easily install, manage, and work with multiple ruby environments from interpreters to sets of gems. </p>\n<p>If your current <code>.gnupg/</code> folder is in root permission, then change the permission to <code>USERNAME</code> with the command <code>sudo chown -R USERNAME:USERNAME ~/.gnupg/</code></p>\n<pre><code>$ gpg --keyserver hkp://keys.gnupg.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3\n\n$ \\curl -sSL -ip4 https://get.rvm.io | bash -s stable\n</code></pre><p>to run rvm from anywhere</p>\n<pre><code>$ source ~/.rvm/scripts/rvm\n</code></pre><p>Once you have rvm installed, go ahead and  install ruby 2.2.2</p>\n<pre><code>$ rvm install ruby-2.2.2\n</code></pre><p>This will download and install and setup ruby for ya. !</p>\n<p>set the installed ruby as default</p>\n<pre><code>$ rvm use ruby-2.2.2 --default\n</code></pre><h2 id=\"Using-Ruby\"><a href=\"#Using-Ruby\" class=\"headerlink\" title=\"Using Ruby\"></a>Using Ruby</h2><pre><code>$ rvm list\n\nrvm rubies\n\n=\\* ruby-2.2.2 [ x86_64 ]\n\n=&gt; - current\n=* - current &amp;&amp; default\n * - default  ``\n</code></pre><p>##Ruby on Rails<br>If you wish to work on a ruby on rails project like <a href=\"https://github.com/megamsys/nilavu.git\" target=\"_blank\" rel=\"external\">Nilavu</a></p>\n<p>its quite simple.</p>\n<pre><code>$ git clone https://github.com/megamsys/nilavu.git\n\n$ cd nilavu\n\n$ bundle update\n\n$ bundle install\n\n$ rails s\n</code></pre><p>Voila! we covered installing ruby and using it to run a RoR application. </p>\n<p>You can use <strong><a href=\"https://www.megam.io\">Megam - Cloud Management</a></strong> to launch a Ruby on Rails App in minutes.. </p>\n","excerpt":"","more":"<p>We recommend you install <em>git</em>, <em>curl</em> before you get started.</p>\n<p>In Ubuntu</p>\n<pre><code>sudo apt-get install git curl\n</code></pre><p>#Pre-reqs</p>\n<p>Make your current non-root user as a sudoer. To do so, write a file /etc/sudoers.d/USERNAME</p>\n<pre><code>USERNAME  ALL = (root) NOPASSWD:ALL\n</code></pre><p>Make it as only readable</p>\n<pre><code>$ chmod 0440 /etc/sudoers.d/USERNAME\n</code></pre><p><code>NOTE</code> Please avoid using superuser(root) from here. Run all the below commands as <code>USERNAME</code></p>\n<p>#Install RVM</p>\n<p>RVM is a command-line tool which allows you to easily install, manage, and work with multiple ruby environments from interpreters to sets of gems. </p>\n<p>If your current <code>.gnupg/</code> folder is in root permission, then change the permission to <code>USERNAME</code> with the command <code>sudo chown -R USERNAME:USERNAME ~/.gnupg/</code></p>\n<pre><code>$ gpg --keyserver hkp://keys.gnupg.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3\n\n$ \\curl -sSL -ip4 https://get.rvm.io | bash -s stable\n</code></pre><p>to run rvm from anywhere</p>\n<pre><code>$ source ~/.rvm/scripts/rvm\n</code></pre><p>Once you have rvm installed, go ahead and  install ruby 2.2.2</p>\n<pre><code>$ rvm install ruby-2.2.2\n</code></pre><p>This will download and install and setup ruby for ya. !</p>\n<p>set the installed ruby as default</p>\n<pre><code>$ rvm use ruby-2.2.2 --default\n</code></pre><h2 id=\"Using-Ruby\"><a href=\"#Using-Ruby\" class=\"headerlink\" title=\"Using Ruby\"></a>Using Ruby</h2><pre><code>$ rvm list\n\nrvm rubies\n\n=\\* ruby-2.2.2 [ x86_64 ]\n\n=&gt; - current\n=* - current &amp;&amp; default\n * - default  ``\n</code></pre><p>##Ruby on Rails<br>If you wish to work on a ruby on rails project like <a href=\"https://github.com/megamsys/nilavu.git\">Nilavu</a></p>\n<p>its quite simple.</p>\n<pre><code>$ git clone https://github.com/megamsys/nilavu.git\n\n$ cd nilavu\n\n$ bundle update\n\n$ bundle install\n\n$ rails s\n</code></pre><p>Voila! we covered installing ruby and using it to run a RoR application. </p>\n<p>You can use <strong><a href=\"https://www.megam.io\">Megam - Cloud Management</a></strong> to launch a Ruby on Rails App in minutes.. </p>\n"},{"title":"Git for Newbies,made easy!","slug":"2015-03-12-git-for-newbies","date_published":"2015-03-12T09:30:30.492Z","date_updated":"2015-03-12T09:40:08.063Z","_content":"\n####Wondering what Git and Github are all about? Well,firstly:\n\n##Git and GitHub- What is the difference?\n\n>**Git** is a **version control system**; think of it as a series of snapshots(commits) of your code. You see a *path of these snapshots*, in which order they where created. You can make *branches to experiment* and come back to snapshots you took.\n\n>**GitHub**, is a **web-page** on which you can **publish** your **Git repositories** and **collaborate** with **other people**.It is the best place to *share code* with friends, co-workers, classmates, and complete strangers. Did you know that over **eight million people use GitHub to build amazing things together?!**(Now that's something to read about,eh?)\n\n\nNow let's get started! Now that you know what is the difference between Git and Github,let us go ahead and set up your Git tool. It's a simple 4 step process.(Piece of cake,really!)\n\n####How to setup Git tool:\t\t\t\t\t\t\t\t\n#####STEP 1:\n>http://git-scm.com/downloads.\n\n>**Download the latest version of Git** from the link mentioned above.\n\n#####STEP 2:\n>On your computer, **open terminal**.\n#####STEP 3:\n>Now, you need to **tell Git your name** so your commits will be properly labeled. Type the following:\n\n>>`$ git config --global user.name  Your name`\n\n#####STEP 4:\n>**Tell Git the email address** that will be associated with your Git commits. Type:\n\n>>`$ git config --global user.mail  Your mail`\n\nNow that you've got **your Git tool is setup.** Let's proceed. What next?\nFIRST THINGS FIRST!! \n######How do you create a Repository?                                                                                                                                                \n>**Create a new directory** , open it and **type**\n\t\t\n  >>`$git init`\n\n>to create a new repository.(This is on your terminal ofcourse).\n\t\n\n**Next.**\n\n######HOW DO YOU FORK A REPOSITORY?\n>**Hang on.**\n\n>**Fork?! What's a fork?**\n\n>**A fork is a copy of a repository.** Forking a repository allows you to freely experiment with changes without affecting the original project.                                                                      Most commonly, forks are used to either **propose changes to someone else's project** or to **use someone else's project as a starting point for your own idea.**\nA great example of using forks to propose changes is for **bug fixes**. Rather than logging an issue for a bug you've found, **you can:**\n**1.Fork the repository.**\n\n>**2.Make the fix.**\n\n>**3.Submit a pull request to the project owner.**\nIf the project owner likes your work, they might pull your fix into the original repository!\nAt the heart of open source is the idea that by sharing code, we can make better, more reliable software.\nIn fact, when you create a repository on GitHub, you have a choice of automatically including a license file, which determines how you want your project to be shared with others.\n\n######STEPS TO FORK A REPOSITORY:\n\n>1.On GitHub, **navigate to the repository** that you want to **fork**.\n\n>2.\nIn the **top-right corner of the page**, click **FORK**.\n*Now you have a fork of the original repository!*\n>\nYou might fork a project in order to propose changes to the upstream, or original, repository. In this case, it's good practice to regularly sync your fork with the upstream repository.\n\nSo, right now, you have a fork of the repository that you want to make changes to, but you don't have the files in that repository on your computer!So, **let's create a clone of your fork locally on your computer.**\n######HOW DO YOU CREATE A CLONE OF A REPOSITORY ON YOUR OWN COMPUTER?\n\n**There are two ways to clone a repository in GitHub.**\n\n>**1.Using HTTPS:**\n\n>To clone using HTTPS, type:\n\n>>`$  git clone path/to/repository`\n\n>**2.Using SSH:**\n\n>To clone using SSH, type:\n\n         \n       \n       \n\n>>`$  git clone username@host:path/to/repository`\n\n######STEPS TO CREATE A CLONE:\n>1.On GitHub, **navigate to your fork** of the repository you just forked.\n\n>2.In the **right sidebar** of your fork's repository page, click the button with an arrow, below the **HTTP CLONE URL** to copy the clone URL for your fork.\n\n>3.**Open Terminal** (for Mac and Linux users) **or the command line** (for Windows users).\n\n>4.**Type** the following:\n           \n  >>`$ git clone https://github.com/YOUR-USERNAME/REPOSITORY-NAME`\n  \n>5.**Press enter** and your clone will be created.\nNow, **you have a local copy of your fork of your\nrepository!**\n\nWhen you fork a project in order to propose changes to the original repository, you can configure Git to pull changes from the original, or upstream, repository into the local clone of your fork.\n######How do you configure Git to sync your fork with the original repository?\n>1.Repeat the steps above to create a clone(as mentioned above^).\n\n>2.**Change directories** to the location of the fork you cloned in\n\n >3.**Type** the following:\n\t\t>>`$ git remote -v`\n        \n>4.**Press Enter.** \n\n>You'll see the current configured remote repository for your fork.\n\n>5.Type :\n\t>>`$ git remote add upstream`\n\n>Type the URL you copied and press Enter.\n\n>7.To verify the new upstream repository you've specified for your fork, type\n>>`git remote -v` \n\n>again. You should see the URL for your fork as origin,\nand the URL for the original repository as upstream.\n\n**So now that's done.**\n**What do you do next?**\n######CREATING BRANCHES:\n>Branches allow you to **build new features** or **test out ideas without putting your main project at risk**.\n######OPENING PULL REQUESTS:\n>If you are hoping to contribute back to the original repository, you can **send a request to the original author to pull your fork** into their repository by submitting a pull request.\n\n**Every public repository can be forked, so find a project you're interested in and get forking!**\n\nYayy,done!It may look a bit daunting in the beginning but once you get a hang of it, it gets really simple.\n**GO AHEAD AND GIVE IT A TRY!**\n\n\n\n\n\n          \n    \n\n","source":"_posts/2015-03-12-git-for-newbies.md","raw":"---\ntitle: Git for Newbies,made easy!\nslug: git-for-newbies\ndate_published: 2015-03-12T15:00:30.492Z\ndate_updated:   2015-03-12T15:10:08.063Z\n---\n\n####Wondering what Git and Github are all about? Well,firstly:\n\n##Git and GitHub- What is the difference?\n\n>**Git** is a **version control system**; think of it as a series of snapshots(commits) of your code. You see a *path of these snapshots*, in which order they where created. You can make *branches to experiment* and come back to snapshots you took.\n\n>**GitHub**, is a **web-page** on which you can **publish** your **Git repositories** and **collaborate** with **other people**.It is the best place to *share code* with friends, co-workers, classmates, and complete strangers. Did you know that over **eight million people use GitHub to build amazing things together?!**(Now that's something to read about,eh?)\n\n\nNow let's get started! Now that you know what is the difference between Git and Github,let us go ahead and set up your Git tool. It's a simple 4 step process.(Piece of cake,really!)\n\n####How to setup Git tool:\t\t\t\t\t\t\t\t\n#####STEP 1:\n>http://git-scm.com/downloads.\n\n>**Download the latest version of Git** from the link mentioned above.\n\n#####STEP 2:\n>On your computer, **open terminal**.\n#####STEP 3:\n>Now, you need to **tell Git your name** so your commits will be properly labeled. Type the following:\n\n>>`$ git config --global user.name  Your name`\n\n#####STEP 4:\n>**Tell Git the email address** that will be associated with your Git commits. Type:\n\n>>`$ git config --global user.mail  Your mail`\n\nNow that you've got **your Git tool is setup.** Let's proceed. What next?\nFIRST THINGS FIRST!! \n######How do you create a Repository?                                                                                                                                                \n>**Create a new directory** , open it and **type**\n\t\t\n  >>`$git init`\n\n>to create a new repository.(This is on your terminal ofcourse).\n\t\n\n**Next.**\n\n######HOW DO YOU FORK A REPOSITORY?\n>**Hang on.**\n\n>**Fork?! What's a fork?**\n\n>**A fork is a copy of a repository.** Forking a repository allows you to freely experiment with changes without affecting the original project.                                                                      Most commonly, forks are used to either **propose changes to someone else's project** or to **use someone else's project as a starting point for your own idea.**\nA great example of using forks to propose changes is for **bug fixes**. Rather than logging an issue for a bug you've found, **you can:**\n**1.Fork the repository.**\n\n>**2.Make the fix.**\n\n>**3.Submit a pull request to the project owner.**\nIf the project owner likes your work, they might pull your fix into the original repository!\nAt the heart of open source is the idea that by sharing code, we can make better, more reliable software.\nIn fact, when you create a repository on GitHub, you have a choice of automatically including a license file, which determines how you want your project to be shared with others.\n\n######STEPS TO FORK A REPOSITORY:\n\n>1.On GitHub, **navigate to the repository** that you want to **fork**.\n\n>2.\nIn the **top-right corner of the page**, click **FORK**.\n*Now you have a fork of the original repository!*\n>\nYou might fork a project in order to propose changes to the upstream, or original, repository. In this case, it's good practice to regularly sync your fork with the upstream repository.\n\nSo, right now, you have a fork of the repository that you want to make changes to, but you don't have the files in that repository on your computer!So, **let's create a clone of your fork locally on your computer.**\n######HOW DO YOU CREATE A CLONE OF A REPOSITORY ON YOUR OWN COMPUTER?\n\n**There are two ways to clone a repository in GitHub.**\n\n>**1.Using HTTPS:**\n\n>To clone using HTTPS, type:\n\n>>`$  git clone path/to/repository`\n\n>**2.Using SSH:**\n\n>To clone using SSH, type:\n\n         \n       \n       \n\n>>`$  git clone username@host:path/to/repository`\n\n######STEPS TO CREATE A CLONE:\n>1.On GitHub, **navigate to your fork** of the repository you just forked.\n\n>2.In the **right sidebar** of your fork's repository page, click the button with an arrow, below the **HTTP CLONE URL** to copy the clone URL for your fork.\n\n>3.**Open Terminal** (for Mac and Linux users) **or the command line** (for Windows users).\n\n>4.**Type** the following:\n           \n  >>`$ git clone https://github.com/YOUR-USERNAME/REPOSITORY-NAME`\n  \n>5.**Press enter** and your clone will be created.\nNow, **you have a local copy of your fork of your\nrepository!**\n\nWhen you fork a project in order to propose changes to the original repository, you can configure Git to pull changes from the original, or upstream, repository into the local clone of your fork.\n######How do you configure Git to sync your fork with the original repository?\n>1.Repeat the steps above to create a clone(as mentioned above^).\n\n>2.**Change directories** to the location of the fork you cloned in\n\n >3.**Type** the following:\n\t\t>>`$ git remote -v`\n        \n>4.**Press Enter.** \n\n>You'll see the current configured remote repository for your fork.\n\n>5.Type :\n\t>>`$ git remote add upstream`\n\n>Type the URL you copied and press Enter.\n\n>7.To verify the new upstream repository you've specified for your fork, type\n>>`git remote -v` \n\n>again. You should see the URL for your fork as origin,\nand the URL for the original repository as upstream.\n\n**So now that's done.**\n**What do you do next?**\n######CREATING BRANCHES:\n>Branches allow you to **build new features** or **test out ideas without putting your main project at risk**.\n######OPENING PULL REQUESTS:\n>If you are hoping to contribute back to the original repository, you can **send a request to the original author to pull your fork** into their repository by submitting a pull request.\n\n**Every public repository can be forked, so find a project you're interested in and get forking!**\n\nYayy,done!It may look a bit daunting in the beginning but once you get a hang of it, it gets really simple.\n**GO AHEAD AND GIVE IT A TRY!**\n\n\n\n\n\n          \n    \n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaiqw0003drgbo4iak6ew","content":"<p>####Wondering what Git and Github are all about? Well,firstly:</p>\n<p>##Git and GitHub- What is the difference?</p>\n<blockquote>\n<p><strong>Git</strong> is a <strong>version control system</strong>; think of it as a series of snapshots(commits) of your code. You see a <em>path of these snapshots</em>, in which order they where created. You can make <em>branches to experiment</em> and come back to snapshots you took.</p>\n<p><strong>GitHub</strong>, is a <strong>web-page</strong> on which you can <strong>publish</strong> your <strong>Git repositories</strong> and <strong>collaborate</strong> with <strong>other people</strong>.It is the best place to <em>share code</em> with friends, co-workers, classmates, and complete strangers. Did you know that over <strong>eight million people use GitHub to build amazing things together?!</strong>(Now thats something to read about,eh?)</p>\n</blockquote>\n<p>Now lets get started! Now that you know what is the difference between Git and Github,let us go ahead and set up your Git tool. Its a simple 4 step process.(Piece of cake,really!)</p>\n<p>####How to setup Git tool:                                </p>\n<p>#####STEP 1:</p>\n<blockquote>\n<p><a href=\"http://git-scm.com/downloads\" target=\"_blank\" rel=\"external\">http://git-scm.com/downloads</a>.</p>\n<p><strong>Download the latest version of Git</strong> from the link mentioned above.</p>\n</blockquote>\n<p>#####STEP 2:</p>\n<blockquote>\n<p>On your computer, <strong>open terminal</strong>.</p>\n<p>#####STEP 3:<br>Now, you need to <strong>tell Git your name</strong> so your commits will be properly labeled. Type the following:</p>\n<blockquote>\n<p><code>$ git config --global user.name  Your name</code></p>\n</blockquote>\n</blockquote>\n<p>#####STEP 4:</p>\n<blockquote>\n<p><strong>Tell Git the email address</strong> that will be associated with your Git commits. Type:</p>\n<blockquote>\n<p><code>$ git config --global user.mail  Your mail</code></p>\n</blockquote>\n</blockquote>\n<p>Now that youve got <strong>your Git tool is setup.</strong> Lets proceed. What next?<br>FIRST THINGS FIRST!! </p>\n<p>######How do you create a Repository?                                                                                                                                                </p>\n<blockquote>\n<p><strong>Create a new directory</strong> , open it and <strong>type</strong></p>\n<blockquote>\n<p><code>$git init</code></p>\n</blockquote>\n<p>to create a new repository.(This is on your terminal ofcourse).</p>\n</blockquote>\n<p><strong>Next.</strong></p>\n<p>######HOW DO YOU FORK A REPOSITORY?</p>\n<blockquote>\n<p><strong>Hang on.</strong></p>\n<p><strong>Fork?! Whats a fork?</strong></p>\n<p><strong>A fork is a copy of a repository.</strong> Forking a repository allows you to freely experiment with changes without affecting the original project.                                                                      Most commonly, forks are used to either <strong>propose changes to someone elses project</strong> or to <strong>use someone elses project as a starting point for your own idea.</strong><br>A great example of using forks to propose changes is for <strong>bug fixes</strong>. Rather than logging an issue for a bug youve found, <strong>you can:</strong><br><strong>1.Fork the repository.</strong></p>\n<p><strong>2.Make the fix.</strong></p>\n<p><strong>3.Submit a pull request to the project owner.</strong><br>If the project owner likes your work, they might pull your fix into the original repository!<br>At the heart of open source is the idea that by sharing code, we can make better, more reliable software.<br>In fact, when you create a repository on GitHub, you have a choice of automatically including a license file, which determines how you want your project to be shared with others.</p>\n</blockquote>\n<p>######STEPS TO FORK A REPOSITORY:</p>\n<blockquote>\n<p>1.On GitHub, <strong>navigate to the repository</strong> that you want to <strong>fork</strong>.</p>\n<p>2.<br>In the <strong>top-right corner of the page</strong>, click <strong>FORK</strong>.<br><em>Now you have a fork of the original repository!</em></p>\n<p>You might fork a project in order to propose changes to the upstream, or original, repository. In this case, its good practice to regularly sync your fork with the upstream repository.</p>\n</blockquote>\n<p>So, right now, you have a fork of the repository that you want to make changes to, but you dont have the files in that repository on your computer!So, <strong>lets create a clone of your fork locally on your computer.</strong></p>\n<p>######HOW DO YOU CREATE A CLONE OF A REPOSITORY ON YOUR OWN COMPUTER?</p>\n<p><strong>There are two ways to clone a repository in GitHub.</strong></p>\n<blockquote>\n<p><strong>1.Using HTTPS:</strong></p>\n<p>To clone using HTTPS, type:</p>\n<blockquote>\n<p><code>$  git clone path/to/repository</code></p>\n</blockquote>\n<p><strong>2.Using SSH:</strong></p>\n<p>To clone using SSH, type:</p>\n<blockquote>\n<p><code>$  git clone username@host:path/to/repository</code></p>\n</blockquote>\n</blockquote>\n<p>######STEPS TO CREATE A CLONE:</p>\n<blockquote>\n<p>1.On GitHub, <strong>navigate to your fork</strong> of the repository you just forked.</p>\n<p>2.In the <strong>right sidebar</strong> of your forks repository page, click the button with an arrow, below the <strong>HTTP CLONE URL</strong> to copy the clone URL for your fork.</p>\n<p>3.<strong>Open Terminal</strong> (for Mac and Linux users) <strong>or the command line</strong> (for Windows users).</p>\n<p>4.<strong>Type</strong> the following:</p>\n<blockquote>\n<p><code>$ git clone https://github.com/YOUR-USERNAME/REPOSITORY-NAME</code></p>\n</blockquote>\n<p>5.<strong>Press enter</strong> and your clone will be created.<br>Now, <strong>you have a local copy of your fork of your<br>repository!</strong></p>\n</blockquote>\n<p>When you fork a project in order to propose changes to the original repository, you can configure Git to pull changes from the original, or upstream, repository into the local clone of your fork.</p>\n<p>######How do you configure Git to sync your fork with the original repository?</p>\n<blockquote>\n<p>1.Repeat the steps above to create a clone(as mentioned above^).</p>\n<p>2.<strong>Change directories</strong> to the location of the fork you cloned in</p>\n<p>3.<strong>Type</strong> the following:</p>\n<blockquote>\n<p><code>$ git remote -v</code></p>\n</blockquote>\n<p>4.<strong>Press Enter.</strong> </p>\n<p>Youll see the current configured remote repository for your fork.</p>\n<p>5.Type :</p>\n<blockquote>\n<p><code>$ git remote add upstream</code></p>\n</blockquote>\n<p>Type the URL you copied and press Enter.</p>\n<p>7.To verify the new upstream repository youve specified for your fork, type</p>\n<blockquote>\n<p><code>git remote -v</code> </p>\n</blockquote>\n<p>again. You should see the URL for your fork as origin,<br>and the URL for the original repository as upstream.</p>\n</blockquote>\n<p><strong>So now thats done.</strong><br><strong>What do you do next?</strong></p>\n<p>######CREATING BRANCHES:</p>\n<blockquote>\n<p>Branches allow you to <strong>build new features</strong> or <strong>test out ideas without putting your main project at risk</strong>.</p>\n<p>######OPENING PULL REQUESTS:<br>If you are hoping to contribute back to the original repository, you can <strong>send a request to the original author to pull your fork</strong> into their repository by submitting a pull request.</p>\n</blockquote>\n<p><strong>Every public repository can be forked, so find a project youre interested in and get forking!</strong></p>\n<p>Yayy,done!It may look a bit daunting in the beginning but once you get a hang of it, it gets really simple.<br><strong>GO AHEAD AND GIVE IT A TRY!</strong></p>\n","excerpt":"","more":"<p>####Wondering what Git and Github are all about? Well,firstly:</p>\n<p>##Git and GitHub- What is the difference?</p>\n<blockquote>\n<p><strong>Git</strong> is a <strong>version control system</strong>; think of it as a series of snapshots(commits) of your code. You see a <em>path of these snapshots</em>, in which order they where created. You can make <em>branches to experiment</em> and come back to snapshots you took.</p>\n<p><strong>GitHub</strong>, is a <strong>web-page</strong> on which you can <strong>publish</strong> your <strong>Git repositories</strong> and <strong>collaborate</strong> with <strong>other people</strong>.It is the best place to <em>share code</em> with friends, co-workers, classmates, and complete strangers. Did you know that over <strong>eight million people use GitHub to build amazing things together?!</strong>(Now thats something to read about,eh?)</p>\n</blockquote>\n<p>Now lets get started! Now that you know what is the difference between Git and Github,let us go ahead and set up your Git tool. Its a simple 4 step process.(Piece of cake,really!)</p>\n<p>####How to setup Git tool:                                </p>\n<p>#####STEP 1:</p>\n<blockquote>\n<p><a href=\"http://git-scm.com/downloads\">http://git-scm.com/downloads</a>.</p>\n<p><strong>Download the latest version of Git</strong> from the link mentioned above.</p>\n</blockquote>\n<p>#####STEP 2:</p>\n<blockquote>\n<p>On your computer, <strong>open terminal</strong>.</p>\n<p>#####STEP 3:<br>Now, you need to <strong>tell Git your name</strong> so your commits will be properly labeled. Type the following:</p>\n<blockquote>\n<p><code>$ git config --global user.name  Your name</code></p>\n</blockquote>\n</blockquote>\n<p>#####STEP 4:</p>\n<blockquote>\n<p><strong>Tell Git the email address</strong> that will be associated with your Git commits. Type:</p>\n<blockquote>\n<p><code>$ git config --global user.mail  Your mail</code></p>\n</blockquote>\n</blockquote>\n<p>Now that youve got <strong>your Git tool is setup.</strong> Lets proceed. What next?<br>FIRST THINGS FIRST!! </p>\n<p>######How do you create a Repository?                                                                                                                                                </p>\n<blockquote>\n<p><strong>Create a new directory</strong> , open it and <strong>type</strong></p>\n<blockquote>\n<p><code>$git init</code></p>\n</blockquote>\n<p>to create a new repository.(This is on your terminal ofcourse).</p>\n</blockquote>\n<p><strong>Next.</strong></p>\n<p>######HOW DO YOU FORK A REPOSITORY?</p>\n<blockquote>\n<p><strong>Hang on.</strong></p>\n<p><strong>Fork?! Whats a fork?</strong></p>\n<p><strong>A fork is a copy of a repository.</strong> Forking a repository allows you to freely experiment with changes without affecting the original project.                                                                      Most commonly, forks are used to either <strong>propose changes to someone elses project</strong> or to <strong>use someone elses project as a starting point for your own idea.</strong><br>A great example of using forks to propose changes is for <strong>bug fixes</strong>. Rather than logging an issue for a bug youve found, <strong>you can:</strong><br><strong>1.Fork the repository.</strong></p>\n<p><strong>2.Make the fix.</strong></p>\n<p><strong>3.Submit a pull request to the project owner.</strong><br>If the project owner likes your work, they might pull your fix into the original repository!<br>At the heart of open source is the idea that by sharing code, we can make better, more reliable software.<br>In fact, when you create a repository on GitHub, you have a choice of automatically including a license file, which determines how you want your project to be shared with others.</p>\n</blockquote>\n<p>######STEPS TO FORK A REPOSITORY:</p>\n<blockquote>\n<p>1.On GitHub, <strong>navigate to the repository</strong> that you want to <strong>fork</strong>.</p>\n<p>2.<br>In the <strong>top-right corner of the page</strong>, click <strong>FORK</strong>.<br><em>Now you have a fork of the original repository!</em></p>\n<p>You might fork a project in order to propose changes to the upstream, or original, repository. In this case, its good practice to regularly sync your fork with the upstream repository.</p>\n</blockquote>\n<p>So, right now, you have a fork of the repository that you want to make changes to, but you dont have the files in that repository on your computer!So, <strong>lets create a clone of your fork locally on your computer.</strong></p>\n<p>######HOW DO YOU CREATE A CLONE OF A REPOSITORY ON YOUR OWN COMPUTER?</p>\n<p><strong>There are two ways to clone a repository in GitHub.</strong></p>\n<blockquote>\n<p><strong>1.Using HTTPS:</strong></p>\n<p>To clone using HTTPS, type:</p>\n<blockquote>\n<p><code>$  git clone path/to/repository</code></p>\n</blockquote>\n<p><strong>2.Using SSH:</strong></p>\n<p>To clone using SSH, type:</p>\n<blockquote>\n<p><code>$  git clone username@host:path/to/repository</code></p>\n</blockquote>\n</blockquote>\n<p>######STEPS TO CREATE A CLONE:</p>\n<blockquote>\n<p>1.On GitHub, <strong>navigate to your fork</strong> of the repository you just forked.</p>\n<p>2.In the <strong>right sidebar</strong> of your forks repository page, click the button with an arrow, below the <strong>HTTP CLONE URL</strong> to copy the clone URL for your fork.</p>\n<p>3.<strong>Open Terminal</strong> (for Mac and Linux users) <strong>or the command line</strong> (for Windows users).</p>\n<p>4.<strong>Type</strong> the following:</p>\n<blockquote>\n<p><code>$ git clone https://github.com/YOUR-USERNAME/REPOSITORY-NAME</code></p>\n</blockquote>\n<p>5.<strong>Press enter</strong> and your clone will be created.<br>Now, <strong>you have a local copy of your fork of your<br>repository!</strong></p>\n</blockquote>\n<p>When you fork a project in order to propose changes to the original repository, you can configure Git to pull changes from the original, or upstream, repository into the local clone of your fork.</p>\n<p>######How do you configure Git to sync your fork with the original repository?</p>\n<blockquote>\n<p>1.Repeat the steps above to create a clone(as mentioned above^).</p>\n<p>2.<strong>Change directories</strong> to the location of the fork you cloned in</p>\n<p>3.<strong>Type</strong> the following:</p>\n<blockquote>\n<p><code>$ git remote -v</code></p>\n</blockquote>\n<p>4.<strong>Press Enter.</strong> </p>\n<p>Youll see the current configured remote repository for your fork.</p>\n<p>5.Type :</p>\n<blockquote>\n<p><code>$ git remote add upstream</code></p>\n</blockquote>\n<p>Type the URL you copied and press Enter.</p>\n<p>7.To verify the new upstream repository youve specified for your fork, type</p>\n<blockquote>\n<p><code>git remote -v</code> </p>\n</blockquote>\n<p>again. You should see the URL for your fork as origin,<br>and the URL for the original repository as upstream.</p>\n</blockquote>\n<p><strong>So now thats done.</strong><br><strong>What do you do next?</strong></p>\n<p>######CREATING BRANCHES:</p>\n<blockquote>\n<p>Branches allow you to <strong>build new features</strong> or <strong>test out ideas without putting your main project at risk</strong>.</p>\n<p>######OPENING PULL REQUESTS:<br>If you are hoping to contribute back to the original repository, you can <strong>send a request to the original author to pull your fork</strong> into their repository by submitting a pull request.</p>\n</blockquote>\n<p><strong>Every public repository can be forked, so find a project youre interested in and get forking!</strong></p>\n<p>Yayy,done!It may look a bit daunting in the beginning but once you get a hang of it, it gets really simple.<br><strong>GO AHEAD AND GIVE IT A TRY!</strong></p>\n"},{"title":"Chef-Setup","slug":"2015-03-13-chef-setup","date_published":"2015-03-13T04:01:27.078Z","date_updated":"2015-03-13T04:03:50.334Z","_content":"\nChef is a configuration management and automation platform from [Opscode](https://www.chef.io/). Chef helps you describe your infrastructure with code. Because your infrastructure is managed with code, it can be automated, tested and reproduced with ease.\n\nAssumption: Ruby installed\n\n#Server Installation\nThe Chef server acts as a hub for configuration data. The Chef server stores cookbooks, the policies that are applied to nodes, and metadata that describes each registered node that is being managed by the chef-client. Nodes use the chef-client to ask the Chef server for configuration details, such as recipes, templates, and file distributions. The chef-client then does as much of the configuration work as possible on the nodes themselves (and not on the Chef server). This scalable approach distributes the configuration effort throughout the organization.\n\nDownload chef-server package from here [http://downloads.chef.io/chef-server/](http://downloads.chef.io/chef-server/)\n\n\t$ wget https://web-dl.packagecloud.io/chef/stable/packages/ubuntu/trusty/chef-server-core_12.0.1-1_amd64.deb\n\nThis will download the installation package that you can then install like this:\n\n\t$ sudo apt-get update\n    $ dpkg -i chef-server-core_12.0.1-1_amd64.deb\n\nThis will install the server component on the machine.\nIt prints to the screen afterwards that you should run this next command to actually configure the service around your specific machine. This will configure everything automatically:\n\n\t$ sudo chef-server-ctl reconfigure\n\nVerify chef-server installation by entering this command\n\n\t$ sudo chef-server-ctl test\n    \nOnce this step is complete, the server should be up and running. You can access the web interface immediately by typing https:// followed by your server's domain name or IP address.\n\n\thttps://server_domain_or_IP\n\n\nBecause the SSL certificates were signed by an authority that your browser does not recognize by default, you will see a warning message appear.\nClick the \"Proceed anyway\" button to bypass this screen and access the login screen.\n\nThe default login credentials are as follows:\n\n\tDefault Username: admin\n\tDefault Password: p@ssw0rd1\n\n\n##Workstation Installation\n\nInstall chef using rubygems\n\n\t$ gem install chef\n\nWe should setup a file structure that will help us organise our various Chef files. Opscode, the makers of Chef provide one. They call it simply the Chef Repository.\n\n\t$ wget http://github.com/opscode/chef-repo/tarball/master\n\t$ tar -zxf master\n\t$ mv opscode-chef-repo* chef-repo\n\t$ rm master\nIf we look inside the chef-repo directory we can see the following:\n\n\t$ cd chef-repo/\n\t$ ls\n    config  cookbooks  data_bags  environments  nodes  Rakefile  README.md  roles\n\n\nWe can use the command [knife](https://docs.chef.io/knife.html) to help us manage our cookbooks. First we should tell knife where to find our cookbooks directory.\n\n\t$ mkdir chef-repo/.chef\n\ndownload /etc/chef-server/chef-validator.pem and  /etc/chef-server/admin.pem from chef-server to this chef-repo/.chef\n\nEdit chef-repo/.chef/knife.rb\n\n    log_level                :info\n    log_location             STDOUT\n    node_name                admin\n    client_key               'chef-repo/.chef/admin.pem'\n    validation_client_name   'chef-validator'\n    validation_key           'chef-repo/.chef/chef-    validator.pem'\n    chef_server_url            'https://server_domain_or_IP'\n    cache_type               'BasicFile'\n    cookbook_path [ 'chef-repo/cookbooks' ]\n\n\nThats all :-)\nchef-setup is over.\n\nNow you can check it from workstation with the below commands\n\n    knife client list\n    knife node list\n\n\n\n","source":"_posts/2015-03-13-chef-setup.md","raw":"---\ntitle: Chef-Setup\nslug: chef-setup\ndate_published: 2015-03-13T09:31:27.078Z\ndate_updated:   2015-03-13T09:33:50.334Z\n---\n\nChef is a configuration management and automation platform from [Opscode](https://www.chef.io/). Chef helps you describe your infrastructure with code. Because your infrastructure is managed with code, it can be automated, tested and reproduced with ease.\n\nAssumption: Ruby installed\n\n#Server Installation\nThe Chef server acts as a hub for configuration data. The Chef server stores cookbooks, the policies that are applied to nodes, and metadata that describes each registered node that is being managed by the chef-client. Nodes use the chef-client to ask the Chef server for configuration details, such as recipes, templates, and file distributions. The chef-client then does as much of the configuration work as possible on the nodes themselves (and not on the Chef server). This scalable approach distributes the configuration effort throughout the organization.\n\nDownload chef-server package from here [http://downloads.chef.io/chef-server/](http://downloads.chef.io/chef-server/)\n\n\t$ wget https://web-dl.packagecloud.io/chef/stable/packages/ubuntu/trusty/chef-server-core_12.0.1-1_amd64.deb\n\nThis will download the installation package that you can then install like this:\n\n\t$ sudo apt-get update\n    $ dpkg -i chef-server-core_12.0.1-1_amd64.deb\n\nThis will install the server component on the machine.\nIt prints to the screen afterwards that you should run this next command to actually configure the service around your specific machine. This will configure everything automatically:\n\n\t$ sudo chef-server-ctl reconfigure\n\nVerify chef-server installation by entering this command\n\n\t$ sudo chef-server-ctl test\n    \nOnce this step is complete, the server should be up and running. You can access the web interface immediately by typing https:// followed by your server's domain name or IP address.\n\n\thttps://server_domain_or_IP\n\n\nBecause the SSL certificates were signed by an authority that your browser does not recognize by default, you will see a warning message appear.\nClick the \"Proceed anyway\" button to bypass this screen and access the login screen.\n\nThe default login credentials are as follows:\n\n\tDefault Username: admin\n\tDefault Password: p@ssw0rd1\n\n\n##Workstation Installation\n\nInstall chef using rubygems\n\n\t$ gem install chef\n\nWe should setup a file structure that will help us organise our various Chef files. Opscode, the makers of Chef provide one. They call it simply the Chef Repository.\n\n\t$ wget http://github.com/opscode/chef-repo/tarball/master\n\t$ tar -zxf master\n\t$ mv opscode-chef-repo* chef-repo\n\t$ rm master\nIf we look inside the chef-repo directory we can see the following:\n\n\t$ cd chef-repo/\n\t$ ls\n    config  cookbooks  data_bags  environments  nodes  Rakefile  README.md  roles\n\n\nWe can use the command [knife](https://docs.chef.io/knife.html) to help us manage our cookbooks. First we should tell knife where to find our cookbooks directory.\n\n\t$ mkdir chef-repo/.chef\n\ndownload /etc/chef-server/chef-validator.pem and  /etc/chef-server/admin.pem from chef-server to this chef-repo/.chef\n\nEdit chef-repo/.chef/knife.rb\n\n    log_level                :info\n    log_location             STDOUT\n    node_name                admin\n    client_key               'chef-repo/.chef/admin.pem'\n    validation_client_name   'chef-validator'\n    validation_key           'chef-repo/.chef/chef-    validator.pem'\n    chef_server_url            'https://server_domain_or_IP'\n    cache_type               'BasicFile'\n    cookbook_path [ 'chef-repo/cookbooks' ]\n\n\nThats all :-)\nchef-setup is over.\n\nNow you can check it from workstation with the below commands\n\n    knife client list\n    knife node list\n\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaira0005drgbsnjoq389","content":"<p>Chef is a configuration management and automation platform from <a href=\"https://www.chef.io/\" target=\"_blank\" rel=\"external\">Opscode</a>. Chef helps you describe your infrastructure with code. Because your infrastructure is managed with code, it can be automated, tested and reproduced with ease.</p>\n<p>Assumption: Ruby installed</p>\n<p>#Server Installation<br>The Chef server acts as a hub for configuration data. The Chef server stores cookbooks, the policies that are applied to nodes, and metadata that describes each registered node that is being managed by the chef-client. Nodes use the chef-client to ask the Chef server for configuration details, such as recipes, templates, and file distributions. The chef-client then does as much of the configuration work as possible on the nodes themselves (and not on the Chef server). This scalable approach distributes the configuration effort throughout the organization.</p>\n<p>Download chef-server package from here <a href=\"http://downloads.chef.io/chef-server/\" target=\"_blank\" rel=\"external\">http://downloads.chef.io/chef-server/</a></p>\n<pre><code>$ wget https://web-dl.packagecloud.io/chef/stable/packages/ubuntu/trusty/chef-server-core_12.0.1-1_amd64.deb\n</code></pre><p>This will download the installation package that you can then install like this:</p>\n<pre><code>$ sudo apt-get update\n$ dpkg -i chef-server-core_12.0.1-1_amd64.deb\n</code></pre><p>This will install the server component on the machine.<br>It prints to the screen afterwards that you should run this next command to actually configure the service around your specific machine. This will configure everything automatically:</p>\n<pre><code>$ sudo chef-server-ctl reconfigure\n</code></pre><p>Verify chef-server installation by entering this command</p>\n<pre><code>$ sudo chef-server-ctl test\n</code></pre><p>Once this step is complete, the server should be up and running. You can access the web interface immediately by typing https:// followed by your servers domain name or IP address.</p>\n<pre><code>https://server_domain_or_IP\n</code></pre><p>Because the SSL certificates were signed by an authority that your browser does not recognize by default, you will see a warning message appear.<br>Click the Proceed anyway button to bypass this screen and access the login screen.</p>\n<p>The default login credentials are as follows:</p>\n<pre><code>Default Username: admin\nDefault Password: p@ssw0rd1\n</code></pre><p>##Workstation Installation</p>\n<p>Install chef using rubygems</p>\n<pre><code>$ gem install chef\n</code></pre><p>We should setup a file structure that will help us organise our various Chef files. Opscode, the makers of Chef provide one. They call it simply the Chef Repository.</p>\n<pre><code>$ wget http://github.com/opscode/chef-repo/tarball/master\n$ tar -zxf master\n$ mv opscode-chef-repo* chef-repo\n$ rm master\n</code></pre><p>If we look inside the chef-repo directory we can see the following:</p>\n<pre><code>$ cd chef-repo/\n$ ls\nconfig  cookbooks  data_bags  environments  nodes  Rakefile  README.md  roles\n</code></pre><p>We can use the command <a href=\"https://docs.chef.io/knife.html\" target=\"_blank\" rel=\"external\">knife</a> to help us manage our cookbooks. First we should tell knife where to find our cookbooks directory.</p>\n<pre><code>$ mkdir chef-repo/.chef\n</code></pre><p>download /etc/chef-server/chef-validator.pem and  /etc/chef-server/admin.pem from chef-server to this chef-repo/.chef</p>\n<p>Edit chef-repo/.chef/knife.rb</p>\n<pre><code>log_level                :info\nlog_location             STDOUT\nnode_name                admin\nclient_key               &apos;chef-repo/.chef/admin.pem&apos;\nvalidation_client_name   &apos;chef-validator&apos;\nvalidation_key           &apos;chef-repo/.chef/chef-    validator.pem&apos;\nchef_server_url            &apos;https://server_domain_or_IP&apos;\ncache_type               &apos;BasicFile&apos;\ncookbook_path [ &apos;chef-repo/cookbooks&apos; ]\n</code></pre><p>Thats all :-)<br>chef-setup is over.</p>\n<p>Now you can check it from workstation with the below commands</p>\n<pre><code>knife client list\nknife node list\n</code></pre>","excerpt":"","more":"<p>Chef is a configuration management and automation platform from <a href=\"https://www.chef.io/\">Opscode</a>. Chef helps you describe your infrastructure with code. Because your infrastructure is managed with code, it can be automated, tested and reproduced with ease.</p>\n<p>Assumption: Ruby installed</p>\n<p>#Server Installation<br>The Chef server acts as a hub for configuration data. The Chef server stores cookbooks, the policies that are applied to nodes, and metadata that describes each registered node that is being managed by the chef-client. Nodes use the chef-client to ask the Chef server for configuration details, such as recipes, templates, and file distributions. The chef-client then does as much of the configuration work as possible on the nodes themselves (and not on the Chef server). This scalable approach distributes the configuration effort throughout the organization.</p>\n<p>Download chef-server package from here <a href=\"http://downloads.chef.io/chef-server/\">http://downloads.chef.io/chef-server/</a></p>\n<pre><code>$ wget https://web-dl.packagecloud.io/chef/stable/packages/ubuntu/trusty/chef-server-core_12.0.1-1_amd64.deb\n</code></pre><p>This will download the installation package that you can then install like this:</p>\n<pre><code>$ sudo apt-get update\n$ dpkg -i chef-server-core_12.0.1-1_amd64.deb\n</code></pre><p>This will install the server component on the machine.<br>It prints to the screen afterwards that you should run this next command to actually configure the service around your specific machine. This will configure everything automatically:</p>\n<pre><code>$ sudo chef-server-ctl reconfigure\n</code></pre><p>Verify chef-server installation by entering this command</p>\n<pre><code>$ sudo chef-server-ctl test\n</code></pre><p>Once this step is complete, the server should be up and running. You can access the web interface immediately by typing https:// followed by your servers domain name or IP address.</p>\n<pre><code>https://server_domain_or_IP\n</code></pre><p>Because the SSL certificates were signed by an authority that your browser does not recognize by default, you will see a warning message appear.<br>Click the Proceed anyway button to bypass this screen and access the login screen.</p>\n<p>The default login credentials are as follows:</p>\n<pre><code>Default Username: admin\nDefault Password: p@ssw0rd1\n</code></pre><p>##Workstation Installation</p>\n<p>Install chef using rubygems</p>\n<pre><code>$ gem install chef\n</code></pre><p>We should setup a file structure that will help us organise our various Chef files. Opscode, the makers of Chef provide one. They call it simply the Chef Repository.</p>\n<pre><code>$ wget http://github.com/opscode/chef-repo/tarball/master\n$ tar -zxf master\n$ mv opscode-chef-repo* chef-repo\n$ rm master\n</code></pre><p>If we look inside the chef-repo directory we can see the following:</p>\n<pre><code>$ cd chef-repo/\n$ ls\nconfig  cookbooks  data_bags  environments  nodes  Rakefile  README.md  roles\n</code></pre><p>We can use the command <a href=\"https://docs.chef.io/knife.html\">knife</a> to help us manage our cookbooks. First we should tell knife where to find our cookbooks directory.</p>\n<pre><code>$ mkdir chef-repo/.chef\n</code></pre><p>download /etc/chef-server/chef-validator.pem and  /etc/chef-server/admin.pem from chef-server to this chef-repo/.chef</p>\n<p>Edit chef-repo/.chef/knife.rb</p>\n<pre><code>log_level                :info\nlog_location             STDOUT\nnode_name                admin\nclient_key               &apos;chef-repo/.chef/admin.pem&apos;\nvalidation_client_name   &apos;chef-validator&apos;\nvalidation_key           &apos;chef-repo/.chef/chef-    validator.pem&apos;\nchef_server_url            &apos;https://server_domain_or_IP&apos;\ncache_type               &apos;BasicFile&apos;\ncookbook_path [ &apos;chef-repo/cookbooks&apos; ]\n</code></pre><p>Thats all :-)<br>chef-setup is over.</p>\n<p>Now you can check it from workstation with the below commands</p>\n<pre><code>knife client list\nknife node list\n</code></pre>"},{"title":"How to use Oauth in ROR","slug":"2015-03-13-how-to-use-oauth-in-ror","date_published":"2015-03-13T01:51:56.646Z","date_updated":"2015-03-27T06:07:05.947Z","_content":"\nI hate signing up for websites. Ive already signed up for so many, using different usernames, that going back to one of them and trying to remember my credentials is sometimes impossible. These days, most sites have begun offering alternative ways to sign up, by allowing you to use your Facebook, Twitter or even your Google account. Creating such an integration sometimes feels like a long task. But fear not, Oauth is here to help.\n\nIn this tutorial, im going to explain how to integrate these authentication providers into your Rails app. Here i use omniauth gem. Because Omniauth allows you to easily integrate more than sixty authentication providers, including Facebook, Google, Twitter and GitHub.\n\n####Step 1: Preparing your Appllication\n\nLets create a new Rails application and add the necessary gems. Im going to assume youve already installed Ruby on Rails 4.0 or latest using RubyGems.\n\nRun this command in your terminal\n\n`rails new omniauth-tutorial`\n\nNow open your Gemfile and reference the omniauth gem.\n\n`gem 'omniauth'`\n\nNext, per usual, run the bundle install command to install the gem.\n\n####Step 2: Creating a Provider\n\nIn order to add a provider to Omniauth, you will need to sign up as a developer on the providers site. Once youve signed up, youll be given two strings (sort of like a username and a password), that needs to be passed on to Omniauth.\n\n####Step 3: Add your Providers to the App\n\nCreate a new file under config/initializers called **omniauth.rb**. Were going to configure our authentication providers through this file.\n\nPaste the following code into the file we created earlier\n\n\tRails.application.config.middleware.use OmniAuth::Builder do\n \t\tprovider << provider >>, \n        Rails.configuration.<< provider >>_client_id,\n    \tRails.configuration.<< provider >>_secret_key , \n        << options >>\n\tend\n    \nFor example use the google provider then use the following\n\n\tRails.application.config.middleware.use OmniAuth::Builder do\n \t\tprovider :google_oauth2,\n    \tRails.configuration.google_client_id,     \n    \tRails.configuration.google_secret_key , { :scope =>\n    \t\"userinfo.profile, userinfo.email, devstorage.full_control,\n    \tcompute\", :prompt => 'consent'}\n\tend\n    \n####Step 4: Creating the Login Page\n\nLets create our sessions controller. Run the following code in your terminal to create a new sessions controller.\n\n`rails generate controller sessions`\n\nAnd add some actions in your controller.\nNext, open your **config/routes.rb** file and add this\n\n\tget   '/login', :to => 'sessions#new', :as => :login\n\tmatch '/auth/:provider/callback', :to => 'sessions#create'\n    \nLets break this down:\n\nThe first line is used to create a simple login form where the user will see a simple `Connect with Provider` link.\nThe second line is to catch the providers callback. After a user authorizes your app, the provider redirects the user to this url, so we can make use of their data.\n\nOpen your app/controllers/sessions_controller.rb file and write the create method, like so\n\n\tdef create\n      auth_hash = request.env['omniauth.auth']\n      render :text => auth_hash.inspect\n\tend\n    \nThis is used to make sure everything is working. Point your browser to [localhost:3000/auth/provider](http://) and youll be redirected to provider page so you can authorize your app. Authorize it, and you will be redirected back to your app and see a hash with some information.\n\n####Step 5: Creating the User Model\n\nIn the Rails console (rails console), create the new model.\n\n`rails generate model User name:string email:string`\n\n For now, our user model will only have a name and an email. With that out of the way, we need a way to recognize the user the next time they log in.\n\n####Step 6: Adding create action on controller\n\nLets add some code to our sessions controller so that it logs a user in or signs them up, depending on the case. Open **app/controllers/sessions_controller.rb** and modify the create method, like so:\n\n\tdef create\n \t auth_hash = request.env['omniauth.auth']\n \t user_identity = User.find_by_email(auth_hash[\"info\"] [\"email\"])\n \tif user_identity\n       render :text => \"Welcome back #{user_identity.user.name}! You have already signed up.\"\n \telse\n       user = User.new :name => auth_hash[\"info\"][\"name\"], :email => auth_hash[\"info\"][\"email\"]\n       user.save\n       render :text => \"Hi #{user.name}! You've signed up.\"\n \tend\n\tend\n    \nWe check whether an authorization exists for that provider and that email. If one exists, we welcome our user back.\n\nIf no authorization exists, we sign the user up. We create a new user with the name and email that the provider gives us, and we associate an authorization with the provider.\nGive it a test! Go to [localhost:3000/auth/provider](http://) and you should see Youve signed up. If you refresh the page, you should now see Welcome back.\n\n####Step 7: Create html\n\nOpen `app/views/sessions/new.html.erb` and add\n\n\t<%= link_to \"Connect\", \"/auth/<< provider >>\" %>\n","source":"_posts/2015-03-13-how-to-use-oauth-in-ror.md","raw":"---\ntitle: How to use Oauth in ROR\nslug: how-to-use-oauth-in-ror\ndate_published: 2015-03-13T07:21:56.646Z\ndate_updated:   2015-03-27T11:37:05.947Z\ntags: expert, Ruby on Rails, oauth\n---\n\nI hate signing up for websites. Ive already signed up for so many, using different usernames, that going back to one of them and trying to remember my credentials is sometimes impossible. These days, most sites have begun offering alternative ways to sign up, by allowing you to use your Facebook, Twitter or even your Google account. Creating such an integration sometimes feels like a long task. But fear not, Oauth is here to help.\n\nIn this tutorial, im going to explain how to integrate these authentication providers into your Rails app. Here i use omniauth gem. Because Omniauth allows you to easily integrate more than sixty authentication providers, including Facebook, Google, Twitter and GitHub.\n\n####Step 1: Preparing your Appllication\n\nLets create a new Rails application and add the necessary gems. Im going to assume youve already installed Ruby on Rails 4.0 or latest using RubyGems.\n\nRun this command in your terminal\n\n`rails new omniauth-tutorial`\n\nNow open your Gemfile and reference the omniauth gem.\n\n`gem 'omniauth'`\n\nNext, per usual, run the bundle install command to install the gem.\n\n####Step 2: Creating a Provider\n\nIn order to add a provider to Omniauth, you will need to sign up as a developer on the providers site. Once youve signed up, youll be given two strings (sort of like a username and a password), that needs to be passed on to Omniauth.\n\n####Step 3: Add your Providers to the App\n\nCreate a new file under config/initializers called **omniauth.rb**. Were going to configure our authentication providers through this file.\n\nPaste the following code into the file we created earlier\n\n\tRails.application.config.middleware.use OmniAuth::Builder do\n \t\tprovider << provider >>, \n        Rails.configuration.<< provider >>_client_id,\n    \tRails.configuration.<< provider >>_secret_key , \n        << options >>\n\tend\n    \nFor example use the google provider then use the following\n\n\tRails.application.config.middleware.use OmniAuth::Builder do\n \t\tprovider :google_oauth2,\n    \tRails.configuration.google_client_id,     \n    \tRails.configuration.google_secret_key , { :scope =>\n    \t\"userinfo.profile, userinfo.email, devstorage.full_control,\n    \tcompute\", :prompt => 'consent'}\n\tend\n    \n####Step 4: Creating the Login Page\n\nLets create our sessions controller. Run the following code in your terminal to create a new sessions controller.\n\n`rails generate controller sessions`\n\nAnd add some actions in your controller.\nNext, open your **config/routes.rb** file and add this\n\n\tget   '/login', :to => 'sessions#new', :as => :login\n\tmatch '/auth/:provider/callback', :to => 'sessions#create'\n    \nLets break this down:\n\nThe first line is used to create a simple login form where the user will see a simple `Connect with Provider` link.\nThe second line is to catch the providers callback. After a user authorizes your app, the provider redirects the user to this url, so we can make use of their data.\n\nOpen your app/controllers/sessions_controller.rb file and write the create method, like so\n\n\tdef create\n      auth_hash = request.env['omniauth.auth']\n      render :text => auth_hash.inspect\n\tend\n    \nThis is used to make sure everything is working. Point your browser to [localhost:3000/auth/provider](http://) and youll be redirected to provider page so you can authorize your app. Authorize it, and you will be redirected back to your app and see a hash with some information.\n\n####Step 5: Creating the User Model\n\nIn the Rails console (rails console), create the new model.\n\n`rails generate model User name:string email:string`\n\n For now, our user model will only have a name and an email. With that out of the way, we need a way to recognize the user the next time they log in.\n\n####Step 6: Adding create action on controller\n\nLets add some code to our sessions controller so that it logs a user in or signs them up, depending on the case. Open **app/controllers/sessions_controller.rb** and modify the create method, like so:\n\n\tdef create\n \t auth_hash = request.env['omniauth.auth']\n \t user_identity = User.find_by_email(auth_hash[\"info\"] [\"email\"])\n \tif user_identity\n       render :text => \"Welcome back #{user_identity.user.name}! You have already signed up.\"\n \telse\n       user = User.new :name => auth_hash[\"info\"][\"name\"], :email => auth_hash[\"info\"][\"email\"]\n       user.save\n       render :text => \"Hi #{user.name}! You've signed up.\"\n \tend\n\tend\n    \nWe check whether an authorization exists for that provider and that email. If one exists, we welcome our user back.\n\nIf no authorization exists, we sign the user up. We create a new user with the name and email that the provider gives us, and we associate an authorization with the provider.\nGive it a test! Go to [localhost:3000/auth/provider](http://) and you should see Youve signed up. If you refresh the page, you should now see Welcome back.\n\n####Step 7: Create html\n\nOpen `app/views/sessions/new.html.erb` and add\n\n\t<%= link_to \"Connect\", \"/auth/<< provider >>\" %>\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzairb0006drgbho24hq3x","content":"<p>I hate signing up for websites. Ive already signed up for so many, using different usernames, that going back to one of them and trying to remember my credentials is sometimes impossible. These days, most sites have begun offering alternative ways to sign up, by allowing you to use your Facebook, Twitter or even your Google account. Creating such an integration sometimes feels like a long task. But fear not, Oauth is here to help.</p>\n<p>In this tutorial, im going to explain how to integrate these authentication providers into your Rails app. Here i use omniauth gem. Because Omniauth allows you to easily integrate more than sixty authentication providers, including Facebook, Google, Twitter and GitHub.</p>\n<p>####Step 1: Preparing your Appllication</p>\n<p>Lets create a new Rails application and add the necessary gems. Im going to assume youve already installed Ruby on Rails 4.0 or latest using RubyGems.</p>\n<p>Run this command in your terminal</p>\n<p><code>rails new omniauth-tutorial</code></p>\n<p>Now open your Gemfile and reference the omniauth gem.</p>\n<p><code>gem &#39;omniauth&#39;</code></p>\n<p>Next, per usual, run the bundle install command to install the gem.</p>\n<p>####Step 2: Creating a Provider</p>\n<p>In order to add a provider to Omniauth, you will need to sign up as a developer on the providers site. Once youve signed up, youll be given two strings (sort of like a username and a password), that needs to be passed on to Omniauth.</p>\n<p>####Step 3: Add your Providers to the App</p>\n<p>Create a new file under config/initializers called <strong>omniauth.rb</strong>. Were going to configure our authentication providers through this file.</p>\n<p>Paste the following code into the file we created earlier</p>\n<pre><code>Rails.application.config.middleware.use OmniAuth::Builder do\n     provider &lt;&lt; provider &gt;&gt;, \n    Rails.configuration.&lt;&lt; provider &gt;&gt;_client_id,\n    Rails.configuration.&lt;&lt; provider &gt;&gt;_secret_key , \n    &lt;&lt; options &gt;&gt;\nend\n</code></pre><p>For example use the google provider then use the following</p>\n<pre><code>Rails.application.config.middleware.use OmniAuth::Builder do\n     provider :google_oauth2,\n    Rails.configuration.google_client_id,     \n    Rails.configuration.google_secret_key , { :scope =&gt;\n    &quot;userinfo.profile, userinfo.email, devstorage.full_control,\n    compute&quot;, :prompt =&gt; &apos;consent&apos;}\nend\n</code></pre><p>####Step 4: Creating the Login Page</p>\n<p>Lets create our sessions controller. Run the following code in your terminal to create a new sessions controller.</p>\n<p><code>rails generate controller sessions</code></p>\n<p>And add some actions in your controller.<br>Next, open your <strong>config/routes.rb</strong> file and add this</p>\n<pre><code>get   &apos;/login&apos;, :to =&gt; &apos;sessions#new&apos;, :as =&gt; :login\nmatch &apos;/auth/:provider/callback&apos;, :to =&gt; &apos;sessions#create&apos;\n</code></pre><p>Lets break this down:</p>\n<p>The first line is used to create a simple login form where the user will see a simple <code>Connect with Provider</code> link.<br>The second line is to catch the providers callback. After a user authorizes your app, the provider redirects the user to this url, so we can make use of their data.</p>\n<p>Open your app/controllers/sessions_controller.rb file and write the create method, like so</p>\n<pre><code>def create\n  auth_hash = request.env[&apos;omniauth.auth&apos;]\n  render :text =&gt; auth_hash.inspect\nend\n</code></pre><p>This is used to make sure everything is working. Point your browser to <a href=\"http://\" target=\"_blank\" rel=\"external\">localhost:3000/auth/provider</a> and youll be redirected to provider page so you can authorize your app. Authorize it, and you will be redirected back to your app and see a hash with some information.</p>\n<p>####Step 5: Creating the User Model</p>\n<p>In the Rails console (rails console), create the new model.</p>\n<p><code>rails generate model User name:string email:string</code></p>\n<p> For now, our user model will only have a name and an email. With that out of the way, we need a way to recognize the user the next time they log in.</p>\n<p>####Step 6: Adding create action on controller</p>\n<p>Lets add some code to our sessions controller so that it logs a user in or signs them up, depending on the case. Open <strong>app/controllers/sessions_controller.rb</strong> and modify the create method, like so:</p>\n<pre><code>def create\n  auth_hash = request.env[&apos;omniauth.auth&apos;]\n  user_identity = User.find_by_email(auth_hash[&quot;info&quot;] [&quot;email&quot;])\n if user_identity\n   render :text =&gt; &quot;Welcome back #{user_identity.user.name}! You have already signed up.&quot;\n else\n   user = User.new :name =&gt; auth_hash[&quot;info&quot;][&quot;name&quot;], :email =&gt; auth_hash[&quot;info&quot;][&quot;email&quot;]\n   user.save\n   render :text =&gt; &quot;Hi #{user.name}! You&apos;ve signed up.&quot;\n end\nend\n</code></pre><p>We check whether an authorization exists for that provider and that email. If one exists, we welcome our user back.</p>\n<p>If no authorization exists, we sign the user up. We create a new user with the name and email that the provider gives us, and we associate an authorization with the provider.<br>Give it a test! Go to <a href=\"http://\" target=\"_blank\" rel=\"external\">localhost:3000/auth/provider</a> and you should see Youve signed up. If you refresh the page, you should now see Welcome back.</p>\n<p>####Step 7: Create html</p>\n<p>Open <code>app/views/sessions/new.html.erb</code> and add</p>\n<pre><code>&lt;%= link_to &quot;Connect&quot;, &quot;/auth/&lt;&lt; provider &gt;&gt;&quot; %&gt;\n</code></pre>","excerpt":"","more":"<p>I hate signing up for websites. Ive already signed up for so many, using different usernames, that going back to one of them and trying to remember my credentials is sometimes impossible. These days, most sites have begun offering alternative ways to sign up, by allowing you to use your Facebook, Twitter or even your Google account. Creating such an integration sometimes feels like a long task. But fear not, Oauth is here to help.</p>\n<p>In this tutorial, im going to explain how to integrate these authentication providers into your Rails app. Here i use omniauth gem. Because Omniauth allows you to easily integrate more than sixty authentication providers, including Facebook, Google, Twitter and GitHub.</p>\n<p>####Step 1: Preparing your Appllication</p>\n<p>Lets create a new Rails application and add the necessary gems. Im going to assume youve already installed Ruby on Rails 4.0 or latest using RubyGems.</p>\n<p>Run this command in your terminal</p>\n<p><code>rails new omniauth-tutorial</code></p>\n<p>Now open your Gemfile and reference the omniauth gem.</p>\n<p><code>gem &#39;omniauth&#39;</code></p>\n<p>Next, per usual, run the bundle install command to install the gem.</p>\n<p>####Step 2: Creating a Provider</p>\n<p>In order to add a provider to Omniauth, you will need to sign up as a developer on the providers site. Once youve signed up, youll be given two strings (sort of like a username and a password), that needs to be passed on to Omniauth.</p>\n<p>####Step 3: Add your Providers to the App</p>\n<p>Create a new file under config/initializers called <strong>omniauth.rb</strong>. Were going to configure our authentication providers through this file.</p>\n<p>Paste the following code into the file we created earlier</p>\n<pre><code>Rails.application.config.middleware.use OmniAuth::Builder do\n     provider &lt;&lt; provider &gt;&gt;, \n    Rails.configuration.&lt;&lt; provider &gt;&gt;_client_id,\n    Rails.configuration.&lt;&lt; provider &gt;&gt;_secret_key , \n    &lt;&lt; options &gt;&gt;\nend\n</code></pre><p>For example use the google provider then use the following</p>\n<pre><code>Rails.application.config.middleware.use OmniAuth::Builder do\n     provider :google_oauth2,\n    Rails.configuration.google_client_id,     \n    Rails.configuration.google_secret_key , { :scope =&gt;\n    &quot;userinfo.profile, userinfo.email, devstorage.full_control,\n    compute&quot;, :prompt =&gt; &apos;consent&apos;}\nend\n</code></pre><p>####Step 4: Creating the Login Page</p>\n<p>Lets create our sessions controller. Run the following code in your terminal to create a new sessions controller.</p>\n<p><code>rails generate controller sessions</code></p>\n<p>And add some actions in your controller.<br>Next, open your <strong>config/routes.rb</strong> file and add this</p>\n<pre><code>get   &apos;/login&apos;, :to =&gt; &apos;sessions#new&apos;, :as =&gt; :login\nmatch &apos;/auth/:provider/callback&apos;, :to =&gt; &apos;sessions#create&apos;\n</code></pre><p>Lets break this down:</p>\n<p>The first line is used to create a simple login form where the user will see a simple <code>Connect with Provider</code> link.<br>The second line is to catch the providers callback. After a user authorizes your app, the provider redirects the user to this url, so we can make use of their data.</p>\n<p>Open your app/controllers/sessions_controller.rb file and write the create method, like so</p>\n<pre><code>def create\n  auth_hash = request.env[&apos;omniauth.auth&apos;]\n  render :text =&gt; auth_hash.inspect\nend\n</code></pre><p>This is used to make sure everything is working. Point your browser to <a href=\"http://\">localhost:3000/auth/provider</a> and youll be redirected to provider page so you can authorize your app. Authorize it, and you will be redirected back to your app and see a hash with some information.</p>\n<p>####Step 5: Creating the User Model</p>\n<p>In the Rails console (rails console), create the new model.</p>\n<p><code>rails generate model User name:string email:string</code></p>\n<p> For now, our user model will only have a name and an email. With that out of the way, we need a way to recognize the user the next time they log in.</p>\n<p>####Step 6: Adding create action on controller</p>\n<p>Lets add some code to our sessions controller so that it logs a user in or signs them up, depending on the case. Open <strong>app/controllers/sessions_controller.rb</strong> and modify the create method, like so:</p>\n<pre><code>def create\n  auth_hash = request.env[&apos;omniauth.auth&apos;]\n  user_identity = User.find_by_email(auth_hash[&quot;info&quot;] [&quot;email&quot;])\n if user_identity\n   render :text =&gt; &quot;Welcome back #{user_identity.user.name}! You have already signed up.&quot;\n else\n   user = User.new :name =&gt; auth_hash[&quot;info&quot;][&quot;name&quot;], :email =&gt; auth_hash[&quot;info&quot;][&quot;email&quot;]\n   user.save\n   render :text =&gt; &quot;Hi #{user.name}! You&apos;ve signed up.&quot;\n end\nend\n</code></pre><p>We check whether an authorization exists for that provider and that email. If one exists, we welcome our user back.</p>\n<p>If no authorization exists, we sign the user up. We create a new user with the name and email that the provider gives us, and we associate an authorization with the provider.<br>Give it a test! Go to <a href=\"http://\">localhost:3000/auth/provider</a> and you should see Youve signed up. If you refresh the page, you should now see Welcome back.</p>\n<p>####Step 7: Create html</p>\n<p>Open <code>app/views/sessions/new.html.erb</code> and add</p>\n<pre><code>&lt;%= link_to &quot;Connect&quot;, &quot;/auth/&lt;&lt; provider &gt;&gt;&quot; %&gt;\n</code></pre>"},{"title":"Setting up Golang","slug":"2015-03-13-setting-up-golang","date_published":"2015-03-13T01:51:36.209Z","date_updated":"2015-08-12T02:31:44.396Z","_content":"\n###Introduction\n\nGo, also commonly referred to as golang, is a programming language initially developed at Google in 2007 by `Robert Griesemer, Rob Pike, and Ken Thompson`.\n\n>**Go** is: \n>\n open source\n>\n concurrent \n>\n garbage-collected \n>\n efficient \n>\n scalable \n>\n simple \n>\n fun \n>\n boring (to some) \n\n[http://golang.org](http://golang.org)\n\n####Setup\n\nThere are many ways to configure the Go development environment on your computer, you can choose any one you like. But i suggest following ways.\n\n######Way 1 : Install Go Package\n\nThe golang Debian package may have already made its way into your Ubuntu distribution. Try this:\n\n>`$ sudo apt-get install golang`\n\nexport the settings youre gonna need to ~/.bashrc file:\n\n>`$ export GOROOT=/usr/lib/go`\n>\n`$ export GOBIN=/usr/bin/go`\n\n\n######Way 2 : From Binary\n\nDownload [golang 1.4+ amd64 linux](https://storage.googleapis.com/golang/go1.4.2.linux-amd64.tar.gz),  create a `~/golang` directory, and untar into that directory.\n\n>`$ mkdir ~/golang`\n>\n`$ cd ~/golang`\n>\n`$ wget https://storage.googleapis.com/golang/go1.4.2.linux-amd64.tar.gz`\n>\n`$ tar -xzf go1.4.2.linux-amd64.tar.gz`\n\nNow setup Go binary path. Use the **$GOROOT** and **$PATH** environment variables. In order to make these variables persist through logins/reboots/etc, add the following lines to ~/.bashrc file:\n\n>`$ export GOROOT=$HOME/golang/go`\n>\n`$ export PATH=$PATH:$GOROOT/bin`\n\n######Way 3 : From Source\n\nGo will install to a directory named go. Change to the directory that will be its parent and make sure the go directory does not exist. Then clone the repository and check out the latest release tag:\n\n>`$ git clone https://go.googlesource.com/go`\n>\n`$ cd go`\n>\n`$ git checkout go1.4.2`\n\n(Optional) Switch to the master branch\n\nIf you intend to modify the go source code, and contribute your changes to the project, then move your repository off the release branch, and onto the master (development) branch. Otherwise, skip this step.\n\n>`$ git checkout master`\n\nTo build the Go distribution, run\n\n>`$ cd go/src`\n>\n`$ ./all.bash`\n\nFinally set the environment variables on ~/.bashrc file\n\n>`$ export GOROOT=$HOME/golang/go`\n>\n`$ export PATH=$PATH:$GOROOT/bin`\n\nTest your installation\n\nTry this,\n\n>`$ go version`\n>\ngo version go1.4.2 linux/amd64\n\n\n####Set up your work environment\n\n######Introducing workspaces\n\nYour Go code is kept in a workspace. A workspace contains many source repositories (git, hg). The Go tool understands the layout of a workspace. You don't need a Makefile. A workspace is a directory hierarchy with three directories at its root:\n\n>**src** contains Go source files organized into packages (one package per directory),\n>\n**pkg** contains package objects, and\n>\n**bin** contains executable commands.\n\nThe go tool builds source packages and installs the resulting binaries to the pkg and bin directories.\n\nThe src subdirectory typically contains multiple version control repositories (such as for Git or Mercurial) that track the development of one or more source packages.\n\nTo give you an idea of how a workspace looks in practice, here's an example:\n\n\tbin/\n            hello                   # command executable\n            outyet                  # command executable\n\tpkg/\n            linux_amd64/\n                    github.com/golang/example/\n                            stringutil.a           # package object\n\tsrc/\n            github.com/golang/example/\n                    .git/             # Git repository metadata\n                    hello/\n                        hello.go      # command source\n                    outyet/\n                        main.go       # command source\n                        main_test.go  # test source\n                    stringutil/\n                        reverse.go    # package source\n                        reverse_test.go   # test source\n\nThis workspace contains one repository (example) comprising two commands (hello and outyet) and one library (stringutil).\n\nA typical workspace would contain many source repositories containing many packages and commands. Most Go programmers keep all their Go source code and dependencies in a single workspace.\n\nGo commands all rely on one important environment variable which is called `$GOPATH`. Notice that this is not the `$GOROOT` where Go is installed. This variable points to the workspace of Go in your computer.\n\n######The GOPATH environment variable\n\nThe GOPATH environment variable specifies the location of your workspace. It is likely the only environment variable you'll need to set when developing Go code.\n\nTo get started, create a workspace directory and set GOPATH accordingly. Your \nworkspace can be located wherever you like, but we'll use $HOME/go in this document.\nNote that this must not be the same path as your Go installation.\n\n>`$ mkdir $HOME/go`\n>\n`$ export GOPATH=$HOME/go`\n\nFor convenience, add the workspace's bin subdirectory to your PATH:\n\n>`$ export PATH=$PATH:$GOPATH/bin`\n\n\n######Testing with Workspace\n\nTo compile and run a simple program, first choose a package path (we'll use github.com/user/hello) and create a corresponding package directory inside your workspace:\n\n>`$ mkdir $GOPATH/src/github.com/user/hello`\n\nNext, create a file named hello.go inside that directory, containing the following Go code.\n\n\tpackage main\n\timport \"fmt\"\n\tfunc main() {\n    \tfmt.Printf(\"Hello, world.\\n\")\n\t}\n\nNow you can build and install that program with the go tool:\n\n>`$ go install github.com/user/hello`\n\nNote that you can run this command from anywhere on your system. The go tool finds the source code by looking for the **github.com/user/hello** package inside the workspace specified by GOPATH.\n\nYou can also omit the package path if you run go install from the package directory:\n\n>`$ cd $GOPATH/src/github.com/user/hello`\n>\n`$ go install`\n\nThis command builds the hello command, producing an executable binary. It then installs that binary to the workspace's bin directory as hello (or, under Windows, hello.exe). In our example, that will be **$GOPATH/bin/hello**, which is **$HOME/go/bin/hello**.\n\nThe go tool will only print output when an error occurs, so if these commands produce no output they have executed successfully.\n\nYou can now run the program by typing its full path at the command line:\n\n>`$ $GOPATH/bin/hello`\n>\nHello, world.\n\nIf you see the \"Hello, world\" message then your Go installation is working\n\n","source":"_posts/2015-03-13-setting-up-golang.md","raw":"---\ntitle: Setting up Golang\nslug: setting-up-golang\ndate_published: 2015-03-13T07:21:36.209Z\ndate_updated:   2015-08-12T08:01:44.396Z\n---\n\n###Introduction\n\nGo, also commonly referred to as golang, is a programming language initially developed at Google in 2007 by `Robert Griesemer, Rob Pike, and Ken Thompson`.\n\n>**Go** is: \n>\n open source\n>\n concurrent \n>\n garbage-collected \n>\n efficient \n>\n scalable \n>\n simple \n>\n fun \n>\n boring (to some) \n\n[http://golang.org](http://golang.org)\n\n####Setup\n\nThere are many ways to configure the Go development environment on your computer, you can choose any one you like. But i suggest following ways.\n\n######Way 1 : Install Go Package\n\nThe golang Debian package may have already made its way into your Ubuntu distribution. Try this:\n\n>`$ sudo apt-get install golang`\n\nexport the settings youre gonna need to ~/.bashrc file:\n\n>`$ export GOROOT=/usr/lib/go`\n>\n`$ export GOBIN=/usr/bin/go`\n\n\n######Way 2 : From Binary\n\nDownload [golang 1.4+ amd64 linux](https://storage.googleapis.com/golang/go1.4.2.linux-amd64.tar.gz),  create a `~/golang` directory, and untar into that directory.\n\n>`$ mkdir ~/golang`\n>\n`$ cd ~/golang`\n>\n`$ wget https://storage.googleapis.com/golang/go1.4.2.linux-amd64.tar.gz`\n>\n`$ tar -xzf go1.4.2.linux-amd64.tar.gz`\n\nNow setup Go binary path. Use the **$GOROOT** and **$PATH** environment variables. In order to make these variables persist through logins/reboots/etc, add the following lines to ~/.bashrc file:\n\n>`$ export GOROOT=$HOME/golang/go`\n>\n`$ export PATH=$PATH:$GOROOT/bin`\n\n######Way 3 : From Source\n\nGo will install to a directory named go. Change to the directory that will be its parent and make sure the go directory does not exist. Then clone the repository and check out the latest release tag:\n\n>`$ git clone https://go.googlesource.com/go`\n>\n`$ cd go`\n>\n`$ git checkout go1.4.2`\n\n(Optional) Switch to the master branch\n\nIf you intend to modify the go source code, and contribute your changes to the project, then move your repository off the release branch, and onto the master (development) branch. Otherwise, skip this step.\n\n>`$ git checkout master`\n\nTo build the Go distribution, run\n\n>`$ cd go/src`\n>\n`$ ./all.bash`\n\nFinally set the environment variables on ~/.bashrc file\n\n>`$ export GOROOT=$HOME/golang/go`\n>\n`$ export PATH=$PATH:$GOROOT/bin`\n\nTest your installation\n\nTry this,\n\n>`$ go version`\n>\ngo version go1.4.2 linux/amd64\n\n\n####Set up your work environment\n\n######Introducing workspaces\n\nYour Go code is kept in a workspace. A workspace contains many source repositories (git, hg). The Go tool understands the layout of a workspace. You don't need a Makefile. A workspace is a directory hierarchy with three directories at its root:\n\n>**src** contains Go source files organized into packages (one package per directory),\n>\n**pkg** contains package objects, and\n>\n**bin** contains executable commands.\n\nThe go tool builds source packages and installs the resulting binaries to the pkg and bin directories.\n\nThe src subdirectory typically contains multiple version control repositories (such as for Git or Mercurial) that track the development of one or more source packages.\n\nTo give you an idea of how a workspace looks in practice, here's an example:\n\n\tbin/\n            hello                   # command executable\n            outyet                  # command executable\n\tpkg/\n            linux_amd64/\n                    github.com/golang/example/\n                            stringutil.a           # package object\n\tsrc/\n            github.com/golang/example/\n                    .git/             # Git repository metadata\n                    hello/\n                        hello.go      # command source\n                    outyet/\n                        main.go       # command source\n                        main_test.go  # test source\n                    stringutil/\n                        reverse.go    # package source\n                        reverse_test.go   # test source\n\nThis workspace contains one repository (example) comprising two commands (hello and outyet) and one library (stringutil).\n\nA typical workspace would contain many source repositories containing many packages and commands. Most Go programmers keep all their Go source code and dependencies in a single workspace.\n\nGo commands all rely on one important environment variable which is called `$GOPATH`. Notice that this is not the `$GOROOT` where Go is installed. This variable points to the workspace of Go in your computer.\n\n######The GOPATH environment variable\n\nThe GOPATH environment variable specifies the location of your workspace. It is likely the only environment variable you'll need to set when developing Go code.\n\nTo get started, create a workspace directory and set GOPATH accordingly. Your \nworkspace can be located wherever you like, but we'll use $HOME/go in this document.\nNote that this must not be the same path as your Go installation.\n\n>`$ mkdir $HOME/go`\n>\n`$ export GOPATH=$HOME/go`\n\nFor convenience, add the workspace's bin subdirectory to your PATH:\n\n>`$ export PATH=$PATH:$GOPATH/bin`\n\n\n######Testing with Workspace\n\nTo compile and run a simple program, first choose a package path (we'll use github.com/user/hello) and create a corresponding package directory inside your workspace:\n\n>`$ mkdir $GOPATH/src/github.com/user/hello`\n\nNext, create a file named hello.go inside that directory, containing the following Go code.\n\n\tpackage main\n\timport \"fmt\"\n\tfunc main() {\n    \tfmt.Printf(\"Hello, world.\\n\")\n\t}\n\nNow you can build and install that program with the go tool:\n\n>`$ go install github.com/user/hello`\n\nNote that you can run this command from anywhere on your system. The go tool finds the source code by looking for the **github.com/user/hello** package inside the workspace specified by GOPATH.\n\nYou can also omit the package path if you run go install from the package directory:\n\n>`$ cd $GOPATH/src/github.com/user/hello`\n>\n`$ go install`\n\nThis command builds the hello command, producing an executable binary. It then installs that binary to the workspace's bin directory as hello (or, under Windows, hello.exe). In our example, that will be **$GOPATH/bin/hello**, which is **$HOME/go/bin/hello**.\n\nThe go tool will only print output when an error occurs, so if these commands produce no output they have executed successfully.\n\nYou can now run the program by typing its full path at the command line:\n\n>`$ $GOPATH/bin/hello`\n>\nHello, world.\n\nIf you see the \"Hello, world\" message then your Go installation is working\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:58.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzairc0007drgbkv81vec6","content":"<p>###Introduction</p>\n<p>Go, also commonly referred to as golang, is a programming language initially developed at Google in 2007 by <code>Robert Griesemer, Rob Pike, and Ken Thompson</code>.</p>\n<blockquote>\n<p><strong>Go</strong> is: </p>\n<p> open source</p>\n<p> concurrent </p>\n<p> garbage-collected </p>\n<p> efficient </p>\n<p> scalable </p>\n<p> simple </p>\n<p> fun </p>\n<p> boring (to some) </p>\n</blockquote>\n<p><a href=\"http://golang.org\" target=\"_blank\" rel=\"external\">http://golang.org</a></p>\n<p>####Setup</p>\n<p>There are many ways to configure the Go development environment on your computer, you can choose any one you like. But i suggest following ways.</p>\n<p>######Way 1 : Install Go Package</p>\n<p>The golang Debian package may have already made its way into your Ubuntu distribution. Try this:</p>\n<blockquote>\n<p><code>$ sudo apt-get install golang</code></p>\n</blockquote>\n<p>export the settings youre gonna need to ~/.bashrc file:</p>\n<blockquote>\n<p><code>$ export GOROOT=/usr/lib/go</code></p>\n<p><code>$ export GOBIN=/usr/bin/go</code></p>\n</blockquote>\n<p>######Way 2 : From Binary</p>\n<p>Download <a href=\"https://storage.googleapis.com/golang/go1.4.2.linux-amd64.tar.gz\" target=\"_blank\" rel=\"external\">golang 1.4+ amd64 linux</a>,  create a <code>~/golang</code> directory, and untar into that directory.</p>\n<blockquote>\n<p><code>$ mkdir ~/golang</code></p>\n<p><code>$ cd ~/golang</code></p>\n<p><code>$ wget https://storage.googleapis.com/golang/go1.4.2.linux-amd64.tar.gz</code></p>\n<p><code>$ tar -xzf go1.4.2.linux-amd64.tar.gz</code></p>\n</blockquote>\n<p>Now setup Go binary path. Use the <strong>$GOROOT</strong> and <strong>$PATH</strong> environment variables. In order to make these variables persist through logins/reboots/etc, add the following lines to ~/.bashrc file:</p>\n<blockquote>\n<p><code>$ export GOROOT=$HOME/golang/go</code></p>\n<p><code>$ export PATH=$PATH:$GOROOT/bin</code></p>\n</blockquote>\n<p>######Way 3 : From Source</p>\n<p>Go will install to a directory named go. Change to the directory that will be its parent and make sure the go directory does not exist. Then clone the repository and check out the latest release tag:</p>\n<blockquote>\n<p><code>$ git clone https://go.googlesource.com/go</code></p>\n<p><code>$ cd go</code></p>\n<p><code>$ git checkout go1.4.2</code></p>\n</blockquote>\n<p>(Optional) Switch to the master branch</p>\n<p>If you intend to modify the go source code, and contribute your changes to the project, then move your repository off the release branch, and onto the master (development) branch. Otherwise, skip this step.</p>\n<blockquote>\n<p><code>$ git checkout master</code></p>\n</blockquote>\n<p>To build the Go distribution, run</p>\n<blockquote>\n<p><code>$ cd go/src</code></p>\n<p><code>$ ./all.bash</code></p>\n</blockquote>\n<p>Finally set the environment variables on ~/.bashrc file</p>\n<blockquote>\n<p><code>$ export GOROOT=$HOME/golang/go</code></p>\n<p><code>$ export PATH=$PATH:$GOROOT/bin</code></p>\n</blockquote>\n<p>Test your installation</p>\n<p>Try this,</p>\n<blockquote>\n<p><code>$ go version</code></p>\n<p>go version go1.4.2 linux/amd64</p>\n</blockquote>\n<p>####Set up your work environment</p>\n<p>######Introducing workspaces</p>\n<p>Your Go code is kept in a workspace. A workspace contains many source repositories (git, hg). The Go tool understands the layout of a workspace. You dont need a Makefile. A workspace is a directory hierarchy with three directories at its root:</p>\n<blockquote>\n<p><strong>src</strong> contains Go source files organized into packages (one package per directory),</p>\n<p><strong>pkg</strong> contains package objects, and</p>\n<p><strong>bin</strong> contains executable commands.</p>\n</blockquote>\n<p>The go tool builds source packages and installs the resulting binaries to the pkg and bin directories.</p>\n<p>The src subdirectory typically contains multiple version control repositories (such as for Git or Mercurial) that track the development of one or more source packages.</p>\n<p>To give you an idea of how a workspace looks in practice, heres an example:</p>\n<pre><code>bin/\n        hello                   # command executable\n        outyet                  # command executable\npkg/\n        linux_amd64/\n                github.com/golang/example/\n                        stringutil.a           # package object\nsrc/\n        github.com/golang/example/\n                .git/             # Git repository metadata\n                hello/\n                    hello.go      # command source\n                outyet/\n                    main.go       # command source\n                    main_test.go  # test source\n                stringutil/\n                    reverse.go    # package source\n                    reverse_test.go   # test source\n</code></pre><p>This workspace contains one repository (example) comprising two commands (hello and outyet) and one library (stringutil).</p>\n<p>A typical workspace would contain many source repositories containing many packages and commands. Most Go programmers keep all their Go source code and dependencies in a single workspace.</p>\n<p>Go commands all rely on one important environment variable which is called <code>$GOPATH</code>. Notice that this is not the <code>$GOROOT</code> where Go is installed. This variable points to the workspace of Go in your computer.</p>\n<p>######The GOPATH environment variable</p>\n<p>The GOPATH environment variable specifies the location of your workspace. It is likely the only environment variable youll need to set when developing Go code.</p>\n<p>To get started, create a workspace directory and set GOPATH accordingly. Your<br>workspace can be located wherever you like, but well use $HOME/go in this document.<br>Note that this must not be the same path as your Go installation.</p>\n<blockquote>\n<p><code>$ mkdir $HOME/go</code></p>\n<p><code>$ export GOPATH=$HOME/go</code></p>\n</blockquote>\n<p>For convenience, add the workspaces bin subdirectory to your PATH:</p>\n<blockquote>\n<p><code>$ export PATH=$PATH:$GOPATH/bin</code></p>\n</blockquote>\n<p>######Testing with Workspace</p>\n<p>To compile and run a simple program, first choose a package path (well use github.com/user/hello) and create a corresponding package directory inside your workspace:</p>\n<blockquote>\n<p><code>$ mkdir $GOPATH/src/github.com/user/hello</code></p>\n</blockquote>\n<p>Next, create a file named hello.go inside that directory, containing the following Go code.</p>\n<pre><code>package main\nimport &quot;fmt&quot;\nfunc main() {\n    fmt.Printf(&quot;Hello, world.\\n&quot;)\n}\n</code></pre><p>Now you can build and install that program with the go tool:</p>\n<blockquote>\n<p><code>$ go install github.com/user/hello</code></p>\n</blockquote>\n<p>Note that you can run this command from anywhere on your system. The go tool finds the source code by looking for the <strong>github.com/user/hello</strong> package inside the workspace specified by GOPATH.</p>\n<p>You can also omit the package path if you run go install from the package directory:</p>\n<blockquote>\n<p><code>$ cd $GOPATH/src/github.com/user/hello</code></p>\n<p><code>$ go install</code></p>\n</blockquote>\n<p>This command builds the hello command, producing an executable binary. It then installs that binary to the workspaces bin directory as hello (or, under Windows, hello.exe). In our example, that will be <strong>$GOPATH/bin/hello</strong>, which is <strong>$HOME/go/bin/hello</strong>.</p>\n<p>The go tool will only print output when an error occurs, so if these commands produce no output they have executed successfully.</p>\n<p>You can now run the program by typing its full path at the command line:</p>\n<blockquote>\n<p><code>$ $GOPATH/bin/hello</code></p>\n<p>Hello, world.</p>\n</blockquote>\n<p>If you see the Hello, world message then your Go installation is working</p>\n","excerpt":"","more":"<p>###Introduction</p>\n<p>Go, also commonly referred to as golang, is a programming language initially developed at Google in 2007 by <code>Robert Griesemer, Rob Pike, and Ken Thompson</code>.</p>\n<blockquote>\n<p><strong>Go</strong> is: </p>\n<p> open source</p>\n<p> concurrent </p>\n<p> garbage-collected </p>\n<p> efficient </p>\n<p> scalable </p>\n<p> simple </p>\n<p> fun </p>\n<p> boring (to some) </p>\n</blockquote>\n<p><a href=\"http://golang.org\">http://golang.org</a></p>\n<p>####Setup</p>\n<p>There are many ways to configure the Go development environment on your computer, you can choose any one you like. But i suggest following ways.</p>\n<p>######Way 1 : Install Go Package</p>\n<p>The golang Debian package may have already made its way into your Ubuntu distribution. Try this:</p>\n<blockquote>\n<p><code>$ sudo apt-get install golang</code></p>\n</blockquote>\n<p>export the settings youre gonna need to ~/.bashrc file:</p>\n<blockquote>\n<p><code>$ export GOROOT=/usr/lib/go</code></p>\n<p><code>$ export GOBIN=/usr/bin/go</code></p>\n</blockquote>\n<p>######Way 2 : From Binary</p>\n<p>Download <a href=\"https://storage.googleapis.com/golang/go1.4.2.linux-amd64.tar.gz\">golang 1.4+ amd64 linux</a>,  create a <code>~/golang</code> directory, and untar into that directory.</p>\n<blockquote>\n<p><code>$ mkdir ~/golang</code></p>\n<p><code>$ cd ~/golang</code></p>\n<p><code>$ wget https://storage.googleapis.com/golang/go1.4.2.linux-amd64.tar.gz</code></p>\n<p><code>$ tar -xzf go1.4.2.linux-amd64.tar.gz</code></p>\n</blockquote>\n<p>Now setup Go binary path. Use the <strong>$GOROOT</strong> and <strong>$PATH</strong> environment variables. In order to make these variables persist through logins/reboots/etc, add the following lines to ~/.bashrc file:</p>\n<blockquote>\n<p><code>$ export GOROOT=$HOME/golang/go</code></p>\n<p><code>$ export PATH=$PATH:$GOROOT/bin</code></p>\n</blockquote>\n<p>######Way 3 : From Source</p>\n<p>Go will install to a directory named go. Change to the directory that will be its parent and make sure the go directory does not exist. Then clone the repository and check out the latest release tag:</p>\n<blockquote>\n<p><code>$ git clone https://go.googlesource.com/go</code></p>\n<p><code>$ cd go</code></p>\n<p><code>$ git checkout go1.4.2</code></p>\n</blockquote>\n<p>(Optional) Switch to the master branch</p>\n<p>If you intend to modify the go source code, and contribute your changes to the project, then move your repository off the release branch, and onto the master (development) branch. Otherwise, skip this step.</p>\n<blockquote>\n<p><code>$ git checkout master</code></p>\n</blockquote>\n<p>To build the Go distribution, run</p>\n<blockquote>\n<p><code>$ cd go/src</code></p>\n<p><code>$ ./all.bash</code></p>\n</blockquote>\n<p>Finally set the environment variables on ~/.bashrc file</p>\n<blockquote>\n<p><code>$ export GOROOT=$HOME/golang/go</code></p>\n<p><code>$ export PATH=$PATH:$GOROOT/bin</code></p>\n</blockquote>\n<p>Test your installation</p>\n<p>Try this,</p>\n<blockquote>\n<p><code>$ go version</code></p>\n<p>go version go1.4.2 linux/amd64</p>\n</blockquote>\n<p>####Set up your work environment</p>\n<p>######Introducing workspaces</p>\n<p>Your Go code is kept in a workspace. A workspace contains many source repositories (git, hg). The Go tool understands the layout of a workspace. You dont need a Makefile. A workspace is a directory hierarchy with three directories at its root:</p>\n<blockquote>\n<p><strong>src</strong> contains Go source files organized into packages (one package per directory),</p>\n<p><strong>pkg</strong> contains package objects, and</p>\n<p><strong>bin</strong> contains executable commands.</p>\n</blockquote>\n<p>The go tool builds source packages and installs the resulting binaries to the pkg and bin directories.</p>\n<p>The src subdirectory typically contains multiple version control repositories (such as for Git or Mercurial) that track the development of one or more source packages.</p>\n<p>To give you an idea of how a workspace looks in practice, heres an example:</p>\n<pre><code>bin/\n        hello                   # command executable\n        outyet                  # command executable\npkg/\n        linux_amd64/\n                github.com/golang/example/\n                        stringutil.a           # package object\nsrc/\n        github.com/golang/example/\n                .git/             # Git repository metadata\n                hello/\n                    hello.go      # command source\n                outyet/\n                    main.go       # command source\n                    main_test.go  # test source\n                stringutil/\n                    reverse.go    # package source\n                    reverse_test.go   # test source\n</code></pre><p>This workspace contains one repository (example) comprising two commands (hello and outyet) and one library (stringutil).</p>\n<p>A typical workspace would contain many source repositories containing many packages and commands. Most Go programmers keep all their Go source code and dependencies in a single workspace.</p>\n<p>Go commands all rely on one important environment variable which is called <code>$GOPATH</code>. Notice that this is not the <code>$GOROOT</code> where Go is installed. This variable points to the workspace of Go in your computer.</p>\n<p>######The GOPATH environment variable</p>\n<p>The GOPATH environment variable specifies the location of your workspace. It is likely the only environment variable youll need to set when developing Go code.</p>\n<p>To get started, create a workspace directory and set GOPATH accordingly. Your<br>workspace can be located wherever you like, but well use $HOME/go in this document.<br>Note that this must not be the same path as your Go installation.</p>\n<blockquote>\n<p><code>$ mkdir $HOME/go</code></p>\n<p><code>$ export GOPATH=$HOME/go</code></p>\n</blockquote>\n<p>For convenience, add the workspaces bin subdirectory to your PATH:</p>\n<blockquote>\n<p><code>$ export PATH=$PATH:$GOPATH/bin</code></p>\n</blockquote>\n<p>######Testing with Workspace</p>\n<p>To compile and run a simple program, first choose a package path (well use github.com/user/hello) and create a corresponding package directory inside your workspace:</p>\n<blockquote>\n<p><code>$ mkdir $GOPATH/src/github.com/user/hello</code></p>\n</blockquote>\n<p>Next, create a file named hello.go inside that directory, containing the following Go code.</p>\n<pre><code>package main\nimport &quot;fmt&quot;\nfunc main() {\n    fmt.Printf(&quot;Hello, world.\\n&quot;)\n}\n</code></pre><p>Now you can build and install that program with the go tool:</p>\n<blockquote>\n<p><code>$ go install github.com/user/hello</code></p>\n</blockquote>\n<p>Note that you can run this command from anywhere on your system. The go tool finds the source code by looking for the <strong>github.com/user/hello</strong> package inside the workspace specified by GOPATH.</p>\n<p>You can also omit the package path if you run go install from the package directory:</p>\n<blockquote>\n<p><code>$ cd $GOPATH/src/github.com/user/hello</code></p>\n<p><code>$ go install</code></p>\n</blockquote>\n<p>This command builds the hello command, producing an executable binary. It then installs that binary to the workspaces bin directory as hello (or, under Windows, hello.exe). In our example, that will be <strong>$GOPATH/bin/hello</strong>, which is <strong>$HOME/go/bin/hello</strong>.</p>\n<p>The go tool will only print output when an error occurs, so if these commands produce no output they have executed successfully.</p>\n<p>You can now run the program by typing its full path at the command line:</p>\n<blockquote>\n<p><code>$ $GOPATH/bin/hello</code></p>\n<p>Hello, world.</p>\n</blockquote>\n<p>If you see the Hello, world message then your Go installation is working</p>\n"},{"title":"How to contribute to a Git Repository","slug":"2015-03-14-how-to-contribute-to-a-git-repository","date_published":"2015-03-14T04:50:13.813Z","date_updated":"2015-03-14T04:50:15.177Z","_content":"\nNow that you know the little gists on creating a forking and cloning a repository,let's move on and learn about how to contribute to a Git repository.\n**A great way to get involved in open source is to contribute to the existing projects youre using. GitHub is home to more than 5 million open source projects.**\nSay you want to contribute changes to someone elses repository? \n**You must first fork the repository.** We have seen all about Forking a repository in our previous post.\nso,moving on.\n**Next,send a pull request.**\nWhat is a pull request?\n\n######PULL REQUESTS:\n\n>Pull requests let you tell others about changes you've pushed to a repository on GitHub. Once a pull request is sent, interested parties can review the set of changes, discuss potential modifications, and even push follow-up commits if necessary.\n\nAh, now that's interesting. Wondering how do you initiate one?\nIt's easy. Follow these steps.\n######Initiating a Pull Request:\n>>1.Navigate to your repository with the changes you want someone else to pull and press the Pull Request button. \n\n>>2.Switch to your branch.\n\n>>3.Click the Compare & review button.\n\n>Pull requests can be sent from any branch or commit but it's recommended that a topic branch be used so that follow-up commits can be pushed to update the pull request if necessary.\n\n\nNow..what is this **branch?**\n###### WHAT IS A BRANCH?\n\n>-**Branches allow you to build new features or test out ideas without putting your main project at risk.**\n\n>-The **main branch of a repository is usually named master**, and represents a relatively stable version of the project you're working on. So far, all the changes you've made have been on the master branch.\n\n>-If you're making an app or website, for example, you might have a bunch of different features or ideas in progress at any given time  some of which are ready to go, and others which are not. For this reason, master exists as a central point to fold other branches of work into.\n######How to create a branch:\nBranch management is an important part of the Git workflow. You can manage branches directly on GitHub.\n>You can create a new branch in a repository's branch selector menu. Just start typing the name of your branch; if it doesn't exist, GitHub will offer to create it for you.\n \n######Reviewing the pull request :\n>After starting the review, you're presented with a review page where you can get a **high-level overview of what exactly has changed between your branch and the repository's master branch.** You can review all comments made on commits, identify which files changed, and get a list of contributors to your branch.\n\n######Changing the branch range and destination repository :\n>-By default, pull requests are assumed to be based on the parent repository's default branch. In many cases, the defaults are appropriate. If necessary, you can change the parent repository and branch with the drop-down lists. Clicking on Edit at the top allows you to swap between your head and base, as well as establishing differences between various reference points. References here must be branch names in your GitHub repositor\n\n>-The easiest way of thinking about the branch range is this: the **base branch is where you think changes should be applied**, the **head branch is what you would like to be applied.**\n\n>-**Changing the base repository changes who is notified of the pull request.** Everyone that can push to the base repository will receive an email notification and see the new pull request in their dashboard the next time they sign in.\n\n>-When you change any of the info in the branch range, the commit and files changed preview areas will update to show your new range.\n\n######SENDING THE PULL REQUEST :\n######STEPS:\n>>**STEP 1:**When you're ready to submit your pull request, click **Create pull request**.\n\n>>**STEP 2:** You'll be taken to a discussion page where you can **enter a title and optional description.** You'll still be able to see exactly which commits will be included when the pull request is sent.\n\n>>**STEP 3:**Once you've entered the title and description, made any necessary customizations to the commit range, and reviewed the commits and file changes to be sent, **press the Create pull request button.**\n\n>>**STEP 4:** The pull request is sent immediately. **You're taken to the main pull request discussion and review page.**\n\n>After your pull request is sent, any new commits pushed to your branch will automatically be added to the pull request. This is especially useful if you need to make more changes.\n######MANAGING PULL REQUESTS :\n>-All pull requests sent or received by you are browsable through the **pull request dashboard.** Pull requests for a specific repository are also browsable by anyone with access by visiting the **Pull Requests page.**\n\n>-The pull request dashboard and the repository pull request list support a **wide range of filtering and sorting controls.** Use them to narrow down the list to the pull requests you're interested in.\n\n#######REVIEWING PROPOSED CHANGES :\n>-**When you receive a pull request, the first thing to do is review the set of proposed changes.** Pull requests are tightly integrated with the underlying git repository, so **you can see exactly what commits would be merged should the request be accepted**.\n\n>-You can also review the cumulative differences of all file changes across all commits, either split or unified.\n\n######MERGING A PULL REQUEST:\n>-**Merge a pull request into the upstream branch when work is completed.** Anyone with push access to the repository can complete the merge.\n>-If you decide **you don't want the changes in your branch to be merged to the upstream branch, you can also close the pull request without merging.**\n\n#######MERGING A PULL REQUEST USING THE GITHUB WEB INTERFACE :\n>-If the merge will not have any conflicts, you can merge the pull request online. Follow these steps:\n\n>>**STEP 1:** In any repository's right sidebar, **click Pull Requests.**\n\n>>**STEP 2:** In the **\"Pull Requests\" list**, *click the pull request you'd like to merge.*\n\n>>**STEP 3:** Click **Merge pull request.**\n\n>>**STEP 4:** **Type a commit message**, or accept the default message.\n\n>>**STEP 5:** Under the commit message box, click Confirm merge.\n>\nOptionally, delete the branch. This keeps the list of branches in your repository tidy.\n\n######Reverting a pull request :\n**You can revert a pull request after it's been merged to the upstream branch.**\n\n>**Reverting a pull request on GitHub creates a new pull request** that contains one revert of the merge commit from the original merged pull request.\nFollow these steps to revert a pull request:\n\n>>**STEP 1:** In your repository's right sidebar, **click Pull Requests.**\n\n>>**STEP 2:** In the **\"Pull Requests\" list**, *click the pull request you'd like to revert.*\n\n>>**STEP 3:** *Near the bottom of the pull request*, **click Revert.**\n\n>>**STEP 4:** Merge the resulting pull request. \n\n######Closing a pull request\n**You may choose to close a pull request without merging it into the upstream branch.**\nThis can be handy if the changes proposed in the branch are no longer needed, or if another solution has been proposed in another branch.\nFollow these steps to close a pull request:\n\n>**STEP 1:**In any repository's right sidebar, click Pull Requests.\n\n>**STEP 2:**In the **\"Pull Requests\" list**, *click the pull request you'd like to close.*\n\n>**STEP 3:**At the **bottom of the pull request**, below the comment box, **click Close pull request.**\nOptionally, delete the branch. This keeps the list of branches in your repository tidy.\n\nYou can also choose to delete the delete unwanted branches.\n\n######DELETING UNUSED BRANCHES:\n\n>-**After you merge or close a pull request, you can delete the branch.** This keeps the list of branches for your repository as clean and useful as possible.\n\n>-At the **bottom of a merged or closed pull request, youll see a button to delete the lingering branch**\n\n>-You can also **delete branches from the Branches page.**\n \n **Easy,eh?\n Go ahead and get forking!**\n\n\n\n\n\n\n\n","source":"_posts/2015-03-14-how-to-contribute-to-a-git-repository.md","raw":"---\ntitle: How to contribute to a Git Repository\nslug: how-to-contribute-to-a-git-repository\ndate_published: 2015-03-14T10:20:13.813Z\ndate_updated:   2015-03-14T10:20:15.177Z\n---\n\nNow that you know the little gists on creating a forking and cloning a repository,let's move on and learn about how to contribute to a Git repository.\n**A great way to get involved in open source is to contribute to the existing projects youre using. GitHub is home to more than 5 million open source projects.**\nSay you want to contribute changes to someone elses repository? \n**You must first fork the repository.** We have seen all about Forking a repository in our previous post.\nso,moving on.\n**Next,send a pull request.**\nWhat is a pull request?\n\n######PULL REQUESTS:\n\n>Pull requests let you tell others about changes you've pushed to a repository on GitHub. Once a pull request is sent, interested parties can review the set of changes, discuss potential modifications, and even push follow-up commits if necessary.\n\nAh, now that's interesting. Wondering how do you initiate one?\nIt's easy. Follow these steps.\n######Initiating a Pull Request:\n>>1.Navigate to your repository with the changes you want someone else to pull and press the Pull Request button. \n\n>>2.Switch to your branch.\n\n>>3.Click the Compare & review button.\n\n>Pull requests can be sent from any branch or commit but it's recommended that a topic branch be used so that follow-up commits can be pushed to update the pull request if necessary.\n\n\nNow..what is this **branch?**\n###### WHAT IS A BRANCH?\n\n>-**Branches allow you to build new features or test out ideas without putting your main project at risk.**\n\n>-The **main branch of a repository is usually named master**, and represents a relatively stable version of the project you're working on. So far, all the changes you've made have been on the master branch.\n\n>-If you're making an app or website, for example, you might have a bunch of different features or ideas in progress at any given time  some of which are ready to go, and others which are not. For this reason, master exists as a central point to fold other branches of work into.\n######How to create a branch:\nBranch management is an important part of the Git workflow. You can manage branches directly on GitHub.\n>You can create a new branch in a repository's branch selector menu. Just start typing the name of your branch; if it doesn't exist, GitHub will offer to create it for you.\n \n######Reviewing the pull request :\n>After starting the review, you're presented with a review page where you can get a **high-level overview of what exactly has changed between your branch and the repository's master branch.** You can review all comments made on commits, identify which files changed, and get a list of contributors to your branch.\n\n######Changing the branch range and destination repository :\n>-By default, pull requests are assumed to be based on the parent repository's default branch. In many cases, the defaults are appropriate. If necessary, you can change the parent repository and branch with the drop-down lists. Clicking on Edit at the top allows you to swap between your head and base, as well as establishing differences between various reference points. References here must be branch names in your GitHub repositor\n\n>-The easiest way of thinking about the branch range is this: the **base branch is where you think changes should be applied**, the **head branch is what you would like to be applied.**\n\n>-**Changing the base repository changes who is notified of the pull request.** Everyone that can push to the base repository will receive an email notification and see the new pull request in their dashboard the next time they sign in.\n\n>-When you change any of the info in the branch range, the commit and files changed preview areas will update to show your new range.\n\n######SENDING THE PULL REQUEST :\n######STEPS:\n>>**STEP 1:**When you're ready to submit your pull request, click **Create pull request**.\n\n>>**STEP 2:** You'll be taken to a discussion page where you can **enter a title and optional description.** You'll still be able to see exactly which commits will be included when the pull request is sent.\n\n>>**STEP 3:**Once you've entered the title and description, made any necessary customizations to the commit range, and reviewed the commits and file changes to be sent, **press the Create pull request button.**\n\n>>**STEP 4:** The pull request is sent immediately. **You're taken to the main pull request discussion and review page.**\n\n>After your pull request is sent, any new commits pushed to your branch will automatically be added to the pull request. This is especially useful if you need to make more changes.\n######MANAGING PULL REQUESTS :\n>-All pull requests sent or received by you are browsable through the **pull request dashboard.** Pull requests for a specific repository are also browsable by anyone with access by visiting the **Pull Requests page.**\n\n>-The pull request dashboard and the repository pull request list support a **wide range of filtering and sorting controls.** Use them to narrow down the list to the pull requests you're interested in.\n\n#######REVIEWING PROPOSED CHANGES :\n>-**When you receive a pull request, the first thing to do is review the set of proposed changes.** Pull requests are tightly integrated with the underlying git repository, so **you can see exactly what commits would be merged should the request be accepted**.\n\n>-You can also review the cumulative differences of all file changes across all commits, either split or unified.\n\n######MERGING A PULL REQUEST:\n>-**Merge a pull request into the upstream branch when work is completed.** Anyone with push access to the repository can complete the merge.\n>-If you decide **you don't want the changes in your branch to be merged to the upstream branch, you can also close the pull request without merging.**\n\n#######MERGING A PULL REQUEST USING THE GITHUB WEB INTERFACE :\n>-If the merge will not have any conflicts, you can merge the pull request online. Follow these steps:\n\n>>**STEP 1:** In any repository's right sidebar, **click Pull Requests.**\n\n>>**STEP 2:** In the **\"Pull Requests\" list**, *click the pull request you'd like to merge.*\n\n>>**STEP 3:** Click **Merge pull request.**\n\n>>**STEP 4:** **Type a commit message**, or accept the default message.\n\n>>**STEP 5:** Under the commit message box, click Confirm merge.\n>\nOptionally, delete the branch. This keeps the list of branches in your repository tidy.\n\n######Reverting a pull request :\n**You can revert a pull request after it's been merged to the upstream branch.**\n\n>**Reverting a pull request on GitHub creates a new pull request** that contains one revert of the merge commit from the original merged pull request.\nFollow these steps to revert a pull request:\n\n>>**STEP 1:** In your repository's right sidebar, **click Pull Requests.**\n\n>>**STEP 2:** In the **\"Pull Requests\" list**, *click the pull request you'd like to revert.*\n\n>>**STEP 3:** *Near the bottom of the pull request*, **click Revert.**\n\n>>**STEP 4:** Merge the resulting pull request. \n\n######Closing a pull request\n**You may choose to close a pull request without merging it into the upstream branch.**\nThis can be handy if the changes proposed in the branch are no longer needed, or if another solution has been proposed in another branch.\nFollow these steps to close a pull request:\n\n>**STEP 1:**In any repository's right sidebar, click Pull Requests.\n\n>**STEP 2:**In the **\"Pull Requests\" list**, *click the pull request you'd like to close.*\n\n>**STEP 3:**At the **bottom of the pull request**, below the comment box, **click Close pull request.**\nOptionally, delete the branch. This keeps the list of branches in your repository tidy.\n\nYou can also choose to delete the delete unwanted branches.\n\n######DELETING UNUSED BRANCHES:\n\n>-**After you merge or close a pull request, you can delete the branch.** This keeps the list of branches for your repository as clean and useful as possible.\n\n>-At the **bottom of a merged or closed pull request, youll see a button to delete the lingering branch**\n\n>-You can also **delete branches from the Branches page.**\n \n **Easy,eh?\n Go ahead and get forking!**\n\n\n\n\n\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzairg000adrgbdnpns1u2","content":"<p>Now that you know the little gists on creating a forking and cloning a repository,lets move on and learn about how to contribute to a Git repository.<br><strong>A great way to get involved in open source is to contribute to the existing projects youre using. GitHub is home to more than 5 million open source projects.</strong><br>Say you want to contribute changes to someone elses repository?<br><strong>You must first fork the repository.</strong> We have seen all about Forking a repository in our previous post.<br>so,moving on.<br><strong>Next,send a pull request.</strong><br>What is a pull request?</p>\n<p>######PULL REQUESTS:</p>\n<blockquote>\n<p>Pull requests let you tell others about changes youve pushed to a repository on GitHub. Once a pull request is sent, interested parties can review the set of changes, discuss potential modifications, and even push follow-up commits if necessary.</p>\n</blockquote>\n<p>Ah, now thats interesting. Wondering how do you initiate one?<br>Its easy. Follow these steps.</p>\n<p>######Initiating a Pull Request:</p>\n<blockquote>\n<blockquote>\n<p>1.Navigate to your repository with the changes you want someone else to pull and press the Pull Request button. </p>\n<p>2.Switch to your branch.</p>\n<p>3.Click the Compare &amp; review button.</p>\n</blockquote>\n<p>Pull requests can be sent from any branch or commit but its recommended that a topic branch be used so that follow-up commits can be pushed to update the pull request if necessary.</p>\n</blockquote>\n<p>Now..what is this <strong>branch?</strong></p>\n<h6 id=\"WHAT-IS-A-BRANCH\"><a href=\"#WHAT-IS-A-BRANCH\" class=\"headerlink\" title=\"WHAT IS A BRANCH?\"></a>WHAT IS A BRANCH?</h6><blockquote>\n<p>-<strong>Branches allow you to build new features or test out ideas without putting your main project at risk.</strong></p>\n<p>-The <strong>main branch of a repository is usually named master</strong>, and represents a relatively stable version of the project youre working on. So far, all the changes youve made have been on the master branch.</p>\n<p>-If youre making an app or website, for example, you might have a bunch of different features or ideas in progress at any given time  some of which are ready to go, and others which are not. For this reason, master exists as a central point to fold other branches of work into.</p>\n<p>######How to create a branch:<br>Branch management is an important part of the Git workflow. You can manage branches directly on GitHub.<br>You can create a new branch in a repositorys branch selector menu. Just start typing the name of your branch; if it doesnt exist, GitHub will offer to create it for you.</p>\n</blockquote>\n<p>######Reviewing the pull request :</p>\n<blockquote>\n<p>After starting the review, youre presented with a review page where you can get a <strong>high-level overview of what exactly has changed between your branch and the repositorys master branch.</strong> You can review all comments made on commits, identify which files changed, and get a list of contributors to your branch.</p>\n</blockquote>\n<p>######Changing the branch range and destination repository :</p>\n<blockquote>\n<p>-By default, pull requests are assumed to be based on the parent repositorys default branch. In many cases, the defaults are appropriate. If necessary, you can change the parent repository and branch with the drop-down lists. Clicking on Edit at the top allows you to swap between your head and base, as well as establishing differences between various reference points. References here must be branch names in your GitHub repositor</p>\n<p>-The easiest way of thinking about the branch range is this: the <strong>base branch is where you think changes should be applied</strong>, the <strong>head branch is what you would like to be applied.</strong></p>\n<p>-<strong>Changing the base repository changes who is notified of the pull request.</strong> Everyone that can push to the base repository will receive an email notification and see the new pull request in their dashboard the next time they sign in.</p>\n<p>-When you change any of the info in the branch range, the commit and files changed preview areas will update to show your new range.</p>\n</blockquote>\n<p>######SENDING THE PULL REQUEST :</p>\n<p>######STEPS:</p>\n<blockquote>\n<blockquote>\n<p><strong>STEP 1:</strong>When youre ready to submit your pull request, click <strong>Create pull request</strong>.</p>\n<p><strong>STEP 2:</strong> Youll be taken to a discussion page where you can <strong>enter a title and optional description.</strong> Youll still be able to see exactly which commits will be included when the pull request is sent.</p>\n<p><strong>STEP 3:</strong>Once youve entered the title and description, made any necessary customizations to the commit range, and reviewed the commits and file changes to be sent, <strong>press the Create pull request button.</strong></p>\n<p><strong>STEP 4:</strong> The pull request is sent immediately. <strong>Youre taken to the main pull request discussion and review page.</strong></p>\n</blockquote>\n<p>After your pull request is sent, any new commits pushed to your branch will automatically be added to the pull request. This is especially useful if you need to make more changes.</p>\n<p>######MANAGING PULL REQUESTS :<br>-All pull requests sent or received by you are browsable through the <strong>pull request dashboard.</strong> Pull requests for a specific repository are also browsable by anyone with access by visiting the <strong>Pull Requests page.</strong></p>\n<p>-The pull request dashboard and the repository pull request list support a <strong>wide range of filtering and sorting controls.</strong> Use them to narrow down the list to the pull requests youre interested in.</p>\n</blockquote>\n<p>#######REVIEWING PROPOSED CHANGES :</p>\n<blockquote>\n<p>-<strong>When you receive a pull request, the first thing to do is review the set of proposed changes.</strong> Pull requests are tightly integrated with the underlying git repository, so <strong>you can see exactly what commits would be merged should the request be accepted</strong>.</p>\n<p>-You can also review the cumulative differences of all file changes across all commits, either split or unified.</p>\n</blockquote>\n<p>######MERGING A PULL REQUEST:</p>\n<blockquote>\n<p>-<strong>Merge a pull request into the upstream branch when work is completed.</strong> Anyone with push access to the repository can complete the merge.<br>-If you decide <strong>you dont want the changes in your branch to be merged to the upstream branch, you can also close the pull request without merging.</strong></p>\n</blockquote>\n<p>#######MERGING A PULL REQUEST USING THE GITHUB WEB INTERFACE :</p>\n<blockquote>\n<p>-If the merge will not have any conflicts, you can merge the pull request online. Follow these steps:</p>\n<blockquote>\n<p><strong>STEP 1:</strong> In any repositorys right sidebar, <strong>click Pull Requests.</strong></p>\n<p><strong>STEP 2:</strong> In the <strong>Pull Requests list</strong>, <em>click the pull request youd like to merge.</em></p>\n<p><strong>STEP 3:</strong> Click <strong>Merge pull request.</strong></p>\n<p><strong>STEP 4:</strong> <strong>Type a commit message</strong>, or accept the default message.</p>\n<p><strong>STEP 5:</strong> Under the commit message box, click Confirm merge.</p>\n</blockquote>\n<p>Optionally, delete the branch. This keeps the list of branches in your repository tidy.</p>\n</blockquote>\n<p>######Reverting a pull request :<br><strong>You can revert a pull request after its been merged to the upstream branch.</strong></p>\n<blockquote>\n<p><strong>Reverting a pull request on GitHub creates a new pull request</strong> that contains one revert of the merge commit from the original merged pull request.<br>Follow these steps to revert a pull request:</p>\n<blockquote>\n<p><strong>STEP 1:</strong> In your repositorys right sidebar, <strong>click Pull Requests.</strong></p>\n<p><strong>STEP 2:</strong> In the <strong>Pull Requests list</strong>, <em>click the pull request youd like to revert.</em></p>\n<p><strong>STEP 3:</strong> <em>Near the bottom of the pull request</em>, <strong>click Revert.</strong></p>\n<p><strong>STEP 4:</strong> Merge the resulting pull request. </p>\n</blockquote>\n</blockquote>\n<p>######Closing a pull request<br><strong>You may choose to close a pull request without merging it into the upstream branch.</strong><br>This can be handy if the changes proposed in the branch are no longer needed, or if another solution has been proposed in another branch.<br>Follow these steps to close a pull request:</p>\n<blockquote>\n<p><strong>STEP 1:</strong>In any repositorys right sidebar, click Pull Requests.</p>\n<p><strong>STEP 2:</strong>In the <strong>Pull Requests list</strong>, <em>click the pull request youd like to close.</em></p>\n<p><strong>STEP 3:</strong>At the <strong>bottom of the pull request</strong>, below the comment box, <strong>click Close pull request.</strong><br>Optionally, delete the branch. This keeps the list of branches in your repository tidy.</p>\n</blockquote>\n<p>You can also choose to delete the delete unwanted branches.</p>\n<p>######DELETING UNUSED BRANCHES:</p>\n<blockquote>\n<p>-<strong>After you merge or close a pull request, you can delete the branch.</strong> This keeps the list of branches for your repository as clean and useful as possible.</p>\n<p>-At the <strong>bottom of a merged or closed pull request, youll see a button to delete the lingering branch</strong></p>\n<p>-You can also <strong>delete branches from the Branches page.</strong></p>\n</blockquote>\n<p> <strong>Easy,eh?<br> Go ahead and get forking!</strong></p>\n","excerpt":"","more":"<p>Now that you know the little gists on creating a forking and cloning a repository,lets move on and learn about how to contribute to a Git repository.<br><strong>A great way to get involved in open source is to contribute to the existing projects youre using. GitHub is home to more than 5 million open source projects.</strong><br>Say you want to contribute changes to someone elses repository?<br><strong>You must first fork the repository.</strong> We have seen all about Forking a repository in our previous post.<br>so,moving on.<br><strong>Next,send a pull request.</strong><br>What is a pull request?</p>\n<p>######PULL REQUESTS:</p>\n<blockquote>\n<p>Pull requests let you tell others about changes youve pushed to a repository on GitHub. Once a pull request is sent, interested parties can review the set of changes, discuss potential modifications, and even push follow-up commits if necessary.</p>\n</blockquote>\n<p>Ah, now thats interesting. Wondering how do you initiate one?<br>Its easy. Follow these steps.</p>\n<p>######Initiating a Pull Request:</p>\n<blockquote>\n<blockquote>\n<p>1.Navigate to your repository with the changes you want someone else to pull and press the Pull Request button. </p>\n<p>2.Switch to your branch.</p>\n<p>3.Click the Compare &amp; review button.</p>\n</blockquote>\n<p>Pull requests can be sent from any branch or commit but its recommended that a topic branch be used so that follow-up commits can be pushed to update the pull request if necessary.</p>\n</blockquote>\n<p>Now..what is this <strong>branch?</strong></p>\n<h6 id=\"WHAT-IS-A-BRANCH\"><a href=\"#WHAT-IS-A-BRANCH\" class=\"headerlink\" title=\"WHAT IS A BRANCH?\"></a>WHAT IS A BRANCH?</h6><blockquote>\n<p>-<strong>Branches allow you to build new features or test out ideas without putting your main project at risk.</strong></p>\n<p>-The <strong>main branch of a repository is usually named master</strong>, and represents a relatively stable version of the project youre working on. So far, all the changes youve made have been on the master branch.</p>\n<p>-If youre making an app or website, for example, you might have a bunch of different features or ideas in progress at any given time  some of which are ready to go, and others which are not. For this reason, master exists as a central point to fold other branches of work into.</p>\n<p>######How to create a branch:<br>Branch management is an important part of the Git workflow. You can manage branches directly on GitHub.<br>You can create a new branch in a repositorys branch selector menu. Just start typing the name of your branch; if it doesnt exist, GitHub will offer to create it for you.</p>\n</blockquote>\n<p>######Reviewing the pull request :</p>\n<blockquote>\n<p>After starting the review, youre presented with a review page where you can get a <strong>high-level overview of what exactly has changed between your branch and the repositorys master branch.</strong> You can review all comments made on commits, identify which files changed, and get a list of contributors to your branch.</p>\n</blockquote>\n<p>######Changing the branch range and destination repository :</p>\n<blockquote>\n<p>-By default, pull requests are assumed to be based on the parent repositorys default branch. In many cases, the defaults are appropriate. If necessary, you can change the parent repository and branch with the drop-down lists. Clicking on Edit at the top allows you to swap between your head and base, as well as establishing differences between various reference points. References here must be branch names in your GitHub repositor</p>\n<p>-The easiest way of thinking about the branch range is this: the <strong>base branch is where you think changes should be applied</strong>, the <strong>head branch is what you would like to be applied.</strong></p>\n<p>-<strong>Changing the base repository changes who is notified of the pull request.</strong> Everyone that can push to the base repository will receive an email notification and see the new pull request in their dashboard the next time they sign in.</p>\n<p>-When you change any of the info in the branch range, the commit and files changed preview areas will update to show your new range.</p>\n</blockquote>\n<p>######SENDING THE PULL REQUEST :</p>\n<p>######STEPS:</p>\n<blockquote>\n<blockquote>\n<p><strong>STEP 1:</strong>When youre ready to submit your pull request, click <strong>Create pull request</strong>.</p>\n<p><strong>STEP 2:</strong> Youll be taken to a discussion page where you can <strong>enter a title and optional description.</strong> Youll still be able to see exactly which commits will be included when the pull request is sent.</p>\n<p><strong>STEP 3:</strong>Once youve entered the title and description, made any necessary customizations to the commit range, and reviewed the commits and file changes to be sent, <strong>press the Create pull request button.</strong></p>\n<p><strong>STEP 4:</strong> The pull request is sent immediately. <strong>Youre taken to the main pull request discussion and review page.</strong></p>\n</blockquote>\n<p>After your pull request is sent, any new commits pushed to your branch will automatically be added to the pull request. This is especially useful if you need to make more changes.</p>\n<p>######MANAGING PULL REQUESTS :<br>-All pull requests sent or received by you are browsable through the <strong>pull request dashboard.</strong> Pull requests for a specific repository are also browsable by anyone with access by visiting the <strong>Pull Requests page.</strong></p>\n<p>-The pull request dashboard and the repository pull request list support a <strong>wide range of filtering and sorting controls.</strong> Use them to narrow down the list to the pull requests youre interested in.</p>\n</blockquote>\n<p>#######REVIEWING PROPOSED CHANGES :</p>\n<blockquote>\n<p>-<strong>When you receive a pull request, the first thing to do is review the set of proposed changes.</strong> Pull requests are tightly integrated with the underlying git repository, so <strong>you can see exactly what commits would be merged should the request be accepted</strong>.</p>\n<p>-You can also review the cumulative differences of all file changes across all commits, either split or unified.</p>\n</blockquote>\n<p>######MERGING A PULL REQUEST:</p>\n<blockquote>\n<p>-<strong>Merge a pull request into the upstream branch when work is completed.</strong> Anyone with push access to the repository can complete the merge.<br>-If you decide <strong>you dont want the changes in your branch to be merged to the upstream branch, you can also close the pull request without merging.</strong></p>\n</blockquote>\n<p>#######MERGING A PULL REQUEST USING THE GITHUB WEB INTERFACE :</p>\n<blockquote>\n<p>-If the merge will not have any conflicts, you can merge the pull request online. Follow these steps:</p>\n<blockquote>\n<p><strong>STEP 1:</strong> In any repositorys right sidebar, <strong>click Pull Requests.</strong></p>\n<p><strong>STEP 2:</strong> In the <strong>Pull Requests list</strong>, <em>click the pull request youd like to merge.</em></p>\n<p><strong>STEP 3:</strong> Click <strong>Merge pull request.</strong></p>\n<p><strong>STEP 4:</strong> <strong>Type a commit message</strong>, or accept the default message.</p>\n<p><strong>STEP 5:</strong> Under the commit message box, click Confirm merge.</p>\n</blockquote>\n<p>Optionally, delete the branch. This keeps the list of branches in your repository tidy.</p>\n</blockquote>\n<p>######Reverting a pull request :<br><strong>You can revert a pull request after its been merged to the upstream branch.</strong></p>\n<blockquote>\n<p><strong>Reverting a pull request on GitHub creates a new pull request</strong> that contains one revert of the merge commit from the original merged pull request.<br>Follow these steps to revert a pull request:</p>\n<blockquote>\n<p><strong>STEP 1:</strong> In your repositorys right sidebar, <strong>click Pull Requests.</strong></p>\n<p><strong>STEP 2:</strong> In the <strong>Pull Requests list</strong>, <em>click the pull request youd like to revert.</em></p>\n<p><strong>STEP 3:</strong> <em>Near the bottom of the pull request</em>, <strong>click Revert.</strong></p>\n<p><strong>STEP 4:</strong> Merge the resulting pull request. </p>\n</blockquote>\n</blockquote>\n<p>######Closing a pull request<br><strong>You may choose to close a pull request without merging it into the upstream branch.</strong><br>This can be handy if the changes proposed in the branch are no longer needed, or if another solution has been proposed in another branch.<br>Follow these steps to close a pull request:</p>\n<blockquote>\n<p><strong>STEP 1:</strong>In any repositorys right sidebar, click Pull Requests.</p>\n<p><strong>STEP 2:</strong>In the <strong>Pull Requests list</strong>, <em>click the pull request youd like to close.</em></p>\n<p><strong>STEP 3:</strong>At the <strong>bottom of the pull request</strong>, below the comment box, <strong>click Close pull request.</strong><br>Optionally, delete the branch. This keeps the list of branches in your repository tidy.</p>\n</blockquote>\n<p>You can also choose to delete the delete unwanted branches.</p>\n<p>######DELETING UNUSED BRANCHES:</p>\n<blockquote>\n<p>-<strong>After you merge or close a pull request, you can delete the branch.</strong> This keeps the list of branches for your repository as clean and useful as possible.</p>\n<p>-At the <strong>bottom of a merged or closed pull request, youll see a button to delete the lingering branch</strong></p>\n<p>-You can also <strong>delete branches from the Branches page.</strong></p>\n</blockquote>\n<p> <strong>Easy,eh?<br> Go ahead and get forking!</strong></p>\n"},{"title":"Setting up Scala, SBT, Play, Akka","slug":"2015-03-16-setting-up-scala-sbt-play-akka","date_published":"2015-03-16T01:21:17.639Z","date_updated":"2015-08-16T08:18:58.571Z","_content":"\n###Part 1 : Setting up Scala, SBT, Play, Akka \n\nThis will be multi-part series in building a cloud API server for our PaaS with cloud instrumentation using a messaging layer.\n\n###1. Let us setup SBT 0.13.\n\n#### Installing in debian\n\n    echo \"deb https://dl.bintray.com/sbt/debian /\" | sudo tee -a /etc/apt/sources.list.d/sbt.list\n    sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 642AC823\n    sudo apt-get update\n    sudo apt-get install sbt\n\n(or)\n\n#### Manual install of sbt\n\n- Download the [sbt_launch.jar](https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/sbt-launch/0.13.9/sbt-launch.jar?_ga=1.124271561.2110266759.1437462670) to your ~/bin directory.\n\n- Create a script named `sbt` in your ~/bin directory with the following contents.\n\n    java -server -Xms1024M -Xmx3072M -Xss32M     -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=1024M -XX:+UseG1GC -XX:+AggressiveOpts -XX:SurvivorRatio=128 -XX:MaxTenuringThreshold=0 -jar `dirname $0`/sbt-launch.jar \"$@\"\n    \n- Adjust the -Xmx, -Xms -XX:MaxPermSize based on the RAM you have. \n\nAt Megam we all have atleast 8GB or > of RAM. \n\n#### *optional Install sbt-eclipse \n\nInstall the scala-ide eclipse plugin for Eclipse Mars. \n\nHelp > Install New Software > \n\nAdd the correct link from herehttp://scala-ide.org/download/nightly.html\n\nYou can install typesafe stack and download templates from here. http://typesafe.com/stack/download#template \nhttp://typesafe.com/resources/typesafe-stack/downloading-installing.html \n\n- Create a new project in eclipse. \nScala  Worksheet allows you to play around with REPL inside eclipse editor. or use command line, to use REPL\n\n\n\n`sbt console`\n\nIf you only plan to use scala, you are done here. You can tweak your Build.scala to use the scala version you want.\n\n###2. Eclipsify scala project\n\nhttps://github.com/typesafehub/sbteclipse/wiki https://github.com/typesafehub/sbteclipse Create a file .sbt/plugins/plugins.sbt and add the following to include eclipse plugin support.\n\n    addSbtPlugin(\"com.typesafe.sbteclipse\" % \"sbteclipse-plugin\" % \"2.3.0\"\n    \nIf you created a project from command line then run sbt > eclipse to eclipsify a project..\n\n    ram@rammegam:~/code/megam/workspace/nilam$ sbt\n    [info] Loading project definition from /home/ram/code/megam/workspace/nilam/project\n    [info] Set current project to nilam (in build     file:/home/ram/code/megam/workspace/nilam/)\n    [nilam] $ eclipse\n    [info] About to create Eclipse project files for your project(s).\n    [info] Updating {file:/home/ram/code/megam/workspace/nilam/}nilam...\n    [info] Resolving org.hibernate.javax.persistence#hibernate-jpa-2.0-api;1.0.1.Fin                                                                                [info] Done updating.\n    [info] Compiling 6 Scala sources and 1 Java source to /home/ram/code/megam/workspace/nilam/target/scala-2.9.1/classes...\n    [info] Successfully created Eclipse project files for project(s):\n    [info] nilam\n    \n   \n###3. If you with to use akka\n\nA sample akka source code for the Typesafe Stack (http://typesafe.com/stack). http://typesafe.com/resources/tutorials/getting-started-with-akka-scala.html From your akka code type sbt run:\n\n    ram@rammegam:~/code/megam/workspace/megam_akka$ sbt run\n    [info] Loading project definition from /home/ram/code/megam/workspace/megam_akka/project\n    [info] Set current project to nilam (in build     file:/home/ram/code/megam/workspace/megam_akka/)\n    [info] Updating {file:/home/ram/code/megam/workspace/megam_akka/}nilam...\n    [info] Resolving com.typesafe#config;0.3.1 ...\n    [info] downloading http://repo.typesafe.com/typesafe/releases/com/typesafe/akka/akka-actor/2.0.3/akka-actor-2.0.3.jar ...\n    [info]     [SUCCESSFUL ] com.typesafe.akka#akka-actor;2.0.3!akka-actor.jar (9117ms)\n    [info] downloading http://repo.typesafe.com/typesafe/releases/com/typesafe/config/0.3.1/config-0.3.1.jar ...\n    [info]     [SUCCESSFUL ] com.typesafe#config;0.3.1!config.jar(bundle) (3345ms)\n    [info] Done updating.\n    [info] Compiling 1 Scala source to /home/ram/code/megam/workspace/megam_akka/target/scala-2.9.2/classes...\n    [info] Running org.megam.akka.Nilam\n    Count is 3\n    [success] Total time: 25 s, completed 6 Nov, 2012 12:31:57 PM\n\n\n\n###4. Setting up Play framework\n\nLet us create a project titled megam_play which will use external dependencies like scaliak, newman, scalaz This project megam_play was created by cloning an existing typesafe_stack (play scala sample template). You are free to pick any other template from Github.com Adding library dependencies in your Build.scala file. The scaliak, amqp dependency has been moved to a common artifact named megam_common\n\n    import sbt._\n    import play.Project._\n\n    object ApplicationBuild extends Build {\n\n     val appName = \"megam_play\"\n\n      val appVersion = \"0.1.0\"\n\n      val organization = \"Megam Systems\"\n\n      val homepage = Some(url(\"http://www.megam.co\"))\n\n      val startYear = Some(2013)\n\n      val description = \"RESTful API server for the megam platform. Uses Riak and Memcache\"\n\n      /**\n       *   if you use groupID %% artifactID % revision instead of groupID % artifactID % revision\n       *   (the difference is the double %% after the groupID), sbt will add your projects Scala version\n       *   to the artifact name.\n       */\n\n      val play2AuthVersion = \"0.11.0-SNAPSHOT\"\n      val megamVersion = \"0.1.0-SNAPSHOT\"\n\n      val appDependencies = Seq(\n        javaCore, cache,javaEbean,\n        \"com.twitter.service\" % \"snowflake\" % \"1.0.2\" from \"https://s3-ap-southeast-1.amazonaws.com/megampub/0.1/jars/snowflake.jar\", //don't move this below.\n    \"com.github.indykish\" % \"megam_common_2.10\" % megamVersion excludeAll (\n      ExclusionRule(\"commons-logging\",\"commons-logging\"),\n      ExclusionRule(\"org.slf4j\",\"slf4j-jdk14\")),\n    \"com.github.mumoshu\" %% \"play2-memcached\" % \"0.3.0.2\",\n    \"jp.t2v\" %% \"play2-auth\" % play2AuthVersion,\n    \"jp.t2v\" %% \"play2-auth-test\" % play2AuthVersion % \"test\",\n    \"com.stackmob\" %% \"newman\" % \"1.3.0\" % \"test\")\n\n      val main = play.Project(appName, appVersion, appDependencies).settings(    \n    sbt.Keys.resolvers += \"Sonatype Snapshots\" at \"https://oss.sonatype.org/content/repositories/snapshots\",\n    sbt.Keys.resolvers += \"Typesafe Snapshots\" at \"http://repo.typesafe.com/typesafe/snapshots/\",\n    sbt.Keys.resolvers += \"Scala-Tools Maven2 Snapshots Repository\" at \"http://scala-tools.org/repo-snapshots\",\n    sbt.Keys.resolvers += \"Twitter Repo\" at \"http://maven.twttr.com\", // finagle \n    sbt.Keys.resolvers += \"spray repo\" at \"http://repo.spray.io\", //spray client used in newman.\n    sbt.Keys.resolvers += \"spray nightly\" at \"http://nightlies.spray.io\", //spray client nighly used in newman (0.23.0).\n    sbt.Keys.resolvers += \"Spy Repository\" at \"http://files.couchbase.com/maven2\" // required to resolve `spymemcached`, the plugin's dependency.\n    )\n\n    }\n    \nWe package debs, hence build.sbt contains the required statements\n\n    import sbt\n    import Process._\n    import com.typesafe.sbt.packager.debian.Keys._\n    import    com.typesafe.sbt.packager.linux.LinuxPackageMapping\n    import S3._\n\n    scalaVersion := \"2.10.3\"\n\n    scalacOptions := Seq(\n      \"-unchecked\", \n      \"-deprecation\",\n      \"-feature\",\n      \"-optimise\",\n    \"-Xcheckinit\",\n    \"-Xlint\",\n    \"-Xverify\",\n    \"-Yinline-warnings\",\n    \"-Yclosure-elim\",\n    \"-language:postfixOps\",\n    \"-language:implicitConversions\",\n    \"-Ydead-code\")\n\n    com.typesafe.sbt.packager.debian.Keys.name in Debian := \"megamplay\"\n\n    maintainer in Debian:= \"Rajthilak <rajthilak@megam.co.in>\"\n\n    packageSummary := \"Cloud API server - Megam.\" \n\n    packageDescription in Debian:= \" (REST based) Cloud API server for Megam platform.The API server protects the resources using HMAC based authorization, as provided to a customer during onboarding.\"\n\n    s3Settings\n\n    linuxPackageMappings in Debian <+= (baseDirectory) map { bd =>\n      (packageMapping((bd / \"bin/mp\") -> \"/usr/local/share/megamplay/bin/mp\")\n       withUser \"root\" withGroup \"root\" withPerms \"0755\")\n    }\n\n    linuxPackageMappings <+= (baseDirectory) map { bd =>\n      val src = bd / \"target/staged\"\n     val dest = \"/usr/local/share/megamplay/lib\"\n    LinuxPackageMapping(\n    for {\n      path <- (src ***).get\n      if !path.isDirectory\n    } yield path -> path.toString.replaceFirst(src.toString, dest)\n    )\n    }\n\n    linuxPackageMappings in Debian <+= (baseDirectory) map { bd =>\n      (packageMapping((bd / \"conf/application-production.conf\") -> \"/usr/local/share/megamplay/conf/application-production.conf\")\n    withConfig())\n    }\n\n    linuxPackageMappings in Debian <+= (baseDirectory) map { bd =>\n      (packageMapping((bd / \"conf/application-logger.xml\") -> \"/usr/local/share/megamplay/conf/application-logger.xml\")\n    withConfig()) \n    }\n\n    linuxPackageMappings in Debian <+= (baseDirectory) map { bd =>\n    (packageMapping((bd / \"conf/routes\") -> \"/usr/local/share/megamplay/conf/routes\")\n    withConfig())\n    }\n\n    linuxPackageMappings in Debian <+= (baseDirectory) map { bd =>\n    (packageMapping((bd / \"conf/messages\") -> \"/usr/local/share/megamplay/conf/messages\")\n    withConfig())\n    }\n\n    linuxPackageMappings in Debian <+= (baseDirectory) map { bd =>\n    (packageMapping((bd / \"conf/play.plugins\") -> \"/usr/local/share/megamplay/conf/play.plugins\")\n    withConfig())\n    }\n\n    com.typesafe.sbt.packager.debian.Keys.version in Debian <<= (com.typesafe.sbt.packager.debian.Keys.version, sbtVersion) apply { (v, sv) =>\n    sv + \"-build-\" + (v split \"\\.\" map (_.toInt) dropWhile (_ == 0) map (\"%02d\" format _) mkString \"\")\n    }\n\n    debianPackageDependencies in Debian ++= Seq(\"curl\", \"java2-runtime\", \"bash (>= 2.05a-11)\")\n\n    debianPackageRecommends in Debian += \"riak\"\n\n    linuxPackageMappings <+= (baseDirectory) map { bd =>\n    packageMapping(\n    (bd / \"copyright\") -> \"/usr/share/doc/megam_play/copyright\"\n    ) withPerms \"0644\" asDocs()\n    }\n\n    linuxPackageMappings in Debian <+= (com.typesafe.sbt.packager.debian.Keys.sourceDirectory) map { bd =>\n    (packageMapping(\n    (bd / \"debian/changelog\") -> \"/usr/share/doc/megam_play/changelog.gz\"\n    ) withUser \"root\" withGroup \"root\" withPerms \"0644\" gzipped) asDocs()\n    }\n\n    mappings in upload := Seq((new java.io.File((\"%s-%s.deb\") format(\"target/megamplay\", \"0.12.4-build-0100\")),\"0.1/debs/megam_play.deb\"))\n\n    host in upload := \"megampub.s3.amazonaws.com\"\n\n    credentials += Credentials(Path.userHome / \"software\" / \"aws\" / \"keys\" / \"sbt_s3_keys\")\n\n    S3.progress in S3.upload := true\n    \n    \n 1.Plugins.sb\n\n    // Comment to get more information during initialization\n    logLevel := Level.Warn\n\n    // The Typesafe repository \n    resolvers += \"Typesafe repository\" at     \"http://repo.typesafe.com/typesafe/releases/\"\n\n    // Typesafe snapshots\n    resolvers += \"Typesafe Snapshots\" at    \"http://repo.typesafe.com/typesafe/snapshots/\"\n\n    // Use the Play sbt plugin for Play projects\n\n    addSbtPlugin(\"play\" % \"sbt-plugin\" % \"2.2.0\")\n    \n    \nproject/build.properties\n\n`sbt.version=0.13.0`\n\nWe built our own AMQP based on scalaz, and is available in http://github.com/indykish/megam_common. Now build and publish megam_common jars using the process as described in this link into https://oss.sonatype.org/content/repositories/snapshots/com/github/indykish/megam_common_2.10/0.1.0-SNAPSHOT/.\n\n`sbt publish`\n\n\nRun the play project megam_play\n\n    ram@ramhome:~/code/megam/workspace/megam_play$ sbt\n    [info] Loading global plugins from /home/ram/.sbt/0.13/plugins\n    [info] Loading project definition from /home/ram/code/megam/workspace/megam_play/project\n    [info] Set current project to megam_play (in build     file:/home/ram/code/megam/workspace/megam_play/)\n    [megam_play] $ play\n           _\n      _ __ | | __ _ _  _\n     | '_ | |/ _' | || | \n     |  __/|_|___|__ /\n     |_|          |__/\n\n    play 2.2.0 built with Scala 2.10.2 (running Java 1.7.0_25), http://www.playframework.com\n\n    > Type \"help play\" or \"license\" for more information.\n    > Type \"exit\" or use Ctrl+D to leave this console.\n\n    [megam_play] $\n\nYou can use lsof as shown below to see if the server runs on port 9000.\n\n\n\n    [nilam] $ run\n\n    $ sudo lsof -i:9000\n    [sudo] password for ram:\n    COMMAND   PID USER   FD   TYPE DEVICE SIZE NODE NAME\n    java    15640  ram  270u  IPv6  40094       TCP *:9000 (LISTEN)\n\nNow let us add a template to show the\n\n    1. index page,\n    2. Error when an invalid URL is passed\n\n####index.scala.html\n\n    @(message: String)(implicit flash: play.api.mvc.Flash)\n    @main(\"Megam Cloud v1\") {\n    @welcome(message)\n    }\n    \n    \n####main.scala.html\n\n\n\n    @(title: String)(content: Html)\n    <!DOCTYPE html>\n    <html>\n    <head>\n    <title>@title</title>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta name=\"description\" content=\"\">\n    <meta name=\"author\" content=\"\">\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"https://fonts.googleapis.com/css?family=Lato:300,400,700\" />\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"@routes.Assets.at(\"stylesheets/theme.css\")\" >\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"@routes.Assets.at(\"stylesheets/bootstrap-theme.css\")\" >\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"@routes.Assets.at(\"stylesheets/bootstrap.css\")\" >\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"@routes.Assets.at(\"stylesheets/bootstrap-glyphicons.css\")\">\n    <link rel=\"stylesheet\" href=\"styles/default.css\">\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"@routes.Assets.at(\"stylesheets/styles/default.css\")\" >\n    <link rel=\"shortcut icon\" type=\"image/png\" href=\"@routes.Assets.at(\"images/favicon.png\")\">\n\n    <!-- Bootstrap -->\n    <script src=\"@routes.Assets.at(\"javascripts/jquery.js\")\" type=\"text/javascript\"></script>\n    <script src=\"@routes.Assets.at(\"javascripts/bootstrap.js\")\" type=\"text/javascript\"></script>\n    <script  src=\"@routes.Assets.at(\"javascripts/highlight.pack.js\")\" type=\"text/javascript\"></script>\n\n    <script type=\"text/javascript\">\n            $(document).ready(function() {\n                hljs.initHighlightingOnLoad();\n                $('pre code').each(function(i, e) {\n                    hljs.highlightBlock(e)\n                });\n                $('a[data-toggle=\"tab\"]').on('shown.bs.tab', function(e) {\n                    e.target// activated tab\n                    e.relatedTarget // previous tab\n                });\n\n            });\n    </script>\n    <style type=\"text/css\">\n      /* <![CDATA[ */\n      #pagetoc li {\n        padding-left: 22px;\n        text-indent: -22px;\n      }\n\n      /* ]]> */\n    </style>\n      </head>\n       <body>\n       <div>     \n        <div>\n            @leftmenu()\n            @content\n        </div>\n      </div>\n\n    <!-- JQuery will invoke via the spinner and display a loading modal lock. -->\n    <div id=\"loading\" />\n  </body>\n</html>\n\n\n####errorPage.scala.html\n\n\n    @(ex: Throwable)\n\n    @main(\"An error occurred while trying to run megam_play. contact support.\") {\n    <div class=\"api-doc\">\n      <div class=\"mddoc margin-top-large\">\n       <image src=\"@routes.Assets.at(\"images/nirvana.png\")\"/>\n    <h1><a name=\"rest_docs\" href=\"#a-rest_docs\">Sucked into Nirvana</a></h1>\n    <p class=\"lead\">\n      <code>\n        @(ex getMessage)\n      </code>\n    </p>\n    <div class=\"page-header\">\n      <h2>Stacktrace</h2>\n    </div>\n    \n     <div class=\"\">\n     \n    \n    <code class=\"brush: bash; toolbar:     false;\">@({val u = new java.io.StringWriter; ex.printStackTrace(new java.io.PrintWriter(u)); u.toString})\n        </code>\n      </div>\n     </div>\n    </div>\n    }\n    \n    \n    object Global extends GlobalSettings {\n\n     override def onStart(app: Application) {\n    play.api.Logger.info(\"Megam Play %s App - started\".format(\"0.1\"))\n    }\n\n    override def onStop(app: Application) {\n    play.api.Logger.info(\"Megam Play %s App - going down. Stateless folks - you don't care.\".format(\"0.1\"))\n    }\n\n    override def onError(request: RequestHeader, ex: Throwable) : Future[play.api.mvc.SimpleResult] = {\n    Future.successful(InternalServerError(\n      views.html.errorPage(ex)))\n    }\n\n    override def onHandlerNotFound(request: RequestHeader): Future[play.api.mvc.SimpleResult] = {\n    Future.successful(NotFound(\n      views.html.errorPage(new Throwable(NOT_FOUND + \":\" + request.path + \" NOT_FOUND\"))))\n     }\n    }\n    \n\nThee view files are placed under views directory.\n\nType https://localhost:9000\n\n\n\n\n\n\n","source":"_posts/2015-03-16-setting-up-scala-sbt-play-akka.md","raw":"---\ntitle: Setting up Scala, SBT, Play, Akka\nslug: setting-up-scala-sbt-play-akka\ndate_published: 2015-03-16T06:51:17.639Z\ndate_updated:   2015-08-16T13:48:58.571Z\n---\n\n###Part 1 : Setting up Scala, SBT, Play, Akka \n\nThis will be multi-part series in building a cloud API server for our PaaS with cloud instrumentation using a messaging layer.\n\n###1. Let us setup SBT 0.13.\n\n#### Installing in debian\n\n    echo \"deb https://dl.bintray.com/sbt/debian /\" | sudo tee -a /etc/apt/sources.list.d/sbt.list\n    sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 642AC823\n    sudo apt-get update\n    sudo apt-get install sbt\n\n(or)\n\n#### Manual install of sbt\n\n- Download the [sbt_launch.jar](https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/sbt-launch/0.13.9/sbt-launch.jar?_ga=1.124271561.2110266759.1437462670) to your ~/bin directory.\n\n- Create a script named `sbt` in your ~/bin directory with the following contents.\n\n    java -server -Xms1024M -Xmx3072M -Xss32M     -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=1024M -XX:+UseG1GC -XX:+AggressiveOpts -XX:SurvivorRatio=128 -XX:MaxTenuringThreshold=0 -jar `dirname $0`/sbt-launch.jar \"$@\"\n    \n- Adjust the -Xmx, -Xms -XX:MaxPermSize based on the RAM you have. \n\nAt Megam we all have atleast 8GB or > of RAM. \n\n#### *optional Install sbt-eclipse \n\nInstall the scala-ide eclipse plugin for Eclipse Mars. \n\nHelp > Install New Software > \n\nAdd the correct link from herehttp://scala-ide.org/download/nightly.html\n\nYou can install typesafe stack and download templates from here. http://typesafe.com/stack/download#template \nhttp://typesafe.com/resources/typesafe-stack/downloading-installing.html \n\n- Create a new project in eclipse. \nScala  Worksheet allows you to play around with REPL inside eclipse editor. or use command line, to use REPL\n\n\n\n`sbt console`\n\nIf you only plan to use scala, you are done here. You can tweak your Build.scala to use the scala version you want.\n\n###2. Eclipsify scala project\n\nhttps://github.com/typesafehub/sbteclipse/wiki https://github.com/typesafehub/sbteclipse Create a file .sbt/plugins/plugins.sbt and add the following to include eclipse plugin support.\n\n    addSbtPlugin(\"com.typesafe.sbteclipse\" % \"sbteclipse-plugin\" % \"2.3.0\"\n    \nIf you created a project from command line then run sbt > eclipse to eclipsify a project..\n\n    ram@rammegam:~/code/megam/workspace/nilam$ sbt\n    [info] Loading project definition from /home/ram/code/megam/workspace/nilam/project\n    [info] Set current project to nilam (in build     file:/home/ram/code/megam/workspace/nilam/)\n    [nilam] $ eclipse\n    [info] About to create Eclipse project files for your project(s).\n    [info] Updating {file:/home/ram/code/megam/workspace/nilam/}nilam...\n    [info] Resolving org.hibernate.javax.persistence#hibernate-jpa-2.0-api;1.0.1.Fin                                                                                [info] Done updating.\n    [info] Compiling 6 Scala sources and 1 Java source to /home/ram/code/megam/workspace/nilam/target/scala-2.9.1/classes...\n    [info] Successfully created Eclipse project files for project(s):\n    [info] nilam\n    \n   \n###3. If you with to use akka\n\nA sample akka source code for the Typesafe Stack (http://typesafe.com/stack). http://typesafe.com/resources/tutorials/getting-started-with-akka-scala.html From your akka code type sbt run:\n\n    ram@rammegam:~/code/megam/workspace/megam_akka$ sbt run\n    [info] Loading project definition from /home/ram/code/megam/workspace/megam_akka/project\n    [info] Set current project to nilam (in build     file:/home/ram/code/megam/workspace/megam_akka/)\n    [info] Updating {file:/home/ram/code/megam/workspace/megam_akka/}nilam...\n    [info] Resolving com.typesafe#config;0.3.1 ...\n    [info] downloading http://repo.typesafe.com/typesafe/releases/com/typesafe/akka/akka-actor/2.0.3/akka-actor-2.0.3.jar ...\n    [info]     [SUCCESSFUL ] com.typesafe.akka#akka-actor;2.0.3!akka-actor.jar (9117ms)\n    [info] downloading http://repo.typesafe.com/typesafe/releases/com/typesafe/config/0.3.1/config-0.3.1.jar ...\n    [info]     [SUCCESSFUL ] com.typesafe#config;0.3.1!config.jar(bundle) (3345ms)\n    [info] Done updating.\n    [info] Compiling 1 Scala source to /home/ram/code/megam/workspace/megam_akka/target/scala-2.9.2/classes...\n    [info] Running org.megam.akka.Nilam\n    Count is 3\n    [success] Total time: 25 s, completed 6 Nov, 2012 12:31:57 PM\n\n\n\n###4. Setting up Play framework\n\nLet us create a project titled megam_play which will use external dependencies like scaliak, newman, scalaz This project megam_play was created by cloning an existing typesafe_stack (play scala sample template). You are free to pick any other template from Github.com Adding library dependencies in your Build.scala file. The scaliak, amqp dependency has been moved to a common artifact named megam_common\n\n    import sbt._\n    import play.Project._\n\n    object ApplicationBuild extends Build {\n\n     val appName = \"megam_play\"\n\n      val appVersion = \"0.1.0\"\n\n      val organization = \"Megam Systems\"\n\n      val homepage = Some(url(\"http://www.megam.co\"))\n\n      val startYear = Some(2013)\n\n      val description = \"RESTful API server for the megam platform. Uses Riak and Memcache\"\n\n      /**\n       *   if you use groupID %% artifactID % revision instead of groupID % artifactID % revision\n       *   (the difference is the double %% after the groupID), sbt will add your projects Scala version\n       *   to the artifact name.\n       */\n\n      val play2AuthVersion = \"0.11.0-SNAPSHOT\"\n      val megamVersion = \"0.1.0-SNAPSHOT\"\n\n      val appDependencies = Seq(\n        javaCore, cache,javaEbean,\n        \"com.twitter.service\" % \"snowflake\" % \"1.0.2\" from \"https://s3-ap-southeast-1.amazonaws.com/megampub/0.1/jars/snowflake.jar\", //don't move this below.\n    \"com.github.indykish\" % \"megam_common_2.10\" % megamVersion excludeAll (\n      ExclusionRule(\"commons-logging\",\"commons-logging\"),\n      ExclusionRule(\"org.slf4j\",\"slf4j-jdk14\")),\n    \"com.github.mumoshu\" %% \"play2-memcached\" % \"0.3.0.2\",\n    \"jp.t2v\" %% \"play2-auth\" % play2AuthVersion,\n    \"jp.t2v\" %% \"play2-auth-test\" % play2AuthVersion % \"test\",\n    \"com.stackmob\" %% \"newman\" % \"1.3.0\" % \"test\")\n\n      val main = play.Project(appName, appVersion, appDependencies).settings(    \n    sbt.Keys.resolvers += \"Sonatype Snapshots\" at \"https://oss.sonatype.org/content/repositories/snapshots\",\n    sbt.Keys.resolvers += \"Typesafe Snapshots\" at \"http://repo.typesafe.com/typesafe/snapshots/\",\n    sbt.Keys.resolvers += \"Scala-Tools Maven2 Snapshots Repository\" at \"http://scala-tools.org/repo-snapshots\",\n    sbt.Keys.resolvers += \"Twitter Repo\" at \"http://maven.twttr.com\", // finagle \n    sbt.Keys.resolvers += \"spray repo\" at \"http://repo.spray.io\", //spray client used in newman.\n    sbt.Keys.resolvers += \"spray nightly\" at \"http://nightlies.spray.io\", //spray client nighly used in newman (0.23.0).\n    sbt.Keys.resolvers += \"Spy Repository\" at \"http://files.couchbase.com/maven2\" // required to resolve `spymemcached`, the plugin's dependency.\n    )\n\n    }\n    \nWe package debs, hence build.sbt contains the required statements\n\n    import sbt\n    import Process._\n    import com.typesafe.sbt.packager.debian.Keys._\n    import    com.typesafe.sbt.packager.linux.LinuxPackageMapping\n    import S3._\n\n    scalaVersion := \"2.10.3\"\n\n    scalacOptions := Seq(\n      \"-unchecked\", \n      \"-deprecation\",\n      \"-feature\",\n      \"-optimise\",\n    \"-Xcheckinit\",\n    \"-Xlint\",\n    \"-Xverify\",\n    \"-Yinline-warnings\",\n    \"-Yclosure-elim\",\n    \"-language:postfixOps\",\n    \"-language:implicitConversions\",\n    \"-Ydead-code\")\n\n    com.typesafe.sbt.packager.debian.Keys.name in Debian := \"megamplay\"\n\n    maintainer in Debian:= \"Rajthilak <rajthilak@megam.co.in>\"\n\n    packageSummary := \"Cloud API server - Megam.\" \n\n    packageDescription in Debian:= \" (REST based) Cloud API server for Megam platform.The API server protects the resources using HMAC based authorization, as provided to a customer during onboarding.\"\n\n    s3Settings\n\n    linuxPackageMappings in Debian <+= (baseDirectory) map { bd =>\n      (packageMapping((bd / \"bin/mp\") -> \"/usr/local/share/megamplay/bin/mp\")\n       withUser \"root\" withGroup \"root\" withPerms \"0755\")\n    }\n\n    linuxPackageMappings <+= (baseDirectory) map { bd =>\n      val src = bd / \"target/staged\"\n     val dest = \"/usr/local/share/megamplay/lib\"\n    LinuxPackageMapping(\n    for {\n      path <- (src ***).get\n      if !path.isDirectory\n    } yield path -> path.toString.replaceFirst(src.toString, dest)\n    )\n    }\n\n    linuxPackageMappings in Debian <+= (baseDirectory) map { bd =>\n      (packageMapping((bd / \"conf/application-production.conf\") -> \"/usr/local/share/megamplay/conf/application-production.conf\")\n    withConfig())\n    }\n\n    linuxPackageMappings in Debian <+= (baseDirectory) map { bd =>\n      (packageMapping((bd / \"conf/application-logger.xml\") -> \"/usr/local/share/megamplay/conf/application-logger.xml\")\n    withConfig()) \n    }\n\n    linuxPackageMappings in Debian <+= (baseDirectory) map { bd =>\n    (packageMapping((bd / \"conf/routes\") -> \"/usr/local/share/megamplay/conf/routes\")\n    withConfig())\n    }\n\n    linuxPackageMappings in Debian <+= (baseDirectory) map { bd =>\n    (packageMapping((bd / \"conf/messages\") -> \"/usr/local/share/megamplay/conf/messages\")\n    withConfig())\n    }\n\n    linuxPackageMappings in Debian <+= (baseDirectory) map { bd =>\n    (packageMapping((bd / \"conf/play.plugins\") -> \"/usr/local/share/megamplay/conf/play.plugins\")\n    withConfig())\n    }\n\n    com.typesafe.sbt.packager.debian.Keys.version in Debian <<= (com.typesafe.sbt.packager.debian.Keys.version, sbtVersion) apply { (v, sv) =>\n    sv + \"-build-\" + (v split \"\\.\" map (_.toInt) dropWhile (_ == 0) map (\"%02d\" format _) mkString \"\")\n    }\n\n    debianPackageDependencies in Debian ++= Seq(\"curl\", \"java2-runtime\", \"bash (>= 2.05a-11)\")\n\n    debianPackageRecommends in Debian += \"riak\"\n\n    linuxPackageMappings <+= (baseDirectory) map { bd =>\n    packageMapping(\n    (bd / \"copyright\") -> \"/usr/share/doc/megam_play/copyright\"\n    ) withPerms \"0644\" asDocs()\n    }\n\n    linuxPackageMappings in Debian <+= (com.typesafe.sbt.packager.debian.Keys.sourceDirectory) map { bd =>\n    (packageMapping(\n    (bd / \"debian/changelog\") -> \"/usr/share/doc/megam_play/changelog.gz\"\n    ) withUser \"root\" withGroup \"root\" withPerms \"0644\" gzipped) asDocs()\n    }\n\n    mappings in upload := Seq((new java.io.File((\"%s-%s.deb\") format(\"target/megamplay\", \"0.12.4-build-0100\")),\"0.1/debs/megam_play.deb\"))\n\n    host in upload := \"megampub.s3.amazonaws.com\"\n\n    credentials += Credentials(Path.userHome / \"software\" / \"aws\" / \"keys\" / \"sbt_s3_keys\")\n\n    S3.progress in S3.upload := true\n    \n    \n 1.Plugins.sb\n\n    // Comment to get more information during initialization\n    logLevel := Level.Warn\n\n    // The Typesafe repository \n    resolvers += \"Typesafe repository\" at     \"http://repo.typesafe.com/typesafe/releases/\"\n\n    // Typesafe snapshots\n    resolvers += \"Typesafe Snapshots\" at    \"http://repo.typesafe.com/typesafe/snapshots/\"\n\n    // Use the Play sbt plugin for Play projects\n\n    addSbtPlugin(\"play\" % \"sbt-plugin\" % \"2.2.0\")\n    \n    \nproject/build.properties\n\n`sbt.version=0.13.0`\n\nWe built our own AMQP based on scalaz, and is available in http://github.com/indykish/megam_common. Now build and publish megam_common jars using the process as described in this link into https://oss.sonatype.org/content/repositories/snapshots/com/github/indykish/megam_common_2.10/0.1.0-SNAPSHOT/.\n\n`sbt publish`\n\n\nRun the play project megam_play\n\n    ram@ramhome:~/code/megam/workspace/megam_play$ sbt\n    [info] Loading global plugins from /home/ram/.sbt/0.13/plugins\n    [info] Loading project definition from /home/ram/code/megam/workspace/megam_play/project\n    [info] Set current project to megam_play (in build     file:/home/ram/code/megam/workspace/megam_play/)\n    [megam_play] $ play\n           _\n      _ __ | | __ _ _  _\n     | '_ | |/ _' | || | \n     |  __/|_|___|__ /\n     |_|          |__/\n\n    play 2.2.0 built with Scala 2.10.2 (running Java 1.7.0_25), http://www.playframework.com\n\n    > Type \"help play\" or \"license\" for more information.\n    > Type \"exit\" or use Ctrl+D to leave this console.\n\n    [megam_play] $\n\nYou can use lsof as shown below to see if the server runs on port 9000.\n\n\n\n    [nilam] $ run\n\n    $ sudo lsof -i:9000\n    [sudo] password for ram:\n    COMMAND   PID USER   FD   TYPE DEVICE SIZE NODE NAME\n    java    15640  ram  270u  IPv6  40094       TCP *:9000 (LISTEN)\n\nNow let us add a template to show the\n\n    1. index page,\n    2. Error when an invalid URL is passed\n\n####index.scala.html\n\n    @(message: String)(implicit flash: play.api.mvc.Flash)\n    @main(\"Megam Cloud v1\") {\n    @welcome(message)\n    }\n    \n    \n####main.scala.html\n\n\n\n    @(title: String)(content: Html)\n    <!DOCTYPE html>\n    <html>\n    <head>\n    <title>@title</title>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta name=\"description\" content=\"\">\n    <meta name=\"author\" content=\"\">\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"https://fonts.googleapis.com/css?family=Lato:300,400,700\" />\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"@routes.Assets.at(\"stylesheets/theme.css\")\" >\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"@routes.Assets.at(\"stylesheets/bootstrap-theme.css\")\" >\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"@routes.Assets.at(\"stylesheets/bootstrap.css\")\" >\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"@routes.Assets.at(\"stylesheets/bootstrap-glyphicons.css\")\">\n    <link rel=\"stylesheet\" href=\"styles/default.css\">\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"@routes.Assets.at(\"stylesheets/styles/default.css\")\" >\n    <link rel=\"shortcut icon\" type=\"image/png\" href=\"@routes.Assets.at(\"images/favicon.png\")\">\n\n    <!-- Bootstrap -->\n    <script src=\"@routes.Assets.at(\"javascripts/jquery.js\")\" type=\"text/javascript\"></script>\n    <script src=\"@routes.Assets.at(\"javascripts/bootstrap.js\")\" type=\"text/javascript\"></script>\n    <script  src=\"@routes.Assets.at(\"javascripts/highlight.pack.js\")\" type=\"text/javascript\"></script>\n\n    <script type=\"text/javascript\">\n            $(document).ready(function() {\n                hljs.initHighlightingOnLoad();\n                $('pre code').each(function(i, e) {\n                    hljs.highlightBlock(e)\n                });\n                $('a[data-toggle=\"tab\"]').on('shown.bs.tab', function(e) {\n                    e.target// activated tab\n                    e.relatedTarget // previous tab\n                });\n\n            });\n    </script>\n    <style type=\"text/css\">\n      /* <![CDATA[ */\n      #pagetoc li {\n        padding-left: 22px;\n        text-indent: -22px;\n      }\n\n      /* ]]> */\n    </style>\n      </head>\n       <body>\n       <div>     \n        <div>\n            @leftmenu()\n            @content\n        </div>\n      </div>\n\n    <!-- JQuery will invoke via the spinner and display a loading modal lock. -->\n    <div id=\"loading\" />\n  </body>\n</html>\n\n\n####errorPage.scala.html\n\n\n    @(ex: Throwable)\n\n    @main(\"An error occurred while trying to run megam_play. contact support.\") {\n    <div class=\"api-doc\">\n      <div class=\"mddoc margin-top-large\">\n       <image src=\"@routes.Assets.at(\"images/nirvana.png\")\"/>\n    <h1><a name=\"rest_docs\" href=\"#a-rest_docs\">Sucked into Nirvana</a></h1>\n    <p class=\"lead\">\n      <code>\n        @(ex getMessage)\n      </code>\n    </p>\n    <div class=\"page-header\">\n      <h2>Stacktrace</h2>\n    </div>\n    \n     <div class=\"\">\n     \n    \n    <code class=\"brush: bash; toolbar:     false;\">@({val u = new java.io.StringWriter; ex.printStackTrace(new java.io.PrintWriter(u)); u.toString})\n        </code>\n      </div>\n     </div>\n    </div>\n    }\n    \n    \n    object Global extends GlobalSettings {\n\n     override def onStart(app: Application) {\n    play.api.Logger.info(\"Megam Play %s App - started\".format(\"0.1\"))\n    }\n\n    override def onStop(app: Application) {\n    play.api.Logger.info(\"Megam Play %s App - going down. Stateless folks - you don't care.\".format(\"0.1\"))\n    }\n\n    override def onError(request: RequestHeader, ex: Throwable) : Future[play.api.mvc.SimpleResult] = {\n    Future.successful(InternalServerError(\n      views.html.errorPage(ex)))\n    }\n\n    override def onHandlerNotFound(request: RequestHeader): Future[play.api.mvc.SimpleResult] = {\n    Future.successful(NotFound(\n      views.html.errorPage(new Throwable(NOT_FOUND + \":\" + request.path + \" NOT_FOUND\"))))\n     }\n    }\n    \n\nThee view files are placed under views directory.\n\nType https://localhost:9000\n\n\n\n\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzairi000bdrgb71dau1z6","content":"<p>###Part 1 : Setting up Scala, SBT, Play, Akka </p>\n<p>This will be multi-part series in building a cloud API server for our PaaS with cloud instrumentation using a messaging layer.</p>\n<p>###1. Let us setup SBT 0.13.</p>\n<h4 id=\"Installing-in-debian\"><a href=\"#Installing-in-debian\" class=\"headerlink\" title=\"Installing in debian\"></a>Installing in debian</h4><pre><code>echo &quot;deb https://dl.bintray.com/sbt/debian /&quot; | sudo tee -a /etc/apt/sources.list.d/sbt.list\nsudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 642AC823\nsudo apt-get update\nsudo apt-get install sbt\n</code></pre><p>(or)</p>\n<h4 id=\"Manual-install-of-sbt\"><a href=\"#Manual-install-of-sbt\" class=\"headerlink\" title=\"Manual install of sbt\"></a>Manual install of sbt</h4><ul>\n<li><p>Download the <a href=\"https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/sbt-launch/0.13.9/sbt-launch.jar?_ga=1.124271561.2110266759.1437462670\" target=\"_blank\" rel=\"external\">sbt_launch.jar</a> to your ~/bin directory.</p>\n</li>\n<li><p>Create a script named <code>sbt</code> in your ~/bin directory with the following contents.</p>\n<p>  java -server -Xms1024M -Xmx3072M -Xss32M     -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=1024M -XX:+UseG1GC -XX:+AggressiveOpts -XX:SurvivorRatio=128 -XX:MaxTenuringThreshold=0 -jar <code>dirname $0</code>/sbt-launch.jar $@</p>\n</li>\n<li><p>Adjust the -Xmx, -Xms -XX:MaxPermSize based on the RAM you have. </p>\n</li>\n</ul>\n<p>At Megam we all have atleast 8GB or &gt; of RAM. </p>\n<h4 id=\"optional-Install-sbt-eclipse\"><a href=\"#optional-Install-sbt-eclipse\" class=\"headerlink\" title=\"*optional Install sbt-eclipse\"></a>*optional Install sbt-eclipse</h4><p>Install the scala-ide eclipse plugin for Eclipse Mars. </p>\n<p>Help &gt; Install New Software &gt; </p>\n<p>Add the correct link from here<a href=\"http://scala-ide.org/download/nightly.html\" target=\"_blank\" rel=\"external\">http://scala-ide.org/download/nightly.html</a></p>\n<p>You can install typesafe stack and download templates from here. <a href=\"http://typesafe.com/stack/download#template\" target=\"_blank\" rel=\"external\">http://typesafe.com/stack/download#template</a><br><a href=\"http://typesafe.com/resources/typesafe-stack/downloading-installing.html\" target=\"_blank\" rel=\"external\">http://typesafe.com/resources/typesafe-stack/downloading-installing.html</a> </p>\n<ul>\n<li>Create a new project in eclipse.<br>Scala  Worksheet allows you to play around with REPL inside eclipse editor. or use command line, to use REPL</li>\n</ul>\n<p><code>sbt console</code></p>\n<p>If you only plan to use scala, you are done here. You can tweak your Build.scala to use the scala version you want.</p>\n<p>###2. Eclipsify scala project</p>\n<p><a href=\"https://github.com/typesafehub/sbteclipse/wiki\" target=\"_blank\" rel=\"external\">https://github.com/typesafehub/sbteclipse/wiki</a> <a href=\"https://github.com/typesafehub/sbteclipse\" target=\"_blank\" rel=\"external\">https://github.com/typesafehub/sbteclipse</a> Create a file .sbt/plugins/plugins.sbt and add the following to include eclipse plugin support.</p>\n<pre><code>addSbtPlugin(&quot;com.typesafe.sbteclipse&quot; % &quot;sbteclipse-plugin&quot; % &quot;2.3.0&quot;\n</code></pre><p>If you created a project from command line then run sbt &gt; eclipse to eclipsify a project..</p>\n<pre><code>ram@rammegam:~/code/megam/workspace/nilam$ sbt\n[info] Loading project definition from /home/ram/code/megam/workspace/nilam/project\n[info] Set current project to nilam (in build     file:/home/ram/code/megam/workspace/nilam/)\n[nilam] $ eclipse\n[info] About to create Eclipse project files for your project(s).\n[info] Updating {file:/home/ram/code/megam/workspace/nilam/}nilam...\n[info] Resolving org.hibernate.javax.persistence#hibernate-jpa-2.0-api;1.0.1.Fin                                                                                [info] Done updating.\n[info] Compiling 6 Scala sources and 1 Java source to /home/ram/code/megam/workspace/nilam/target/scala-2.9.1/classes...\n[info] Successfully created Eclipse project files for project(s):\n[info] nilam\n</code></pre><p>###3. If you with to use akka</p>\n<p>A sample akka source code for the Typesafe Stack (<a href=\"http://typesafe.com/stack\" target=\"_blank\" rel=\"external\">http://typesafe.com/stack</a>). <a href=\"http://typesafe.com/resources/tutorials/getting-started-with-akka-scala.html\" target=\"_blank\" rel=\"external\">http://typesafe.com/resources/tutorials/getting-started-with-akka-scala.html</a> From your akka code type sbt run:</p>\n<pre><code>ram@rammegam:~/code/megam/workspace/megam_akka$ sbt run\n[info] Loading project definition from /home/ram/code/megam/workspace/megam_akka/project\n[info] Set current project to nilam (in build     file:/home/ram/code/megam/workspace/megam_akka/)\n[info] Updating {file:/home/ram/code/megam/workspace/megam_akka/}nilam...\n[info] Resolving com.typesafe#config;0.3.1 ...\n[info] downloading http://repo.typesafe.com/typesafe/releases/com/typesafe/akka/akka-actor/2.0.3/akka-actor-2.0.3.jar ...\n[info]     [SUCCESSFUL ] com.typesafe.akka#akka-actor;2.0.3!akka-actor.jar (9117ms)\n[info] downloading http://repo.typesafe.com/typesafe/releases/com/typesafe/config/0.3.1/config-0.3.1.jar ...\n[info]     [SUCCESSFUL ] com.typesafe#config;0.3.1!config.jar(bundle) (3345ms)\n[info] Done updating.\n[info] Compiling 1 Scala source to /home/ram/code/megam/workspace/megam_akka/target/scala-2.9.2/classes...\n[info] Running org.megam.akka.Nilam\nCount is 3\n[success] Total time: 25 s, completed 6 Nov, 2012 12:31:57 PM\n</code></pre><p>###4. Setting up Play framework</p>\n<p>Let us create a project titled megam_play which will use external dependencies like scaliak, newman, scalaz This project megam_play was created by cloning an existing typesafe_stack (play scala sample template). You are free to pick any other template from Github.com Adding library dependencies in your Build.scala file. The scaliak, amqp dependency has been moved to a common artifact named megam_common</p>\n<pre><code>import sbt._\nimport play.Project._\n\nobject ApplicationBuild extends Build {\n\n val appName = &quot;megam_play&quot;\n\n  val appVersion = &quot;0.1.0&quot;\n\n  val organization = &quot;Megam Systems&quot;\n\n  val homepage = Some(url(&quot;http://www.megam.co&quot;))\n\n  val startYear = Some(2013)\n\n  val description = &quot;RESTful API server for the megam platform. Uses Riak and Memcache&quot;\n\n  /**\n   *   if you use groupID %% artifactID % revision instead of groupID % artifactID % revision\n   *   (the difference is the double %% after the groupID), sbt will add your projects Scala version\n   *   to the artifact name.\n   */\n\n  val play2AuthVersion = &quot;0.11.0-SNAPSHOT&quot;\n  val megamVersion = &quot;0.1.0-SNAPSHOT&quot;\n\n  val appDependencies = Seq(\n    javaCore, cache,javaEbean,\n    &quot;com.twitter.service&quot; % &quot;snowflake&quot; % &quot;1.0.2&quot; from &quot;https://s3-ap-southeast-1.amazonaws.com/megampub/0.1/jars/snowflake.jar&quot;, //don&apos;t move this below.\n&quot;com.github.indykish&quot; % &quot;megam_common_2.10&quot; % megamVersion excludeAll (\n  ExclusionRule(&quot;commons-logging&quot;,&quot;commons-logging&quot;),\n  ExclusionRule(&quot;org.slf4j&quot;,&quot;slf4j-jdk14&quot;)),\n&quot;com.github.mumoshu&quot; %% &quot;play2-memcached&quot; % &quot;0.3.0.2&quot;,\n&quot;jp.t2v&quot; %% &quot;play2-auth&quot; % play2AuthVersion,\n&quot;jp.t2v&quot; %% &quot;play2-auth-test&quot; % play2AuthVersion % &quot;test&quot;,\n&quot;com.stackmob&quot; %% &quot;newman&quot; % &quot;1.3.0&quot; % &quot;test&quot;)\n\n  val main = play.Project(appName, appVersion, appDependencies).settings(    \nsbt.Keys.resolvers += &quot;Sonatype Snapshots&quot; at &quot;https://oss.sonatype.org/content/repositories/snapshots&quot;,\nsbt.Keys.resolvers += &quot;Typesafe Snapshots&quot; at &quot;http://repo.typesafe.com/typesafe/snapshots/&quot;,\nsbt.Keys.resolvers += &quot;Scala-Tools Maven2 Snapshots Repository&quot; at &quot;http://scala-tools.org/repo-snapshots&quot;,\nsbt.Keys.resolvers += &quot;Twitter Repo&quot; at &quot;http://maven.twttr.com&quot;, // finagle \nsbt.Keys.resolvers += &quot;spray repo&quot; at &quot;http://repo.spray.io&quot;, //spray client used in newman.\nsbt.Keys.resolvers += &quot;spray nightly&quot; at &quot;http://nightlies.spray.io&quot;, //spray client nighly used in newman (0.23.0).\nsbt.Keys.resolvers += &quot;Spy Repository&quot; at &quot;http://files.couchbase.com/maven2&quot; // required to resolve `spymemcached`, the plugin&apos;s dependency.\n)\n\n}\n</code></pre><p>We package debs, hence build.sbt contains the required statements</p>\n<pre><code>import sbt\nimport Process._\nimport com.typesafe.sbt.packager.debian.Keys._\nimport    com.typesafe.sbt.packager.linux.LinuxPackageMapping\nimport S3._\n\nscalaVersion := &quot;2.10.3&quot;\n\nscalacOptions := Seq(\n  &quot;-unchecked&quot;, \n  &quot;-deprecation&quot;,\n  &quot;-feature&quot;,\n  &quot;-optimise&quot;,\n&quot;-Xcheckinit&quot;,\n&quot;-Xlint&quot;,\n&quot;-Xverify&quot;,\n&quot;-Yinline-warnings&quot;,\n&quot;-Yclosure-elim&quot;,\n&quot;-language:postfixOps&quot;,\n&quot;-language:implicitConversions&quot;,\n&quot;-Ydead-code&quot;)\n\ncom.typesafe.sbt.packager.debian.Keys.name in Debian := &quot;megamplay&quot;\n\nmaintainer in Debian:= &quot;Rajthilak &lt;rajthilak@megam.co.in&gt;&quot;\n\npackageSummary := &quot;Cloud API server - Megam.&quot; \n\npackageDescription in Debian:= &quot; (REST based) Cloud API server for Megam platform.The API server protects the resources using HMAC based authorization, as provided to a customer during onboarding.&quot;\n\ns3Settings\n\nlinuxPackageMappings in Debian &lt;+= (baseDirectory) map { bd =&gt;\n  (packageMapping((bd / &quot;bin/mp&quot;) -&gt; &quot;/usr/local/share/megamplay/bin/mp&quot;)\n   withUser &quot;root&quot; withGroup &quot;root&quot; withPerms &quot;0755&quot;)\n}\n\nlinuxPackageMappings &lt;+= (baseDirectory) map { bd =&gt;\n  val src = bd / &quot;target/staged&quot;\n val dest = &quot;/usr/local/share/megamplay/lib&quot;\nLinuxPackageMapping(\nfor {\n  path &lt;- (src ***).get\n  if !path.isDirectory\n} yield path -&gt; path.toString.replaceFirst(src.toString, dest)\n)\n}\n\nlinuxPackageMappings in Debian &lt;+= (baseDirectory) map { bd =&gt;\n  (packageMapping((bd / &quot;conf/application-production.conf&quot;) -&gt; &quot;/usr/local/share/megamplay/conf/application-production.conf&quot;)\nwithConfig())\n}\n\nlinuxPackageMappings in Debian &lt;+= (baseDirectory) map { bd =&gt;\n  (packageMapping((bd / &quot;conf/application-logger.xml&quot;) -&gt; &quot;/usr/local/share/megamplay/conf/application-logger.xml&quot;)\nwithConfig()) \n}\n\nlinuxPackageMappings in Debian &lt;+= (baseDirectory) map { bd =&gt;\n(packageMapping((bd / &quot;conf/routes&quot;) -&gt; &quot;/usr/local/share/megamplay/conf/routes&quot;)\nwithConfig())\n}\n\nlinuxPackageMappings in Debian &lt;+= (baseDirectory) map { bd =&gt;\n(packageMapping((bd / &quot;conf/messages&quot;) -&gt; &quot;/usr/local/share/megamplay/conf/messages&quot;)\nwithConfig())\n}\n\nlinuxPackageMappings in Debian &lt;+= (baseDirectory) map { bd =&gt;\n(packageMapping((bd / &quot;conf/play.plugins&quot;) -&gt; &quot;/usr/local/share/megamplay/conf/play.plugins&quot;)\nwithConfig())\n}\n\ncom.typesafe.sbt.packager.debian.Keys.version in Debian &lt;&lt;= (com.typesafe.sbt.packager.debian.Keys.version, sbtVersion) apply { (v, sv) =&gt;\nsv + &quot;-build-&quot; + (v split &quot;\\.&quot; map (_.toInt) dropWhile (_ == 0) map (&quot;%02d&quot; format _) mkString &quot;&quot;)\n}\n\ndebianPackageDependencies in Debian ++= Seq(&quot;curl&quot;, &quot;java2-runtime&quot;, &quot;bash (&gt;= 2.05a-11)&quot;)\n\ndebianPackageRecommends in Debian += &quot;riak&quot;\n\nlinuxPackageMappings &lt;+= (baseDirectory) map { bd =&gt;\npackageMapping(\n(bd / &quot;copyright&quot;) -&gt; &quot;/usr/share/doc/megam_play/copyright&quot;\n) withPerms &quot;0644&quot; asDocs()\n}\n\nlinuxPackageMappings in Debian &lt;+= (com.typesafe.sbt.packager.debian.Keys.sourceDirectory) map { bd =&gt;\n(packageMapping(\n(bd / &quot;debian/changelog&quot;) -&gt; &quot;/usr/share/doc/megam_play/changelog.gz&quot;\n) withUser &quot;root&quot; withGroup &quot;root&quot; withPerms &quot;0644&quot; gzipped) asDocs()\n}\n\nmappings in upload := Seq((new java.io.File((&quot;%s-%s.deb&quot;) format(&quot;target/megamplay&quot;, &quot;0.12.4-build-0100&quot;)),&quot;0.1/debs/megam_play.deb&quot;))\n\nhost in upload := &quot;megampub.s3.amazonaws.com&quot;\n\ncredentials += Credentials(Path.userHome / &quot;software&quot; / &quot;aws&quot; / &quot;keys&quot; / &quot;sbt_s3_keys&quot;)\n\nS3.progress in S3.upload := true\n</code></pre><p> 1.Plugins.sb</p>\n<pre><code>// Comment to get more information during initialization\nlogLevel := Level.Warn\n\n// The Typesafe repository \nresolvers += &quot;Typesafe repository&quot; at     &quot;http://repo.typesafe.com/typesafe/releases/&quot;\n\n// Typesafe snapshots\nresolvers += &quot;Typesafe Snapshots&quot; at    &quot;http://repo.typesafe.com/typesafe/snapshots/&quot;\n\n// Use the Play sbt plugin for Play projects\n\naddSbtPlugin(&quot;play&quot; % &quot;sbt-plugin&quot; % &quot;2.2.0&quot;)\n</code></pre><p>project/build.properties</p>\n<p><code>sbt.version=0.13.0</code></p>\n<p>We built our own AMQP based on scalaz, and is available in <a href=\"http://github.com/indykish/megam_common\" target=\"_blank\" rel=\"external\">http://github.com/indykish/megam_common</a>. Now build and publish megam_common jars using the process as described in this link into <a href=\"https://oss.sonatype.org/content/repositories/snapshots/com/github/indykish/megam_common_2.10/0.1.0-SNAPSHOT/\" target=\"_blank\" rel=\"external\">https://oss.sonatype.org/content/repositories/snapshots/com/github/indykish/megam_common_2.10/0.1.0-SNAPSHOT/</a>.</p>\n<p><code>sbt publish</code></p>\n<p>Run the play project megam_play</p>\n<pre><code>ram@ramhome:~/code/megam/workspace/megam_play$ sbt\n[info] Loading global plugins from /home/ram/.sbt/0.13/plugins\n[info] Loading project definition from /home/ram/code/megam/workspace/megam_play/project\n[info] Set current project to megam_play (in build     file:/home/ram/code/megam/workspace/megam_play/)\n[megam_play] $ play\n       _\n  _ __ | | __ _ _  _\n | &apos;_ | |/ _&apos; | || | \n |  __/|_|___|__ /\n |_|          |__/\n\nplay 2.2.0 built with Scala 2.10.2 (running Java 1.7.0_25), http://www.playframework.com\n\n&gt; Type &quot;help play&quot; or &quot;license&quot; for more information.\n&gt; Type &quot;exit&quot; or use Ctrl+D to leave this console.\n\n[megam_play] $\n</code></pre><p>You can use lsof as shown below to see if the server runs on port 9000.</p>\n<pre><code>[nilam] $ run\n\n$ sudo lsof -i:9000\n[sudo] password for ram:\nCOMMAND   PID USER   FD   TYPE DEVICE SIZE NODE NAME\njava    15640  ram  270u  IPv6  40094       TCP *:9000 (LISTEN)\n</code></pre><p>Now let us add a template to show the</p>\n<pre><code>1. index page,\n2. Error when an invalid URL is passed\n</code></pre><p>####index.scala.html</p>\n<pre><code>@(message: String)(implicit flash: play.api.mvc.Flash)\n@main(&quot;Megam Cloud v1&quot;) {\n@welcome(message)\n}\n</code></pre><p>####main.scala.html</p>\n<pre><code>@(title: String)(content: Html)\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;@title&lt;/title&gt;\n&lt;meta charset=&quot;utf-8&quot;&gt;\n&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;\n&lt;meta name=&quot;description&quot; content=&quot;&quot;&gt;\n&lt;meta name=&quot;author&quot; content=&quot;&quot;&gt;\n&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://fonts.googleapis.com/css?family=Lato:300,400,700&quot; /&gt;\n&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;@routes.Assets.at(&quot;stylesheets/theme.css&quot;)&quot; &gt;\n&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;@routes.Assets.at(&quot;stylesheets/bootstrap-theme.css&quot;)&quot; &gt;\n&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;@routes.Assets.at(&quot;stylesheets/bootstrap.css&quot;)&quot; &gt;\n&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;@routes.Assets.at(&quot;stylesheets/bootstrap-glyphicons.css&quot;)&quot;&gt;\n&lt;link rel=&quot;stylesheet&quot; href=&quot;styles/default.css&quot;&gt;\n&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;@routes.Assets.at(&quot;stylesheets/styles/default.css&quot;)&quot; &gt;\n&lt;link rel=&quot;shortcut icon&quot; type=&quot;image/png&quot; href=&quot;@routes.Assets.at(&quot;images/favicon.png&quot;)&quot;&gt;\n\n&lt;!-- Bootstrap --&gt;\n&lt;script src=&quot;@routes.Assets.at(&quot;javascripts/jquery.js&quot;)&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;\n&lt;script src=&quot;@routes.Assets.at(&quot;javascripts/bootstrap.js&quot;)&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;\n&lt;script  src=&quot;@routes.Assets.at(&quot;javascripts/highlight.pack.js&quot;)&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;\n\n&lt;script type=&quot;text/javascript&quot;&gt;\n        $(document).ready(function() {\n            hljs.initHighlightingOnLoad();\n            $(&apos;pre code&apos;).each(function(i, e) {\n                hljs.highlightBlock(e)\n            });\n            $(&apos;a[data-toggle=&quot;tab&quot;]&apos;).on(&apos;shown.bs.tab&apos;, function(e) {\n                e.target// activated tab\n                e.relatedTarget // previous tab\n            });\n\n        });\n&lt;/script&gt;\n&lt;style type=&quot;text/css&quot;&gt;\n  /* &lt;![CDATA[ */\n  #pagetoc li {\n    padding-left: 22px;\n    text-indent: -22px;\n  }\n\n  /* ]]&gt; */\n&lt;/style&gt;\n  &lt;/head&gt;\n   &lt;body&gt;\n   &lt;div&gt;     \n    &lt;div&gt;\n        @leftmenu()\n        @content\n    &lt;/div&gt;\n  &lt;/div&gt;\n\n&lt;!-- JQuery will invoke via the spinner and display a loading modal lock. --&gt;\n&lt;div id=&quot;loading&quot; /&gt;\n</code></pre><p>  <br></p>\n<p>####errorPage.scala.html</p>\n<pre><code>@(ex: Throwable)\n\n@main(&quot;An error occurred while trying to run megam_play. contact support.&quot;) {\n&lt;div class=&quot;api-doc&quot;&gt;\n  &lt;div class=&quot;mddoc margin-top-large&quot;&gt;\n   &lt;image src=&quot;@routes.Assets.at(&quot;images/nirvana.png&quot;)&quot;/&gt;\n&lt;h1&gt;&lt;a name=&quot;rest_docs&quot; href=&quot;#a-rest_docs&quot;&gt;Sucked into Nirvana&lt;/a&gt;&lt;/h1&gt;\n&lt;p class=&quot;lead&quot;&gt;\n  &lt;code&gt;\n    @(ex getMessage)\n  &lt;/code&gt;\n&lt;/p&gt;\n&lt;div class=&quot;page-header&quot;&gt;\n  &lt;h2&gt;Stacktrace&lt;/h2&gt;\n&lt;/div&gt;\n\n &lt;div class=&quot;&quot;&gt;\n\n\n&lt;code class=&quot;brush: bash; toolbar:     false;&quot;&gt;@({val u = new java.io.StringWriter; ex.printStackTrace(new java.io.PrintWriter(u)); u.toString})\n    &lt;/code&gt;\n  &lt;/div&gt;\n &lt;/div&gt;\n&lt;/div&gt;\n}\n\n\nobject Global extends GlobalSettings {\n\n override def onStart(app: Application) {\nplay.api.Logger.info(&quot;Megam Play %s App - started&quot;.format(&quot;0.1&quot;))\n}\n\noverride def onStop(app: Application) {\nplay.api.Logger.info(&quot;Megam Play %s App - going down. Stateless folks - you don&apos;t care.&quot;.format(&quot;0.1&quot;))\n}\n\noverride def onError(request: RequestHeader, ex: Throwable) : Future[play.api.mvc.SimpleResult] = {\nFuture.successful(InternalServerError(\n  views.html.errorPage(ex)))\n}\n\noverride def onHandlerNotFound(request: RequestHeader): Future[play.api.mvc.SimpleResult] = {\nFuture.successful(NotFound(\n  views.html.errorPage(new Throwable(NOT_FOUND + &quot;:&quot; + request.path + &quot; NOT_FOUND&quot;))))\n }\n}\n</code></pre><p>Thee view files are placed under views directory.</p>\n<p>Type <a href=\"https://localhost:9000\" target=\"_blank\" rel=\"external\">https://localhost:9000</a></p>\n","excerpt":"","more":"<p>###Part 1 : Setting up Scala, SBT, Play, Akka </p>\n<p>This will be multi-part series in building a cloud API server for our PaaS with cloud instrumentation using a messaging layer.</p>\n<p>###1. Let us setup SBT 0.13.</p>\n<h4 id=\"Installing-in-debian\"><a href=\"#Installing-in-debian\" class=\"headerlink\" title=\"Installing in debian\"></a>Installing in debian</h4><pre><code>echo &quot;deb https://dl.bintray.com/sbt/debian /&quot; | sudo tee -a /etc/apt/sources.list.d/sbt.list\nsudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 642AC823\nsudo apt-get update\nsudo apt-get install sbt\n</code></pre><p>(or)</p>\n<h4 id=\"Manual-install-of-sbt\"><a href=\"#Manual-install-of-sbt\" class=\"headerlink\" title=\"Manual install of sbt\"></a>Manual install of sbt</h4><ul>\n<li><p>Download the <a href=\"https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/sbt-launch/0.13.9/sbt-launch.jar?_ga=1.124271561.2110266759.1437462670\">sbt_launch.jar</a> to your ~/bin directory.</p>\n</li>\n<li><p>Create a script named <code>sbt</code> in your ~/bin directory with the following contents.</p>\n<p>  java -server -Xms1024M -Xmx3072M -Xss32M     -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=1024M -XX:+UseG1GC -XX:+AggressiveOpts -XX:SurvivorRatio=128 -XX:MaxTenuringThreshold=0 -jar <code>dirname $0</code>/sbt-launch.jar $@</p>\n</li>\n<li><p>Adjust the -Xmx, -Xms -XX:MaxPermSize based on the RAM you have. </p>\n</li>\n</ul>\n<p>At Megam we all have atleast 8GB or &gt; of RAM. </p>\n<h4 id=\"optional-Install-sbt-eclipse\"><a href=\"#optional-Install-sbt-eclipse\" class=\"headerlink\" title=\"*optional Install sbt-eclipse\"></a>*optional Install sbt-eclipse</h4><p>Install the scala-ide eclipse plugin for Eclipse Mars. </p>\n<p>Help &gt; Install New Software &gt; </p>\n<p>Add the correct link from here<a href=\"http://scala-ide.org/download/nightly.html\">http://scala-ide.org/download/nightly.html</a></p>\n<p>You can install typesafe stack and download templates from here. <a href=\"http://typesafe.com/stack/download#template\">http://typesafe.com/stack/download#template</a><br><a href=\"http://typesafe.com/resources/typesafe-stack/downloading-installing.html\">http://typesafe.com/resources/typesafe-stack/downloading-installing.html</a> </p>\n<ul>\n<li>Create a new project in eclipse.<br>Scala  Worksheet allows you to play around with REPL inside eclipse editor. or use command line, to use REPL</li>\n</ul>\n<p><code>sbt console</code></p>\n<p>If you only plan to use scala, you are done here. You can tweak your Build.scala to use the scala version you want.</p>\n<p>###2. Eclipsify scala project</p>\n<p><a href=\"https://github.com/typesafehub/sbteclipse/wiki\">https://github.com/typesafehub/sbteclipse/wiki</a> <a href=\"https://github.com/typesafehub/sbteclipse\">https://github.com/typesafehub/sbteclipse</a> Create a file .sbt/plugins/plugins.sbt and add the following to include eclipse plugin support.</p>\n<pre><code>addSbtPlugin(&quot;com.typesafe.sbteclipse&quot; % &quot;sbteclipse-plugin&quot; % &quot;2.3.0&quot;\n</code></pre><p>If you created a project from command line then run sbt &gt; eclipse to eclipsify a project..</p>\n<pre><code>ram@rammegam:~/code/megam/workspace/nilam$ sbt\n[info] Loading project definition from /home/ram/code/megam/workspace/nilam/project\n[info] Set current project to nilam (in build     file:/home/ram/code/megam/workspace/nilam/)\n[nilam] $ eclipse\n[info] About to create Eclipse project files for your project(s).\n[info] Updating {file:/home/ram/code/megam/workspace/nilam/}nilam...\n[info] Resolving org.hibernate.javax.persistence#hibernate-jpa-2.0-api;1.0.1.Fin                                                                                [info] Done updating.\n[info] Compiling 6 Scala sources and 1 Java source to /home/ram/code/megam/workspace/nilam/target/scala-2.9.1/classes...\n[info] Successfully created Eclipse project files for project(s):\n[info] nilam\n</code></pre><p>###3. If you with to use akka</p>\n<p>A sample akka source code for the Typesafe Stack (<a href=\"http://typesafe.com/stack\">http://typesafe.com/stack</a>). <a href=\"http://typesafe.com/resources/tutorials/getting-started-with-akka-scala.html\">http://typesafe.com/resources/tutorials/getting-started-with-akka-scala.html</a> From your akka code type sbt run:</p>\n<pre><code>ram@rammegam:~/code/megam/workspace/megam_akka$ sbt run\n[info] Loading project definition from /home/ram/code/megam/workspace/megam_akka/project\n[info] Set current project to nilam (in build     file:/home/ram/code/megam/workspace/megam_akka/)\n[info] Updating {file:/home/ram/code/megam/workspace/megam_akka/}nilam...\n[info] Resolving com.typesafe#config;0.3.1 ...\n[info] downloading http://repo.typesafe.com/typesafe/releases/com/typesafe/akka/akka-actor/2.0.3/akka-actor-2.0.3.jar ...\n[info]     [SUCCESSFUL ] com.typesafe.akka#akka-actor;2.0.3!akka-actor.jar (9117ms)\n[info] downloading http://repo.typesafe.com/typesafe/releases/com/typesafe/config/0.3.1/config-0.3.1.jar ...\n[info]     [SUCCESSFUL ] com.typesafe#config;0.3.1!config.jar(bundle) (3345ms)\n[info] Done updating.\n[info] Compiling 1 Scala source to /home/ram/code/megam/workspace/megam_akka/target/scala-2.9.2/classes...\n[info] Running org.megam.akka.Nilam\nCount is 3\n[success] Total time: 25 s, completed 6 Nov, 2012 12:31:57 PM\n</code></pre><p>###4. Setting up Play framework</p>\n<p>Let us create a project titled megam_play which will use external dependencies like scaliak, newman, scalaz This project megam_play was created by cloning an existing typesafe_stack (play scala sample template). You are free to pick any other template from Github.com Adding library dependencies in your Build.scala file. The scaliak, amqp dependency has been moved to a common artifact named megam_common</p>\n<pre><code>import sbt._\nimport play.Project._\n\nobject ApplicationBuild extends Build {\n\n val appName = &quot;megam_play&quot;\n\n  val appVersion = &quot;0.1.0&quot;\n\n  val organization = &quot;Megam Systems&quot;\n\n  val homepage = Some(url(&quot;http://www.megam.co&quot;))\n\n  val startYear = Some(2013)\n\n  val description = &quot;RESTful API server for the megam platform. Uses Riak and Memcache&quot;\n\n  /**\n   *   if you use groupID %% artifactID % revision instead of groupID % artifactID % revision\n   *   (the difference is the double %% after the groupID), sbt will add your projects Scala version\n   *   to the artifact name.\n   */\n\n  val play2AuthVersion = &quot;0.11.0-SNAPSHOT&quot;\n  val megamVersion = &quot;0.1.0-SNAPSHOT&quot;\n\n  val appDependencies = Seq(\n    javaCore, cache,javaEbean,\n    &quot;com.twitter.service&quot; % &quot;snowflake&quot; % &quot;1.0.2&quot; from &quot;https://s3-ap-southeast-1.amazonaws.com/megampub/0.1/jars/snowflake.jar&quot;, //don&apos;t move this below.\n&quot;com.github.indykish&quot; % &quot;megam_common_2.10&quot; % megamVersion excludeAll (\n  ExclusionRule(&quot;commons-logging&quot;,&quot;commons-logging&quot;),\n  ExclusionRule(&quot;org.slf4j&quot;,&quot;slf4j-jdk14&quot;)),\n&quot;com.github.mumoshu&quot; %% &quot;play2-memcached&quot; % &quot;0.3.0.2&quot;,\n&quot;jp.t2v&quot; %% &quot;play2-auth&quot; % play2AuthVersion,\n&quot;jp.t2v&quot; %% &quot;play2-auth-test&quot; % play2AuthVersion % &quot;test&quot;,\n&quot;com.stackmob&quot; %% &quot;newman&quot; % &quot;1.3.0&quot; % &quot;test&quot;)\n\n  val main = play.Project(appName, appVersion, appDependencies).settings(    \nsbt.Keys.resolvers += &quot;Sonatype Snapshots&quot; at &quot;https://oss.sonatype.org/content/repositories/snapshots&quot;,\nsbt.Keys.resolvers += &quot;Typesafe Snapshots&quot; at &quot;http://repo.typesafe.com/typesafe/snapshots/&quot;,\nsbt.Keys.resolvers += &quot;Scala-Tools Maven2 Snapshots Repository&quot; at &quot;http://scala-tools.org/repo-snapshots&quot;,\nsbt.Keys.resolvers += &quot;Twitter Repo&quot; at &quot;http://maven.twttr.com&quot;, // finagle \nsbt.Keys.resolvers += &quot;spray repo&quot; at &quot;http://repo.spray.io&quot;, //spray client used in newman.\nsbt.Keys.resolvers += &quot;spray nightly&quot; at &quot;http://nightlies.spray.io&quot;, //spray client nighly used in newman (0.23.0).\nsbt.Keys.resolvers += &quot;Spy Repository&quot; at &quot;http://files.couchbase.com/maven2&quot; // required to resolve `spymemcached`, the plugin&apos;s dependency.\n)\n\n}\n</code></pre><p>We package debs, hence build.sbt contains the required statements</p>\n<pre><code>import sbt\nimport Process._\nimport com.typesafe.sbt.packager.debian.Keys._\nimport    com.typesafe.sbt.packager.linux.LinuxPackageMapping\nimport S3._\n\nscalaVersion := &quot;2.10.3&quot;\n\nscalacOptions := Seq(\n  &quot;-unchecked&quot;, \n  &quot;-deprecation&quot;,\n  &quot;-feature&quot;,\n  &quot;-optimise&quot;,\n&quot;-Xcheckinit&quot;,\n&quot;-Xlint&quot;,\n&quot;-Xverify&quot;,\n&quot;-Yinline-warnings&quot;,\n&quot;-Yclosure-elim&quot;,\n&quot;-language:postfixOps&quot;,\n&quot;-language:implicitConversions&quot;,\n&quot;-Ydead-code&quot;)\n\ncom.typesafe.sbt.packager.debian.Keys.name in Debian := &quot;megamplay&quot;\n\nmaintainer in Debian:= &quot;Rajthilak &lt;rajthilak@megam.co.in&gt;&quot;\n\npackageSummary := &quot;Cloud API server - Megam.&quot; \n\npackageDescription in Debian:= &quot; (REST based) Cloud API server for Megam platform.The API server protects the resources using HMAC based authorization, as provided to a customer during onboarding.&quot;\n\ns3Settings\n\nlinuxPackageMappings in Debian &lt;+= (baseDirectory) map { bd =&gt;\n  (packageMapping((bd / &quot;bin/mp&quot;) -&gt; &quot;/usr/local/share/megamplay/bin/mp&quot;)\n   withUser &quot;root&quot; withGroup &quot;root&quot; withPerms &quot;0755&quot;)\n}\n\nlinuxPackageMappings &lt;+= (baseDirectory) map { bd =&gt;\n  val src = bd / &quot;target/staged&quot;\n val dest = &quot;/usr/local/share/megamplay/lib&quot;\nLinuxPackageMapping(\nfor {\n  path &lt;- (src ***).get\n  if !path.isDirectory\n} yield path -&gt; path.toString.replaceFirst(src.toString, dest)\n)\n}\n\nlinuxPackageMappings in Debian &lt;+= (baseDirectory) map { bd =&gt;\n  (packageMapping((bd / &quot;conf/application-production.conf&quot;) -&gt; &quot;/usr/local/share/megamplay/conf/application-production.conf&quot;)\nwithConfig())\n}\n\nlinuxPackageMappings in Debian &lt;+= (baseDirectory) map { bd =&gt;\n  (packageMapping((bd / &quot;conf/application-logger.xml&quot;) -&gt; &quot;/usr/local/share/megamplay/conf/application-logger.xml&quot;)\nwithConfig()) \n}\n\nlinuxPackageMappings in Debian &lt;+= (baseDirectory) map { bd =&gt;\n(packageMapping((bd / &quot;conf/routes&quot;) -&gt; &quot;/usr/local/share/megamplay/conf/routes&quot;)\nwithConfig())\n}\n\nlinuxPackageMappings in Debian &lt;+= (baseDirectory) map { bd =&gt;\n(packageMapping((bd / &quot;conf/messages&quot;) -&gt; &quot;/usr/local/share/megamplay/conf/messages&quot;)\nwithConfig())\n}\n\nlinuxPackageMappings in Debian &lt;+= (baseDirectory) map { bd =&gt;\n(packageMapping((bd / &quot;conf/play.plugins&quot;) -&gt; &quot;/usr/local/share/megamplay/conf/play.plugins&quot;)\nwithConfig())\n}\n\ncom.typesafe.sbt.packager.debian.Keys.version in Debian &lt;&lt;= (com.typesafe.sbt.packager.debian.Keys.version, sbtVersion) apply { (v, sv) =&gt;\nsv + &quot;-build-&quot; + (v split &quot;\\.&quot; map (_.toInt) dropWhile (_ == 0) map (&quot;%02d&quot; format _) mkString &quot;&quot;)\n}\n\ndebianPackageDependencies in Debian ++= Seq(&quot;curl&quot;, &quot;java2-runtime&quot;, &quot;bash (&gt;= 2.05a-11)&quot;)\n\ndebianPackageRecommends in Debian += &quot;riak&quot;\n\nlinuxPackageMappings &lt;+= (baseDirectory) map { bd =&gt;\npackageMapping(\n(bd / &quot;copyright&quot;) -&gt; &quot;/usr/share/doc/megam_play/copyright&quot;\n) withPerms &quot;0644&quot; asDocs()\n}\n\nlinuxPackageMappings in Debian &lt;+= (com.typesafe.sbt.packager.debian.Keys.sourceDirectory) map { bd =&gt;\n(packageMapping(\n(bd / &quot;debian/changelog&quot;) -&gt; &quot;/usr/share/doc/megam_play/changelog.gz&quot;\n) withUser &quot;root&quot; withGroup &quot;root&quot; withPerms &quot;0644&quot; gzipped) asDocs()\n}\n\nmappings in upload := Seq((new java.io.File((&quot;%s-%s.deb&quot;) format(&quot;target/megamplay&quot;, &quot;0.12.4-build-0100&quot;)),&quot;0.1/debs/megam_play.deb&quot;))\n\nhost in upload := &quot;megampub.s3.amazonaws.com&quot;\n\ncredentials += Credentials(Path.userHome / &quot;software&quot; / &quot;aws&quot; / &quot;keys&quot; / &quot;sbt_s3_keys&quot;)\n\nS3.progress in S3.upload := true\n</code></pre><p> 1.Plugins.sb</p>\n<pre><code>// Comment to get more information during initialization\nlogLevel := Level.Warn\n\n// The Typesafe repository \nresolvers += &quot;Typesafe repository&quot; at     &quot;http://repo.typesafe.com/typesafe/releases/&quot;\n\n// Typesafe snapshots\nresolvers += &quot;Typesafe Snapshots&quot; at    &quot;http://repo.typesafe.com/typesafe/snapshots/&quot;\n\n// Use the Play sbt plugin for Play projects\n\naddSbtPlugin(&quot;play&quot; % &quot;sbt-plugin&quot; % &quot;2.2.0&quot;)\n</code></pre><p>project/build.properties</p>\n<p><code>sbt.version=0.13.0</code></p>\n<p>We built our own AMQP based on scalaz, and is available in <a href=\"http://github.com/indykish/megam_common\">http://github.com/indykish/megam_common</a>. Now build and publish megam_common jars using the process as described in this link into <a href=\"https://oss.sonatype.org/content/repositories/snapshots/com/github/indykish/megam_common_2.10/0.1.0-SNAPSHOT/\">https://oss.sonatype.org/content/repositories/snapshots/com/github/indykish/megam_common_2.10/0.1.0-SNAPSHOT/</a>.</p>\n<p><code>sbt publish</code></p>\n<p>Run the play project megam_play</p>\n<pre><code>ram@ramhome:~/code/megam/workspace/megam_play$ sbt\n[info] Loading global plugins from /home/ram/.sbt/0.13/plugins\n[info] Loading project definition from /home/ram/code/megam/workspace/megam_play/project\n[info] Set current project to megam_play (in build     file:/home/ram/code/megam/workspace/megam_play/)\n[megam_play] $ play\n       _\n  _ __ | | __ _ _  _\n | &apos;_ | |/ _&apos; | || | \n |  __/|_|___|__ /\n |_|          |__/\n\nplay 2.2.0 built with Scala 2.10.2 (running Java 1.7.0_25), http://www.playframework.com\n\n&gt; Type &quot;help play&quot; or &quot;license&quot; for more information.\n&gt; Type &quot;exit&quot; or use Ctrl+D to leave this console.\n\n[megam_play] $\n</code></pre><p>You can use lsof as shown below to see if the server runs on port 9000.</p>\n<pre><code>[nilam] $ run\n\n$ sudo lsof -i:9000\n[sudo] password for ram:\nCOMMAND   PID USER   FD   TYPE DEVICE SIZE NODE NAME\njava    15640  ram  270u  IPv6  40094       TCP *:9000 (LISTEN)\n</code></pre><p>Now let us add a template to show the</p>\n<pre><code>1. index page,\n2. Error when an invalid URL is passed\n</code></pre><p>####index.scala.html</p>\n<pre><code>@(message: String)(implicit flash: play.api.mvc.Flash)\n@main(&quot;Megam Cloud v1&quot;) {\n@welcome(message)\n}\n</code></pre><p>####main.scala.html</p>\n<pre><code>@(title: String)(content: Html)\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;@title&lt;/title&gt;\n&lt;meta charset=&quot;utf-8&quot;&gt;\n&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;\n&lt;meta name=&quot;description&quot; content=&quot;&quot;&gt;\n&lt;meta name=&quot;author&quot; content=&quot;&quot;&gt;\n&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://fonts.googleapis.com/css?family=Lato:300,400,700&quot; /&gt;\n&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;@routes.Assets.at(&quot;stylesheets/theme.css&quot;)&quot; &gt;\n&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;@routes.Assets.at(&quot;stylesheets/bootstrap-theme.css&quot;)&quot; &gt;\n&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;@routes.Assets.at(&quot;stylesheets/bootstrap.css&quot;)&quot; &gt;\n&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;@routes.Assets.at(&quot;stylesheets/bootstrap-glyphicons.css&quot;)&quot;&gt;\n&lt;link rel=&quot;stylesheet&quot; href=&quot;styles/default.css&quot;&gt;\n&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;@routes.Assets.at(&quot;stylesheets/styles/default.css&quot;)&quot; &gt;\n&lt;link rel=&quot;shortcut icon&quot; type=&quot;image/png&quot; href=&quot;@routes.Assets.at(&quot;images/favicon.png&quot;)&quot;&gt;\n\n&lt;!-- Bootstrap --&gt;\n&lt;script src=&quot;@routes.Assets.at(&quot;javascripts/jquery.js&quot;)&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;\n&lt;script src=&quot;@routes.Assets.at(&quot;javascripts/bootstrap.js&quot;)&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;\n&lt;script  src=&quot;@routes.Assets.at(&quot;javascripts/highlight.pack.js&quot;)&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;\n\n&lt;script type=&quot;text/javascript&quot;&gt;\n        $(document).ready(function() {\n            hljs.initHighlightingOnLoad();\n            $(&apos;pre code&apos;).each(function(i, e) {\n                hljs.highlightBlock(e)\n            });\n            $(&apos;a[data-toggle=&quot;tab&quot;]&apos;).on(&apos;shown.bs.tab&apos;, function(e) {\n                e.target// activated tab\n                e.relatedTarget // previous tab\n            });\n\n        });\n&lt;/script&gt;\n&lt;style type=&quot;text/css&quot;&gt;\n  /* &lt;![CDATA[ */\n  #pagetoc li {\n    padding-left: 22px;\n    text-indent: -22px;\n  }\n\n  /* ]]&gt; */\n&lt;/style&gt;\n  &lt;/head&gt;\n   &lt;body&gt;\n   &lt;div&gt;     \n    &lt;div&gt;\n        @leftmenu()\n        @content\n    &lt;/div&gt;\n  &lt;/div&gt;\n\n&lt;!-- JQuery will invoke via the spinner and display a loading modal lock. --&gt;\n&lt;div id=&quot;loading&quot; /&gt;\n</code></pre><p>  </body><br></html></p>\n<p>####errorPage.scala.html</p>\n<pre><code>@(ex: Throwable)\n\n@main(&quot;An error occurred while trying to run megam_play. contact support.&quot;) {\n&lt;div class=&quot;api-doc&quot;&gt;\n  &lt;div class=&quot;mddoc margin-top-large&quot;&gt;\n   &lt;image src=&quot;@routes.Assets.at(&quot;images/nirvana.png&quot;)&quot;/&gt;\n&lt;h1&gt;&lt;a name=&quot;rest_docs&quot; href=&quot;#a-rest_docs&quot;&gt;Sucked into Nirvana&lt;/a&gt;&lt;/h1&gt;\n&lt;p class=&quot;lead&quot;&gt;\n  &lt;code&gt;\n    @(ex getMessage)\n  &lt;/code&gt;\n&lt;/p&gt;\n&lt;div class=&quot;page-header&quot;&gt;\n  &lt;h2&gt;Stacktrace&lt;/h2&gt;\n&lt;/div&gt;\n\n &lt;div class=&quot;&quot;&gt;\n\n\n&lt;code class=&quot;brush: bash; toolbar:     false;&quot;&gt;@({val u = new java.io.StringWriter; ex.printStackTrace(new java.io.PrintWriter(u)); u.toString})\n    &lt;/code&gt;\n  &lt;/div&gt;\n &lt;/div&gt;\n&lt;/div&gt;\n}\n\n\nobject Global extends GlobalSettings {\n\n override def onStart(app: Application) {\nplay.api.Logger.info(&quot;Megam Play %s App - started&quot;.format(&quot;0.1&quot;))\n}\n\noverride def onStop(app: Application) {\nplay.api.Logger.info(&quot;Megam Play %s App - going down. Stateless folks - you don&apos;t care.&quot;.format(&quot;0.1&quot;))\n}\n\noverride def onError(request: RequestHeader, ex: Throwable) : Future[play.api.mvc.SimpleResult] = {\nFuture.successful(InternalServerError(\n  views.html.errorPage(ex)))\n}\n\noverride def onHandlerNotFound(request: RequestHeader): Future[play.api.mvc.SimpleResult] = {\nFuture.successful(NotFound(\n  views.html.errorPage(new Throwable(NOT_FOUND + &quot;:&quot; + request.path + &quot; NOT_FOUND&quot;))))\n }\n}\n</code></pre><p>Thee view files are placed under views directory.</p>\n<p>Type <a href=\"https://localhost:9000\">https://localhost:9000</a></p>\n"},{"title":"Beautiful API using Scala based Playframework","slug":"2015-03-18-rest_api_playframework","date_published":"2015-03-18T04:49:27.209Z","date_updated":"2015-03-18T22:54:45.357Z","_content":"\nWe are going to build a beautiful REST API based on a modern [playframework](www.playframework.com) using [Scala](scala-lang.org) in a functional way.\n\nLet us start by understanding the concept of REST in a simpler sense.\n\n##RESTful API\n[REST](http://en.wikipedia.org/wiki/Representational_state_transfer) came from Roy Fieldings desertation in claiming to make web stateles again based on designing your system using nouns. So some of the examples are\n\n* accounts \n* users\n* profiles\n* logs\n* assemblies\n* apps\n\nYou no longer need the clugy [SOAP](http://en.wikipedia.org/wiki/SOAP) heavyweight XML, but rather a nimble JSON using fundamental HTTP will do.\n\nHow do you arrive on a design for the RESTful approach for your system is beyond the scope of this article. However we recommend you to read about [apigees REST API Design](http://apigee.com/about/resources/webcasts/restful-api-design-second-edition), which talks about the same.\n\nThe RESTful API's transport mechanism is pure [HTTP](https://www.ietf.org/rfc/rfc2616.txt)\n\nWe will use [HMAC](http://en.wikipedia.org/wiki/Hash-based_message_authentication_code) to encrypt the payload sent across from a client. \n\nThe client code we will use in our usecase will be Ruby or Scala.\n\nFirst let us start with the core *HTTP payload* we would like to send across.\n\nThe constructs of the payload which would help us multi tenantized system are, \n\n###Parts of the payload. \n\n- HEADER\n\nOur header that we wish to send will have the following\n\nX_Megam_EMAIL  - The email address of the user\nX_Megam_APIKEY - The api key generated for the user\nX_Megam_DATE   - The date on which the data was sent\nX_Megam_HMAC   - The MD5 hmac calculated by the client in the format of **email:hmac value**\nPath           - URL path from the HTTP Request\n\nThe HMAC value is calculated as follows \nX_Megam_DATE +  Path + MD5(body JSON)\n\nThe HMAC string makes sure the payload sent from the client is well formed and is valid.\n\n* BODY\nA JSON as sent by  the client. The body JSON may or may not be present. In case where a HTTP GET is done there body will be empty\n\n####HEADER\n\n    \nSample scala code in building Header.\n \n    val defaultHeaderOpt = Map(Content_Type -> application_json,\n    X_Megam_EMAIL -> \"megam@mypaas.io\", X_Megam_APIKEY -> \"IamAtlas{74}NobodyCanSeeME#07\",\n    //X_Megam_EMAIL -> \"fake@mypaas.io\", X_Megam_APIKEY -> \"fakemypaas#megam\",\n   // X_Megam_EMAIL -> \"steve@olympics.com\", X_Megam_APIKEY -> \"mAFfm45XnvYJMqPTpP5Dow==\",\n    X_Megam_DATE -> currentDate, Accept -> application_vnd_megam_json)\n\n####BODY\n\nSample scala code.\n\n    val contentToEncode = \"{\\\"collapsedmail\\\":\\\"megam@mypaas.io\\\", \\\"inval_api_key\\\":\\\"IamAtlas{74}NobodyCanSeeME#075488\\\", \\\"authority\\\":\\\"user\\\" }\"\n\n####HMAC\n\nWe design a cryptographic hash based on the popular MD5 or SHA1 which can be encrypted during the send and decrypted upon receipt.\n\nNow that we have set the playground for the various definitions let us put to use in the platframework.\n\nOur RESTful API Serveer will be named as megam_gateway and is designed to be stateless.\n\n###Approach\nWe will use a novel approach to authenticate and authorize any request that come to our megam_gateway. The approach should be intelligent enought to authenticate any number of layers, return back on malformed header (invalid email could be one of them), mismatch API key and exception condition in megam_gateway.\n\n###Controller\nA regular controller which the requests coming in to the megam_gateway.\n\n###play-auth\nAn authentication library that helps to quickly build authentication function in a play project. \n\n\n###APIAuthElement : Extension of StackActionController \nA trait, that extends a StackActionController and \ncan be invoked by extending this trait in relevant controller.\n\n    object Accounts extends Controller with APIAuthElement {\n\nAlso you have coarse control to decide if you wish to authenticate all HTTP verbs or not. \n\nFor instance when an account is created initially there is no point authenticating, you know why.\n\nIf an authentication is needed, then we wrap the particular action in controller using StackAction.\n\n    def show(id: String) = StackAction(parse.tolerantText) { implicit request =>\n\nYou can read the guide availabe in [play-auth](https://github.com/t2v/play2-auth) for more information.\n\n###SecurityActions\nA helper function that handles authentication after everything is verified. \n\nLets put everything together and create our first api **accounts**\n\n##Step 1: FunnelRequest\n\nThe first step we do is to find those actions in the controller that require authentication. We wrap them  with **StackAction**.\n\n    trait APIAuthElement extends StackableController \n\nThe trait has an implicit which helps to converts the input HTTPRequest inputs to a **FunnelRequest** The **FunnelRequest** just maps the HTTPRequestInput and maps the header, body, hmac to an internal object.\n\n##Step 2: Validate FunnelRequest\n\nAfter that the SecurityActions.Authenticates the FunnelRequest Object and returns to serve the request if every is valid. If the Header is malformed its immediately sent back. \n\n    object SecurityActions {\n\n \n  def Authenticated[A](req: FunnelRequestBuilder[A]): ValidationNel[Throwable, Option[String]] = {\n    Logger.debug((\"%-20s -->[%s]\").format(\"SecurityActions\", \"Authenticated:Entry\"))\n    req.funneled match {\n\n###Step3: Serve the request.\n\nNow when things are validated, the controller handles the request\n\n    def show(id: String) = StackAction(parse.tolerantText) { implicit request =>\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"controllers.Accounts\", \"show:Entry\"))\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"email\", id))\n    models.Accounts.findByEmail(id) match {\n\n\nWe saw bits and pieces on how everything comes together. Let us look at how to implement an account..\n\n##Account \n\n/accounts\nLet us implement the simple API which has the following requirements   \n  \n  \n<table>\n    <tr>\n        <td>HTTP Verb</td>\n        <td>REST API</td>\n        <td>Description</td>\n    </tr>\n    <tr>\n        <td>GET</td>\n        <td>accounts</td>\n        <td>GET the account information of the user\n    </tr>\n    <tr>\n        <td>POST</td>\n        <td>accounts</td>\n        <td>Posts a new account</td>\n    </tr>\n    \n   \n</table>\n\nGreat. For both of the functions we need a controller.\n\n#AccountsController\n\n    import controllers.funnel.FunnelErrors._\n    import controllers.funnel.FunnelResponse\n    import models._\n    import play.api._\n    import play.api.mvc._\n    import play.api.mvc.Result\n    import scalaz._\n    import Scalaz._\n    import scalaz.effect.IO\n    import scalaz.EitherT._\n    import scalaz.Validation\n    //import scalaz.Validation.FlatMap._\n    import scalaz.NonEmptyList._\n\n    /**\n     * @author rajthilak\n     *\n     */\n\n    /*\n    * This controller performs onboarding a customer and     registers an email/api_key \n    * into riak.\n    * Output: FunnelResponse as JSON with the msg.  \n    */\n    object Accounts extends Controller with APIAuthElement {\n\n\nYou can see that we are using the APIAuthElement here which means we are indicating that our controller needs to authenticated.\n\nClick here for full source code of the [AccountsController](https://github.com/megamsys/megam_gateway/blob/0.7/app/controllers/Accounts.scala).\n\n\n###POST\n\n/accounts\n\nLet us hack an action method, that pulls the email and api_key and stores in a storage. How store and manipulate JSON will be dealt in another tutorial.\n\n    def post = Action(parse.tolerantText) { implicit request =>\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"controllers.Accounts\", \"post:Entry\"))\n    val input = (request.body).toString()\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"input\", input))\n    models.Accounts.create(input) match {\n      case Success(succ) =>    \n        PlatformAppPrimer.clone_predefcloud(succ.get.email).flatMap { x =>\n          Status(CREATED)(\n            FunnelResponse(CREATED, \"\"\"Onboard successful. email '%s' and api_key '%s' is registered.\"\"\".\n              format(succ.get.email, succ.get.api_key).stripMargin, \"Megam::Account\").toJson(true)).successNel[Error]\n        } match {\n          case Success(succ_cpc) => succ_cpc\n          case Failure(errcpc) =>\n            val rncpc: FunnelResponse = new HttpReturningError(errcpc)\n            Status(rncpc.code)(rncpc.toJson(true))\n        }\n              \n        PlatformAppPrimer.clone_organizations(succ.get.email).flatMap { x =>\n          Status(CREATED)(\n            FunnelResponse(CREATED, \"\"\"Onboard successful. email '%s' and api_key '%s' is registered.\"\"\".\n              format(succ.get.email,succ.get.api_key).stripMargin, \"Megam::Account\").toJson(true)).successNel[Error]\n        } match {\n          case Success(succ_cpc) => succ_cpc\n          case Failure(errcpc) =>\n            val rncpc: FunnelResponse = new HttpReturningError(errcpc)\n            Status(rncpc.code)(rncpc.toJson(true))\n        }\n\n       \n  \n        case Failure(err) => {\n        val rn: FunnelResponse = new HttpReturningError(err)\n        Status(rn.code)(rn.toJson(true))\n      }\n    }\n  }\n\n\nOfcourse we more more things after an user is registered, those are system specific. For instance we create default settings for an user after getting registered successfuly.\n\nA good api, communicates to an user the correct success JSON or an Error\n\nAfter all is well done, we send back a **FunnelResponse**. Stay tuned we will cover it in the next part\n\n\n###GET\n\n/accounts/:id\n\nLet us hack an action method, in this case you can see that we are using **StackAction**. \n\nYou can see that we don't tell what needs to be done to authenticate, it all happens magically with the set framework. \n\n\n    def show(id: String) = StackAction(parse.tolerantText) { implicit request =>\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"controllers.Accounts\", \"show:Entry\"))\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"email\", id))\n    models.Accounts.findByEmail(id) match {\n      case Success(succ) => {\n        Ok((succ.map(s => s.toJson(true))).getOrElse(\n          AccountResult(id).toJson(true)))\n      }\n      case Failure(err) => {\n        val rn: FunnelResponse = new HttpReturningError(err)\n        Status(rn.code)(rn.toJson(true))\n      }\n    }\n\n  }\n  \nOk. this is the first part of the series, we are done with the authentication. \n\nIn the subsequent parts we will cover JSON Convertors, FunnelResponse, Cache using StateMonad, IO Monad, Validation of Scalaz.\n\nHere is the [full source code](https://github.com/megamsys/megam_gateway.git) of the project.\n\n            \n\n","source":"_posts/2015-03-18-rest_api_playframework.md","raw":"---\ntitle: Beautiful API using Scala based Playframework\nslug: rest_api_playframework\ndate_published: 2015-03-18T10:19:27.209Z\ndate_updated:   2015-03-19T04:24:45.357Z\n---\n\nWe are going to build a beautiful REST API based on a modern [playframework](www.playframework.com) using [Scala](scala-lang.org) in a functional way.\n\nLet us start by understanding the concept of REST in a simpler sense.\n\n##RESTful API\n[REST](http://en.wikipedia.org/wiki/Representational_state_transfer) came from Roy Fieldings desertation in claiming to make web stateles again based on designing your system using nouns. So some of the examples are\n\n* accounts \n* users\n* profiles\n* logs\n* assemblies\n* apps\n\nYou no longer need the clugy [SOAP](http://en.wikipedia.org/wiki/SOAP) heavyweight XML, but rather a nimble JSON using fundamental HTTP will do.\n\nHow do you arrive on a design for the RESTful approach for your system is beyond the scope of this article. However we recommend you to read about [apigees REST API Design](http://apigee.com/about/resources/webcasts/restful-api-design-second-edition), which talks about the same.\n\nThe RESTful API's transport mechanism is pure [HTTP](https://www.ietf.org/rfc/rfc2616.txt)\n\nWe will use [HMAC](http://en.wikipedia.org/wiki/Hash-based_message_authentication_code) to encrypt the payload sent across from a client. \n\nThe client code we will use in our usecase will be Ruby or Scala.\n\nFirst let us start with the core *HTTP payload* we would like to send across.\n\nThe constructs of the payload which would help us multi tenantized system are, \n\n###Parts of the payload. \n\n- HEADER\n\nOur header that we wish to send will have the following\n\nX_Megam_EMAIL  - The email address of the user\nX_Megam_APIKEY - The api key generated for the user\nX_Megam_DATE   - The date on which the data was sent\nX_Megam_HMAC   - The MD5 hmac calculated by the client in the format of **email:hmac value**\nPath           - URL path from the HTTP Request\n\nThe HMAC value is calculated as follows \nX_Megam_DATE +  Path + MD5(body JSON)\n\nThe HMAC string makes sure the payload sent from the client is well formed and is valid.\n\n* BODY\nA JSON as sent by  the client. The body JSON may or may not be present. In case where a HTTP GET is done there body will be empty\n\n####HEADER\n\n    \nSample scala code in building Header.\n \n    val defaultHeaderOpt = Map(Content_Type -> application_json,\n    X_Megam_EMAIL -> \"megam@mypaas.io\", X_Megam_APIKEY -> \"IamAtlas{74}NobodyCanSeeME#07\",\n    //X_Megam_EMAIL -> \"fake@mypaas.io\", X_Megam_APIKEY -> \"fakemypaas#megam\",\n   // X_Megam_EMAIL -> \"steve@olympics.com\", X_Megam_APIKEY -> \"mAFfm45XnvYJMqPTpP5Dow==\",\n    X_Megam_DATE -> currentDate, Accept -> application_vnd_megam_json)\n\n####BODY\n\nSample scala code.\n\n    val contentToEncode = \"{\\\"collapsedmail\\\":\\\"megam@mypaas.io\\\", \\\"inval_api_key\\\":\\\"IamAtlas{74}NobodyCanSeeME#075488\\\", \\\"authority\\\":\\\"user\\\" }\"\n\n####HMAC\n\nWe design a cryptographic hash based on the popular MD5 or SHA1 which can be encrypted during the send and decrypted upon receipt.\n\nNow that we have set the playground for the various definitions let us put to use in the platframework.\n\nOur RESTful API Serveer will be named as megam_gateway and is designed to be stateless.\n\n###Approach\nWe will use a novel approach to authenticate and authorize any request that come to our megam_gateway. The approach should be intelligent enought to authenticate any number of layers, return back on malformed header (invalid email could be one of them), mismatch API key and exception condition in megam_gateway.\n\n###Controller\nA regular controller which the requests coming in to the megam_gateway.\n\n###play-auth\nAn authentication library that helps to quickly build authentication function in a play project. \n\n\n###APIAuthElement : Extension of StackActionController \nA trait, that extends a StackActionController and \ncan be invoked by extending this trait in relevant controller.\n\n    object Accounts extends Controller with APIAuthElement {\n\nAlso you have coarse control to decide if you wish to authenticate all HTTP verbs or not. \n\nFor instance when an account is created initially there is no point authenticating, you know why.\n\nIf an authentication is needed, then we wrap the particular action in controller using StackAction.\n\n    def show(id: String) = StackAction(parse.tolerantText) { implicit request =>\n\nYou can read the guide availabe in [play-auth](https://github.com/t2v/play2-auth) for more information.\n\n###SecurityActions\nA helper function that handles authentication after everything is verified. \n\nLets put everything together and create our first api **accounts**\n\n##Step 1: FunnelRequest\n\nThe first step we do is to find those actions in the controller that require authentication. We wrap them  with **StackAction**.\n\n    trait APIAuthElement extends StackableController \n\nThe trait has an implicit which helps to converts the input HTTPRequest inputs to a **FunnelRequest** The **FunnelRequest** just maps the HTTPRequestInput and maps the header, body, hmac to an internal object.\n\n##Step 2: Validate FunnelRequest\n\nAfter that the SecurityActions.Authenticates the FunnelRequest Object and returns to serve the request if every is valid. If the Header is malformed its immediately sent back. \n\n    object SecurityActions {\n\n \n  def Authenticated[A](req: FunnelRequestBuilder[A]): ValidationNel[Throwable, Option[String]] = {\n    Logger.debug((\"%-20s -->[%s]\").format(\"SecurityActions\", \"Authenticated:Entry\"))\n    req.funneled match {\n\n###Step3: Serve the request.\n\nNow when things are validated, the controller handles the request\n\n    def show(id: String) = StackAction(parse.tolerantText) { implicit request =>\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"controllers.Accounts\", \"show:Entry\"))\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"email\", id))\n    models.Accounts.findByEmail(id) match {\n\n\nWe saw bits and pieces on how everything comes together. Let us look at how to implement an account..\n\n##Account \n\n/accounts\nLet us implement the simple API which has the following requirements   \n  \n  \n<table>\n    <tr>\n        <td>HTTP Verb</td>\n        <td>REST API</td>\n        <td>Description</td>\n    </tr>\n    <tr>\n        <td>GET</td>\n        <td>accounts</td>\n        <td>GET the account information of the user\n    </tr>\n    <tr>\n        <td>POST</td>\n        <td>accounts</td>\n        <td>Posts a new account</td>\n    </tr>\n    \n   \n</table>\n\nGreat. For both of the functions we need a controller.\n\n#AccountsController\n\n    import controllers.funnel.FunnelErrors._\n    import controllers.funnel.FunnelResponse\n    import models._\n    import play.api._\n    import play.api.mvc._\n    import play.api.mvc.Result\n    import scalaz._\n    import Scalaz._\n    import scalaz.effect.IO\n    import scalaz.EitherT._\n    import scalaz.Validation\n    //import scalaz.Validation.FlatMap._\n    import scalaz.NonEmptyList._\n\n    /**\n     * @author rajthilak\n     *\n     */\n\n    /*\n    * This controller performs onboarding a customer and     registers an email/api_key \n    * into riak.\n    * Output: FunnelResponse as JSON with the msg.  \n    */\n    object Accounts extends Controller with APIAuthElement {\n\n\nYou can see that we are using the APIAuthElement here which means we are indicating that our controller needs to authenticated.\n\nClick here for full source code of the [AccountsController](https://github.com/megamsys/megam_gateway/blob/0.7/app/controllers/Accounts.scala).\n\n\n###POST\n\n/accounts\n\nLet us hack an action method, that pulls the email and api_key and stores in a storage. How store and manipulate JSON will be dealt in another tutorial.\n\n    def post = Action(parse.tolerantText) { implicit request =>\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"controllers.Accounts\", \"post:Entry\"))\n    val input = (request.body).toString()\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"input\", input))\n    models.Accounts.create(input) match {\n      case Success(succ) =>    \n        PlatformAppPrimer.clone_predefcloud(succ.get.email).flatMap { x =>\n          Status(CREATED)(\n            FunnelResponse(CREATED, \"\"\"Onboard successful. email '%s' and api_key '%s' is registered.\"\"\".\n              format(succ.get.email, succ.get.api_key).stripMargin, \"Megam::Account\").toJson(true)).successNel[Error]\n        } match {\n          case Success(succ_cpc) => succ_cpc\n          case Failure(errcpc) =>\n            val rncpc: FunnelResponse = new HttpReturningError(errcpc)\n            Status(rncpc.code)(rncpc.toJson(true))\n        }\n              \n        PlatformAppPrimer.clone_organizations(succ.get.email).flatMap { x =>\n          Status(CREATED)(\n            FunnelResponse(CREATED, \"\"\"Onboard successful. email '%s' and api_key '%s' is registered.\"\"\".\n              format(succ.get.email,succ.get.api_key).stripMargin, \"Megam::Account\").toJson(true)).successNel[Error]\n        } match {\n          case Success(succ_cpc) => succ_cpc\n          case Failure(errcpc) =>\n            val rncpc: FunnelResponse = new HttpReturningError(errcpc)\n            Status(rncpc.code)(rncpc.toJson(true))\n        }\n\n       \n  \n        case Failure(err) => {\n        val rn: FunnelResponse = new HttpReturningError(err)\n        Status(rn.code)(rn.toJson(true))\n      }\n    }\n  }\n\n\nOfcourse we more more things after an user is registered, those are system specific. For instance we create default settings for an user after getting registered successfuly.\n\nA good api, communicates to an user the correct success JSON or an Error\n\nAfter all is well done, we send back a **FunnelResponse**. Stay tuned we will cover it in the next part\n\n\n###GET\n\n/accounts/:id\n\nLet us hack an action method, in this case you can see that we are using **StackAction**. \n\nYou can see that we don't tell what needs to be done to authenticate, it all happens magically with the set framework. \n\n\n    def show(id: String) = StackAction(parse.tolerantText) { implicit request =>\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"controllers.Accounts\", \"show:Entry\"))\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"email\", id))\n    models.Accounts.findByEmail(id) match {\n      case Success(succ) => {\n        Ok((succ.map(s => s.toJson(true))).getOrElse(\n          AccountResult(id).toJson(true)))\n      }\n      case Failure(err) => {\n        val rn: FunnelResponse = new HttpReturningError(err)\n        Status(rn.code)(rn.toJson(true))\n      }\n    }\n\n  }\n  \nOk. this is the first part of the series, we are done with the authentication. \n\nIn the subsequent parts we will cover JSON Convertors, FunnelResponse, Cache using StateMonad, IO Monad, Validation of Scalaz.\n\nHere is the [full source code](https://github.com/megamsys/megam_gateway.git) of the project.\n\n            \n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzairk000cdrgbo5n320pk","content":"<p>We are going to build a beautiful REST API based on a modern <a href=\"www.playframework.com\">playframework</a> using <a href=\"scala-lang.org\">Scala</a> in a functional way.</p>\n<p>Let us start by understanding the concept of REST in a simpler sense.</p>\n<p>##RESTful API<br><a href=\"http://en.wikipedia.org/wiki/Representational_state_transfer\" target=\"_blank\" rel=\"external\">REST</a> came from Roy Fieldings desertation in claiming to make web stateles again based on designing your system using nouns. So some of the examples are</p>\n<ul>\n<li>accounts </li>\n<li>users</li>\n<li>profiles</li>\n<li>logs</li>\n<li>assemblies</li>\n<li>apps</li>\n</ul>\n<p>You no longer need the clugy <a href=\"http://en.wikipedia.org/wiki/SOAP\" target=\"_blank\" rel=\"external\">SOAP</a> heavyweight XML, but rather a nimble JSON using fundamental HTTP will do.</p>\n<p>How do you arrive on a design for the RESTful approach for your system is beyond the scope of this article. However we recommend you to read about <a href=\"http://apigee.com/about/resources/webcasts/restful-api-design-second-edition\" target=\"_blank\" rel=\"external\">apigees REST API Design</a>, which talks about the same.</p>\n<p>The RESTful APIs transport mechanism is pure <a href=\"https://www.ietf.org/rfc/rfc2616.txt\" target=\"_blank\" rel=\"external\">HTTP</a></p>\n<p>We will use <a href=\"http://en.wikipedia.org/wiki/Hash-based_message_authentication_code\" target=\"_blank\" rel=\"external\">HMAC</a> to encrypt the payload sent across from a client. </p>\n<p>The client code we will use in our usecase will be Ruby or Scala.</p>\n<p>First let us start with the core <em>HTTP payload</em> we would like to send across.</p>\n<p>The constructs of the payload which would help us multi tenantized system are, </p>\n<p>###Parts of the payload. </p>\n<ul>\n<li>HEADER</li>\n</ul>\n<p>Our header that we wish to send will have the following</p>\n<p>X_Megam_EMAIL  - The email address of the user<br>X_Megam_APIKEY - The api key generated for the user<br>X_Megam_DATE   - The date on which the data was sent<br>X_Megam_HMAC   - The MD5 hmac calculated by the client in the format of <strong>email:hmac value</strong><br>Path           - URL path from the HTTP Request</p>\n<p>The HMAC value is calculated as follows<br>X_Megam_DATE +  Path + MD5(body JSON)</p>\n<p>The HMAC string makes sure the payload sent from the client is well formed and is valid.</p>\n<ul>\n<li>BODY<br>A JSON as sent by  the client. The body JSON may or may not be present. In case where a HTTP GET is done there body will be empty</li>\n</ul>\n<p>####HEADER</p>\n<p>Sample scala code in building Header.</p>\n<pre><code>val defaultHeaderOpt = Map(Content_Type -&gt; application_json,\nX_Megam_EMAIL -&gt; &quot;megam@mypaas.io&quot;, X_Megam_APIKEY -&gt; &quot;IamAtlas{74}NobodyCanSeeME#07&quot;,\n//X_Megam_EMAIL -&gt; &quot;fake@mypaas.io&quot;, X_Megam_APIKEY -&gt; &quot;fakemypaas#megam&quot;,\n</code></pre><p>   // X_Megam_EMAIL -&gt; steve@olympics.com, X_Megam_APIKEY -&gt; mAFfm45XnvYJMqPTpP5Dow==,<br>    X_Megam_DATE -&gt; currentDate, Accept -&gt; application_vnd_megam_json)</p>\n<p>####BODY</p>\n<p>Sample scala code.</p>\n<pre><code>val contentToEncode = &quot;{\\&quot;collapsedmail\\&quot;:\\&quot;megam@mypaas.io\\&quot;, \\&quot;inval_api_key\\&quot;:\\&quot;IamAtlas{74}NobodyCanSeeME#075488\\&quot;, \\&quot;authority\\&quot;:\\&quot;user\\&quot; }&quot;\n</code></pre><p>####HMAC</p>\n<p>We design a cryptographic hash based on the popular MD5 or SHA1 which can be encrypted during the send and decrypted upon receipt.</p>\n<p>Now that we have set the playground for the various definitions let us put to use in the platframework.</p>\n<p>Our RESTful API Serveer will be named as megam_gateway and is designed to be stateless.</p>\n<p>###Approach<br>We will use a novel approach to authenticate and authorize any request that come to our megam_gateway. The approach should be intelligent enought to authenticate any number of layers, return back on malformed header (invalid email could be one of them), mismatch API key and exception condition in megam_gateway.</p>\n<p>###Controller<br>A regular controller which the requests coming in to the megam_gateway.</p>\n<p>###play-auth<br>An authentication library that helps to quickly build authentication function in a play project. </p>\n<p>###APIAuthElement : Extension of StackActionController<br>A trait, that extends a StackActionController and<br>can be invoked by extending this trait in relevant controller.</p>\n<pre><code>object Accounts extends Controller with APIAuthElement {\n</code></pre><p>Also you have coarse control to decide if you wish to authenticate all HTTP verbs or not. </p>\n<p>For instance when an account is created initially there is no point authenticating, you know why.</p>\n<p>If an authentication is needed, then we wrap the particular action in controller using StackAction.</p>\n<pre><code>def show(id: String) = StackAction(parse.tolerantText) { implicit request =&gt;\n</code></pre><p>You can read the guide availabe in <a href=\"https://github.com/t2v/play2-auth\" target=\"_blank\" rel=\"external\">play-auth</a> for more information.</p>\n<p>###SecurityActions<br>A helper function that handles authentication after everything is verified. </p>\n<p>Lets put everything together and create our first api <strong>accounts</strong></p>\n<p>##Step 1: FunnelRequest</p>\n<p>The first step we do is to find those actions in the controller that require authentication. We wrap them  with <strong>StackAction</strong>.</p>\n<pre><code>trait APIAuthElement extends StackableController \n</code></pre><p>The trait has an implicit which helps to converts the input HTTPRequest inputs to a <strong>FunnelRequest</strong> The <strong>FunnelRequest</strong> just maps the HTTPRequestInput and maps the header, body, hmac to an internal object.</p>\n<p>##Step 2: Validate FunnelRequest</p>\n<p>After that the SecurityActions.Authenticates the FunnelRequest Object and returns to serve the request if every is valid. If the Header is malformed its immediately sent back. </p>\n<pre><code>object SecurityActions {\n</code></pre><p>  def Authenticated<a href=\"req: FunnelRequestBuilder[A]\" target=\"_blank\" rel=\"external\">A</a>: ValidationNel[Throwable, Option[String]] = {<br>    Logger.debug((%-20s &gt;[%s]).format(SecurityActions, Authenticated:Entry))<br>    req.funneled match {</p>\n<p>###Step3: Serve the request.</p>\n<p>Now when things are validated, the controller handles the request</p>\n<pre><code>def show(id: String) = StackAction(parse.tolerantText) { implicit request =&gt;\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;controllers.Accounts&quot;, &quot;show:Entry&quot;))\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;email&quot;, id))\nmodels.Accounts.findByEmail(id) match {\n</code></pre><p>We saw bits and pieces on how everything comes together. Let us look at how to implement an account..</p>\n<p>##Account </p>\n<p>/accounts<br>Let us implement the simple API which has the following requirements   </p>\n<table><br>    <tr><br>        <td>HTTP Verb</td><br>        <td>REST API</td><br>        <td>Description</td><br>    </tr><br>    <tr><br>        <td>GET</td><br>        <td>accounts</td><br>        <td>GET the account information of the user<br>    </td></tr><br>    <tr><br>        <td>POST</td><br>        <td>accounts</td><br>        <td>Posts a new account</td><br>    </tr><br><br><br></table>\n\n<p>Great. For both of the functions we need a controller.</p>\n<p>#AccountsController</p>\n<pre><code>import controllers.funnel.FunnelErrors._\nimport controllers.funnel.FunnelResponse\nimport models._\nimport play.api._\nimport play.api.mvc._\nimport play.api.mvc.Result\nimport scalaz._\nimport Scalaz._\nimport scalaz.effect.IO\nimport scalaz.EitherT._\nimport scalaz.Validation\n//import scalaz.Validation.FlatMap._\nimport scalaz.NonEmptyList._\n\n/**\n * @author rajthilak\n *\n */\n\n/*\n* This controller performs onboarding a customer and     registers an email/api_key \n* into riak.\n* Output: FunnelResponse as JSON with the msg.  \n*/\nobject Accounts extends Controller with APIAuthElement {\n</code></pre><p>You can see that we are using the APIAuthElement here which means we are indicating that our controller needs to authenticated.</p>\n<p>Click here for full source code of the <a href=\"https://github.com/megamsys/megam_gateway/blob/0.7/app/controllers/Accounts.scala\" target=\"_blank\" rel=\"external\">AccountsController</a>.</p>\n<p>###POST</p>\n<p>/accounts</p>\n<p>Let us hack an action method, that pulls the email and api_key and stores in a storage. How store and manipulate JSON will be dealt in another tutorial.</p>\n<pre><code>def post = Action(parse.tolerantText) { implicit request =&gt;\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;controllers.Accounts&quot;, &quot;post:Entry&quot;))\nval input = (request.body).toString()\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;input&quot;, input))\nmodels.Accounts.create(input) match {\n  case Success(succ) =&gt;    \n    PlatformAppPrimer.clone_predefcloud(succ.get.email).flatMap { x =&gt;\n      Status(CREATED)(\n        FunnelResponse(CREATED, &quot;&quot;&quot;Onboard successful. email &apos;%s&apos; and api_key &apos;%s&apos; is registered.&quot;&quot;&quot;.\n          format(succ.get.email, succ.get.api_key).stripMargin, &quot;Megam::Account&quot;).toJson(true)).successNel[Error]\n    } match {\n      case Success(succ_cpc) =&gt; succ_cpc\n      case Failure(errcpc) =&gt;\n        val rncpc: FunnelResponse = new HttpReturningError(errcpc)\n        Status(rncpc.code)(rncpc.toJson(true))\n    }\n\n    PlatformAppPrimer.clone_organizations(succ.get.email).flatMap { x =&gt;\n      Status(CREATED)(\n        FunnelResponse(CREATED, &quot;&quot;&quot;Onboard successful. email &apos;%s&apos; and api_key &apos;%s&apos; is registered.&quot;&quot;&quot;.\n          format(succ.get.email,succ.get.api_key).stripMargin, &quot;Megam::Account&quot;).toJson(true)).successNel[Error]\n    } match {\n      case Success(succ_cpc) =&gt; succ_cpc\n      case Failure(errcpc) =&gt;\n        val rncpc: FunnelResponse = new HttpReturningError(errcpc)\n        Status(rncpc.code)(rncpc.toJson(true))\n    }\n\n\n\n    case Failure(err) =&gt; {\n    val rn: FunnelResponse = new HttpReturningError(err)\n    Status(rn.code)(rn.toJson(true))\n  }\n}\n</code></pre><p>  }</p>\n<p>Ofcourse we more more things after an user is registered, those are system specific. For instance we create default settings for an user after getting registered successfuly.</p>\n<p>A good api, communicates to an user the correct success JSON or an Error</p>\n<p>After all is well done, we send back a <strong>FunnelResponse</strong>. Stay tuned we will cover it in the next part</p>\n<p>###GET</p>\n<p>/accounts/:id</p>\n<p>Let us hack an action method, in this case you can see that we are using <strong>StackAction</strong>. </p>\n<p>You can see that we dont tell what needs to be done to authenticate, it all happens magically with the set framework. </p>\n<pre><code>def show(id: String) = StackAction(parse.tolerantText) { implicit request =&gt;\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;controllers.Accounts&quot;, &quot;show:Entry&quot;))\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;email&quot;, id))\nmodels.Accounts.findByEmail(id) match {\n  case Success(succ) =&gt; {\n    Ok((succ.map(s =&gt; s.toJson(true))).getOrElse(\n      AccountResult(id).toJson(true)))\n  }\n  case Failure(err) =&gt; {\n    val rn: FunnelResponse = new HttpReturningError(err)\n    Status(rn.code)(rn.toJson(true))\n  }\n}\n</code></pre><p>  }</p>\n<p>Ok. this is the first part of the series, we are done with the authentication. </p>\n<p>In the subsequent parts we will cover JSON Convertors, FunnelResponse, Cache using StateMonad, IO Monad, Validation of Scalaz.</p>\n<p>Here is the <a href=\"https://github.com/megamsys/megam_gateway.git\" target=\"_blank\" rel=\"external\">full source code</a> of the project.</p>\n","excerpt":"","more":"<p>We are going to build a beautiful REST API based on a modern <a href=\"www.playframework.com\">playframework</a> using <a href=\"scala-lang.org\">Scala</a> in a functional way.</p>\n<p>Let us start by understanding the concept of REST in a simpler sense.</p>\n<p>##RESTful API<br><a href=\"http://en.wikipedia.org/wiki/Representational_state_transfer\">REST</a> came from Roy Fieldings desertation in claiming to make web stateles again based on designing your system using nouns. So some of the examples are</p>\n<ul>\n<li>accounts </li>\n<li>users</li>\n<li>profiles</li>\n<li>logs</li>\n<li>assemblies</li>\n<li>apps</li>\n</ul>\n<p>You no longer need the clugy <a href=\"http://en.wikipedia.org/wiki/SOAP\">SOAP</a> heavyweight XML, but rather a nimble JSON using fundamental HTTP will do.</p>\n<p>How do you arrive on a design for the RESTful approach for your system is beyond the scope of this article. However we recommend you to read about <a href=\"http://apigee.com/about/resources/webcasts/restful-api-design-second-edition\">apigees REST API Design</a>, which talks about the same.</p>\n<p>The RESTful APIs transport mechanism is pure <a href=\"https://www.ietf.org/rfc/rfc2616.txt\">HTTP</a></p>\n<p>We will use <a href=\"http://en.wikipedia.org/wiki/Hash-based_message_authentication_code\">HMAC</a> to encrypt the payload sent across from a client. </p>\n<p>The client code we will use in our usecase will be Ruby or Scala.</p>\n<p>First let us start with the core <em>HTTP payload</em> we would like to send across.</p>\n<p>The constructs of the payload which would help us multi tenantized system are, </p>\n<p>###Parts of the payload. </p>\n<ul>\n<li>HEADER</li>\n</ul>\n<p>Our header that we wish to send will have the following</p>\n<p>X_Megam_EMAIL  - The email address of the user<br>X_Megam_APIKEY - The api key generated for the user<br>X_Megam_DATE   - The date on which the data was sent<br>X_Megam_HMAC   - The MD5 hmac calculated by the client in the format of <strong>email:hmac value</strong><br>Path           - URL path from the HTTP Request</p>\n<p>The HMAC value is calculated as follows<br>X_Megam_DATE +  Path + MD5(body JSON)</p>\n<p>The HMAC string makes sure the payload sent from the client is well formed and is valid.</p>\n<ul>\n<li>BODY<br>A JSON as sent by  the client. The body JSON may or may not be present. In case where a HTTP GET is done there body will be empty</li>\n</ul>\n<p>####HEADER</p>\n<p>Sample scala code in building Header.</p>\n<pre><code>val defaultHeaderOpt = Map(Content_Type -&gt; application_json,\nX_Megam_EMAIL -&gt; &quot;megam@mypaas.io&quot;, X_Megam_APIKEY -&gt; &quot;IamAtlas{74}NobodyCanSeeME#07&quot;,\n//X_Megam_EMAIL -&gt; &quot;fake@mypaas.io&quot;, X_Megam_APIKEY -&gt; &quot;fakemypaas#megam&quot;,\n</code></pre><p>   // X_Megam_EMAIL -&gt; steve@olympics.com, X_Megam_APIKEY -&gt; mAFfm45XnvYJMqPTpP5Dow==,<br>    X_Megam_DATE -&gt; currentDate, Accept -&gt; application_vnd_megam_json)</p>\n<p>####BODY</p>\n<p>Sample scala code.</p>\n<pre><code>val contentToEncode = &quot;{\\&quot;collapsedmail\\&quot;:\\&quot;megam@mypaas.io\\&quot;, \\&quot;inval_api_key\\&quot;:\\&quot;IamAtlas{74}NobodyCanSeeME#075488\\&quot;, \\&quot;authority\\&quot;:\\&quot;user\\&quot; }&quot;\n</code></pre><p>####HMAC</p>\n<p>We design a cryptographic hash based on the popular MD5 or SHA1 which can be encrypted during the send and decrypted upon receipt.</p>\n<p>Now that we have set the playground for the various definitions let us put to use in the platframework.</p>\n<p>Our RESTful API Serveer will be named as megam_gateway and is designed to be stateless.</p>\n<p>###Approach<br>We will use a novel approach to authenticate and authorize any request that come to our megam_gateway. The approach should be intelligent enought to authenticate any number of layers, return back on malformed header (invalid email could be one of them), mismatch API key and exception condition in megam_gateway.</p>\n<p>###Controller<br>A regular controller which the requests coming in to the megam_gateway.</p>\n<p>###play-auth<br>An authentication library that helps to quickly build authentication function in a play project. </p>\n<p>###APIAuthElement : Extension of StackActionController<br>A trait, that extends a StackActionController and<br>can be invoked by extending this trait in relevant controller.</p>\n<pre><code>object Accounts extends Controller with APIAuthElement {\n</code></pre><p>Also you have coarse control to decide if you wish to authenticate all HTTP verbs or not. </p>\n<p>For instance when an account is created initially there is no point authenticating, you know why.</p>\n<p>If an authentication is needed, then we wrap the particular action in controller using StackAction.</p>\n<pre><code>def show(id: String) = StackAction(parse.tolerantText) { implicit request =&gt;\n</code></pre><p>You can read the guide availabe in <a href=\"https://github.com/t2v/play2-auth\">play-auth</a> for more information.</p>\n<p>###SecurityActions<br>A helper function that handles authentication after everything is verified. </p>\n<p>Lets put everything together and create our first api <strong>accounts</strong></p>\n<p>##Step 1: FunnelRequest</p>\n<p>The first step we do is to find those actions in the controller that require authentication. We wrap them  with <strong>StackAction</strong>.</p>\n<pre><code>trait APIAuthElement extends StackableController \n</code></pre><p>The trait has an implicit which helps to converts the input HTTPRequest inputs to a <strong>FunnelRequest</strong> The <strong>FunnelRequest</strong> just maps the HTTPRequestInput and maps the header, body, hmac to an internal object.</p>\n<p>##Step 2: Validate FunnelRequest</p>\n<p>After that the SecurityActions.Authenticates the FunnelRequest Object and returns to serve the request if every is valid. If the Header is malformed its immediately sent back. </p>\n<pre><code>object SecurityActions {\n</code></pre><p>  def Authenticated<a href=\"req: FunnelRequestBuilder[A]\">A</a>: ValidationNel[Throwable, Option[String]] = {<br>    Logger.debug((%-20s &gt;[%s]).format(SecurityActions, Authenticated:Entry))<br>    req.funneled match {</p>\n<p>###Step3: Serve the request.</p>\n<p>Now when things are validated, the controller handles the request</p>\n<pre><code>def show(id: String) = StackAction(parse.tolerantText) { implicit request =&gt;\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;controllers.Accounts&quot;, &quot;show:Entry&quot;))\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;email&quot;, id))\nmodels.Accounts.findByEmail(id) match {\n</code></pre><p>We saw bits and pieces on how everything comes together. Let us look at how to implement an account..</p>\n<p>##Account </p>\n<p>/accounts<br>Let us implement the simple API which has the following requirements   </p>\n<table><br>    <tr><br>        <td>HTTP Verb</td><br>        <td>REST API</td><br>        <td>Description</td><br>    </tr><br>    <tr><br>        <td>GET</td><br>        <td>accounts</td><br>        <td>GET the account information of the user<br>    </tr><br>    <tr><br>        <td>POST</td><br>        <td>accounts</td><br>        <td>Posts a new account</td><br>    </tr><br><br><br></table>\n\n<p>Great. For both of the functions we need a controller.</p>\n<p>#AccountsController</p>\n<pre><code>import controllers.funnel.FunnelErrors._\nimport controllers.funnel.FunnelResponse\nimport models._\nimport play.api._\nimport play.api.mvc._\nimport play.api.mvc.Result\nimport scalaz._\nimport Scalaz._\nimport scalaz.effect.IO\nimport scalaz.EitherT._\nimport scalaz.Validation\n//import scalaz.Validation.FlatMap._\nimport scalaz.NonEmptyList._\n\n/**\n * @author rajthilak\n *\n */\n\n/*\n* This controller performs onboarding a customer and     registers an email/api_key \n* into riak.\n* Output: FunnelResponse as JSON with the msg.  \n*/\nobject Accounts extends Controller with APIAuthElement {\n</code></pre><p>You can see that we are using the APIAuthElement here which means we are indicating that our controller needs to authenticated.</p>\n<p>Click here for full source code of the <a href=\"https://github.com/megamsys/megam_gateway/blob/0.7/app/controllers/Accounts.scala\">AccountsController</a>.</p>\n<p>###POST</p>\n<p>/accounts</p>\n<p>Let us hack an action method, that pulls the email and api_key and stores in a storage. How store and manipulate JSON will be dealt in another tutorial.</p>\n<pre><code>def post = Action(parse.tolerantText) { implicit request =&gt;\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;controllers.Accounts&quot;, &quot;post:Entry&quot;))\nval input = (request.body).toString()\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;input&quot;, input))\nmodels.Accounts.create(input) match {\n  case Success(succ) =&gt;    \n    PlatformAppPrimer.clone_predefcloud(succ.get.email).flatMap { x =&gt;\n      Status(CREATED)(\n        FunnelResponse(CREATED, &quot;&quot;&quot;Onboard successful. email &apos;%s&apos; and api_key &apos;%s&apos; is registered.&quot;&quot;&quot;.\n          format(succ.get.email, succ.get.api_key).stripMargin, &quot;Megam::Account&quot;).toJson(true)).successNel[Error]\n    } match {\n      case Success(succ_cpc) =&gt; succ_cpc\n      case Failure(errcpc) =&gt;\n        val rncpc: FunnelResponse = new HttpReturningError(errcpc)\n        Status(rncpc.code)(rncpc.toJson(true))\n    }\n\n    PlatformAppPrimer.clone_organizations(succ.get.email).flatMap { x =&gt;\n      Status(CREATED)(\n        FunnelResponse(CREATED, &quot;&quot;&quot;Onboard successful. email &apos;%s&apos; and api_key &apos;%s&apos; is registered.&quot;&quot;&quot;.\n          format(succ.get.email,succ.get.api_key).stripMargin, &quot;Megam::Account&quot;).toJson(true)).successNel[Error]\n    } match {\n      case Success(succ_cpc) =&gt; succ_cpc\n      case Failure(errcpc) =&gt;\n        val rncpc: FunnelResponse = new HttpReturningError(errcpc)\n        Status(rncpc.code)(rncpc.toJson(true))\n    }\n\n\n\n    case Failure(err) =&gt; {\n    val rn: FunnelResponse = new HttpReturningError(err)\n    Status(rn.code)(rn.toJson(true))\n  }\n}\n</code></pre><p>  }</p>\n<p>Ofcourse we more more things after an user is registered, those are system specific. For instance we create default settings for an user after getting registered successfuly.</p>\n<p>A good api, communicates to an user the correct success JSON or an Error</p>\n<p>After all is well done, we send back a <strong>FunnelResponse</strong>. Stay tuned we will cover it in the next part</p>\n<p>###GET</p>\n<p>/accounts/:id</p>\n<p>Let us hack an action method, in this case you can see that we are using <strong>StackAction</strong>. </p>\n<p>You can see that we dont tell what needs to be done to authenticate, it all happens magically with the set framework. </p>\n<pre><code>def show(id: String) = StackAction(parse.tolerantText) { implicit request =&gt;\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;controllers.Accounts&quot;, &quot;show:Entry&quot;))\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;email&quot;, id))\nmodels.Accounts.findByEmail(id) match {\n  case Success(succ) =&gt; {\n    Ok((succ.map(s =&gt; s.toJson(true))).getOrElse(\n      AccountResult(id).toJson(true)))\n  }\n  case Failure(err) =&gt; {\n    val rn: FunnelResponse = new HttpReturningError(err)\n    Status(rn.code)(rn.toJson(true))\n  }\n}\n</code></pre><p>  }</p>\n<p>Ok. this is the first part of the series, we are done with the authentication. </p>\n<p>In the subsequent parts we will cover JSON Convertors, FunnelResponse, Cache using StateMonad, IO Monad, Validation of Scalaz.</p>\n<p>Here is the <a href=\"https://github.com/megamsys/megam_gateway.git\">full source code</a> of the project.</p>\n"},{"title":"Hadoop/Spark multi-node setup","slug":"2015-03-26-haddop_spark_multinode_setup","date_published":"2015-03-25T20:19:35.801Z","date_updated":"2015-03-27T04:49:24.470Z","_content":"\nThis is an installation guide for Apache Hadoop and Apache Spark on a multi node setup. We will use  Cloudera v5 as it has the packages for debian. You are free to use Hortonworks ,MapR (or) straight up zips from [Hadoop](hadoop.apache.org), [Spark](spark.apache.org).\n\n\nLets clear the terminology of a node. A node means individual servers, Virtual Machines (VMs) (or) Micro services.\n\nIn a multinode setup, we will deploy a topology of\n\n* One  Hadoop namenode\n* Many Hadoop datanode\n* One Spark Master\n* Many Spark Workers\n\n\nThe definition of Hadoop namenode, datanode, Spark can be read from the links here.\n\n[Apache Spark](spark.apache.org)\n[Hadoop](hadoop.apache.org)\n\n###In all the nodes\n\nWe need java, hence do the following in all the nodes.\n\nInstall java \n\n    sudo apt-get install openjdk-7-jdk\n\nInstall cloudera repo package\n\n    wget http://archive.cloudera.com/cdh5/one-click-install/trusty/amd64/cdh5-repository_1.0_all.deb\n    sudo dpkg -i cdh5-repository_1.0_all.deb\n    sudo apt-get -y update\n\n\nFor those of you folks from [Ceph](http://www.ceph.com) background, The Hadoop namenode is like Ceph MDS (Metadata server) which just stores pointer to data/additional info about the data.\n\nThere is a research project we will look at to see how Ceph can be natively used with Apache Spark. Why do you want do that, well Ceph is native (ugly Java can be gotten rid of)\n\n######First node\n\nLets install Hadoop namenode in the first node. \n\n    sudo apt-get -y install hadoop-yarn-resourcemanager hadoop-hdfs-namenode hadoop-yarn-nodemanager hadoop-yarn-proxyserver hadoop-client \n\nMake a directory to store hadoop filesystem and change permission of that directory to `hdfs:hdfs`\n\n\tsudo mkdir -p /hadoopstorage/name\n\tsudo chown -R hdfs:hdfs /hadoopstorage/\n    \nEdit /etc/hadoop/conf/core-site.xml with the $FIRST_NODE_IP_ADDR  to `ip address of first node`\n\n\t<?xml version=\"1.0\"?>\n\t<!--\n\tLicensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership.\n\tThe ASF licenses this file to You under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance withthe License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions and limitations under the License.\n\t-->\n\t<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n\t<configuration>\n\t<property>\n\t<name>fs.default.name</name>\n\t<value>hdfs://$FIRST_NODE_IP_ADDR:8097</value>\n\t</property>\n\t</configuration>\n    \nEdit /etc/hadoop/conf/hdfs-site.xml\n\n\t<?xml version=\"1.0\"?>\n\t<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n\t<!-- Put site-specific property overrides in this file. -->\n\t<configuration>\n    <property>\n     <name>dfs.namenode.name.dir</name>\n     <value>/hadoopstorage/name/</value>\n    </property>\n\t<property>\n\t\t<name>dfs.permissions.enabled</name>\n\t\t<value>false</value>\n\t</property>\n\t</configuration>\n\n\nMake symbolic links\n\n\tsudo ln -s /usr/lib/hadoop/libexec /usr/lib/hadoop-yarn/libexec\n\tsudo ln -s /usr/lib/hadoop/libexec /usr/lib/hadoop-hdfs/libexec\n\nStart Hadoop namenode\n\n\tsudo -u hdfs hadoop namenode -format -force\n\tsudo service hadoop-hdfs-namenode start\n    \n###Second node\n\nLet us install Spark Master.\n\n    apt-get install spark-core spark-master spark-history-server \n\nChange STANDALONE_SPARK_MASTER_HOST by replacing the $SECONDNODE_IP_ADDR with your second node ip address.\n\n\tsed -i \"s/^[ \\t]*export STANDALONE_SPARK_MASTER_HOST=.*/export STANDALONE_SPARK_MASTER_HOST='$SECONDNODE_IP_ADDR'/\" /etc/spark/conf/spark-env.sh\n\t\n\nAdd below lines in /etc/spark/conf/spark-defaults.conf\n\n\tspark.master    spark://$SECONDNODE_IP_ADDR:7077\n\tspark.eventLog.dir  /usr/spark/applicationHistory\n\tspark.eventLog.enabled           true\n    \nAfter changing configurations, you need to restart spark-master\n\n\tsudo service spark-master restart\n    \n###Adding a Hadoop datanode\n\nLet us install Hadoop datanode in another node you have.\n\nInstall packages\n\n\tsudo apt-get -y install hadoop-hdfs-datanode\n    \nCreate hadoop storage directory\n\n\tsudo mkdir -p /hadoopstorage/data/\n\nEdit /etc/hadoop/conf/core-site.xml\n\n\t<?xml version=\"1.0\"?>\n\t<!--\n\tLicensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership.\n\tThe ASF licenses this file to You under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance withthe License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions and limitations under the License.\n\t-->\n\t<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n\t<configuration>\n\t<property>\n\t<name>fs.default.name</name>\n\t<value>hdfs://$HADOOP_NAMENODE_IP_ADDR:8097</value>\n\t</property>\n\t</configuration>\n    \nEdit /etc/hadoop/conf/hdfs-site.xml\n\n\t<?xml version=\"1.0\"?>\n\t<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n\t<!-- Put site-specific property overrides in this file. -->\n\t<configuration>\n\t<property>\n\t\t<name>dfs.permissions.enabled</name>\n\t\t<value>false</value>\n\t</property>\n    <property>\n  \t <name>dfs.datanode.data.dir</name>\n\t <value>/hadoopstorage/data/</value>\n\t</property>\n\t</configuration>\n    \nMake symbolic links\n\n\tsudo ln -s /usr/lib/hadoop/libexec /usr/lib/hadoop-hdfs/libexec\n    \nRestart service\n\n\tsudo service hadoop-hdfs-datanode restart\n\n\n###Adding a Spark Worker\n\n\nLet us install spark worker in another node you have.\n\n    sudo apt-get install libgfortran3\n    apt-get install spark-core spark-worker\n\nChange STANDALONE_SPARK_MASTER_HOST by replacing the $SPARK_MASTER_IP_ADDR with your spark master's ip address. In this case the second node is our Spark Master\n\n\tsed -i \"s/^[ \\t]*export STANDALONE_SPARK_MASTER_HOST=.*/export STANDALONE_SPARK_MASTER_HOST='$SPARK_MASTER_IP_ADDR'/\" /etc/spark/conf/spark-env.sh\n    \nAdd the below in /etc/spark/conf/spark-defaults.conf\n\n\tspark.master    spark://$SPARK_MASTER_IP_ADDR:7077\n    \nRestart Service\n\n\tsudo service spark-worker restart\n\nAfter this we will launch the [retail analytics app](https://github.com/megamsys/retail_analytics.git) to predict a product buying behaviour. We will cover it in the next part.\n\n    NOTE : \nIf you want to store the history of spark, create spark history storage space into HDFS.\n\nAt this point, hadoop-hdfs-namenode and hadoop-hdfs-datanode services should be running.\n\nExecute the below in master server to create history storage\n\n\tsudo -u hdfs hadoop fs -mkdir /user\n\tsudo -u hdfs hadoop fs -mkdir /user/spark \n\tsudo -u hdfs hadoop fs -mkdir /user/spark/applicationHistory \n\tsudo -u hdfs hadoop fs -chown -R spark:spark /user/spark\n\tsudo -u hdfs hadoop fs -chmod 1777 /user/spark/applicationHistory\n    \nNow restart the service\n\n\tsudo service spark-history-server restart\n","source":"_posts/2015-03-26-haddop_spark_multinode_setup.md","raw":"---\ntitle: Hadoop/Spark multi-node setup\nslug: haddop_spark_multinode_setup\ndate_published: 2015-03-26T01:49:35.801Z\ndate_updated:   2015-03-27T10:19:24.470Z\n---\n\nThis is an installation guide for Apache Hadoop and Apache Spark on a multi node setup. We will use  Cloudera v5 as it has the packages for debian. You are free to use Hortonworks ,MapR (or) straight up zips from [Hadoop](hadoop.apache.org), [Spark](spark.apache.org).\n\n\nLets clear the terminology of a node. A node means individual servers, Virtual Machines (VMs) (or) Micro services.\n\nIn a multinode setup, we will deploy a topology of\n\n* One  Hadoop namenode\n* Many Hadoop datanode\n* One Spark Master\n* Many Spark Workers\n\n\nThe definition of Hadoop namenode, datanode, Spark can be read from the links here.\n\n[Apache Spark](spark.apache.org)\n[Hadoop](hadoop.apache.org)\n\n###In all the nodes\n\nWe need java, hence do the following in all the nodes.\n\nInstall java \n\n    sudo apt-get install openjdk-7-jdk\n\nInstall cloudera repo package\n\n    wget http://archive.cloudera.com/cdh5/one-click-install/trusty/amd64/cdh5-repository_1.0_all.deb\n    sudo dpkg -i cdh5-repository_1.0_all.deb\n    sudo apt-get -y update\n\n\nFor those of you folks from [Ceph](http://www.ceph.com) background, The Hadoop namenode is like Ceph MDS (Metadata server) which just stores pointer to data/additional info about the data.\n\nThere is a research project we will look at to see how Ceph can be natively used with Apache Spark. Why do you want do that, well Ceph is native (ugly Java can be gotten rid of)\n\n######First node\n\nLets install Hadoop namenode in the first node. \n\n    sudo apt-get -y install hadoop-yarn-resourcemanager hadoop-hdfs-namenode hadoop-yarn-nodemanager hadoop-yarn-proxyserver hadoop-client \n\nMake a directory to store hadoop filesystem and change permission of that directory to `hdfs:hdfs`\n\n\tsudo mkdir -p /hadoopstorage/name\n\tsudo chown -R hdfs:hdfs /hadoopstorage/\n    \nEdit /etc/hadoop/conf/core-site.xml with the $FIRST_NODE_IP_ADDR  to `ip address of first node`\n\n\t<?xml version=\"1.0\"?>\n\t<!--\n\tLicensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership.\n\tThe ASF licenses this file to You under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance withthe License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions and limitations under the License.\n\t-->\n\t<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n\t<configuration>\n\t<property>\n\t<name>fs.default.name</name>\n\t<value>hdfs://$FIRST_NODE_IP_ADDR:8097</value>\n\t</property>\n\t</configuration>\n    \nEdit /etc/hadoop/conf/hdfs-site.xml\n\n\t<?xml version=\"1.0\"?>\n\t<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n\t<!-- Put site-specific property overrides in this file. -->\n\t<configuration>\n    <property>\n     <name>dfs.namenode.name.dir</name>\n     <value>/hadoopstorage/name/</value>\n    </property>\n\t<property>\n\t\t<name>dfs.permissions.enabled</name>\n\t\t<value>false</value>\n\t</property>\n\t</configuration>\n\n\nMake symbolic links\n\n\tsudo ln -s /usr/lib/hadoop/libexec /usr/lib/hadoop-yarn/libexec\n\tsudo ln -s /usr/lib/hadoop/libexec /usr/lib/hadoop-hdfs/libexec\n\nStart Hadoop namenode\n\n\tsudo -u hdfs hadoop namenode -format -force\n\tsudo service hadoop-hdfs-namenode start\n    \n###Second node\n\nLet us install Spark Master.\n\n    apt-get install spark-core spark-master spark-history-server \n\nChange STANDALONE_SPARK_MASTER_HOST by replacing the $SECONDNODE_IP_ADDR with your second node ip address.\n\n\tsed -i \"s/^[ \\t]*export STANDALONE_SPARK_MASTER_HOST=.*/export STANDALONE_SPARK_MASTER_HOST='$SECONDNODE_IP_ADDR'/\" /etc/spark/conf/spark-env.sh\n\t\n\nAdd below lines in /etc/spark/conf/spark-defaults.conf\n\n\tspark.master    spark://$SECONDNODE_IP_ADDR:7077\n\tspark.eventLog.dir  /usr/spark/applicationHistory\n\tspark.eventLog.enabled           true\n    \nAfter changing configurations, you need to restart spark-master\n\n\tsudo service spark-master restart\n    \n###Adding a Hadoop datanode\n\nLet us install Hadoop datanode in another node you have.\n\nInstall packages\n\n\tsudo apt-get -y install hadoop-hdfs-datanode\n    \nCreate hadoop storage directory\n\n\tsudo mkdir -p /hadoopstorage/data/\n\nEdit /etc/hadoop/conf/core-site.xml\n\n\t<?xml version=\"1.0\"?>\n\t<!--\n\tLicensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership.\n\tThe ASF licenses this file to You under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance withthe License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions and limitations under the License.\n\t-->\n\t<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n\t<configuration>\n\t<property>\n\t<name>fs.default.name</name>\n\t<value>hdfs://$HADOOP_NAMENODE_IP_ADDR:8097</value>\n\t</property>\n\t</configuration>\n    \nEdit /etc/hadoop/conf/hdfs-site.xml\n\n\t<?xml version=\"1.0\"?>\n\t<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n\t<!-- Put site-specific property overrides in this file. -->\n\t<configuration>\n\t<property>\n\t\t<name>dfs.permissions.enabled</name>\n\t\t<value>false</value>\n\t</property>\n    <property>\n  \t <name>dfs.datanode.data.dir</name>\n\t <value>/hadoopstorage/data/</value>\n\t</property>\n\t</configuration>\n    \nMake symbolic links\n\n\tsudo ln -s /usr/lib/hadoop/libexec /usr/lib/hadoop-hdfs/libexec\n    \nRestart service\n\n\tsudo service hadoop-hdfs-datanode restart\n\n\n###Adding a Spark Worker\n\n\nLet us install spark worker in another node you have.\n\n    sudo apt-get install libgfortran3\n    apt-get install spark-core spark-worker\n\nChange STANDALONE_SPARK_MASTER_HOST by replacing the $SPARK_MASTER_IP_ADDR with your spark master's ip address. In this case the second node is our Spark Master\n\n\tsed -i \"s/^[ \\t]*export STANDALONE_SPARK_MASTER_HOST=.*/export STANDALONE_SPARK_MASTER_HOST='$SPARK_MASTER_IP_ADDR'/\" /etc/spark/conf/spark-env.sh\n    \nAdd the below in /etc/spark/conf/spark-defaults.conf\n\n\tspark.master    spark://$SPARK_MASTER_IP_ADDR:7077\n    \nRestart Service\n\n\tsudo service spark-worker restart\n\nAfter this we will launch the [retail analytics app](https://github.com/megamsys/retail_analytics.git) to predict a product buying behaviour. We will cover it in the next part.\n\n    NOTE : \nIf you want to store the history of spark, create spark history storage space into HDFS.\n\nAt this point, hadoop-hdfs-namenode and hadoop-hdfs-datanode services should be running.\n\nExecute the below in master server to create history storage\n\n\tsudo -u hdfs hadoop fs -mkdir /user\n\tsudo -u hdfs hadoop fs -mkdir /user/spark \n\tsudo -u hdfs hadoop fs -mkdir /user/spark/applicationHistory \n\tsudo -u hdfs hadoop fs -chown -R spark:spark /user/spark\n\tsudo -u hdfs hadoop fs -chmod 1777 /user/spark/applicationHistory\n    \nNow restart the service\n\n\tsudo service spark-history-server restart\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzairl000edrgbely1c464","content":"<p>This is an installation guide for Apache Hadoop and Apache Spark on a multi node setup. We will use  Cloudera v5 as it has the packages for debian. You are free to use Hortonworks ,MapR (or) straight up zips from <a href=\"hadoop.apache.org\">Hadoop</a>, <a href=\"spark.apache.org\">Spark</a>.</p>\n<p>Lets clear the terminology of a node. A node means individual servers, Virtual Machines (VMs) (or) Micro services.</p>\n<p>In a multinode setup, we will deploy a topology of</p>\n<ul>\n<li>One  Hadoop namenode</li>\n<li>Many Hadoop datanode</li>\n<li>One Spark Master</li>\n<li>Many Spark Workers</li>\n</ul>\n<p>The definition of Hadoop namenode, datanode, Spark can be read from the links here.</p>\n<p><a href=\"spark.apache.org\">Apache Spark</a><br><a href=\"hadoop.apache.org\">Hadoop</a></p>\n<p>###In all the nodes</p>\n<p>We need java, hence do the following in all the nodes.</p>\n<p>Install java </p>\n<pre><code>sudo apt-get install openjdk-7-jdk\n</code></pre><p>Install cloudera repo package</p>\n<pre><code>wget http://archive.cloudera.com/cdh5/one-click-install/trusty/amd64/cdh5-repository_1.0_all.deb\nsudo dpkg -i cdh5-repository_1.0_all.deb\nsudo apt-get -y update\n</code></pre><p>For those of you folks from <a href=\"http://www.ceph.com\" target=\"_blank\" rel=\"external\">Ceph</a> background, The Hadoop namenode is like Ceph MDS (Metadata server) which just stores pointer to data/additional info about the data.</p>\n<p>There is a research project we will look at to see how Ceph can be natively used with Apache Spark. Why do you want do that, well Ceph is native (ugly Java can be gotten rid of)</p>\n<p>######First node</p>\n<p>Lets install Hadoop namenode in the first node. </p>\n<pre><code>sudo apt-get -y install hadoop-yarn-resourcemanager hadoop-hdfs-namenode hadoop-yarn-nodemanager hadoop-yarn-proxyserver hadoop-client \n</code></pre><p>Make a directory to store hadoop filesystem and change permission of that directory to <code>hdfs:hdfs</code></p>\n<pre><code>sudo mkdir -p /hadoopstorage/name\nsudo chown -R hdfs:hdfs /hadoopstorage/\n</code></pre><p>Edit /etc/hadoop/conf/core-site.xml with the $FIRST_NODE_IP_ADDR  to <code>ip address of first node</code></p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!--\nLicensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership.\nThe ASF licenses this file to You under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance withthe License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions and limitations under the License.\n--&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;configuration&gt;\n&lt;property&gt;\n&lt;name&gt;fs.default.name&lt;/name&gt;\n&lt;value&gt;hdfs://$FIRST_NODE_IP_ADDR:8097&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>Edit /etc/hadoop/conf/hdfs-site.xml</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;!-- Put site-specific property overrides in this file. --&gt;\n&lt;configuration&gt;\n&lt;property&gt;\n &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n &lt;value&gt;/hadoopstorage/name/&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;\n    &lt;value&gt;false&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>Make symbolic links</p>\n<pre><code>sudo ln -s /usr/lib/hadoop/libexec /usr/lib/hadoop-yarn/libexec\nsudo ln -s /usr/lib/hadoop/libexec /usr/lib/hadoop-hdfs/libexec\n</code></pre><p>Start Hadoop namenode</p>\n<pre><code>sudo -u hdfs hadoop namenode -format -force\nsudo service hadoop-hdfs-namenode start\n</code></pre><p>###Second node</p>\n<p>Let us install Spark Master.</p>\n<pre><code>apt-get install spark-core spark-master spark-history-server \n</code></pre><p>Change STANDALONE_SPARK_MASTER_HOST by replacing the $SECONDNODE_IP_ADDR with your second node ip address.</p>\n<pre><code>sed -i &quot;s/^[ \\t]*export STANDALONE_SPARK_MASTER_HOST=.*/export STANDALONE_SPARK_MASTER_HOST=&apos;$SECONDNODE_IP_ADDR&apos;/&quot; /etc/spark/conf/spark-env.sh\n</code></pre><p>Add below lines in /etc/spark/conf/spark-defaults.conf</p>\n<pre><code>spark.master    spark://$SECONDNODE_IP_ADDR:7077\nspark.eventLog.dir  /usr/spark/applicationHistory\nspark.eventLog.enabled           true\n</code></pre><p>After changing configurations, you need to restart spark-master</p>\n<pre><code>sudo service spark-master restart\n</code></pre><p>###Adding a Hadoop datanode</p>\n<p>Let us install Hadoop datanode in another node you have.</p>\n<p>Install packages</p>\n<pre><code>sudo apt-get -y install hadoop-hdfs-datanode\n</code></pre><p>Create hadoop storage directory</p>\n<pre><code>sudo mkdir -p /hadoopstorage/data/\n</code></pre><p>Edit /etc/hadoop/conf/core-site.xml</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!--\nLicensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership.\nThe ASF licenses this file to You under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance withthe License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions and limitations under the License.\n--&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;configuration&gt;\n&lt;property&gt;\n&lt;name&gt;fs.default.name&lt;/name&gt;\n&lt;value&gt;hdfs://$HADOOP_NAMENODE_IP_ADDR:8097&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>Edit /etc/hadoop/conf/hdfs-site.xml</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;!-- Put site-specific property overrides in this file. --&gt;\n&lt;configuration&gt;\n&lt;property&gt;\n    &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;\n    &lt;value&gt;false&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n   &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n &lt;value&gt;/hadoopstorage/data/&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>Make symbolic links</p>\n<pre><code>sudo ln -s /usr/lib/hadoop/libexec /usr/lib/hadoop-hdfs/libexec\n</code></pre><p>Restart service</p>\n<pre><code>sudo service hadoop-hdfs-datanode restart\n</code></pre><p>###Adding a Spark Worker</p>\n<p>Let us install spark worker in another node you have.</p>\n<pre><code>sudo apt-get install libgfortran3\napt-get install spark-core spark-worker\n</code></pre><p>Change STANDALONE_SPARK_MASTER_HOST by replacing the $SPARK_MASTER_IP_ADDR with your spark masters ip address. In this case the second node is our Spark Master</p>\n<pre><code>sed -i &quot;s/^[ \\t]*export STANDALONE_SPARK_MASTER_HOST=.*/export STANDALONE_SPARK_MASTER_HOST=&apos;$SPARK_MASTER_IP_ADDR&apos;/&quot; /etc/spark/conf/spark-env.sh\n</code></pre><p>Add the below in /etc/spark/conf/spark-defaults.conf</p>\n<pre><code>spark.master    spark://$SPARK_MASTER_IP_ADDR:7077\n</code></pre><p>Restart Service</p>\n<pre><code>sudo service spark-worker restart\n</code></pre><p>After this we will launch the <a href=\"https://github.com/megamsys/retail_analytics.git\" target=\"_blank\" rel=\"external\">retail analytics app</a> to predict a product buying behaviour. We will cover it in the next part.</p>\n<pre><code>NOTE : \n</code></pre><p>If you want to store the history of spark, create spark history storage space into HDFS.</p>\n<p>At this point, hadoop-hdfs-namenode and hadoop-hdfs-datanode services should be running.</p>\n<p>Execute the below in master server to create history storage</p>\n<pre><code>sudo -u hdfs hadoop fs -mkdir /user\nsudo -u hdfs hadoop fs -mkdir /user/spark \nsudo -u hdfs hadoop fs -mkdir /user/spark/applicationHistory \nsudo -u hdfs hadoop fs -chown -R spark:spark /user/spark\nsudo -u hdfs hadoop fs -chmod 1777 /user/spark/applicationHistory\n</code></pre><p>Now restart the service</p>\n<pre><code>sudo service spark-history-server restart\n</code></pre>","excerpt":"","more":"<p>This is an installation guide for Apache Hadoop and Apache Spark on a multi node setup. We will use  Cloudera v5 as it has the packages for debian. You are free to use Hortonworks ,MapR (or) straight up zips from <a href=\"hadoop.apache.org\">Hadoop</a>, <a href=\"spark.apache.org\">Spark</a>.</p>\n<p>Lets clear the terminology of a node. A node means individual servers, Virtual Machines (VMs) (or) Micro services.</p>\n<p>In a multinode setup, we will deploy a topology of</p>\n<ul>\n<li>One  Hadoop namenode</li>\n<li>Many Hadoop datanode</li>\n<li>One Spark Master</li>\n<li>Many Spark Workers</li>\n</ul>\n<p>The definition of Hadoop namenode, datanode, Spark can be read from the links here.</p>\n<p><a href=\"spark.apache.org\">Apache Spark</a><br><a href=\"hadoop.apache.org\">Hadoop</a></p>\n<p>###In all the nodes</p>\n<p>We need java, hence do the following in all the nodes.</p>\n<p>Install java </p>\n<pre><code>sudo apt-get install openjdk-7-jdk\n</code></pre><p>Install cloudera repo package</p>\n<pre><code>wget http://archive.cloudera.com/cdh5/one-click-install/trusty/amd64/cdh5-repository_1.0_all.deb\nsudo dpkg -i cdh5-repository_1.0_all.deb\nsudo apt-get -y update\n</code></pre><p>For those of you folks from <a href=\"http://www.ceph.com\">Ceph</a> background, The Hadoop namenode is like Ceph MDS (Metadata server) which just stores pointer to data/additional info about the data.</p>\n<p>There is a research project we will look at to see how Ceph can be natively used with Apache Spark. Why do you want do that, well Ceph is native (ugly Java can be gotten rid of)</p>\n<p>######First node</p>\n<p>Lets install Hadoop namenode in the first node. </p>\n<pre><code>sudo apt-get -y install hadoop-yarn-resourcemanager hadoop-hdfs-namenode hadoop-yarn-nodemanager hadoop-yarn-proxyserver hadoop-client \n</code></pre><p>Make a directory to store hadoop filesystem and change permission of that directory to <code>hdfs:hdfs</code></p>\n<pre><code>sudo mkdir -p /hadoopstorage/name\nsudo chown -R hdfs:hdfs /hadoopstorage/\n</code></pre><p>Edit /etc/hadoop/conf/core-site.xml with the $FIRST_NODE_IP_ADDR  to <code>ip address of first node</code></p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!--\nLicensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership.\nThe ASF licenses this file to You under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance withthe License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions and limitations under the License.\n--&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;configuration&gt;\n&lt;property&gt;\n&lt;name&gt;fs.default.name&lt;/name&gt;\n&lt;value&gt;hdfs://$FIRST_NODE_IP_ADDR:8097&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>Edit /etc/hadoop/conf/hdfs-site.xml</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;!-- Put site-specific property overrides in this file. --&gt;\n&lt;configuration&gt;\n&lt;property&gt;\n &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n &lt;value&gt;/hadoopstorage/name/&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;\n    &lt;value&gt;false&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>Make symbolic links</p>\n<pre><code>sudo ln -s /usr/lib/hadoop/libexec /usr/lib/hadoop-yarn/libexec\nsudo ln -s /usr/lib/hadoop/libexec /usr/lib/hadoop-hdfs/libexec\n</code></pre><p>Start Hadoop namenode</p>\n<pre><code>sudo -u hdfs hadoop namenode -format -force\nsudo service hadoop-hdfs-namenode start\n</code></pre><p>###Second node</p>\n<p>Let us install Spark Master.</p>\n<pre><code>apt-get install spark-core spark-master spark-history-server \n</code></pre><p>Change STANDALONE_SPARK_MASTER_HOST by replacing the $SECONDNODE_IP_ADDR with your second node ip address.</p>\n<pre><code>sed -i &quot;s/^[ \\t]*export STANDALONE_SPARK_MASTER_HOST=.*/export STANDALONE_SPARK_MASTER_HOST=&apos;$SECONDNODE_IP_ADDR&apos;/&quot; /etc/spark/conf/spark-env.sh\n</code></pre><p>Add below lines in /etc/spark/conf/spark-defaults.conf</p>\n<pre><code>spark.master    spark://$SECONDNODE_IP_ADDR:7077\nspark.eventLog.dir  /usr/spark/applicationHistory\nspark.eventLog.enabled           true\n</code></pre><p>After changing configurations, you need to restart spark-master</p>\n<pre><code>sudo service spark-master restart\n</code></pre><p>###Adding a Hadoop datanode</p>\n<p>Let us install Hadoop datanode in another node you have.</p>\n<p>Install packages</p>\n<pre><code>sudo apt-get -y install hadoop-hdfs-datanode\n</code></pre><p>Create hadoop storage directory</p>\n<pre><code>sudo mkdir -p /hadoopstorage/data/\n</code></pre><p>Edit /etc/hadoop/conf/core-site.xml</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!--\nLicensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership.\nThe ASF licenses this file to You under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance withthe License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions and limitations under the License.\n--&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;configuration&gt;\n&lt;property&gt;\n&lt;name&gt;fs.default.name&lt;/name&gt;\n&lt;value&gt;hdfs://$HADOOP_NAMENODE_IP_ADDR:8097&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>Edit /etc/hadoop/conf/hdfs-site.xml</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;!-- Put site-specific property overrides in this file. --&gt;\n&lt;configuration&gt;\n&lt;property&gt;\n    &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;\n    &lt;value&gt;false&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n   &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n &lt;value&gt;/hadoopstorage/data/&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>Make symbolic links</p>\n<pre><code>sudo ln -s /usr/lib/hadoop/libexec /usr/lib/hadoop-hdfs/libexec\n</code></pre><p>Restart service</p>\n<pre><code>sudo service hadoop-hdfs-datanode restart\n</code></pre><p>###Adding a Spark Worker</p>\n<p>Let us install spark worker in another node you have.</p>\n<pre><code>sudo apt-get install libgfortran3\napt-get install spark-core spark-worker\n</code></pre><p>Change STANDALONE_SPARK_MASTER_HOST by replacing the $SPARK_MASTER_IP_ADDR with your spark masters ip address. In this case the second node is our Spark Master</p>\n<pre><code>sed -i &quot;s/^[ \\t]*export STANDALONE_SPARK_MASTER_HOST=.*/export STANDALONE_SPARK_MASTER_HOST=&apos;$SPARK_MASTER_IP_ADDR&apos;/&quot; /etc/spark/conf/spark-env.sh\n</code></pre><p>Add the below in /etc/spark/conf/spark-defaults.conf</p>\n<pre><code>spark.master    spark://$SPARK_MASTER_IP_ADDR:7077\n</code></pre><p>Restart Service</p>\n<pre><code>sudo service spark-worker restart\n</code></pre><p>After this we will launch the <a href=\"https://github.com/megamsys/retail_analytics.git\">retail analytics app</a> to predict a product buying behaviour. We will cover it in the next part.</p>\n<pre><code>NOTE : \n</code></pre><p>If you want to store the history of spark, create spark history storage space into HDFS.</p>\n<p>At this point, hadoop-hdfs-namenode and hadoop-hdfs-datanode services should be running.</p>\n<p>Execute the below in master server to create history storage</p>\n<pre><code>sudo -u hdfs hadoop fs -mkdir /user\nsudo -u hdfs hadoop fs -mkdir /user/spark \nsudo -u hdfs hadoop fs -mkdir /user/spark/applicationHistory \nsudo -u hdfs hadoop fs -chown -R spark:spark /user/spark\nsudo -u hdfs hadoop fs -chmod 1777 /user/spark/applicationHistory\n</code></pre><p>Now restart the service</p>\n<pre><code>sudo service spark-history-server restart\n</code></pre>"},{"title":"Ceph in a single node cluster","slug":"2015-03-27-ceph-in-a-single-node","date_published":"2015-03-27T08:59:26.544Z","date_updated":"2015-03-27T08:59:26.535Z","_content":"\n[Ceph](http://ceph.com) is one of the most interesting distributed storage systems available, with a very active development and a complete set of features that make it a valuable candidate for cloud storage services\n\n######Assumptions\n\n    Ceph version: 0.87\n    Installation with ceph-deploy\n    Operating system for the Ceph nodes: Ubuntu 14.04\n\n     \n######Preparing the storage\n\n`WARNING`: preparing the storage for Ceph means to delete a disks partition table and lose all its data. Proceed only if you know exactly what you are doing!\n\nCeph will need some physical storage to be used as Object Storage Devices (OSD) and Journal. Ceph supports ext4, btrfs and xfs. I tried setting up clusters with ext4.\n\nI have three storage partitions as\n\n\t$ df -h\n\t/dev/sdb1       115G   /storage1\n\t/dev/sdb2       115G   /storage2\n\t/dev/sda3       115G   /storage3\n\n\n######Install Ceph \n\nThe ceph-deploy tool must only be installed on the admin node. Access to the other nodes for configuration purposes will be handled by ceph-deploy over SSH (with keys).\n\nAdd Ceph repository to your apt configuration\n\n\techo deb http://ceph.com/debian-giant/ $(lsb_release -sc) main | sudo tee /etc/apt/sources.list.d/ceph.list\n    \nInstall the trusted key with\n\n\twget -q -O- 'https://ceph.com/git/?p=ceph.git;a=blob_plain;f=keys/release.asc' | sudo apt-key add -\n    \nInstall ceph-deploy \n\n\tsudo apt-get -y update\n\tsudo apt-get -y install ceph-deploy ceph-common ceph-mds\n\n######Setup the admin node\n\nEach Ceph node will be setup with an user having passwordless sudo permissions and each node will store the public key of the admin node to allow for passwordless SSH access. With this configuration, ceph-deploy will be able to install and configure every node of the cluster.\n\n`NOTE`: the hostnames (i.e., the output of hostname -s) must match the Ceph node names!\n\nAdd a ceph user on each Ceph cluster node (even if a cluster node is also an admin node) and give it passwordless sudo permissions\n\n\t$ sudo useradd -d /home/ceph -m ceph -s /bin/bash\n\t$ sudo passwd ceph\n\t<Enter password>\n\t$ echo \"ceph ALL = (root) NOPASSWD:ALL\" | sudo tee /etc/sudoers.d/ceph\n\t$ sudo chmod 0440 /etc/sudoers.d/ceph\n    \nEdit the /etc/hosts file to add mappings to the cluster nodes. Example:\n\n\t$ cat /etc/hosts\n\t127.0.0.1       localhost\n    192.168.1.100 cephserver\n\nto enable dns resolution with the hosts file, install dnsmasq\n\n\t$ sudo apt-get install dnsmasq\n\nGenerate a public key for the admin user and install it on every ceph nodes\n\n\t$ ssh-keygen\n    \n\nSetup an SSH access configuration by editing the .ssh/config file. Example:\n\n\tHost cephserver\n\t  Hostname cephserver\n      User ceph\n\n\n######Setup the cluster\n\nAdministration of the cluster is done entirely from the admin node.\n\nstep1: Move to a dedicated directory to collect the files that ceph-deploy will generate. This will be the working directory for any further use of ceph-deploy\n\n    $ mkdir ceph-cluster\n    $ cd ceph-cluster\n\nstep2: Deploy the monitor node(s)  replace mon0 with the list of hostnames of the initial monitor nodes\n\n    $ ceph-deploy new cephmaster\n    [ceph_deploy.cli][INFO  ] Invoked (1.4.0): /usr/bin/ceph-deploy new cephmaster\n    [ceph_deploy.new][DEBUG ] Creating new cluster named ceph\n    [ceph_deploy.new][DEBUG ] Resolving host cephmaster\n    [ceph_deploy.new][DEBUG ] Monitor cephmaster at 192.168.1.100\n    [ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds\n    [ceph_deploy.new][DEBUG ] Monitor initial members are ['cephmaster']\n    [ceph_deploy.new][DEBUG ] Monitor addrs are ['192.168.1.100']\n    [ceph_deploy.new][DEBUG ] Creating a random mon key...\n    [ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...\n    [ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...\n\n\n\n`Tip` Assuming only one node for your Ceph Storage Cluster, you will need to modify the default osd crush chooseleaf type setting (it defaults to 1 for node) to 0 for device so that it will peer with OSDs on the local node. Add the following line to your Ceph configuration file:\n\n\tosd crush chooseleaf type = 0\n\n`Tip`\tIf you deploy without executing foregoing step on a single node cluster, your Ceph Storage Cluster will not achieve an active + clean state. To remedy this situation, you must modify your CRUSH Map.\n\n\nstep3: Install ceph in the node\n\n\t$ ceph-deploy install  cephmaster\n\natep4: Create monitor and gather keys\n\n\t$ ceph-deploy mon create-initial\n\n`Note` The content of the working directory after this step should look like\n\n\tcadm@mon0:~/my-cluster$ ls\n\tceph.bootstrap-mds.keyring  ceph.bootstrap-osd.keyring  ceph.client.admin.keyring  ceph.conf  ceph.log  ceph.mon.keyring  release.asc\n    \n\nstep4: Prepare and activate the disks (ceph-deploy also has a create command that should combine this two operations together, but for some reason it was not working for me)\n\n\tceph-deploy osd prepare cephmaster:/storage1 cephmaster:/storage2 cephmaster:/storage3\n\tceph-deploy osd activate cephmaster:/storage1 cephmaster:/storage2 cephmaster:/storage3\n\nstep5: Copy keys and configuration files\n\n\t$ ceph-deploy admin cephmaster\n    \nstep6: Ensure proper permissions for admin keyring\n\n\t$ sudo chmod +r /etc/ceph/ceph.client.admin.keyring\n\nCheck the Ceph status and health\n\n\t$ ceph health\n\t$ ceph status\n    $ ceph osd tree\n\nCeph setup is ok when the health is `HEALTH_OK`. We the software engineers generally don't care about the `WARNINGS`, but in ceph `HEALTH_WARN` is like error.\n\n######Revert installation\n\nThere are useful commands to purge the Ceph installation and configuration from every node so that one can start over again from a clean state.\n\nThis will remove Ceph configuration and keys\n\n\tceph-deploy purgedata cephmaster\n\tceph-deploy forgetkeys\n\nThis will also remove Ceph packages\n\n\tceph-deploy purge cephmaster\n\nBefore getting a healthy Ceph cluster I had to purge and reinstall many times, cycling between the Setup the cluster, Prepare OSDs and OSD Daemons and Final steps parts multiple times, while removing every warning that ceph-deploy was reporting.\n\n","source":"_posts/2015-03-27-ceph-in-a-single-node.md","raw":"---\ntitle: Ceph in a single node cluster\nslug: ceph-in-a-single-node\ndate_published: 2015-03-27T14:29:26.544Z\ndate_updated:   2015-03-27T14:29:26.535Z\ntags: ceph\n---\n\n[Ceph](http://ceph.com) is one of the most interesting distributed storage systems available, with a very active development and a complete set of features that make it a valuable candidate for cloud storage services\n\n######Assumptions\n\n    Ceph version: 0.87\n    Installation with ceph-deploy\n    Operating system for the Ceph nodes: Ubuntu 14.04\n\n     \n######Preparing the storage\n\n`WARNING`: preparing the storage for Ceph means to delete a disks partition table and lose all its data. Proceed only if you know exactly what you are doing!\n\nCeph will need some physical storage to be used as Object Storage Devices (OSD) and Journal. Ceph supports ext4, btrfs and xfs. I tried setting up clusters with ext4.\n\nI have three storage partitions as\n\n\t$ df -h\n\t/dev/sdb1       115G   /storage1\n\t/dev/sdb2       115G   /storage2\n\t/dev/sda3       115G   /storage3\n\n\n######Install Ceph \n\nThe ceph-deploy tool must only be installed on the admin node. Access to the other nodes for configuration purposes will be handled by ceph-deploy over SSH (with keys).\n\nAdd Ceph repository to your apt configuration\n\n\techo deb http://ceph.com/debian-giant/ $(lsb_release -sc) main | sudo tee /etc/apt/sources.list.d/ceph.list\n    \nInstall the trusted key with\n\n\twget -q -O- 'https://ceph.com/git/?p=ceph.git;a=blob_plain;f=keys/release.asc' | sudo apt-key add -\n    \nInstall ceph-deploy \n\n\tsudo apt-get -y update\n\tsudo apt-get -y install ceph-deploy ceph-common ceph-mds\n\n######Setup the admin node\n\nEach Ceph node will be setup with an user having passwordless sudo permissions and each node will store the public key of the admin node to allow for passwordless SSH access. With this configuration, ceph-deploy will be able to install and configure every node of the cluster.\n\n`NOTE`: the hostnames (i.e., the output of hostname -s) must match the Ceph node names!\n\nAdd a ceph user on each Ceph cluster node (even if a cluster node is also an admin node) and give it passwordless sudo permissions\n\n\t$ sudo useradd -d /home/ceph -m ceph -s /bin/bash\n\t$ sudo passwd ceph\n\t<Enter password>\n\t$ echo \"ceph ALL = (root) NOPASSWD:ALL\" | sudo tee /etc/sudoers.d/ceph\n\t$ sudo chmod 0440 /etc/sudoers.d/ceph\n    \nEdit the /etc/hosts file to add mappings to the cluster nodes. Example:\n\n\t$ cat /etc/hosts\n\t127.0.0.1       localhost\n    192.168.1.100 cephserver\n\nto enable dns resolution with the hosts file, install dnsmasq\n\n\t$ sudo apt-get install dnsmasq\n\nGenerate a public key for the admin user and install it on every ceph nodes\n\n\t$ ssh-keygen\n    \n\nSetup an SSH access configuration by editing the .ssh/config file. Example:\n\n\tHost cephserver\n\t  Hostname cephserver\n      User ceph\n\n\n######Setup the cluster\n\nAdministration of the cluster is done entirely from the admin node.\n\nstep1: Move to a dedicated directory to collect the files that ceph-deploy will generate. This will be the working directory for any further use of ceph-deploy\n\n    $ mkdir ceph-cluster\n    $ cd ceph-cluster\n\nstep2: Deploy the monitor node(s)  replace mon0 with the list of hostnames of the initial monitor nodes\n\n    $ ceph-deploy new cephmaster\n    [ceph_deploy.cli][INFO  ] Invoked (1.4.0): /usr/bin/ceph-deploy new cephmaster\n    [ceph_deploy.new][DEBUG ] Creating new cluster named ceph\n    [ceph_deploy.new][DEBUG ] Resolving host cephmaster\n    [ceph_deploy.new][DEBUG ] Monitor cephmaster at 192.168.1.100\n    [ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds\n    [ceph_deploy.new][DEBUG ] Monitor initial members are ['cephmaster']\n    [ceph_deploy.new][DEBUG ] Monitor addrs are ['192.168.1.100']\n    [ceph_deploy.new][DEBUG ] Creating a random mon key...\n    [ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...\n    [ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...\n\n\n\n`Tip` Assuming only one node for your Ceph Storage Cluster, you will need to modify the default osd crush chooseleaf type setting (it defaults to 1 for node) to 0 for device so that it will peer with OSDs on the local node. Add the following line to your Ceph configuration file:\n\n\tosd crush chooseleaf type = 0\n\n`Tip`\tIf you deploy without executing foregoing step on a single node cluster, your Ceph Storage Cluster will not achieve an active + clean state. To remedy this situation, you must modify your CRUSH Map.\n\n\nstep3: Install ceph in the node\n\n\t$ ceph-deploy install  cephmaster\n\natep4: Create monitor and gather keys\n\n\t$ ceph-deploy mon create-initial\n\n`Note` The content of the working directory after this step should look like\n\n\tcadm@mon0:~/my-cluster$ ls\n\tceph.bootstrap-mds.keyring  ceph.bootstrap-osd.keyring  ceph.client.admin.keyring  ceph.conf  ceph.log  ceph.mon.keyring  release.asc\n    \n\nstep4: Prepare and activate the disks (ceph-deploy also has a create command that should combine this two operations together, but for some reason it was not working for me)\n\n\tceph-deploy osd prepare cephmaster:/storage1 cephmaster:/storage2 cephmaster:/storage3\n\tceph-deploy osd activate cephmaster:/storage1 cephmaster:/storage2 cephmaster:/storage3\n\nstep5: Copy keys and configuration files\n\n\t$ ceph-deploy admin cephmaster\n    \nstep6: Ensure proper permissions for admin keyring\n\n\t$ sudo chmod +r /etc/ceph/ceph.client.admin.keyring\n\nCheck the Ceph status and health\n\n\t$ ceph health\n\t$ ceph status\n    $ ceph osd tree\n\nCeph setup is ok when the health is `HEALTH_OK`. We the software engineers generally don't care about the `WARNINGS`, but in ceph `HEALTH_WARN` is like error.\n\n######Revert installation\n\nThere are useful commands to purge the Ceph installation and configuration from every node so that one can start over again from a clean state.\n\nThis will remove Ceph configuration and keys\n\n\tceph-deploy purgedata cephmaster\n\tceph-deploy forgetkeys\n\nThis will also remove Ceph packages\n\n\tceph-deploy purge cephmaster\n\nBefore getting a healthy Ceph cluster I had to purge and reinstall many times, cycling between the Setup the cluster, Prepare OSDs and OSD Daemons and Final steps parts multiple times, while removing every warning that ceph-deploy was reporting.\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzairp000fdrgbmz5c76gp","content":"<p><a href=\"http://ceph.com\" target=\"_blank\" rel=\"external\">Ceph</a> is one of the most interesting distributed storage systems available, with a very active development and a complete set of features that make it a valuable candidate for cloud storage services</p>\n<p>######Assumptions</p>\n<pre><code>Ceph version: 0.87\nInstallation with ceph-deploy\nOperating system for the Ceph nodes: Ubuntu 14.04\n</code></pre><p>######Preparing the storage</p>\n<p><code>WARNING</code>: preparing the storage for Ceph means to delete a disks partition table and lose all its data. Proceed only if you know exactly what you are doing!</p>\n<p>Ceph will need some physical storage to be used as Object Storage Devices (OSD) and Journal. Ceph supports ext4, btrfs and xfs. I tried setting up clusters with ext4.</p>\n<p>I have three storage partitions as</p>\n<pre><code>$ df -h\n/dev/sdb1       115G   /storage1\n/dev/sdb2       115G   /storage2\n/dev/sda3       115G   /storage3\n</code></pre><p>######Install Ceph </p>\n<p>The ceph-deploy tool must only be installed on the admin node. Access to the other nodes for configuration purposes will be handled by ceph-deploy over SSH (with keys).</p>\n<p>Add Ceph repository to your apt configuration</p>\n<pre><code>echo deb http://ceph.com/debian-giant/ $(lsb_release -sc) main | sudo tee /etc/apt/sources.list.d/ceph.list\n</code></pre><p>Install the trusted key with</p>\n<pre><code>wget -q -O- &apos;https://ceph.com/git/?p=ceph.git;a=blob_plain;f=keys/release.asc&apos; | sudo apt-key add -\n</code></pre><p>Install ceph-deploy </p>\n<pre><code>sudo apt-get -y update\nsudo apt-get -y install ceph-deploy ceph-common ceph-mds\n</code></pre><p>######Setup the admin node</p>\n<p>Each Ceph node will be setup with an user having passwordless sudo permissions and each node will store the public key of the admin node to allow for passwordless SSH access. With this configuration, ceph-deploy will be able to install and configure every node of the cluster.</p>\n<p><code>NOTE</code>: the hostnames (i.e., the output of hostname -s) must match the Ceph node names!</p>\n<p>Add a ceph user on each Ceph cluster node (even if a cluster node is also an admin node) and give it passwordless sudo permissions</p>\n<pre><code>$ sudo useradd -d /home/ceph -m ceph -s /bin/bash\n$ sudo passwd ceph\n&lt;Enter password&gt;\n$ echo &quot;ceph ALL = (root) NOPASSWD:ALL&quot; | sudo tee /etc/sudoers.d/ceph\n$ sudo chmod 0440 /etc/sudoers.d/ceph\n</code></pre><p>Edit the /etc/hosts file to add mappings to the cluster nodes. Example:</p>\n<pre><code>$ cat /etc/hosts\n127.0.0.1       localhost\n192.168.1.100 cephserver\n</code></pre><p>to enable dns resolution with the hosts file, install dnsmasq</p>\n<pre><code>$ sudo apt-get install dnsmasq\n</code></pre><p>Generate a public key for the admin user and install it on every ceph nodes</p>\n<pre><code>$ ssh-keygen\n</code></pre><p>Setup an SSH access configuration by editing the .ssh/config file. Example:</p>\n<pre><code>Host cephserver\n  Hostname cephserver\n  User ceph\n</code></pre><p>######Setup the cluster</p>\n<p>Administration of the cluster is done entirely from the admin node.</p>\n<p>step1: Move to a dedicated directory to collect the files that ceph-deploy will generate. This will be the working directory for any further use of ceph-deploy</p>\n<pre><code>$ mkdir ceph-cluster\n$ cd ceph-cluster\n</code></pre><p>step2: Deploy the monitor node(s)  replace mon0 with the list of hostnames of the initial monitor nodes</p>\n<pre><code>$ ceph-deploy new cephmaster\n[ceph_deploy.cli][INFO  ] Invoked (1.4.0): /usr/bin/ceph-deploy new cephmaster\n[ceph_deploy.new][DEBUG ] Creating new cluster named ceph\n[ceph_deploy.new][DEBUG ] Resolving host cephmaster\n[ceph_deploy.new][DEBUG ] Monitor cephmaster at 192.168.1.100\n[ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds\n[ceph_deploy.new][DEBUG ] Monitor initial members are [&apos;cephmaster&apos;]\n[ceph_deploy.new][DEBUG ] Monitor addrs are [&apos;192.168.1.100&apos;]\n[ceph_deploy.new][DEBUG ] Creating a random mon key...\n[ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...\n[ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...\n</code></pre><p><code>Tip</code> Assuming only one node for your Ceph Storage Cluster, you will need to modify the default osd crush chooseleaf type setting (it defaults to 1 for node) to 0 for device so that it will peer with OSDs on the local node. Add the following line to your Ceph configuration file:</p>\n<pre><code>osd crush chooseleaf type = 0\n</code></pre><p><code>Tip</code>    If you deploy without executing foregoing step on a single node cluster, your Ceph Storage Cluster will not achieve an active + clean state. To remedy this situation, you must modify your CRUSH Map.</p>\n<p>step3: Install ceph in the node</p>\n<pre><code>$ ceph-deploy install  cephmaster\n</code></pre><p>atep4: Create monitor and gather keys</p>\n<pre><code>$ ceph-deploy mon create-initial\n</code></pre><p><code>Note</code> The content of the working directory after this step should look like</p>\n<pre><code>cadm@mon0:~/my-cluster$ ls\nceph.bootstrap-mds.keyring  ceph.bootstrap-osd.keyring  ceph.client.admin.keyring  ceph.conf  ceph.log  ceph.mon.keyring  release.asc\n</code></pre><p>step4: Prepare and activate the disks (ceph-deploy also has a create command that should combine this two operations together, but for some reason it was not working for me)</p>\n<pre><code>ceph-deploy osd prepare cephmaster:/storage1 cephmaster:/storage2 cephmaster:/storage3\nceph-deploy osd activate cephmaster:/storage1 cephmaster:/storage2 cephmaster:/storage3\n</code></pre><p>step5: Copy keys and configuration files</p>\n<pre><code>$ ceph-deploy admin cephmaster\n</code></pre><p>step6: Ensure proper permissions for admin keyring</p>\n<pre><code>$ sudo chmod +r /etc/ceph/ceph.client.admin.keyring\n</code></pre><p>Check the Ceph status and health</p>\n<pre><code>$ ceph health\n$ ceph status\n$ ceph osd tree\n</code></pre><p>Ceph setup is ok when the health is <code>HEALTH_OK</code>. We the software engineers generally dont care about the <code>WARNINGS</code>, but in ceph <code>HEALTH_WARN</code> is like error.</p>\n<p>######Revert installation</p>\n<p>There are useful commands to purge the Ceph installation and configuration from every node so that one can start over again from a clean state.</p>\n<p>This will remove Ceph configuration and keys</p>\n<pre><code>ceph-deploy purgedata cephmaster\nceph-deploy forgetkeys\n</code></pre><p>This will also remove Ceph packages</p>\n<pre><code>ceph-deploy purge cephmaster\n</code></pre><p>Before getting a healthy Ceph cluster I had to purge and reinstall many times, cycling between the Setup the cluster, Prepare OSDs and OSD Daemons and Final steps parts multiple times, while removing every warning that ceph-deploy was reporting.</p>\n","excerpt":"","more":"<p><a href=\"http://ceph.com\">Ceph</a> is one of the most interesting distributed storage systems available, with a very active development and a complete set of features that make it a valuable candidate for cloud storage services</p>\n<p>######Assumptions</p>\n<pre><code>Ceph version: 0.87\nInstallation with ceph-deploy\nOperating system for the Ceph nodes: Ubuntu 14.04\n</code></pre><p>######Preparing the storage</p>\n<p><code>WARNING</code>: preparing the storage for Ceph means to delete a disks partition table and lose all its data. Proceed only if you know exactly what you are doing!</p>\n<p>Ceph will need some physical storage to be used as Object Storage Devices (OSD) and Journal. Ceph supports ext4, btrfs and xfs. I tried setting up clusters with ext4.</p>\n<p>I have three storage partitions as</p>\n<pre><code>$ df -h\n/dev/sdb1       115G   /storage1\n/dev/sdb2       115G   /storage2\n/dev/sda3       115G   /storage3\n</code></pre><p>######Install Ceph </p>\n<p>The ceph-deploy tool must only be installed on the admin node. Access to the other nodes for configuration purposes will be handled by ceph-deploy over SSH (with keys).</p>\n<p>Add Ceph repository to your apt configuration</p>\n<pre><code>echo deb http://ceph.com/debian-giant/ $(lsb_release -sc) main | sudo tee /etc/apt/sources.list.d/ceph.list\n</code></pre><p>Install the trusted key with</p>\n<pre><code>wget -q -O- &apos;https://ceph.com/git/?p=ceph.git;a=blob_plain;f=keys/release.asc&apos; | sudo apt-key add -\n</code></pre><p>Install ceph-deploy </p>\n<pre><code>sudo apt-get -y update\nsudo apt-get -y install ceph-deploy ceph-common ceph-mds\n</code></pre><p>######Setup the admin node</p>\n<p>Each Ceph node will be setup with an user having passwordless sudo permissions and each node will store the public key of the admin node to allow for passwordless SSH access. With this configuration, ceph-deploy will be able to install and configure every node of the cluster.</p>\n<p><code>NOTE</code>: the hostnames (i.e., the output of hostname -s) must match the Ceph node names!</p>\n<p>Add a ceph user on each Ceph cluster node (even if a cluster node is also an admin node) and give it passwordless sudo permissions</p>\n<pre><code>$ sudo useradd -d /home/ceph -m ceph -s /bin/bash\n$ sudo passwd ceph\n&lt;Enter password&gt;\n$ echo &quot;ceph ALL = (root) NOPASSWD:ALL&quot; | sudo tee /etc/sudoers.d/ceph\n$ sudo chmod 0440 /etc/sudoers.d/ceph\n</code></pre><p>Edit the /etc/hosts file to add mappings to the cluster nodes. Example:</p>\n<pre><code>$ cat /etc/hosts\n127.0.0.1       localhost\n192.168.1.100 cephserver\n</code></pre><p>to enable dns resolution with the hosts file, install dnsmasq</p>\n<pre><code>$ sudo apt-get install dnsmasq\n</code></pre><p>Generate a public key for the admin user and install it on every ceph nodes</p>\n<pre><code>$ ssh-keygen\n</code></pre><p>Setup an SSH access configuration by editing the .ssh/config file. Example:</p>\n<pre><code>Host cephserver\n  Hostname cephserver\n  User ceph\n</code></pre><p>######Setup the cluster</p>\n<p>Administration of the cluster is done entirely from the admin node.</p>\n<p>step1: Move to a dedicated directory to collect the files that ceph-deploy will generate. This will be the working directory for any further use of ceph-deploy</p>\n<pre><code>$ mkdir ceph-cluster\n$ cd ceph-cluster\n</code></pre><p>step2: Deploy the monitor node(s)  replace mon0 with the list of hostnames of the initial monitor nodes</p>\n<pre><code>$ ceph-deploy new cephmaster\n[ceph_deploy.cli][INFO  ] Invoked (1.4.0): /usr/bin/ceph-deploy new cephmaster\n[ceph_deploy.new][DEBUG ] Creating new cluster named ceph\n[ceph_deploy.new][DEBUG ] Resolving host cephmaster\n[ceph_deploy.new][DEBUG ] Monitor cephmaster at 192.168.1.100\n[ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds\n[ceph_deploy.new][DEBUG ] Monitor initial members are [&apos;cephmaster&apos;]\n[ceph_deploy.new][DEBUG ] Monitor addrs are [&apos;192.168.1.100&apos;]\n[ceph_deploy.new][DEBUG ] Creating a random mon key...\n[ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...\n[ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...\n</code></pre><p><code>Tip</code> Assuming only one node for your Ceph Storage Cluster, you will need to modify the default osd crush chooseleaf type setting (it defaults to 1 for node) to 0 for device so that it will peer with OSDs on the local node. Add the following line to your Ceph configuration file:</p>\n<pre><code>osd crush chooseleaf type = 0\n</code></pre><p><code>Tip</code>    If you deploy without executing foregoing step on a single node cluster, your Ceph Storage Cluster will not achieve an active + clean state. To remedy this situation, you must modify your CRUSH Map.</p>\n<p>step3: Install ceph in the node</p>\n<pre><code>$ ceph-deploy install  cephmaster\n</code></pre><p>atep4: Create monitor and gather keys</p>\n<pre><code>$ ceph-deploy mon create-initial\n</code></pre><p><code>Note</code> The content of the working directory after this step should look like</p>\n<pre><code>cadm@mon0:~/my-cluster$ ls\nceph.bootstrap-mds.keyring  ceph.bootstrap-osd.keyring  ceph.client.admin.keyring  ceph.conf  ceph.log  ceph.mon.keyring  release.asc\n</code></pre><p>step4: Prepare and activate the disks (ceph-deploy also has a create command that should combine this two operations together, but for some reason it was not working for me)</p>\n<pre><code>ceph-deploy osd prepare cephmaster:/storage1 cephmaster:/storage2 cephmaster:/storage3\nceph-deploy osd activate cephmaster:/storage1 cephmaster:/storage2 cephmaster:/storage3\n</code></pre><p>step5: Copy keys and configuration files</p>\n<pre><code>$ ceph-deploy admin cephmaster\n</code></pre><p>step6: Ensure proper permissions for admin keyring</p>\n<pre><code>$ sudo chmod +r /etc/ceph/ceph.client.admin.keyring\n</code></pre><p>Check the Ceph status and health</p>\n<pre><code>$ ceph health\n$ ceph status\n$ ceph osd tree\n</code></pre><p>Ceph setup is ok when the health is <code>HEALTH_OK</code>. We the software engineers generally dont care about the <code>WARNINGS</code>, but in ceph <code>HEALTH_WARN</code> is like error.</p>\n<p>######Revert installation</p>\n<p>There are useful commands to purge the Ceph installation and configuration from every node so that one can start over again from a clean state.</p>\n<p>This will remove Ceph configuration and keys</p>\n<pre><code>ceph-deploy purgedata cephmaster\nceph-deploy forgetkeys\n</code></pre><p>This will also remove Ceph packages</p>\n<pre><code>ceph-deploy purge cephmaster\n</code></pre><p>Before getting a healthy Ceph cluster I had to purge and reinstall many times, cycling between the Setup the cluster, Prepare OSDs and OSD Daemons and Final steps parts multiple times, while removing every warning that ceph-deploy was reporting.</p>\n"},{"title":"Concurrency in Go!","slug":"2015-03-27-concurrency-in-go","date_published":"2015-03-27T09:10:52.413Z","date_updated":"2015-03-27T09:13:18.867Z","_content":"\n###What is concurrency?\n\nExecution of multiple processes independantly and they may or may not be getting executed at the same time.\nImagine a webserver gets multiple smaller requests and they all concurrently gets executed. It is basically multitasking on a single-core processor. \n\n\n###Oh, wait! then Concurrency is parallelism?\n\nParallelism is about running multiple processes at the same time, but concurrency is about dealing with a lot of processes may or may not be getting executed at the same time. Confusing?\n\n**Parallelism**\n\n  * Simultaneous Execution\n  * Running multiple threads on different processors   at the same time against each other.\n  * Requires multiple cores.\n  \n**Concurrency**\n\n*   Independent Execution\n*  Running multiple light-weight concurrent processes(goroutines!!, hold on! we'll see what goroutines are)\n*   Single core \n   \n  > Note: Using GOMAXPROCS, it is possible to run goroutines on different logical processors by configuring the runtime. \n\n\nSo, 'Concurrency is not parallelism' but,\n\n'concurreny can achieve parallelism'. \n\n\n\n#why Go?\n\nGo's concurrency primitives are way too good and it is easy to write concurrent programs.\nGo uses goroutines to achieve concurreny and importantly, it makes communication between goroutines a lot easier. \n\n###what are goroutines ?\nFundamentally, goroutine is a function which runs concurrently with other functions.\n\nSo, here is an example \n\n    package main\n    import (\n        \"fmt\"\n           )\n         \n    func print(s string){\n            for i := 0; i < 5; i++ {\n                 fmt.Println(s)\n         }\n     }\n\n\n     func main() {\n         print(\"Current thread\")    \n\n         go print(\"bye\")  \n\n         var input string\n         fmt.Scanln(&input) \n     }\n        \n        \n   Compile the above code to understand how the goroutines work. We'll look into more details in a bit.\n\n\n\n###what are channels?\nChannels are basically pipelines that are used to communicate between two goroutines. Channels can be used for synchronization of goroutines, etc.\n\n    package main\n    \n    import (\n        \"fmt\"\n        \"time\"\n        )\n        \n        func put(c chan string){\n         for {\n            c <- \"Tadaa!\"\n           }\n          }\n          \n        func print(c chan string){\n          for {\n            message := <- c\n            fmt.Println(message)\n            time.Sleep(time.second * 2)\n            }\n           }\n         func main() {\n           var c chan string = make(chan string)\n           \n           go put(c)\n           go print(c)\n           \n           var input string\n           fmt.Scanln(&input) \n          }\n        \n     \n  How awesome right? Thats how cool goroutines and channels are. It makes it a lot easier and more interesting to program.  \n   \n\n###why are goroutines super cool?\n\nConcurreny was possible in other languages too, but what made concurreny a cherrypie in go?\n\ngoroutines are light-weight, other languages like java, uses threads. \n\nCreating a goroutine hardly takes 2kb of stackspace(it was 8kb till go 1.3) where as a thread consumes 1MB per stack space. \n\n\nI recommend all of you reading this to watch [Go Concurrency Patterns](http://www.youtube.com/watch?v=f6kdp27TYZs) by Rob Pike\n\nFew Links:\n\n[Fundamentals of concurrent programming](https://www.nada.kth.se/~snilsson/concurrency/)\n\n[Concurreny goroutines and GOMAXPROCS](http://www.goinggo.net/2014/01/concurrency-goroutines-and-gomaxprocs.html)\n\n\n","source":"_posts/2015-03-27-concurrency-in-go.md","raw":"---\ntitle: Concurrency in Go!\nslug: concurrency-in-go\ndate_published: 2015-03-27T14:40:52.413Z\ndate_updated:   2015-03-27T14:43:18.867Z\n---\n\n###What is concurrency?\n\nExecution of multiple processes independantly and they may or may not be getting executed at the same time.\nImagine a webserver gets multiple smaller requests and they all concurrently gets executed. It is basically multitasking on a single-core processor. \n\n\n###Oh, wait! then Concurrency is parallelism?\n\nParallelism is about running multiple processes at the same time, but concurrency is about dealing with a lot of processes may or may not be getting executed at the same time. Confusing?\n\n**Parallelism**\n\n  * Simultaneous Execution\n  * Running multiple threads on different processors   at the same time against each other.\n  * Requires multiple cores.\n  \n**Concurrency**\n\n*   Independent Execution\n*  Running multiple light-weight concurrent processes(goroutines!!, hold on! we'll see what goroutines are)\n*   Single core \n   \n  > Note: Using GOMAXPROCS, it is possible to run goroutines on different logical processors by configuring the runtime. \n\n\nSo, 'Concurrency is not parallelism' but,\n\n'concurreny can achieve parallelism'. \n\n\n\n#why Go?\n\nGo's concurrency primitives are way too good and it is easy to write concurrent programs.\nGo uses goroutines to achieve concurreny and importantly, it makes communication between goroutines a lot easier. \n\n###what are goroutines ?\nFundamentally, goroutine is a function which runs concurrently with other functions.\n\nSo, here is an example \n\n    package main\n    import (\n        \"fmt\"\n           )\n         \n    func print(s string){\n            for i := 0; i < 5; i++ {\n                 fmt.Println(s)\n         }\n     }\n\n\n     func main() {\n         print(\"Current thread\")    \n\n         go print(\"bye\")  \n\n         var input string\n         fmt.Scanln(&input) \n     }\n        \n        \n   Compile the above code to understand how the goroutines work. We'll look into more details in a bit.\n\n\n\n###what are channels?\nChannels are basically pipelines that are used to communicate between two goroutines. Channels can be used for synchronization of goroutines, etc.\n\n    package main\n    \n    import (\n        \"fmt\"\n        \"time\"\n        )\n        \n        func put(c chan string){\n         for {\n            c <- \"Tadaa!\"\n           }\n          }\n          \n        func print(c chan string){\n          for {\n            message := <- c\n            fmt.Println(message)\n            time.Sleep(time.second * 2)\n            }\n           }\n         func main() {\n           var c chan string = make(chan string)\n           \n           go put(c)\n           go print(c)\n           \n           var input string\n           fmt.Scanln(&input) \n          }\n        \n     \n  How awesome right? Thats how cool goroutines and channels are. It makes it a lot easier and more interesting to program.  \n   \n\n###why are goroutines super cool?\n\nConcurreny was possible in other languages too, but what made concurreny a cherrypie in go?\n\ngoroutines are light-weight, other languages like java, uses threads. \n\nCreating a goroutine hardly takes 2kb of stackspace(it was 8kb till go 1.3) where as a thread consumes 1MB per stack space. \n\n\nI recommend all of you reading this to watch [Go Concurrency Patterns](http://www.youtube.com/watch?v=f6kdp27TYZs) by Rob Pike\n\nFew Links:\n\n[Fundamentals of concurrent programming](https://www.nada.kth.se/~snilsson/concurrency/)\n\n[Concurreny goroutines and GOMAXPROCS](http://www.goinggo.net/2014/01/concurrency-goroutines-and-gomaxprocs.html)\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzairr000gdrgb1x66axs7","content":"<p>###What is concurrency?</p>\n<p>Execution of multiple processes independantly and they may or may not be getting executed at the same time.<br>Imagine a webserver gets multiple smaller requests and they all concurrently gets executed. It is basically multitasking on a single-core processor. </p>\n<p>###Oh, wait! then Concurrency is parallelism?</p>\n<p>Parallelism is about running multiple processes at the same time, but concurrency is about dealing with a lot of processes may or may not be getting executed at the same time. Confusing?</p>\n<p><strong>Parallelism</strong></p>\n<ul>\n<li>Simultaneous Execution</li>\n<li>Running multiple threads on different processors   at the same time against each other.</li>\n<li>Requires multiple cores.</li>\n</ul>\n<p><strong>Concurrency</strong></p>\n<ul>\n<li>Independent Execution</li>\n<li>Running multiple light-weight concurrent processes(goroutines!!, hold on! well see what goroutines are)</li>\n<li><p>Single core </p>\n<blockquote>\n<p>Note: Using GOMAXPROCS, it is possible to run goroutines on different logical processors by configuring the runtime. </p>\n</blockquote>\n</li>\n</ul>\n<p>So, Concurrency is not parallelism but,</p>\n<p>concurreny can achieve parallelism. </p>\n<p>#why Go?</p>\n<p>Gos concurrency primitives are way too good and it is easy to write concurrent programs.<br>Go uses goroutines to achieve concurreny and importantly, it makes communication between goroutines a lot easier. </p>\n<p>###what are goroutines ?<br>Fundamentally, goroutine is a function which runs concurrently with other functions.</p>\n<p>So, here is an example </p>\n<pre><code>package main\nimport (\n    &quot;fmt&quot;\n       )\n\nfunc print(s string){\n        for i := 0; i &lt; 5; i++ {\n             fmt.Println(s)\n     }\n }\n\n\n func main() {\n     print(&quot;Current thread&quot;)    \n\n     go print(&quot;bye&quot;)  \n\n     var input string\n     fmt.Scanln(&amp;input) \n }\n</code></pre><p>   Compile the above code to understand how the goroutines work. Well look into more details in a bit.</p>\n<p>###what are channels?<br>Channels are basically pipelines that are used to communicate between two goroutines. Channels can be used for synchronization of goroutines, etc.</p>\n<pre><code>package main\n\nimport (\n    &quot;fmt&quot;\n    &quot;time&quot;\n    )\n\n    func put(c chan string){\n     for {\n        c &lt;- &quot;Tadaa!&quot;\n       }\n      }\n\n    func print(c chan string){\n      for {\n        message := &lt;- c\n        fmt.Println(message)\n        time.Sleep(time.second * 2)\n        }\n       }\n     func main() {\n       var c chan string = make(chan string)\n\n       go put(c)\n       go print(c)\n\n       var input string\n       fmt.Scanln(&amp;input) \n      }\n</code></pre><p>  How awesome right? Thats how cool goroutines and channels are. It makes it a lot easier and more interesting to program.  </p>\n<p>###why are goroutines super cool?</p>\n<p>Concurreny was possible in other languages too, but what made concurreny a cherrypie in go?</p>\n<p>goroutines are light-weight, other languages like java, uses threads. </p>\n<p>Creating a goroutine hardly takes 2kb of stackspace(it was 8kb till go 1.3) where as a thread consumes 1MB per stack space. </p>\n<p>I recommend all of you reading this to watch <a href=\"http://www.youtube.com/watch?v=f6kdp27TYZs\" target=\"_blank\" rel=\"external\">Go Concurrency Patterns</a> by Rob Pike</p>\n<p>Few Links:</p>\n<p><a href=\"https://www.nada.kth.se/~snilsson/concurrency/\" target=\"_blank\" rel=\"external\">Fundamentals of concurrent programming</a></p>\n<p><a href=\"http://www.goinggo.net/2014/01/concurrency-goroutines-and-gomaxprocs.html\" target=\"_blank\" rel=\"external\">Concurreny goroutines and GOMAXPROCS</a></p>\n","excerpt":"","more":"<p>###What is concurrency?</p>\n<p>Execution of multiple processes independantly and they may or may not be getting executed at the same time.<br>Imagine a webserver gets multiple smaller requests and they all concurrently gets executed. It is basically multitasking on a single-core processor. </p>\n<p>###Oh, wait! then Concurrency is parallelism?</p>\n<p>Parallelism is about running multiple processes at the same time, but concurrency is about dealing with a lot of processes may or may not be getting executed at the same time. Confusing?</p>\n<p><strong>Parallelism</strong></p>\n<ul>\n<li>Simultaneous Execution</li>\n<li>Running multiple threads on different processors   at the same time against each other.</li>\n<li>Requires multiple cores.</li>\n</ul>\n<p><strong>Concurrency</strong></p>\n<ul>\n<li>Independent Execution</li>\n<li>Running multiple light-weight concurrent processes(goroutines!!, hold on! well see what goroutines are)</li>\n<li><p>Single core </p>\n<blockquote>\n<p>Note: Using GOMAXPROCS, it is possible to run goroutines on different logical processors by configuring the runtime. </p>\n</blockquote>\n</li>\n</ul>\n<p>So, Concurrency is not parallelism but,</p>\n<p>concurreny can achieve parallelism. </p>\n<p>#why Go?</p>\n<p>Gos concurrency primitives are way too good and it is easy to write concurrent programs.<br>Go uses goroutines to achieve concurreny and importantly, it makes communication between goroutines a lot easier. </p>\n<p>###what are goroutines ?<br>Fundamentally, goroutine is a function which runs concurrently with other functions.</p>\n<p>So, here is an example </p>\n<pre><code>package main\nimport (\n    &quot;fmt&quot;\n       )\n\nfunc print(s string){\n        for i := 0; i &lt; 5; i++ {\n             fmt.Println(s)\n     }\n }\n\n\n func main() {\n     print(&quot;Current thread&quot;)    \n\n     go print(&quot;bye&quot;)  \n\n     var input string\n     fmt.Scanln(&amp;input) \n }\n</code></pre><p>   Compile the above code to understand how the goroutines work. Well look into more details in a bit.</p>\n<p>###what are channels?<br>Channels are basically pipelines that are used to communicate between two goroutines. Channels can be used for synchronization of goroutines, etc.</p>\n<pre><code>package main\n\nimport (\n    &quot;fmt&quot;\n    &quot;time&quot;\n    )\n\n    func put(c chan string){\n     for {\n        c &lt;- &quot;Tadaa!&quot;\n       }\n      }\n\n    func print(c chan string){\n      for {\n        message := &lt;- c\n        fmt.Println(message)\n        time.Sleep(time.second * 2)\n        }\n       }\n     func main() {\n       var c chan string = make(chan string)\n\n       go put(c)\n       go print(c)\n\n       var input string\n       fmt.Scanln(&amp;input) \n      }\n</code></pre><p>  How awesome right? Thats how cool goroutines and channels are. It makes it a lot easier and more interesting to program.  </p>\n<p>###why are goroutines super cool?</p>\n<p>Concurreny was possible in other languages too, but what made concurreny a cherrypie in go?</p>\n<p>goroutines are light-weight, other languages like java, uses threads. </p>\n<p>Creating a goroutine hardly takes 2kb of stackspace(it was 8kb till go 1.3) where as a thread consumes 1MB per stack space. </p>\n<p>I recommend all of you reading this to watch <a href=\"http://www.youtube.com/watch?v=f6kdp27TYZs\">Go Concurrency Patterns</a> by Rob Pike</p>\n<p>Few Links:</p>\n<p><a href=\"https://www.nada.kth.se/~snilsson/concurrency/\">Fundamentals of concurrent programming</a></p>\n<p><a href=\"http://www.goinggo.net/2014/01/concurrency-goroutines-and-gomaxprocs.html\">Concurreny goroutines and GOMAXPROCS</a></p>\n"},{"title":"Playing with configuration in Go lang","slug":"2015-03-27-playing-with-configuration-in-gotsuru","date_published":"2015-03-27T07:26:07.873Z","date_updated":"2015-03-28T10:04:27.489Z","_content":"\n#Application configuration\n>A config file is a reasonable way to maintain different environments such as development and production. \n\nFor most applications configuration includes logging levels, port bindings, and database settings. These settings are typically stored in environment variables, for example:\n\n\t export MEGAM_HOME=\"/var/lib/megam\"\n \texport MEGAM_HOST=\"megam.io\"\n\t export MEGAM_PASSWORD=\"password\"\n     \n Once set I can read configuration values from the command line like this:\n \n \t$ echo $MEGAM_HOME\n \t/var/lib/megam\n    \nIts equally as easy to access environment variables in Go using the os package:\n\n\tpackage main\n\n\timport (\n    \t\"fmt\"\n    \t\"os\"    \t\n\t)\n\n\tfunc main() {\n    \thome := os.Getenv(\"MEGAM_HOME\")\n    \tfmt.Printf(\"Megam home is set to: %v\\n\", home)\n\t}\n    \nThe biggest drawback to storing configuration in the environment is that you can only store string values; its up to you to convert these strings into values that can be used by your application.\n\n>**It is highly recommended that we go for configuration files instead of storing our configuration settings using environment variables.**\n\nsample conf yaml file:\n\n\tMEGAM_HOME: /var/lib/megam\n    riak:\n \t url: localhost:8087\n \t bucket: accounts\n     \n>######How to use this conf file in our go application ? \n>tsuru/config is one of way to parse and use conf file in go application\n\n#tsuru/config Introduction\nConfig is a Go package to manage yaml configuration files.\n\nFor usage information, read tsuru package documentation: http://godoc.org/github.com/tsuru/config.\n\n##Usage\n\n\timport \"github.com/tsuru/config\"\n\nPackage config provide configuration facilities, handling configuration files in yaml format.\n\n###Get values\nTo get values from conf file use following code in your application\n\n\ts, err := config.GetString(\"conf_string\")\n    \nIt gets the string value from conf file.\n\nsome examples:\n\n>conf file:\n>\t\n\tMEGAM_HOME: /var/lib/megam\n    riak:\n \t url: localhost:8087\n \t bucket: accounts\n     \nFirst we get \"MEGAM_HOME\"\n\n\thome, err := config.GetString(\"MEGAM_HOME\")\n    if err != nil {\n    \tfmt.Printf(\"Megam home getting error: %v\\n\", err)\n    }\n    fmt.Printf(\"Megam home is set to: %v\\n\", home)\n    \nSecond we get riak url from file\n\n\turl, err := config.GetString(\"riak:url\")\n    if err != nil {\n    \tfmt.Printf(\"getting error: %v\\n\", err)\n    }\n    fmt.Printf(\"Riak url is set to: %v\\n\", url)\n    \nTo get subdivision of key then used **\":\"** in between the keys.\n\n> ###supported formats\n> \n* func GetBool(key string) (bool, error)\n* func GetDuration(key string) (time.Duration, error)\n* func GetFloat(key string) (float64, error)\n* func GetInt(key string) (int, error)\n* func GetList(key string) ([]string, error)\n* func GetString(key string) (string, error)\n* func GetUint(key string) (uint, error)\n\n###conclusion\nHopefully this article has hightlighted the steps in using configuration files in a go project\n    \n\n\n\n\n\n\n","source":"_posts/2015-03-27-playing-with-configuration-in-gotsuru.md","raw":"---\ntitle: Playing with configuration in Go lang\nslug: playing-with-configuration-in-gotsuru\ndate_published: 2015-03-27T12:56:07.873Z\ndate_updated:   2015-03-28T15:34:27.489Z\n---\n\n#Application configuration\n>A config file is a reasonable way to maintain different environments such as development and production. \n\nFor most applications configuration includes logging levels, port bindings, and database settings. These settings are typically stored in environment variables, for example:\n\n\t export MEGAM_HOME=\"/var/lib/megam\"\n \texport MEGAM_HOST=\"megam.io\"\n\t export MEGAM_PASSWORD=\"password\"\n     \n Once set I can read configuration values from the command line like this:\n \n \t$ echo $MEGAM_HOME\n \t/var/lib/megam\n    \nIts equally as easy to access environment variables in Go using the os package:\n\n\tpackage main\n\n\timport (\n    \t\"fmt\"\n    \t\"os\"    \t\n\t)\n\n\tfunc main() {\n    \thome := os.Getenv(\"MEGAM_HOME\")\n    \tfmt.Printf(\"Megam home is set to: %v\\n\", home)\n\t}\n    \nThe biggest drawback to storing configuration in the environment is that you can only store string values; its up to you to convert these strings into values that can be used by your application.\n\n>**It is highly recommended that we go for configuration files instead of storing our configuration settings using environment variables.**\n\nsample conf yaml file:\n\n\tMEGAM_HOME: /var/lib/megam\n    riak:\n \t url: localhost:8087\n \t bucket: accounts\n     \n>######How to use this conf file in our go application ? \n>tsuru/config is one of way to parse and use conf file in go application\n\n#tsuru/config Introduction\nConfig is a Go package to manage yaml configuration files.\n\nFor usage information, read tsuru package documentation: http://godoc.org/github.com/tsuru/config.\n\n##Usage\n\n\timport \"github.com/tsuru/config\"\n\nPackage config provide configuration facilities, handling configuration files in yaml format.\n\n###Get values\nTo get values from conf file use following code in your application\n\n\ts, err := config.GetString(\"conf_string\")\n    \nIt gets the string value from conf file.\n\nsome examples:\n\n>conf file:\n>\t\n\tMEGAM_HOME: /var/lib/megam\n    riak:\n \t url: localhost:8087\n \t bucket: accounts\n     \nFirst we get \"MEGAM_HOME\"\n\n\thome, err := config.GetString(\"MEGAM_HOME\")\n    if err != nil {\n    \tfmt.Printf(\"Megam home getting error: %v\\n\", err)\n    }\n    fmt.Printf(\"Megam home is set to: %v\\n\", home)\n    \nSecond we get riak url from file\n\n\turl, err := config.GetString(\"riak:url\")\n    if err != nil {\n    \tfmt.Printf(\"getting error: %v\\n\", err)\n    }\n    fmt.Printf(\"Riak url is set to: %v\\n\", url)\n    \nTo get subdivision of key then used **\":\"** in between the keys.\n\n> ###supported formats\n> \n* func GetBool(key string) (bool, error)\n* func GetDuration(key string) (time.Duration, error)\n* func GetFloat(key string) (float64, error)\n* func GetInt(key string) (int, error)\n* func GetList(key string) ([]string, error)\n* func GetString(key string) (string, error)\n* func GetUint(key string) (uint, error)\n\n###conclusion\nHopefully this article has hightlighted the steps in using configuration files in a go project\n    \n\n\n\n\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzairu000idrgb4tvp1eeu","content":"<p>#Application configuration</p>\n<blockquote>\n<p>A config file is a reasonable way to maintain different environments such as development and production. </p>\n</blockquote>\n<p>For most applications configuration includes logging levels, port bindings, and database settings. These settings are typically stored in environment variables, for example:</p>\n<pre><code>export MEGAM_HOME=&quot;/var/lib/megam&quot;\nexport MEGAM_HOST=&quot;megam.io&quot;\nexport MEGAM_PASSWORD=&quot;password&quot;\n</code></pre><p> Once set I can read configuration values from the command line like this:</p>\n<pre><code>$ echo $MEGAM_HOME\n/var/lib/megam\n</code></pre><p>Its equally as easy to access environment variables in Go using the os package:</p>\n<pre><code>package main\n\nimport (\n    &quot;fmt&quot;\n    &quot;os&quot;        \n)\n\nfunc main() {\n    home := os.Getenv(&quot;MEGAM_HOME&quot;)\n    fmt.Printf(&quot;Megam home is set to: %v\\n&quot;, home)\n}\n</code></pre><p>The biggest drawback to storing configuration in the environment is that you can only store string values; its up to you to convert these strings into values that can be used by your application.</p>\n<blockquote>\n<p><strong>It is highly recommended that we go for configuration files instead of storing our configuration settings using environment variables.</strong></p>\n</blockquote>\n<p>sample conf yaml file:</p>\n<pre><code>MEGAM_HOME: /var/lib/megam\nriak:\n  url: localhost:8087\n  bucket: accounts\n</code></pre><blockquote>\n<p>######How to use this conf file in our go application ?<br>tsuru/config is one of way to parse and use conf file in go application</p>\n</blockquote>\n<p>#tsuru/config Introduction<br>Config is a Go package to manage yaml configuration files.</p>\n<p>For usage information, read tsuru package documentation: <a href=\"http://godoc.org/github.com/tsuru/config\" target=\"_blank\" rel=\"external\">http://godoc.org/github.com/tsuru/config</a>.</p>\n<p>##Usage</p>\n<pre><code>import &quot;github.com/tsuru/config&quot;\n</code></pre><p>Package config provide configuration facilities, handling configuration files in yaml format.</p>\n<p>###Get values<br>To get values from conf file use following code in your application</p>\n<pre><code>s, err := config.GetString(&quot;conf_string&quot;)\n</code></pre><p>It gets the string value from conf file.</p>\n<p>some examples:</p>\n<blockquote>\n<p>conf file:</p>\n<pre><code>MEGAM_HOME: /var/lib/megam\nriak:\n  url: localhost:8087\n  bucket: accounts\n</code></pre></blockquote>\n<p>First we get MEGAM_HOME</p>\n<pre><code>home, err := config.GetString(&quot;MEGAM_HOME&quot;)\nif err != nil {\n    fmt.Printf(&quot;Megam home getting error: %v\\n&quot;, err)\n}\nfmt.Printf(&quot;Megam home is set to: %v\\n&quot;, home)\n</code></pre><p>Second we get riak url from file</p>\n<pre><code>url, err := config.GetString(&quot;riak:url&quot;)\nif err != nil {\n    fmt.Printf(&quot;getting error: %v\\n&quot;, err)\n}\nfmt.Printf(&quot;Riak url is set to: %v\\n&quot;, url)\n</code></pre><p>To get subdivision of key then used <strong>:</strong> in between the keys.</p>\n<blockquote>\n<p>###supported formats</p>\n<ul>\n<li>func GetBool(key string) (bool, error)</li>\n<li>func GetDuration(key string) (time.Duration, error)</li>\n<li>func GetFloat(key string) (float64, error)</li>\n<li>func GetInt(key string) (int, error)</li>\n<li>func GetList(key string) ([]string, error)</li>\n<li>func GetString(key string) (string, error)</li>\n<li>func GetUint(key string) (uint, error)</li>\n</ul>\n</blockquote>\n<p>###conclusion<br>Hopefully this article has hightlighted the steps in using configuration files in a go project</p>\n","excerpt":"","more":"<p>#Application configuration</p>\n<blockquote>\n<p>A config file is a reasonable way to maintain different environments such as development and production. </p>\n</blockquote>\n<p>For most applications configuration includes logging levels, port bindings, and database settings. These settings are typically stored in environment variables, for example:</p>\n<pre><code>export MEGAM_HOME=&quot;/var/lib/megam&quot;\nexport MEGAM_HOST=&quot;megam.io&quot;\nexport MEGAM_PASSWORD=&quot;password&quot;\n</code></pre><p> Once set I can read configuration values from the command line like this:</p>\n<pre><code>$ echo $MEGAM_HOME\n/var/lib/megam\n</code></pre><p>Its equally as easy to access environment variables in Go using the os package:</p>\n<pre><code>package main\n\nimport (\n    &quot;fmt&quot;\n    &quot;os&quot;        \n)\n\nfunc main() {\n    home := os.Getenv(&quot;MEGAM_HOME&quot;)\n    fmt.Printf(&quot;Megam home is set to: %v\\n&quot;, home)\n}\n</code></pre><p>The biggest drawback to storing configuration in the environment is that you can only store string values; its up to you to convert these strings into values that can be used by your application.</p>\n<blockquote>\n<p><strong>It is highly recommended that we go for configuration files instead of storing our configuration settings using environment variables.</strong></p>\n</blockquote>\n<p>sample conf yaml file:</p>\n<pre><code>MEGAM_HOME: /var/lib/megam\nriak:\n  url: localhost:8087\n  bucket: accounts\n</code></pre><blockquote>\n<p>######How to use this conf file in our go application ?<br>tsuru/config is one of way to parse and use conf file in go application</p>\n</blockquote>\n<p>#tsuru/config Introduction<br>Config is a Go package to manage yaml configuration files.</p>\n<p>For usage information, read tsuru package documentation: <a href=\"http://godoc.org/github.com/tsuru/config\">http://godoc.org/github.com/tsuru/config</a>.</p>\n<p>##Usage</p>\n<pre><code>import &quot;github.com/tsuru/config&quot;\n</code></pre><p>Package config provide configuration facilities, handling configuration files in yaml format.</p>\n<p>###Get values<br>To get values from conf file use following code in your application</p>\n<pre><code>s, err := config.GetString(&quot;conf_string&quot;)\n</code></pre><p>It gets the string value from conf file.</p>\n<p>some examples:</p>\n<blockquote>\n<p>conf file:</p>\n<pre><code>MEGAM_HOME: /var/lib/megam\nriak:\n  url: localhost:8087\n  bucket: accounts\n</code></pre></blockquote>\n<p>First we get MEGAM_HOME</p>\n<pre><code>home, err := config.GetString(&quot;MEGAM_HOME&quot;)\nif err != nil {\n    fmt.Printf(&quot;Megam home getting error: %v\\n&quot;, err)\n}\nfmt.Printf(&quot;Megam home is set to: %v\\n&quot;, home)\n</code></pre><p>Second we get riak url from file</p>\n<pre><code>url, err := config.GetString(&quot;riak:url&quot;)\nif err != nil {\n    fmt.Printf(&quot;getting error: %v\\n&quot;, err)\n}\nfmt.Printf(&quot;Riak url is set to: %v\\n&quot;, url)\n</code></pre><p>To get subdivision of key then used <strong>:</strong> in between the keys.</p>\n<blockquote>\n<p>###supported formats</p>\n<ul>\n<li>func GetBool(key string) (bool, error)</li>\n<li>func GetDuration(key string) (time.Duration, error)</li>\n<li>func GetFloat(key string) (float64, error)</li>\n<li>func GetInt(key string) (int, error)</li>\n<li>func GetList(key string) ([]string, error)</li>\n<li>func GetString(key string) (string, error)</li>\n<li>func GetUint(key string) (uint, error)</li>\n</ul>\n</blockquote>\n<p>###conclusion<br>Hopefully this article has hightlighted the steps in using configuration files in a go project</p>\n"},{"title":"Dockers!  are you ready?","slug":"2015-05-25-docker-introduction","date_published":"2015-05-25T03:27:49.424Z","date_updated":"2015-05-25T04:21:48.577Z","_content":"\n\n### Docker Docker Docker! what the heck..?\n\nLet us consider a scenario where you are planning to deploy an application or service. Now, to deploy an application, the most sensible thing to do is to fire up an instance(VM) and deploy it.\n\nHere, an hypervisor sitting on top of the host os launches a virtual operating system by sharing the hardware resources. \n\n<b>So, option 1:</b>\n\n<b>(V)App/services -> (V)bins, libs -> (V)Guest OS -> HYPERVISOR(KVM, Xen) -> Host OS -> Server\n\n\n<b>Option 2:</b>\n\n(V)App/services -> bins, libs -> Docker engine -> Host OS -> Server</b>\n\n(V) - Virtualized component\n\nContainers, instead of virtualizing hardwares, they sit on one single linux operating system instance, hence for a usecase where VMs are too much of an over head, containers are the right solution.\n\n*Megam's strategy is to deploy with both VMs and dockers to max out resources usage efficiency. We support baremetal docker deployments too.*\n\nIn short, imagine containers as small capsules that contains your application in a well bundled manner, with defined resource usages, that can be read by the docker engine on any linux operating systems. Not to forget, it is highly portable - *Containers gives you instant application portability*\n\nNow you can run multiple applications independantly on a single operating system which runs on your server instead of creating multiple OSes for each application/services. \n\n**The key difference between containers and VMs is that while the hypervisor abstracts an entire device, containers just abstract the operating system kernel. smart right?** \n\n\n#####So docker figured out the whole containerization technology? \n\nNope! containers are in existence for almost  15 years now, Google's open source container technology [lmctfy](https://github.com/google/lmctfy) (let me contain that for you) effecively uses containers for most their infrastructure needs, you search, use gmail, read news, you spin up a container. LXCs, solaris's Zones are all container technology that are there more than a decade ba\n\nDocker, on the other hand made containers easier and safer to depoy. Developers can use docker to pack, ship and run any application as a lightweight, portable  LXC container that can run virtually anywhere. \n\n####Trying docker out (Ubuntu Trusty 14.04)\n\nDocker community is huge and it supports almost all platforms, so nothing to worry. \n\n**First things first,**\n\n     $sudo apt-get update\n\n**now, let us install docker**\n\n     $wget -qO- https://get.docker.com/ | sh\n\n\n####Containerize your application:\n\nOnce you have installed docker we are good to go. First, we will use basic docker commands, \n\n**docker ps - shows running containers <br>\ndocker build - builds a container\ndocker pull/push - pulls/pushes an image from docker hub\ndocker run - runs it** \n\n\n\n**Image? docker hub? what?** \n\nIt is simple, you can build your containers and push it on docker hub and later can just use `docker run` anywhere to deploy it. easy right? \nAn image is your packaged container that is pushed on docker hub. `docker run` automatically pulls if the image is not found locally. Shown below.\n\n\n**Let us run postgres container**\n\n    $sudo docker run postgres\n\nit first searches for local docker images and then pulls it from docker hub and runs it automatically. \n\nNow, see if the container is running..\n\n    $sudo docker ps\n\nthis should list the containers currently running and in our case, it should list postgres. \n\n\nIt is a breeze to simply build, and run docker containers on any linux environment. Thats it for now, I will write about docker clustering using kubernetes, using docker api and geard and also about the deeper understanding of docker containers and how it works internally. \n\nStay tuned!\n\n\n","source":"_posts/2015-05-25-docker-introduction.md","raw":"---\ntitle: 'Dockers!  are you ready?'\nslug: docker-introduction\ndate_published: 2015-05-25T08:57:49.424Z\ndate_updated:   2015-05-25T09:51:48.577Z\ntags: docker, containers, containerization, LXCs, linux\n---\n\n\n### Docker Docker Docker! what the heck..?\n\nLet us consider a scenario where you are planning to deploy an application or service. Now, to deploy an application, the most sensible thing to do is to fire up an instance(VM) and deploy it.\n\nHere, an hypervisor sitting on top of the host os launches a virtual operating system by sharing the hardware resources. \n\n<b>So, option 1:</b>\n\n<b>(V)App/services -> (V)bins, libs -> (V)Guest OS -> HYPERVISOR(KVM, Xen) -> Host OS -> Server\n\n\n<b>Option 2:</b>\n\n(V)App/services -> bins, libs -> Docker engine -> Host OS -> Server</b>\n\n(V) - Virtualized component\n\nContainers, instead of virtualizing hardwares, they sit on one single linux operating system instance, hence for a usecase where VMs are too much of an over head, containers are the right solution.\n\n*Megam's strategy is to deploy with both VMs and dockers to max out resources usage efficiency. We support baremetal docker deployments too.*\n\nIn short, imagine containers as small capsules that contains your application in a well bundled manner, with defined resource usages, that can be read by the docker engine on any linux operating systems. Not to forget, it is highly portable - *Containers gives you instant application portability*\n\nNow you can run multiple applications independantly on a single operating system which runs on your server instead of creating multiple OSes for each application/services. \n\n**The key difference between containers and VMs is that while the hypervisor abstracts an entire device, containers just abstract the operating system kernel. smart right?** \n\n\n#####So docker figured out the whole containerization technology? \n\nNope! containers are in existence for almost  15 years now, Google's open source container technology [lmctfy](https://github.com/google/lmctfy) (let me contain that for you) effecively uses containers for most their infrastructure needs, you search, use gmail, read news, you spin up a container. LXCs, solaris's Zones are all container technology that are there more than a decade ba\n\nDocker, on the other hand made containers easier and safer to depoy. Developers can use docker to pack, ship and run any application as a lightweight, portable  LXC container that can run virtually anywhere. \n\n####Trying docker out (Ubuntu Trusty 14.04)\n\nDocker community is huge and it supports almost all platforms, so nothing to worry. \n\n**First things first,**\n\n     $sudo apt-get update\n\n**now, let us install docker**\n\n     $wget -qO- https://get.docker.com/ | sh\n\n\n####Containerize your application:\n\nOnce you have installed docker we are good to go. First, we will use basic docker commands, \n\n**docker ps - shows running containers <br>\ndocker build - builds a container\ndocker pull/push - pulls/pushes an image from docker hub\ndocker run - runs it** \n\n\n\n**Image? docker hub? what?** \n\nIt is simple, you can build your containers and push it on docker hub and later can just use `docker run` anywhere to deploy it. easy right? \nAn image is your packaged container that is pushed on docker hub. `docker run` automatically pulls if the image is not found locally. Shown below.\n\n\n**Let us run postgres container**\n\n    $sudo docker run postgres\n\nit first searches for local docker images and then pulls it from docker hub and runs it automatically. \n\nNow, see if the container is running..\n\n    $sudo docker ps\n\nthis should list the containers currently running and in our case, it should list postgres. \n\n\nIt is a breeze to simply build, and run docker containers on any linux environment. Thats it for now, I will write about docker clustering using kubernetes, using docker api and geard and also about the deeper understanding of docker containers and how it works internally. \n\nStay tuned!\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzairw000jdrgbpwu4cm59","content":"<h3 id=\"Docker-Docker-Docker-what-the-heck\"><a href=\"#Docker-Docker-Docker-what-the-heck\" class=\"headerlink\" title=\"Docker Docker Docker! what the heck..?\"></a>Docker Docker Docker! what the heck..?</h3><p>Let us consider a scenario where you are planning to deploy an application or service. Now, to deploy an application, the most sensible thing to do is to fire up an instance(VM) and deploy it.</p>\n<p>Here, an hypervisor sitting on top of the host os launches a virtual operating system by sharing the hardware resources. </p>\n<p><b>So, option 1:</b></p>\n<p><b>(V)App/services -&gt; (V)bins, libs -&gt; (V)Guest OS -&gt; HYPERVISOR(KVM, Xen) -&gt; Host OS -&gt; Server</b></p>\n<p><b>Option 2:</b></p>\n<p>(V)App/services -&gt; bins, libs -&gt; Docker engine -&gt; Host OS -&gt; Server</p>\n<p>(V) - Virtualized component</p>\n<p>Containers, instead of virtualizing hardwares, they sit on one single linux operating system instance, hence for a usecase where VMs are too much of an over head, containers are the right solution.</p>\n<p><em>Megams strategy is to deploy with both VMs and dockers to max out resources usage efficiency. We support baremetal docker deployments too.</em></p>\n<p>In short, imagine containers as small capsules that contains your application in a well bundled manner, with defined resource usages, that can be read by the docker engine on any linux operating systems. Not to forget, it is highly portable - <em>Containers gives you instant application portability</em></p>\n<p>Now you can run multiple applications independantly on a single operating system which runs on your server instead of creating multiple OSes for each application/services. </p>\n<p><strong>The key difference between containers and VMs is that while the hypervisor abstracts an entire device, containers just abstract the operating system kernel. smart right?</strong> </p>\n<p>#####So docker figured out the whole containerization technology? </p>\n<p>Nope! containers are in existence for almost  15 years now, Googles open source container technology <a href=\"https://github.com/google/lmctfy\" target=\"_blank\" rel=\"external\">lmctfy</a> (let me contain that for you) effecively uses containers for most their infrastructure needs, you search, use gmail, read news, you spin up a container. LXCs, solariss Zones are all container technology that are there more than a decade ba</p>\n<p>Docker, on the other hand made containers easier and safer to depoy. Developers can use docker to pack, ship and run any application as a lightweight, portable  LXC container that can run virtually anywhere. </p>\n<p>####Trying docker out (Ubuntu Trusty 14.04)</p>\n<p>Docker community is huge and it supports almost all platforms, so nothing to worry. </p>\n<p><strong>First things first,</strong></p>\n<pre><code>$sudo apt-get update\n</code></pre><p><strong>now, let us install docker</strong></p>\n<pre><code>$wget -qO- https://get.docker.com/ | sh\n</code></pre><p>####Containerize your application:</p>\n<p>Once you have installed docker we are good to go. First, we will use basic docker commands, </p>\n<p><strong>docker ps - shows running containers <br><br>docker build - builds a container<br>docker pull/push - pulls/pushes an image from docker hub<br>docker run - runs it</strong> </p>\n<p><strong>Image? docker hub? what?</strong> </p>\n<p>It is simple, you can build your containers and push it on docker hub and later can just use <code>docker run</code> anywhere to deploy it. easy right?<br>An image is your packaged container that is pushed on docker hub. <code>docker run</code> automatically pulls if the image is not found locally. Shown below.</p>\n<p><strong>Let us run postgres container</strong></p>\n<pre><code>$sudo docker run postgres\n</code></pre><p>it first searches for local docker images and then pulls it from docker hub and runs it automatically. </p>\n<p>Now, see if the container is running..</p>\n<pre><code>$sudo docker ps\n</code></pre><p>this should list the containers currently running and in our case, it should list postgres. </p>\n<p>It is a breeze to simply build, and run docker containers on any linux environment. Thats it for now, I will write about docker clustering using kubernetes, using docker api and geard and also about the deeper understanding of docker containers and how it works internally. </p>\n<p>Stay tuned!</p>\n","excerpt":"","more":"<h3 id=\"Docker-Docker-Docker-what-the-heck\"><a href=\"#Docker-Docker-Docker-what-the-heck\" class=\"headerlink\" title=\"Docker Docker Docker! what the heck..?\"></a>Docker Docker Docker! what the heck..?</h3><p>Let us consider a scenario where you are planning to deploy an application or service. Now, to deploy an application, the most sensible thing to do is to fire up an instance(VM) and deploy it.</p>\n<p>Here, an hypervisor sitting on top of the host os launches a virtual operating system by sharing the hardware resources. </p>\n<p><b>So, option 1:</b></p>\n<p><b>(V)App/services -&gt; (V)bins, libs -&gt; (V)Guest OS -&gt; HYPERVISOR(KVM, Xen) -&gt; Host OS -&gt; Server</p>\n<p><b>Option 2:</b></p>\n<p>(V)App/services -&gt; bins, libs -&gt; Docker engine -&gt; Host OS -&gt; Server</b></p>\n<p>(V) - Virtualized component</p>\n<p>Containers, instead of virtualizing hardwares, they sit on one single linux operating system instance, hence for a usecase where VMs are too much of an over head, containers are the right solution.</p>\n<p><em>Megams strategy is to deploy with both VMs and dockers to max out resources usage efficiency. We support baremetal docker deployments too.</em></p>\n<p>In short, imagine containers as small capsules that contains your application in a well bundled manner, with defined resource usages, that can be read by the docker engine on any linux operating systems. Not to forget, it is highly portable - <em>Containers gives you instant application portability</em></p>\n<p>Now you can run multiple applications independantly on a single operating system which runs on your server instead of creating multiple OSes for each application/services. </p>\n<p><strong>The key difference between containers and VMs is that while the hypervisor abstracts an entire device, containers just abstract the operating system kernel. smart right?</strong> </p>\n<p>#####So docker figured out the whole containerization technology? </p>\n<p>Nope! containers are in existence for almost  15 years now, Googles open source container technology <a href=\"https://github.com/google/lmctfy\">lmctfy</a> (let me contain that for you) effecively uses containers for most their infrastructure needs, you search, use gmail, read news, you spin up a container. LXCs, solariss Zones are all container technology that are there more than a decade ba</p>\n<p>Docker, on the other hand made containers easier and safer to depoy. Developers can use docker to pack, ship and run any application as a lightweight, portable  LXC container that can run virtually anywhere. </p>\n<p>####Trying docker out (Ubuntu Trusty 14.04)</p>\n<p>Docker community is huge and it supports almost all platforms, so nothing to worry. </p>\n<p><strong>First things first,</strong></p>\n<pre><code>$sudo apt-get update\n</code></pre><p><strong>now, let us install docker</strong></p>\n<pre><code>$wget -qO- https://get.docker.com/ | sh\n</code></pre><p>####Containerize your application:</p>\n<p>Once you have installed docker we are good to go. First, we will use basic docker commands, </p>\n<p><strong>docker ps - shows running containers <br><br>docker build - builds a container<br>docker pull/push - pulls/pushes an image from docker hub<br>docker run - runs it</strong> </p>\n<p><strong>Image? docker hub? what?</strong> </p>\n<p>It is simple, you can build your containers and push it on docker hub and later can just use <code>docker run</code> anywhere to deploy it. easy right?<br>An image is your packaged container that is pushed on docker hub. <code>docker run</code> automatically pulls if the image is not found locally. Shown below.</p>\n<p><strong>Let us run postgres container</strong></p>\n<pre><code>$sudo docker run postgres\n</code></pre><p>it first searches for local docker images and then pulls it from docker hub and runs it automatically. </p>\n<p>Now, see if the container is running..</p>\n<pre><code>$sudo docker ps\n</code></pre><p>this should list the containers currently running and in our case, it should list postgres. </p>\n<p>It is a breeze to simply build, and run docker containers on any linux environment. Thats it for now, I will write about docker clustering using kubernetes, using docker api and geard and also about the deeper understanding of docker containers and how it works internally. </p>\n<p>Stay tuned!</p>\n"},{"title":"Getting started with Rust","slug":"2015-05-25-rust","date_published":"2015-05-25T08:19:36.074Z","date_updated":"2015-05-25T08:19:36.070Z","_content":"\nIn this we will get started with the cool language from mozilla - Rust.\n\nWe will use functional programming as far as we can. Rust supports it in an elegant way. \n\n###Rust\n\n[rust](http://www.rust-lang.org/) is a systems programming language that is compiled and hence there is not garbage collection unlike Go. Hence its a super cool/fast language. It has an awesome `rubygems` like community in `crates.io`. \n\nThe symantics are little bit different but you'll get used to it. \n\n###Why are we looking at rust ? \n\nWe started out to identitfy memory optimized language for our IoT startegy. So we decided to put it action in our commandline rewrite [meg](https://github.com/megamsys/meg.git)\n\n### Installing rust\n\n* Ubuntu \n\n    sudo add-apt-repository ppa:hansjorg/rust\n\n \tsudo apt-get install rust-stable cargo-nightly\n\n* Arch linux\n    \n    yaourt rust cargo-bin\n\n### Your first rust lang library\n\nA rust lang library is something that can be included as a [crate](https://crates.io) in a program we build.\n\nIn this case we will pull our cli library called `rust-turbo` \n\n*rust-turbo*. \n\nLet us clone this library locally to ~/megam. \n\n    git clone https://github.com/megamsys/rust-turbo\n\n\tcargo clean\n\t\n    cargo build\n    \n    [ram@ramwork:rust-turbo|master]$ cargo build\n   \tCompiling gcc v0.3.5\n   \tCompiling hamcrest v0.1.0 \t\t(https://github.com/carllerche/hamcrest-rust.git#b61fef3e)\n\tCompiling libc v0.1.8\n    Compiling glob v0.2.10\n    Compiling strsim v0.3.0\n    Compiling rustc-serialize v0.3.14\n    Compiling regex v0.1.30\n    Compiling term v0.2.7\n    Compiling log v0.3.1\n    Compiling time v0.1.25\n    Compiling env_logger v0.3.1\n    Compiling docopt v0.6.64\n    Compiling rust-turbo v0.2.0   (file:///home/ram/code/megam/rust/rust-turbo)\n\nCool we just built our first library. \n\nEvery project that uses `cargo` as the build tool will include a file called `Cargo.toml`\n\n* library ? Huh ! \n\nThe question is how do you decide if you are building a binary (executable) or a library to be includeded as a crate.\n\nMake a change in the `cargo.toml` file include the following.\n\n    [lib]\n    name = \"turbo\"\n    path = \"src/turbo/lib.rs\"\n\n\n###testing\n\n    \n    cargo tests\n\nThere are bunch of tests under src/tests that are under the src directory they get run automatically. \n\nUse a matcher like `hamcrest` to compare the output and expected out to decide on the failure or success of your tests. \n\n\n###namespaces\n\nIn our case `cargo` will look forward towards a file called `turbo/lib.rs`. The details of `lib.rs` are\n\n    #![deny(unused)]\n    #![cfg_attr(test, deny(warnings))]\n\n    #[macro_use] extern crate log;\n\n    #[cfg(test)] extern crate hamcrest;\n    extern crate docopt;\n    extern crate glob;\n    extern crate rustc_serialize;\n    extern crate term;\n    extern crate time;\n    extern crate libc;\n    \n    pub mod util;\n    pub mod core;\n    pub mod turbo;\n\nLet us examine the above. \n\n* `extern crate` indicates our intention to use an external library eg: logging, docopt (options command line parsing) etc.\n\n* `pub mod util` indicates that we intend to include a module named util.rs or util/mod.rs. \n\nIf you see our source code we have 3 folders `util`, `core`, and `turbo.rs` \n\n##You first rust executable\n\n\nIn this case we will pull our cli exec we are building called `meg` \n\n*meg*. \n\n Let us clone this library locally to ~/megam. \n\n    git clone https://github.com/megamsys/meg\n\n\tcargo clean\n\t\n    cargo build\n\n The built binary will be under targets. so run it to your hearts content. eg:\n \n \t meg version\n     \nWe have covered setting up rust, and get going with a rust library and an executable. Stay tuned on other design specifics using rusty lang.. Adios.     \n","source":"_posts/2015-05-25-rust.md","raw":"---\ntitle: Getting started with Rust\nslug: rust\ndate_published: 2015-05-25T13:49:36.074Z\ndate_updated:   2015-05-25T13:49:36.070Z\n---\n\nIn this we will get started with the cool language from mozilla - Rust.\n\nWe will use functional programming as far as we can. Rust supports it in an elegant way. \n\n###Rust\n\n[rust](http://www.rust-lang.org/) is a systems programming language that is compiled and hence there is not garbage collection unlike Go. Hence its a super cool/fast language. It has an awesome `rubygems` like community in `crates.io`. \n\nThe symantics are little bit different but you'll get used to it. \n\n###Why are we looking at rust ? \n\nWe started out to identitfy memory optimized language for our IoT startegy. So we decided to put it action in our commandline rewrite [meg](https://github.com/megamsys/meg.git)\n\n### Installing rust\n\n* Ubuntu \n\n    sudo add-apt-repository ppa:hansjorg/rust\n\n \tsudo apt-get install rust-stable cargo-nightly\n\n* Arch linux\n    \n    yaourt rust cargo-bin\n\n### Your first rust lang library\n\nA rust lang library is something that can be included as a [crate](https://crates.io) in a program we build.\n\nIn this case we will pull our cli library called `rust-turbo` \n\n*rust-turbo*. \n\nLet us clone this library locally to ~/megam. \n\n    git clone https://github.com/megamsys/rust-turbo\n\n\tcargo clean\n\t\n    cargo build\n    \n    [ram@ramwork:rust-turbo|master]$ cargo build\n   \tCompiling gcc v0.3.5\n   \tCompiling hamcrest v0.1.0 \t\t(https://github.com/carllerche/hamcrest-rust.git#b61fef3e)\n\tCompiling libc v0.1.8\n    Compiling glob v0.2.10\n    Compiling strsim v0.3.0\n    Compiling rustc-serialize v0.3.14\n    Compiling regex v0.1.30\n    Compiling term v0.2.7\n    Compiling log v0.3.1\n    Compiling time v0.1.25\n    Compiling env_logger v0.3.1\n    Compiling docopt v0.6.64\n    Compiling rust-turbo v0.2.0   (file:///home/ram/code/megam/rust/rust-turbo)\n\nCool we just built our first library. \n\nEvery project that uses `cargo` as the build tool will include a file called `Cargo.toml`\n\n* library ? Huh ! \n\nThe question is how do you decide if you are building a binary (executable) or a library to be includeded as a crate.\n\nMake a change in the `cargo.toml` file include the following.\n\n    [lib]\n    name = \"turbo\"\n    path = \"src/turbo/lib.rs\"\n\n\n###testing\n\n    \n    cargo tests\n\nThere are bunch of tests under src/tests that are under the src directory they get run automatically. \n\nUse a matcher like `hamcrest` to compare the output and expected out to decide on the failure or success of your tests. \n\n\n###namespaces\n\nIn our case `cargo` will look forward towards a file called `turbo/lib.rs`. The details of `lib.rs` are\n\n    #![deny(unused)]\n    #![cfg_attr(test, deny(warnings))]\n\n    #[macro_use] extern crate log;\n\n    #[cfg(test)] extern crate hamcrest;\n    extern crate docopt;\n    extern crate glob;\n    extern crate rustc_serialize;\n    extern crate term;\n    extern crate time;\n    extern crate libc;\n    \n    pub mod util;\n    pub mod core;\n    pub mod turbo;\n\nLet us examine the above. \n\n* `extern crate` indicates our intention to use an external library eg: logging, docopt (options command line parsing) etc.\n\n* `pub mod util` indicates that we intend to include a module named util.rs or util/mod.rs. \n\nIf you see our source code we have 3 folders `util`, `core`, and `turbo.rs` \n\n##You first rust executable\n\n\nIn this case we will pull our cli exec we are building called `meg` \n\n*meg*. \n\n Let us clone this library locally to ~/megam. \n\n    git clone https://github.com/megamsys/meg\n\n\tcargo clean\n\t\n    cargo build\n\n The built binary will be under targets. so run it to your hearts content. eg:\n \n \t meg version\n     \nWe have covered setting up rust, and get going with a rust library and an executable. Stay tuned on other design specifics using rusty lang.. Adios.     \n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzairx000kdrgb766c7ibb","content":"<p>In this we will get started with the cool language from mozilla - Rust.</p>\n<p>We will use functional programming as far as we can. Rust supports it in an elegant way. </p>\n<p>###Rust</p>\n<p><a href=\"http://www.rust-lang.org/\" target=\"_blank\" rel=\"external\">rust</a> is a systems programming language that is compiled and hence there is not garbage collection unlike Go. Hence its a super cool/fast language. It has an awesome <code>rubygems</code> like community in <code>crates.io</code>. </p>\n<p>The symantics are little bit different but youll get used to it. </p>\n<p>###Why are we looking at rust ? </p>\n<p>We started out to identitfy memory optimized language for our IoT startegy. So we decided to put it action in our commandline rewrite <a href=\"https://github.com/megamsys/meg.git\" target=\"_blank\" rel=\"external\">meg</a></p>\n<h3 id=\"Installing-rust\"><a href=\"#Installing-rust\" class=\"headerlink\" title=\"Installing rust\"></a>Installing rust</h3><ul>\n<li><p>Ubuntu </p>\n<p>  sudo add-apt-repository ppa:hansjorg/rust</p>\n<p>   sudo apt-get install rust-stable cargo-nightly</p>\n</li>\n<li><p>Arch linux</p>\n<p>  yaourt rust cargo-bin</p>\n</li>\n</ul>\n<h3 id=\"Your-first-rust-lang-library\"><a href=\"#Your-first-rust-lang-library\" class=\"headerlink\" title=\"Your first rust lang library\"></a>Your first rust lang library</h3><p>A rust lang library is something that can be included as a <a href=\"https://crates.io\" target=\"_blank\" rel=\"external\">crate</a> in a program we build.</p>\n<p>In this case we will pull our cli library called <code>rust-turbo</code> </p>\n<p><em>rust-turbo</em>. </p>\n<p>Let us clone this library locally to ~/megam. </p>\n<pre><code>git clone https://github.com/megamsys/rust-turbo\n\ncargo clean\n\ncargo build\n\n[ram@ramwork:rust-turbo|master]$ cargo build\n   Compiling gcc v0.3.5\n   Compiling hamcrest v0.1.0         (https://github.com/carllerche/hamcrest-rust.git#b61fef3e)\nCompiling libc v0.1.8\nCompiling glob v0.2.10\nCompiling strsim v0.3.0\nCompiling rustc-serialize v0.3.14\nCompiling regex v0.1.30\nCompiling term v0.2.7\nCompiling log v0.3.1\nCompiling time v0.1.25\nCompiling env_logger v0.3.1\nCompiling docopt v0.6.64\nCompiling rust-turbo v0.2.0   (file:///home/ram/code/megam/rust/rust-turbo)\n</code></pre><p>Cool we just built our first library. </p>\n<p>Every project that uses <code>cargo</code> as the build tool will include a file called <code>Cargo.toml</code></p>\n<ul>\n<li>library ? Huh ! </li>\n</ul>\n<p>The question is how do you decide if you are building a binary (executable) or a library to be includeded as a crate.</p>\n<p>Make a change in the <code>cargo.toml</code> file include the following.</p>\n<pre><code>[lib]\nname = &quot;turbo&quot;\npath = &quot;src/turbo/lib.rs&quot;\n</code></pre><p>###testing</p>\n<pre><code>cargo tests\n</code></pre><p>There are bunch of tests under src/tests that are under the src directory they get run automatically. </p>\n<p>Use a matcher like <code>hamcrest</code> to compare the output and expected out to decide on the failure or success of your tests. </p>\n<p>###namespaces</p>\n<p>In our case <code>cargo</code> will look forward towards a file called <code>turbo/lib.rs</code>. The details of <code>lib.rs</code> are</p>\n<pre><code>#![deny(unused)]\n#![cfg_attr(test, deny(warnings))]\n\n#[macro_use] extern crate log;\n\n#[cfg(test)] extern crate hamcrest;\nextern crate docopt;\nextern crate glob;\nextern crate rustc_serialize;\nextern crate term;\nextern crate time;\nextern crate libc;\n\npub mod util;\npub mod core;\npub mod turbo;\n</code></pre><p>Let us examine the above. </p>\n<ul>\n<li><p><code>extern crate</code> indicates our intention to use an external library eg: logging, docopt (options command line parsing) etc.</p>\n</li>\n<li><p><code>pub mod util</code> indicates that we intend to include a module named util.rs or util/mod.rs. </p>\n</li>\n</ul>\n<p>If you see our source code we have 3 folders <code>util</code>, <code>core</code>, and <code>turbo.rs</code> </p>\n<p>##You first rust executable</p>\n<p>In this case we will pull our cli exec we are building called <code>meg</code> </p>\n<p><em>meg</em>. </p>\n<p> Let us clone this library locally to ~/megam. </p>\n<pre><code>git clone https://github.com/megamsys/meg\n\ncargo clean\n\ncargo build\n</code></pre><p> The built binary will be under targets. so run it to your hearts content. eg:</p>\n<pre><code>meg version\n</code></pre><p>We have covered setting up rust, and get going with a rust library and an executable. Stay tuned on other design specifics using rusty lang.. Adios.     </p>\n","excerpt":"","more":"<p>In this we will get started with the cool language from mozilla - Rust.</p>\n<p>We will use functional programming as far as we can. Rust supports it in an elegant way. </p>\n<p>###Rust</p>\n<p><a href=\"http://www.rust-lang.org/\">rust</a> is a systems programming language that is compiled and hence there is not garbage collection unlike Go. Hence its a super cool/fast language. It has an awesome <code>rubygems</code> like community in <code>crates.io</code>. </p>\n<p>The symantics are little bit different but youll get used to it. </p>\n<p>###Why are we looking at rust ? </p>\n<p>We started out to identitfy memory optimized language for our IoT startegy. So we decided to put it action in our commandline rewrite <a href=\"https://github.com/megamsys/meg.git\">meg</a></p>\n<h3 id=\"Installing-rust\"><a href=\"#Installing-rust\" class=\"headerlink\" title=\"Installing rust\"></a>Installing rust</h3><ul>\n<li><p>Ubuntu </p>\n<p>  sudo add-apt-repository ppa:hansjorg/rust</p>\n<p>   sudo apt-get install rust-stable cargo-nightly</p>\n</li>\n<li><p>Arch linux</p>\n<p>  yaourt rust cargo-bin</p>\n</li>\n</ul>\n<h3 id=\"Your-first-rust-lang-library\"><a href=\"#Your-first-rust-lang-library\" class=\"headerlink\" title=\"Your first rust lang library\"></a>Your first rust lang library</h3><p>A rust lang library is something that can be included as a <a href=\"https://crates.io\">crate</a> in a program we build.</p>\n<p>In this case we will pull our cli library called <code>rust-turbo</code> </p>\n<p><em>rust-turbo</em>. </p>\n<p>Let us clone this library locally to ~/megam. </p>\n<pre><code>git clone https://github.com/megamsys/rust-turbo\n\ncargo clean\n\ncargo build\n\n[ram@ramwork:rust-turbo|master]$ cargo build\n   Compiling gcc v0.3.5\n   Compiling hamcrest v0.1.0         (https://github.com/carllerche/hamcrest-rust.git#b61fef3e)\nCompiling libc v0.1.8\nCompiling glob v0.2.10\nCompiling strsim v0.3.0\nCompiling rustc-serialize v0.3.14\nCompiling regex v0.1.30\nCompiling term v0.2.7\nCompiling log v0.3.1\nCompiling time v0.1.25\nCompiling env_logger v0.3.1\nCompiling docopt v0.6.64\nCompiling rust-turbo v0.2.0   (file:///home/ram/code/megam/rust/rust-turbo)\n</code></pre><p>Cool we just built our first library. </p>\n<p>Every project that uses <code>cargo</code> as the build tool will include a file called <code>Cargo.toml</code></p>\n<ul>\n<li>library ? Huh ! </li>\n</ul>\n<p>The question is how do you decide if you are building a binary (executable) or a library to be includeded as a crate.</p>\n<p>Make a change in the <code>cargo.toml</code> file include the following.</p>\n<pre><code>[lib]\nname = &quot;turbo&quot;\npath = &quot;src/turbo/lib.rs&quot;\n</code></pre><p>###testing</p>\n<pre><code>cargo tests\n</code></pre><p>There are bunch of tests under src/tests that are under the src directory they get run automatically. </p>\n<p>Use a matcher like <code>hamcrest</code> to compare the output and expected out to decide on the failure or success of your tests. </p>\n<p>###namespaces</p>\n<p>In our case <code>cargo</code> will look forward towards a file called <code>turbo/lib.rs</code>. The details of <code>lib.rs</code> are</p>\n<pre><code>#![deny(unused)]\n#![cfg_attr(test, deny(warnings))]\n\n#[macro_use] extern crate log;\n\n#[cfg(test)] extern crate hamcrest;\nextern crate docopt;\nextern crate glob;\nextern crate rustc_serialize;\nextern crate term;\nextern crate time;\nextern crate libc;\n\npub mod util;\npub mod core;\npub mod turbo;\n</code></pre><p>Let us examine the above. </p>\n<ul>\n<li><p><code>extern crate</code> indicates our intention to use an external library eg: logging, docopt (options command line parsing) etc.</p>\n</li>\n<li><p><code>pub mod util</code> indicates that we intend to include a module named util.rs or util/mod.rs. </p>\n</li>\n</ul>\n<p>If you see our source code we have 3 folders <code>util</code>, <code>core</code>, and <code>turbo.rs</code> </p>\n<p>##You first rust executable</p>\n<p>In this case we will pull our cli exec we are building called <code>meg</code> </p>\n<p><em>meg</em>. </p>\n<p> Let us clone this library locally to ~/megam. </p>\n<pre><code>git clone https://github.com/megamsys/meg\n\ncargo clean\n\ncargo build\n</code></pre><p> The built binary will be under targets. so run it to your hearts content. eg:</p>\n<pre><code>meg version\n</code></pre><p>We have covered setting up rust, and get going with a rust library and an executable. Stay tuned on other design specifics using rusty lang.. Adios.     </p>\n"},{"title":"Design technique for building an API using scalaz","slug":"2015-07-08-design-technique-for-building-an-api-using-scalaz","date_published":"2015-07-08T08:03:21.905Z","date_updated":"2015-07-09T22:15:39.259Z","_content":"\nIn [Part1](http://devcenter.megam.io/2015/03/18/rest_api_playframework/) we looked at how does the general RESTful API design for the input request look like.\n\nWe will use functional programming design technique - scalaz library and apply it to the design we have so far. \n\n###Scalaz\n\n[scalaz](https://github.com/scalaz/scalaz) is an extension of the core library for functional programming.\n\n\n###Why functional ? \n\nWe can defer the computation until we need to actually do it.\n\nBreak programs in to partitioned computations\n\nJust play with plain old data structures instead of fancy polymorphism types  like *AbstractBufferedToddlerReadyPlaySchool*. \n\nWe will not cover scalaz here, however you can refer a tutorial to [learn scalaz](http://eed3si9n.com/learning-scalaz/).\n\nSome of the libraries that we will use are \n\n* scalaz.Validation\n* scalaz.effect.IO\n* scalaz.EitherT._\n* scalaz.NonEmptyList._\n\n\nMore precisely the following will be imported. \n\n    import scalaz._\n    import scalaz.Validation._\n    import Scalaz._\n    import scalaz.effect.IO\n    import scalaz.EitherT._\n    import scalaz.Validation\n    import scalaz.NonEmptyList._\n    import scalaz.Validation.FlatMap._\n   \nThe first concept we will study is about, *map*. This isn't a theory on monads, but talks about how we used it. so bear with me.\n\n##map\n    //A functor with one fuction.\n    \n    def map[B](f: A => B) : M[B] \n\nFor example you can convert a List of Ints to String. Why would you want to do that ? Lets just say we feel cool :).\n\n    List[Int] -> List[String]\n\nLets change a list of Ints to Option[Int]\n\n\tval listT = List(1,2,3)\n\n\tlistT.map(x => Some(x)) -> List[Option[Int]]\n\nThe next one we will use a lot is, *flatMap*.\n\n##flatMap\n\n    def flatMap[B](f: A => M[B]) : M[B]\n\nLets change a list of Ints to Option[Int]\n\t    \n    val fruits = Seq(\"apple\", \"banana\", \"orange\")\n\n    val ufruits = fruits.map(_.toUpperCase)\n    \n    //lets first map the fruits to make them uppper case\n    :Seq[java.lang.String] = List(APPLE, BANANA, ORANGE)\n\n    ufruits.flatMap(_.toUpperCase)\n    \n    //lets do a flatMap on the uppercased list \n    :Seq[Char] = List(A, P, P, L, E, B, A, N, A, N, A, O, R, A, N, G, E)\n    \n## Validation\n\nMany a times you will find *try catch* to be cumbersome in trapping errors. It becomes ugly where you start throwing down *exceptions* just to propogate and handle it. \n\nSome times you need a *value* of the exception to proceed further or just halt there.\n\nA better way would be to handle *exceptions* as a value. Here you can see that an *CannotAuthenticateError* is returned as below.  \n\n    Validation.failure[Throwable, Option[String]](CannotAuthenticateError(\"\"\"Invalid content in header. API server couldn't parse it\"\"\", \"Request can't be funneled.\"))\n    \n    Validation.success[Throwable, Option[String](Some(\"Hurray I am done\"))\n\nThere are two type parameters in the above **Throwable** and **Option[String]** \n\nWe will use the term \n\n**Left**  to indicate the *failure* (Throwable) and\n\n**Right** to indicate the *success* (Option[String])\n \nDuring a failure, the *Left* is provided with the value of the failure. \n\nDuring a success, the *Right* is provided with the success value.\n\n###ValidatioNel\n\nValidationNel is a convinient method to wrap a NonEmptyList to the list of results. It can be useful where you want to concatenate the results of chained computation.\n\nFor instance - hit the guys head with a nail 10 times and tell the results of it what happened each time. \n\nDid the guy duck or get it ? \n\n    ValidationNel[Throwable, Option[Hit]]\n    \nThere are convenient methods to change *Validation* to *ValidationNel*.\n\n####Where can you use ?\n\nWhen you call your model to create something, you want to return all the results to the callee.\n\nIn the below code, we create an account and return the Left or Right to the callee. \n\n###Model results\nThe first step is that we send  a json string to the model to store. \n\nBut first we need to validate it to a known schema *AccountInput* and see if it satisfies the same. If not we return an error **MalformedBodyError**\n\nWe wrap the schema extraction on **Validation.fromTryCatch** which results in **Left** or **Right** automatically.\n\nSo if we wanted to proceed with upon success of the schema validation we need to use a **flatMap**\n\nSo if we wanted to proceed with upon failure of the schema validation we need to use a **leftMap**\n\n    def create(input: String): ValidationNel[Throwable, Option[AccountResult]] = {\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"models.Accounts\", \"create:Entry\"))\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"input json\", input))\n    (Validation.fromTryCatch[models.AccountInput] {\n      parse(input).extract[AccountInput]\n    } leftMap { t: Throwable => new MalformedBodyError(input, t.getMessage)\n    }).toValidationNel.flatMap\n\nIgnore the *toValidationNel* for now. We will get to it in a minute. \n\nSo you saw how easy its to trap failure/success in a simple scenario.\n\nBy using **for comprehension** imagine the power to  chain computation which decides if it wants to proceed or exit out and inform the callee.\n\nSweet.\n\n    for {\n      m <- accountInput // verify the schema\n      bal <- //create an empty billing record\n      uid <- //get an unique id to store in riak\n    } yield {\n           //yield a success result\n    }\n    \nSo you just understood how to chain computations to arrive at a result, as opposed to the imperative style of a humongous loads of classes.\n\nWe are going to proceed further and explore calling our model a bunch of times and keep storing success or failure. \n\n**toValidationNel**  is a helper method that lets you convert a **Validation** to **ValidationNel**\n\n**ValidationNel** comes handy.\n\n###ValidationNel put to use \n\nLet us take a scenario where in our case when an user clicks the button **Marketplaces** we want to talk to the [gateway - REST API server](https://github.com/megamsys/megam_gateway.git) \n![](/content/images/2015/06/megam_marketplaces.png)\n\nto display the Marketplaces screen \n![](/content/images/2015/06/megam_marketplaces1.png)\n\nYeah. Here is the code. \n\n\n    def findByName(marketPlacesNameList: Option[Stream[String]]): ValidationNel[Throwable, MarketPlaceResults] = {\n    (marketPlacesNameList map {\n      _.map { marketplacesName =>\n        InMemory[ValidationNel[Throwable, MarketPlaceResults]]({\n          cname: String =>  {\n              (riak.fetch(marketplacesName) leftMap { t: NonEmptyList[Throwable] =>\n                new ServiceUnavailableError(marketplacesName, (t.list.map(m => m.getMessage)).mkString(\"\\n\"))\n              }).toValidationNel.flatMap { xso: Option[GunnySack] =>\n                xso match {\n                  case Some(xs) => {                    (Validation.fromTryCatchThrowable[models.MarketPlaceResult,Throwable] {                      parse(xs.value).extract[MarketPlaceResult]\n                    } leftMap { t: Throwable =>\n                      new ResourceItemNotFound(marketplacesName, t.getMessage)\n                    }).toValidationNel.flatMap { j: MarketPlaceResult =>\n                      Validation.success[Throwable, MarketPlaceResults](nels(j.some)).toValidationNel //screwy kishore, every element in a list ?\n                    }\n                  }\n                  case None => Validation.failure[Throwable, MarketPlaceResults](new ResourceItemNotFound(marketplacesName, \"\")).toValidationNel\n                }\n              }\n            }\n        }).get(marketplacesName).eval(InMemoryCache[ValidationNel[Throwable, MarketPlaceResults]]())\n      }\n    } map {\n      _.foldRight((MarketPlaceResults.empty).successNel[Throwable])(_ +++ _)\n    }).head //return the folded element in the head.\n\n  }\n\n\nLets examine the code. What we are saying here is \n\n*I hand you a list of Option[marketplace names], call the db and get me a ValidationNel[Failure/Success result] for each of the list item*\n\n- The first step is to **map** on the  *marketplaceName* and start unwrapping what is inside it.\n- As the type is **Option[Stream]** we see a double map\n- There is a State monad cache **InMemory** used here which basically caches *read only information* inmemory or memcache as configured. The design details of **State Monad** will be explained in another article.\n- For every element *marketplacesName* see if it came out successful (**leftMap**), if not set **ResourceItemNotFound** for this result\n- If the result is successsful, then validate its schema that was stored before and keep accumulating the result\n\n**Note:** Here you see that the computation results are to be store in a list of ValidationNel's **List[ValidationNel]**\n\n- At the end hence we use **fold** using a **Successful accumulator** to get the **head** which contains the results.\n\nSuper cool. eh!...\n\n    \n###Usage of flatMap\n\nWhen you receive the result as `Validation`, the subsequent  computation needs to handle  (Left) or (Right).\n\nTo do so, we use our friend `flatMap`\n\nIn the below code, we marshall a json to a Scala object called models.AccountInput\n\n    (Validation.fromTryCatch[models.AccountInput] {\n      parse(input).extract[AccountInput]\n    } leftMap { t: Throwable => new MalformedBodyError(input, t.getMessage)\n    }).toValidationNel.flatMap { m: AccountInput =>\n\nThe result of the marshalling can result in an **exception** or **models.AccountInput** object\n\nIf the results are successful then the **flatMap** will provide the **AccountInput** object as seen above.\n\n\n###either[T, S]  \\/\n\nWait isn't either \\/ disjunction appear like Validation. \n\n**Note** either \\/  is isomorphic to Validation.\n\nWhat the heck is isomorphism. ?\n\nIsomorphism is a very general concept that derives from the Greek iso, meaning \"equal,\" and morphosis, meaning \"to form\" or \"to shape.\"\n\nLets take this example and illustrate how either[T,S] differs from Validation.\n\nFor instance - hit the guys head with a nail 10 times and tell the singular result of failure or success by aggregating everything. \n\n- 1st hit [Sucess]\n- 2nd hit [Failure]\n- 3rd hit [Success]\n\nDid the guy duck or get it considering even on hit is a failure ? Yes the answer to the above is *[Failure]*\n    \nLets study by taking an example.\n\n    (for {\n      resp <- eitherT[IO, NonEmptyList[Throwable], Option[AccountResult]] { //disjunction Throwabel \\/ Option with a Function IO.\n        (Accounts.findByEmail(freq.maybeEmail.get).disjunction).pure[IO]\n      }\n      found <- eitherT[IO, NonEmptyList[Throwable], Option[String]] {\n        val fres = resp.get\n        val calculatedHMAC = GoofyCrypto.calculateHMAC(fres.api_key, freq.mkSign)\n        if (calculatedHMAC === freq.clientAPIHmac.get) {\n          ((\"\"\"Authorization successful for 'email:' HMAC matches:\n            |%-10s -> %s\n            |%-10s -> %s\n            |%-10s -> %s\"\"\".format(\"email\", fres.email, \"api_key\", fres.api_key, \"authority\", fres.authority).stripMargin)\n            .some).right[NonEmptyList[Throwable]].pure[IO]\n        } else {\n          (nels((CannotAuthenticateError(\"\"\"Authorization failure for 'email:' HMAC doesn't match: '%s'.\"\"\"\n            .format(fres.email).stripMargin, \"\", UNAUTHORIZED))): NonEmptyList[Throwable]).left[Option[String]].pure[IO]\n        }\n      }\n    } yield found).run.map(_.validation).unsafePerformIO()\n  }\n  \n  \n  In the above there are two computations **resp, found** that are wrapped in  **eitherT[IO, NonEmptyList[Throwable], Option[T]]**\n  \n  The first computation returns the results of Account.findByEmail and wraps it in **pure[IO]**\n  \n  The second computation takes the success of the find and see if account is valid and can be authenticated.\n  \n  At the end of the computation you will notice that we yield  the **found** where we convert it to a **Validation** and tell scala to run the unsafe mode now.\n  \nI suppose we have given you an overall perspective of just 3 things in the **scalaz** world.\n\n- map, flatMap \n- Validation, ValidationNel\n- eitherT\n\nWe had applied the same in how this was used in our awesome `api server` [https://github.com/megamsys](https://github.com/megamsys).\n\n#### If you guys want to learn more then `press a few likes here` [functional conf](http://confengine.com/functional-conf-2015/proposal/1321/building-a-rest-api-with-scalaz)\n \n  \n  \n","source":"_posts/2015-07-08-design-technique-for-building-an-api-using-scalaz.md","raw":"---\ntitle: Design technique for building an API using scalaz\nslug: design-technique-for-building-an-api-using-scalaz\ndate_published: 2015-07-08T13:33:21.905Z\ndate_updated:   2015-07-10T03:45:39.259Z\n---\n\nIn [Part1](http://devcenter.megam.io/2015/03/18/rest_api_playframework/) we looked at how does the general RESTful API design for the input request look like.\n\nWe will use functional programming design technique - scalaz library and apply it to the design we have so far. \n\n###Scalaz\n\n[scalaz](https://github.com/scalaz/scalaz) is an extension of the core library for functional programming.\n\n\n###Why functional ? \n\nWe can defer the computation until we need to actually do it.\n\nBreak programs in to partitioned computations\n\nJust play with plain old data structures instead of fancy polymorphism types  like *AbstractBufferedToddlerReadyPlaySchool*. \n\nWe will not cover scalaz here, however you can refer a tutorial to [learn scalaz](http://eed3si9n.com/learning-scalaz/).\n\nSome of the libraries that we will use are \n\n* scalaz.Validation\n* scalaz.effect.IO\n* scalaz.EitherT._\n* scalaz.NonEmptyList._\n\n\nMore precisely the following will be imported. \n\n    import scalaz._\n    import scalaz.Validation._\n    import Scalaz._\n    import scalaz.effect.IO\n    import scalaz.EitherT._\n    import scalaz.Validation\n    import scalaz.NonEmptyList._\n    import scalaz.Validation.FlatMap._\n   \nThe first concept we will study is about, *map*. This isn't a theory on monads, but talks about how we used it. so bear with me.\n\n##map\n    //A functor with one fuction.\n    \n    def map[B](f: A => B) : M[B] \n\nFor example you can convert a List of Ints to String. Why would you want to do that ? Lets just say we feel cool :).\n\n    List[Int] -> List[String]\n\nLets change a list of Ints to Option[Int]\n\n\tval listT = List(1,2,3)\n\n\tlistT.map(x => Some(x)) -> List[Option[Int]]\n\nThe next one we will use a lot is, *flatMap*.\n\n##flatMap\n\n    def flatMap[B](f: A => M[B]) : M[B]\n\nLets change a list of Ints to Option[Int]\n\t    \n    val fruits = Seq(\"apple\", \"banana\", \"orange\")\n\n    val ufruits = fruits.map(_.toUpperCase)\n    \n    //lets first map the fruits to make them uppper case\n    :Seq[java.lang.String] = List(APPLE, BANANA, ORANGE)\n\n    ufruits.flatMap(_.toUpperCase)\n    \n    //lets do a flatMap on the uppercased list \n    :Seq[Char] = List(A, P, P, L, E, B, A, N, A, N, A, O, R, A, N, G, E)\n    \n## Validation\n\nMany a times you will find *try catch* to be cumbersome in trapping errors. It becomes ugly where you start throwing down *exceptions* just to propogate and handle it. \n\nSome times you need a *value* of the exception to proceed further or just halt there.\n\nA better way would be to handle *exceptions* as a value. Here you can see that an *CannotAuthenticateError* is returned as below.  \n\n    Validation.failure[Throwable, Option[String]](CannotAuthenticateError(\"\"\"Invalid content in header. API server couldn't parse it\"\"\", \"Request can't be funneled.\"))\n    \n    Validation.success[Throwable, Option[String](Some(\"Hurray I am done\"))\n\nThere are two type parameters in the above **Throwable** and **Option[String]** \n\nWe will use the term \n\n**Left**  to indicate the *failure* (Throwable) and\n\n**Right** to indicate the *success* (Option[String])\n \nDuring a failure, the *Left* is provided with the value of the failure. \n\nDuring a success, the *Right* is provided with the success value.\n\n###ValidatioNel\n\nValidationNel is a convinient method to wrap a NonEmptyList to the list of results. It can be useful where you want to concatenate the results of chained computation.\n\nFor instance - hit the guys head with a nail 10 times and tell the results of it what happened each time. \n\nDid the guy duck or get it ? \n\n    ValidationNel[Throwable, Option[Hit]]\n    \nThere are convenient methods to change *Validation* to *ValidationNel*.\n\n####Where can you use ?\n\nWhen you call your model to create something, you want to return all the results to the callee.\n\nIn the below code, we create an account and return the Left or Right to the callee. \n\n###Model results\nThe first step is that we send  a json string to the model to store. \n\nBut first we need to validate it to a known schema *AccountInput* and see if it satisfies the same. If not we return an error **MalformedBodyError**\n\nWe wrap the schema extraction on **Validation.fromTryCatch** which results in **Left** or **Right** automatically.\n\nSo if we wanted to proceed with upon success of the schema validation we need to use a **flatMap**\n\nSo if we wanted to proceed with upon failure of the schema validation we need to use a **leftMap**\n\n    def create(input: String): ValidationNel[Throwable, Option[AccountResult]] = {\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"models.Accounts\", \"create:Entry\"))\n    play.api.Logger.debug((\"%-20s -->[%s]\").format(\"input json\", input))\n    (Validation.fromTryCatch[models.AccountInput] {\n      parse(input).extract[AccountInput]\n    } leftMap { t: Throwable => new MalformedBodyError(input, t.getMessage)\n    }).toValidationNel.flatMap\n\nIgnore the *toValidationNel* for now. We will get to it in a minute. \n\nSo you saw how easy its to trap failure/success in a simple scenario.\n\nBy using **for comprehension** imagine the power to  chain computation which decides if it wants to proceed or exit out and inform the callee.\n\nSweet.\n\n    for {\n      m <- accountInput // verify the schema\n      bal <- //create an empty billing record\n      uid <- //get an unique id to store in riak\n    } yield {\n           //yield a success result\n    }\n    \nSo you just understood how to chain computations to arrive at a result, as opposed to the imperative style of a humongous loads of classes.\n\nWe are going to proceed further and explore calling our model a bunch of times and keep storing success or failure. \n\n**toValidationNel**  is a helper method that lets you convert a **Validation** to **ValidationNel**\n\n**ValidationNel** comes handy.\n\n###ValidationNel put to use \n\nLet us take a scenario where in our case when an user clicks the button **Marketplaces** we want to talk to the [gateway - REST API server](https://github.com/megamsys/megam_gateway.git) \n![](/content/images/2015/06/megam_marketplaces.png)\n\nto display the Marketplaces screen \n![](/content/images/2015/06/megam_marketplaces1.png)\n\nYeah. Here is the code. \n\n\n    def findByName(marketPlacesNameList: Option[Stream[String]]): ValidationNel[Throwable, MarketPlaceResults] = {\n    (marketPlacesNameList map {\n      _.map { marketplacesName =>\n        InMemory[ValidationNel[Throwable, MarketPlaceResults]]({\n          cname: String =>  {\n              (riak.fetch(marketplacesName) leftMap { t: NonEmptyList[Throwable] =>\n                new ServiceUnavailableError(marketplacesName, (t.list.map(m => m.getMessage)).mkString(\"\\n\"))\n              }).toValidationNel.flatMap { xso: Option[GunnySack] =>\n                xso match {\n                  case Some(xs) => {                    (Validation.fromTryCatchThrowable[models.MarketPlaceResult,Throwable] {                      parse(xs.value).extract[MarketPlaceResult]\n                    } leftMap { t: Throwable =>\n                      new ResourceItemNotFound(marketplacesName, t.getMessage)\n                    }).toValidationNel.flatMap { j: MarketPlaceResult =>\n                      Validation.success[Throwable, MarketPlaceResults](nels(j.some)).toValidationNel //screwy kishore, every element in a list ?\n                    }\n                  }\n                  case None => Validation.failure[Throwable, MarketPlaceResults](new ResourceItemNotFound(marketplacesName, \"\")).toValidationNel\n                }\n              }\n            }\n        }).get(marketplacesName).eval(InMemoryCache[ValidationNel[Throwable, MarketPlaceResults]]())\n      }\n    } map {\n      _.foldRight((MarketPlaceResults.empty).successNel[Throwable])(_ +++ _)\n    }).head //return the folded element in the head.\n\n  }\n\n\nLets examine the code. What we are saying here is \n\n*I hand you a list of Option[marketplace names], call the db and get me a ValidationNel[Failure/Success result] for each of the list item*\n\n- The first step is to **map** on the  *marketplaceName* and start unwrapping what is inside it.\n- As the type is **Option[Stream]** we see a double map\n- There is a State monad cache **InMemory** used here which basically caches *read only information* inmemory or memcache as configured. The design details of **State Monad** will be explained in another article.\n- For every element *marketplacesName* see if it came out successful (**leftMap**), if not set **ResourceItemNotFound** for this result\n- If the result is successsful, then validate its schema that was stored before and keep accumulating the result\n\n**Note:** Here you see that the computation results are to be store in a list of ValidationNel's **List[ValidationNel]**\n\n- At the end hence we use **fold** using a **Successful accumulator** to get the **head** which contains the results.\n\nSuper cool. eh!...\n\n    \n###Usage of flatMap\n\nWhen you receive the result as `Validation`, the subsequent  computation needs to handle  (Left) or (Right).\n\nTo do so, we use our friend `flatMap`\n\nIn the below code, we marshall a json to a Scala object called models.AccountInput\n\n    (Validation.fromTryCatch[models.AccountInput] {\n      parse(input).extract[AccountInput]\n    } leftMap { t: Throwable => new MalformedBodyError(input, t.getMessage)\n    }).toValidationNel.flatMap { m: AccountInput =>\n\nThe result of the marshalling can result in an **exception** or **models.AccountInput** object\n\nIf the results are successful then the **flatMap** will provide the **AccountInput** object as seen above.\n\n\n###either[T, S]  \\/\n\nWait isn't either \\/ disjunction appear like Validation. \n\n**Note** either \\/  is isomorphic to Validation.\n\nWhat the heck is isomorphism. ?\n\nIsomorphism is a very general concept that derives from the Greek iso, meaning \"equal,\" and morphosis, meaning \"to form\" or \"to shape.\"\n\nLets take this example and illustrate how either[T,S] differs from Validation.\n\nFor instance - hit the guys head with a nail 10 times and tell the singular result of failure or success by aggregating everything. \n\n- 1st hit [Sucess]\n- 2nd hit [Failure]\n- 3rd hit [Success]\n\nDid the guy duck or get it considering even on hit is a failure ? Yes the answer to the above is *[Failure]*\n    \nLets study by taking an example.\n\n    (for {\n      resp <- eitherT[IO, NonEmptyList[Throwable], Option[AccountResult]] { //disjunction Throwabel \\/ Option with a Function IO.\n        (Accounts.findByEmail(freq.maybeEmail.get).disjunction).pure[IO]\n      }\n      found <- eitherT[IO, NonEmptyList[Throwable], Option[String]] {\n        val fres = resp.get\n        val calculatedHMAC = GoofyCrypto.calculateHMAC(fres.api_key, freq.mkSign)\n        if (calculatedHMAC === freq.clientAPIHmac.get) {\n          ((\"\"\"Authorization successful for 'email:' HMAC matches:\n            |%-10s -> %s\n            |%-10s -> %s\n            |%-10s -> %s\"\"\".format(\"email\", fres.email, \"api_key\", fres.api_key, \"authority\", fres.authority).stripMargin)\n            .some).right[NonEmptyList[Throwable]].pure[IO]\n        } else {\n          (nels((CannotAuthenticateError(\"\"\"Authorization failure for 'email:' HMAC doesn't match: '%s'.\"\"\"\n            .format(fres.email).stripMargin, \"\", UNAUTHORIZED))): NonEmptyList[Throwable]).left[Option[String]].pure[IO]\n        }\n      }\n    } yield found).run.map(_.validation).unsafePerformIO()\n  }\n  \n  \n  In the above there are two computations **resp, found** that are wrapped in  **eitherT[IO, NonEmptyList[Throwable], Option[T]]**\n  \n  The first computation returns the results of Account.findByEmail and wraps it in **pure[IO]**\n  \n  The second computation takes the success of the find and see if account is valid and can be authenticated.\n  \n  At the end of the computation you will notice that we yield  the **found** where we convert it to a **Validation** and tell scala to run the unsafe mode now.\n  \nI suppose we have given you an overall perspective of just 3 things in the **scalaz** world.\n\n- map, flatMap \n- Validation, ValidationNel\n- eitherT\n\nWe had applied the same in how this was used in our awesome `api server` [https://github.com/megamsys](https://github.com/megamsys).\n\n#### If you guys want to learn more then `press a few likes here` [functional conf](http://confengine.com/functional-conf-2015/proposal/1321/building-a-rest-api-with-scalaz)\n \n  \n  \n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzairz000ndrgby53j0ki7","content":"<p>In <a href=\"http://devcenter.megam.io/2015/03/18/rest_api_playframework/\" target=\"_blank\" rel=\"external\">Part1</a> we looked at how does the general RESTful API design for the input request look like.</p>\n<p>We will use functional programming design technique - scalaz library and apply it to the design we have so far. </p>\n<p>###Scalaz</p>\n<p><a href=\"https://github.com/scalaz/scalaz\" target=\"_blank\" rel=\"external\">scalaz</a> is an extension of the core library for functional programming.</p>\n<p>###Why functional ? </p>\n<p>We can defer the computation until we need to actually do it.</p>\n<p>Break programs in to partitioned computations</p>\n<p>Just play with plain old data structures instead of fancy polymorphism types  like <em>AbstractBufferedToddlerReadyPlaySchool</em>. </p>\n<p>We will not cover scalaz here, however you can refer a tutorial to <a href=\"http://eed3si9n.com/learning-scalaz/\" target=\"_blank\" rel=\"external\">learn scalaz</a>.</p>\n<p>Some of the libraries that we will use are </p>\n<ul>\n<li>scalaz.Validation</li>\n<li>scalaz.effect.IO</li>\n<li>scalaz.EitherT._</li>\n<li>scalaz.NonEmptyList._</li>\n</ul>\n<p>More precisely the following will be imported. </p>\n<pre><code>import scalaz._\nimport scalaz.Validation._\nimport Scalaz._\nimport scalaz.effect.IO\nimport scalaz.EitherT._\nimport scalaz.Validation\nimport scalaz.NonEmptyList._\nimport scalaz.Validation.FlatMap._\n</code></pre><p>The first concept we will study is about, <em>map</em>. This isnt a theory on monads, but talks about how we used it. so bear with me.</p>\n<p>##map<br>    //A functor with one fuction.</p>\n<pre><code>def map[B](f: A =&gt; B) : M[B] \n</code></pre><p>For example you can convert a List of Ints to String. Why would you want to do that ? Lets just say we feel cool :).</p>\n<pre><code>List[Int] -&gt; List[String]\n</code></pre><p>Lets change a list of Ints to Option[Int]</p>\n<pre><code>val listT = List(1,2,3)\n\nlistT.map(x =&gt; Some(x)) -&gt; List[Option[Int]]\n</code></pre><p>The next one we will use a lot is, <em>flatMap</em>.</p>\n<p>##flatMap</p>\n<pre><code>def flatMap[B](f: A =&gt; M[B]) : M[B]\n</code></pre><p>Lets change a list of Ints to Option[Int]</p>\n<pre><code>val fruits = Seq(&quot;apple&quot;, &quot;banana&quot;, &quot;orange&quot;)\n\nval ufruits = fruits.map(_.toUpperCase)\n\n//lets first map the fruits to make them uppper case\n:Seq[java.lang.String] = List(APPLE, BANANA, ORANGE)\n\nufruits.flatMap(_.toUpperCase)\n\n//lets do a flatMap on the uppercased list \n:Seq[Char] = List(A, P, P, L, E, B, A, N, A, N, A, O, R, A, N, G, E)\n</code></pre><h2 id=\"Validation\"><a href=\"#Validation\" class=\"headerlink\" title=\"Validation\"></a>Validation</h2><p>Many a times you will find <em>try catch</em> to be cumbersome in trapping errors. It becomes ugly where you start throwing down <em>exceptions</em> just to propogate and handle it. </p>\n<p>Some times you need a <em>value</em> of the exception to proceed further or just halt there.</p>\n<p>A better way would be to handle <em>exceptions</em> as a value. Here you can see that an <em>CannotAuthenticateError</em> is returned as below.  </p>\n<pre><code>Validation.failure[Throwable, Option[String]](CannotAuthenticateError(&quot;&quot;&quot;Invalid content in header. API server couldn&apos;t parse it&quot;&quot;&quot;, &quot;Request can&apos;t be funneled.&quot;))\n\nValidation.success[Throwable, Option[String](Some(&quot;Hurray I am done&quot;))\n</code></pre><p>There are two type parameters in the above <strong>Throwable</strong> and <strong>Option[String]</strong> </p>\n<p>We will use the term </p>\n<p><strong>Left</strong>  to indicate the <em>failure</em> (Throwable) and</p>\n<p><strong>Right</strong> to indicate the <em>success</em> (Option[String])</p>\n<p>During a failure, the <em>Left</em> is provided with the value of the failure. </p>\n<p>During a success, the <em>Right</em> is provided with the success value.</p>\n<p>###ValidatioNel</p>\n<p>ValidationNel is a convinient method to wrap a NonEmptyList to the list of results. It can be useful where you want to concatenate the results of chained computation.</p>\n<p>For instance - hit the guys head with a nail 10 times and tell the results of it what happened each time. </p>\n<p>Did the guy duck or get it ? </p>\n<pre><code>ValidationNel[Throwable, Option[Hit]]\n</code></pre><p>There are convenient methods to change <em>Validation</em> to <em>ValidationNel</em>.</p>\n<p>####Where can you use ?</p>\n<p>When you call your model to create something, you want to return all the results to the callee.</p>\n<p>In the below code, we create an account and return the Left or Right to the callee. </p>\n<p>###Model results<br>The first step is that we send  a json string to the model to store. </p>\n<p>But first we need to validate it to a known schema <em>AccountInput</em> and see if it satisfies the same. If not we return an error <strong>MalformedBodyError</strong></p>\n<p>We wrap the schema extraction on <strong>Validation.fromTryCatch</strong> which results in <strong>Left</strong> or <strong>Right</strong> automatically.</p>\n<p>So if we wanted to proceed with upon success of the schema validation we need to use a <strong>flatMap</strong></p>\n<p>So if we wanted to proceed with upon failure of the schema validation we need to use a <strong>leftMap</strong></p>\n<pre><code>def create(input: String): ValidationNel[Throwable, Option[AccountResult]] = {\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;models.Accounts&quot;, &quot;create:Entry&quot;))\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;input json&quot;, input))\n(Validation.fromTryCatch[models.AccountInput] {\n  parse(input).extract[AccountInput]\n} leftMap { t: Throwable =&gt; new MalformedBodyError(input, t.getMessage)\n}).toValidationNel.flatMap\n</code></pre><p>Ignore the <em>toValidationNel</em> for now. We will get to it in a minute. </p>\n<p>So you saw how easy its to trap failure/success in a simple scenario.</p>\n<p>By using <strong>for comprehension</strong> imagine the power to  chain computation which decides if it wants to proceed or exit out and inform the callee.</p>\n<p>Sweet.</p>\n<pre><code>for {\n  m &lt;- accountInput // verify the schema\n  bal &lt;- //create an empty billing record\n  uid &lt;- //get an unique id to store in riak\n} yield {\n       //yield a success result\n}\n</code></pre><p>So you just understood how to chain computations to arrive at a result, as opposed to the imperative style of a humongous loads of classes.</p>\n<p>We are going to proceed further and explore calling our model a bunch of times and keep storing success or failure. </p>\n<p><strong>toValidationNel</strong>  is a helper method that lets you convert a <strong>Validation</strong> to <strong>ValidationNel</strong></p>\n<p><strong>ValidationNel</strong> comes handy.</p>\n<p>###ValidationNel put to use </p>\n<p>Let us take a scenario where in our case when an user clicks the button <strong>Marketplaces</strong> we want to talk to the <a href=\"https://github.com/megamsys/megam_gateway.git\" target=\"_blank\" rel=\"external\">gateway - REST API server</a><br><img src=\"/content/images/2015/06/megam_marketplaces.png\" alt=\"\"></p>\n<p>to display the Marketplaces screen<br><img src=\"/content/images/2015/06/megam_marketplaces1.png\" alt=\"\"></p>\n<p>Yeah. Here is the code. </p>\n<pre><code>def findByName(marketPlacesNameList: Option[Stream[String]]): ValidationNel[Throwable, MarketPlaceResults] = {\n(marketPlacesNameList map {\n  _.map { marketplacesName =&gt;\n    InMemory[ValidationNel[Throwable, MarketPlaceResults]]({\n      cname: String =&gt;  {\n          (riak.fetch(marketplacesName) leftMap { t: NonEmptyList[Throwable] =&gt;\n            new ServiceUnavailableError(marketplacesName, (t.list.map(m =&gt; m.getMessage)).mkString(&quot;\\n&quot;))\n          }).toValidationNel.flatMap { xso: Option[GunnySack] =&gt;\n            xso match {\n              case Some(xs) =&gt; {                    (Validation.fromTryCatchThrowable[models.MarketPlaceResult,Throwable] {                      parse(xs.value).extract[MarketPlaceResult]\n                } leftMap { t: Throwable =&gt;\n                  new ResourceItemNotFound(marketplacesName, t.getMessage)\n                }).toValidationNel.flatMap { j: MarketPlaceResult =&gt;\n                  Validation.success[Throwable, MarketPlaceResults](nels(j.some)).toValidationNel //screwy kishore, every element in a list ?\n                }\n              }\n              case None =&gt; Validation.failure[Throwable, MarketPlaceResults](new ResourceItemNotFound(marketplacesName, &quot;&quot;)).toValidationNel\n            }\n          }\n        }\n    }).get(marketplacesName).eval(InMemoryCache[ValidationNel[Throwable, MarketPlaceResults]]())\n  }\n} map {\n  _.foldRight((MarketPlaceResults.empty).successNel[Throwable])(_ +++ _)\n}).head //return the folded element in the head.\n</code></pre><p>  }</p>\n<p>Lets examine the code. What we are saying here is </p>\n<p><em>I hand you a list of Option[marketplace names], call the db and get me a ValidationNel[Failure/Success result] for each of the list item</em></p>\n<ul>\n<li>The first step is to <strong>map</strong> on the  <em>marketplaceName</em> and start unwrapping what is inside it.</li>\n<li>As the type is <strong>Option[Stream]</strong> we see a double map</li>\n<li>There is a State monad cache <strong>InMemory</strong> used here which basically caches <em>read only information</em> inmemory or memcache as configured. The design details of <strong>State Monad</strong> will be explained in another article.</li>\n<li>For every element <em>marketplacesName</em> see if it came out successful (<strong>leftMap</strong>), if not set <strong>ResourceItemNotFound</strong> for this result</li>\n<li>If the result is successsful, then validate its schema that was stored before and keep accumulating the result</li>\n</ul>\n<p><strong>Note:</strong> Here you see that the computation results are to be store in a list of ValidationNels <strong>List[ValidationNel]</strong></p>\n<ul>\n<li>At the end hence we use <strong>fold</strong> using a <strong>Successful accumulator</strong> to get the <strong>head</strong> which contains the results.</li>\n</ul>\n<p>Super cool. eh!</p>\n<p>###Usage of flatMap</p>\n<p>When you receive the result as <code>Validation</code>, the subsequent  computation needs to handle  (Left) or (Right).</p>\n<p>To do so, we use our friend <code>flatMap</code></p>\n<p>In the below code, we marshall a json to a Scala object called models.AccountInput</p>\n<pre><code>(Validation.fromTryCatch[models.AccountInput] {\n  parse(input).extract[AccountInput]\n} leftMap { t: Throwable =&gt; new MalformedBodyError(input, t.getMessage)\n}).toValidationNel.flatMap { m: AccountInput =&gt;\n</code></pre><p>The result of the marshalling can result in an <strong>exception</strong> or <strong>models.AccountInput</strong> object</p>\n<p>If the results are successful then the <strong>flatMap</strong> will provide the <strong>AccountInput</strong> object as seen above.</p>\n<p>###either[T, S]  \\/</p>\n<p>Wait isnt either \\/ disjunction appear like Validation. </p>\n<p><strong>Note</strong> either \\/  is isomorphic to Validation.</p>\n<p>What the heck is isomorphism. ?</p>\n<p>Isomorphism is a very general concept that derives from the Greek iso, meaning equal, and morphosis, meaning to form or to shape.</p>\n<p>Lets take this example and illustrate how either[T,S] differs from Validation.</p>\n<p>For instance - hit the guys head with a nail 10 times and tell the singular result of failure or success by aggregating everything. </p>\n<ul>\n<li>1st hit [Sucess]</li>\n<li>2nd hit [Failure]</li>\n<li>3rd hit [Success]</li>\n</ul>\n<p>Did the guy duck or get it considering even on hit is a failure ? Yes the answer to the above is <em>[Failure]</em></p>\n<p>Lets study by taking an example.</p>\n<pre><code>(for {\n  resp &lt;- eitherT[IO, NonEmptyList[Throwable], Option[AccountResult]] { //disjunction Throwabel \\/ Option with a Function IO.\n    (Accounts.findByEmail(freq.maybeEmail.get).disjunction).pure[IO]\n  }\n  found &lt;- eitherT[IO, NonEmptyList[Throwable], Option[String]] {\n    val fres = resp.get\n    val calculatedHMAC = GoofyCrypto.calculateHMAC(fres.api_key, freq.mkSign)\n    if (calculatedHMAC === freq.clientAPIHmac.get) {\n      ((&quot;&quot;&quot;Authorization successful for &apos;email:&apos; HMAC matches:\n        |%-10s -&gt; %s\n        |%-10s -&gt; %s\n        |%-10s -&gt; %s&quot;&quot;&quot;.format(&quot;email&quot;, fres.email, &quot;api_key&quot;, fres.api_key, &quot;authority&quot;, fres.authority).stripMargin)\n        .some).right[NonEmptyList[Throwable]].pure[IO]\n    } else {\n      (nels((CannotAuthenticateError(&quot;&quot;&quot;Authorization failure for &apos;email:&apos; HMAC doesn&apos;t match: &apos;%s&apos;.&quot;&quot;&quot;\n        .format(fres.email).stripMargin, &quot;&quot;, UNAUTHORIZED))): NonEmptyList[Throwable]).left[Option[String]].pure[IO]\n    }\n  }\n} yield found).run.map(_.validation).unsafePerformIO()\n</code></pre><p>  }</p>\n<p>  In the above there are two computations <strong>resp, found</strong> that are wrapped in  <strong>eitherT[IO, NonEmptyList[Throwable], Option[T]]</strong></p>\n<p>  The first computation returns the results of Account.findByEmail and wraps it in <strong>pure[IO]</strong></p>\n<p>  The second computation takes the success of the find and see if account is valid and can be authenticated.</p>\n<p>  At the end of the computation you will notice that we yield  the <strong>found</strong> where we convert it to a <strong>Validation</strong> and tell scala to run the unsafe mode now.</p>\n<p>I suppose we have given you an overall perspective of just 3 things in the <strong>scalaz</strong> world.</p>\n<ul>\n<li>map, flatMap </li>\n<li>Validation, ValidationNel</li>\n<li>eitherT</li>\n</ul>\n<p>We had applied the same in how this was used in our awesome <code>api server</code> <a href=\"https://github.com/megamsys\" target=\"_blank\" rel=\"external\">https://github.com/megamsys</a>.</p>\n<h4 id=\"If-you-guys-want-to-learn-more-then-press-a-few-likes-here-functional-conf\"><a href=\"#If-you-guys-want-to-learn-more-then-press-a-few-likes-here-functional-conf\" class=\"headerlink\" title=\"If you guys want to learn more then press a few likes here functional conf\"></a>If you guys want to learn more then <code>press a few likes here</code> <a href=\"http://confengine.com/functional-conf-2015/proposal/1321/building-a-rest-api-with-scalaz\" target=\"_blank\" rel=\"external\">functional conf</a></h4>","excerpt":"","more":"<p>In <a href=\"http://devcenter.megam.io/2015/03/18/rest_api_playframework/\">Part1</a> we looked at how does the general RESTful API design for the input request look like.</p>\n<p>We will use functional programming design technique - scalaz library and apply it to the design we have so far. </p>\n<p>###Scalaz</p>\n<p><a href=\"https://github.com/scalaz/scalaz\">scalaz</a> is an extension of the core library for functional programming.</p>\n<p>###Why functional ? </p>\n<p>We can defer the computation until we need to actually do it.</p>\n<p>Break programs in to partitioned computations</p>\n<p>Just play with plain old data structures instead of fancy polymorphism types  like <em>AbstractBufferedToddlerReadyPlaySchool</em>. </p>\n<p>We will not cover scalaz here, however you can refer a tutorial to <a href=\"http://eed3si9n.com/learning-scalaz/\">learn scalaz</a>.</p>\n<p>Some of the libraries that we will use are </p>\n<ul>\n<li>scalaz.Validation</li>\n<li>scalaz.effect.IO</li>\n<li>scalaz.EitherT._</li>\n<li>scalaz.NonEmptyList._</li>\n</ul>\n<p>More precisely the following will be imported. </p>\n<pre><code>import scalaz._\nimport scalaz.Validation._\nimport Scalaz._\nimport scalaz.effect.IO\nimport scalaz.EitherT._\nimport scalaz.Validation\nimport scalaz.NonEmptyList._\nimport scalaz.Validation.FlatMap._\n</code></pre><p>The first concept we will study is about, <em>map</em>. This isnt a theory on monads, but talks about how we used it. so bear with me.</p>\n<p>##map<br>    //A functor with one fuction.</p>\n<pre><code>def map[B](f: A =&gt; B) : M[B] \n</code></pre><p>For example you can convert a List of Ints to String. Why would you want to do that ? Lets just say we feel cool :).</p>\n<pre><code>List[Int] -&gt; List[String]\n</code></pre><p>Lets change a list of Ints to Option[Int]</p>\n<pre><code>val listT = List(1,2,3)\n\nlistT.map(x =&gt; Some(x)) -&gt; List[Option[Int]]\n</code></pre><p>The next one we will use a lot is, <em>flatMap</em>.</p>\n<p>##flatMap</p>\n<pre><code>def flatMap[B](f: A =&gt; M[B]) : M[B]\n</code></pre><p>Lets change a list of Ints to Option[Int]</p>\n<pre><code>val fruits = Seq(&quot;apple&quot;, &quot;banana&quot;, &quot;orange&quot;)\n\nval ufruits = fruits.map(_.toUpperCase)\n\n//lets first map the fruits to make them uppper case\n:Seq[java.lang.String] = List(APPLE, BANANA, ORANGE)\n\nufruits.flatMap(_.toUpperCase)\n\n//lets do a flatMap on the uppercased list \n:Seq[Char] = List(A, P, P, L, E, B, A, N, A, N, A, O, R, A, N, G, E)\n</code></pre><h2 id=\"Validation\"><a href=\"#Validation\" class=\"headerlink\" title=\"Validation\"></a>Validation</h2><p>Many a times you will find <em>try catch</em> to be cumbersome in trapping errors. It becomes ugly where you start throwing down <em>exceptions</em> just to propogate and handle it. </p>\n<p>Some times you need a <em>value</em> of the exception to proceed further or just halt there.</p>\n<p>A better way would be to handle <em>exceptions</em> as a value. Here you can see that an <em>CannotAuthenticateError</em> is returned as below.  </p>\n<pre><code>Validation.failure[Throwable, Option[String]](CannotAuthenticateError(&quot;&quot;&quot;Invalid content in header. API server couldn&apos;t parse it&quot;&quot;&quot;, &quot;Request can&apos;t be funneled.&quot;))\n\nValidation.success[Throwable, Option[String](Some(&quot;Hurray I am done&quot;))\n</code></pre><p>There are two type parameters in the above <strong>Throwable</strong> and <strong>Option[String]</strong> </p>\n<p>We will use the term </p>\n<p><strong>Left</strong>  to indicate the <em>failure</em> (Throwable) and</p>\n<p><strong>Right</strong> to indicate the <em>success</em> (Option[String])</p>\n<p>During a failure, the <em>Left</em> is provided with the value of the failure. </p>\n<p>During a success, the <em>Right</em> is provided with the success value.</p>\n<p>###ValidatioNel</p>\n<p>ValidationNel is a convinient method to wrap a NonEmptyList to the list of results. It can be useful where you want to concatenate the results of chained computation.</p>\n<p>For instance - hit the guys head with a nail 10 times and tell the results of it what happened each time. </p>\n<p>Did the guy duck or get it ? </p>\n<pre><code>ValidationNel[Throwable, Option[Hit]]\n</code></pre><p>There are convenient methods to change <em>Validation</em> to <em>ValidationNel</em>.</p>\n<p>####Where can you use ?</p>\n<p>When you call your model to create something, you want to return all the results to the callee.</p>\n<p>In the below code, we create an account and return the Left or Right to the callee. </p>\n<p>###Model results<br>The first step is that we send  a json string to the model to store. </p>\n<p>But first we need to validate it to a known schema <em>AccountInput</em> and see if it satisfies the same. If not we return an error <strong>MalformedBodyError</strong></p>\n<p>We wrap the schema extraction on <strong>Validation.fromTryCatch</strong> which results in <strong>Left</strong> or <strong>Right</strong> automatically.</p>\n<p>So if we wanted to proceed with upon success of the schema validation we need to use a <strong>flatMap</strong></p>\n<p>So if we wanted to proceed with upon failure of the schema validation we need to use a <strong>leftMap</strong></p>\n<pre><code>def create(input: String): ValidationNel[Throwable, Option[AccountResult]] = {\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;models.Accounts&quot;, &quot;create:Entry&quot;))\nplay.api.Logger.debug((&quot;%-20s --&gt;[%s]&quot;).format(&quot;input json&quot;, input))\n(Validation.fromTryCatch[models.AccountInput] {\n  parse(input).extract[AccountInput]\n} leftMap { t: Throwable =&gt; new MalformedBodyError(input, t.getMessage)\n}).toValidationNel.flatMap\n</code></pre><p>Ignore the <em>toValidationNel</em> for now. We will get to it in a minute. </p>\n<p>So you saw how easy its to trap failure/success in a simple scenario.</p>\n<p>By using <strong>for comprehension</strong> imagine the power to  chain computation which decides if it wants to proceed or exit out and inform the callee.</p>\n<p>Sweet.</p>\n<pre><code>for {\n  m &lt;- accountInput // verify the schema\n  bal &lt;- //create an empty billing record\n  uid &lt;- //get an unique id to store in riak\n} yield {\n       //yield a success result\n}\n</code></pre><p>So you just understood how to chain computations to arrive at a result, as opposed to the imperative style of a humongous loads of classes.</p>\n<p>We are going to proceed further and explore calling our model a bunch of times and keep storing success or failure. </p>\n<p><strong>toValidationNel</strong>  is a helper method that lets you convert a <strong>Validation</strong> to <strong>ValidationNel</strong></p>\n<p><strong>ValidationNel</strong> comes handy.</p>\n<p>###ValidationNel put to use </p>\n<p>Let us take a scenario where in our case when an user clicks the button <strong>Marketplaces</strong> we want to talk to the <a href=\"https://github.com/megamsys/megam_gateway.git\">gateway - REST API server</a><br><img src=\"/content/images/2015/06/megam_marketplaces.png\" alt=\"\"></p>\n<p>to display the Marketplaces screen<br><img src=\"/content/images/2015/06/megam_marketplaces1.png\" alt=\"\"></p>\n<p>Yeah. Here is the code. </p>\n<pre><code>def findByName(marketPlacesNameList: Option[Stream[String]]): ValidationNel[Throwable, MarketPlaceResults] = {\n(marketPlacesNameList map {\n  _.map { marketplacesName =&gt;\n    InMemory[ValidationNel[Throwable, MarketPlaceResults]]({\n      cname: String =&gt;  {\n          (riak.fetch(marketplacesName) leftMap { t: NonEmptyList[Throwable] =&gt;\n            new ServiceUnavailableError(marketplacesName, (t.list.map(m =&gt; m.getMessage)).mkString(&quot;\\n&quot;))\n          }).toValidationNel.flatMap { xso: Option[GunnySack] =&gt;\n            xso match {\n              case Some(xs) =&gt; {                    (Validation.fromTryCatchThrowable[models.MarketPlaceResult,Throwable] {                      parse(xs.value).extract[MarketPlaceResult]\n                } leftMap { t: Throwable =&gt;\n                  new ResourceItemNotFound(marketplacesName, t.getMessage)\n                }).toValidationNel.flatMap { j: MarketPlaceResult =&gt;\n                  Validation.success[Throwable, MarketPlaceResults](nels(j.some)).toValidationNel //screwy kishore, every element in a list ?\n                }\n              }\n              case None =&gt; Validation.failure[Throwable, MarketPlaceResults](new ResourceItemNotFound(marketplacesName, &quot;&quot;)).toValidationNel\n            }\n          }\n        }\n    }).get(marketplacesName).eval(InMemoryCache[ValidationNel[Throwable, MarketPlaceResults]]())\n  }\n} map {\n  _.foldRight((MarketPlaceResults.empty).successNel[Throwable])(_ +++ _)\n}).head //return the folded element in the head.\n</code></pre><p>  }</p>\n<p>Lets examine the code. What we are saying here is </p>\n<p><em>I hand you a list of Option[marketplace names], call the db and get me a ValidationNel[Failure/Success result] for each of the list item</em></p>\n<ul>\n<li>The first step is to <strong>map</strong> on the  <em>marketplaceName</em> and start unwrapping what is inside it.</li>\n<li>As the type is <strong>Option[Stream]</strong> we see a double map</li>\n<li>There is a State monad cache <strong>InMemory</strong> used here which basically caches <em>read only information</em> inmemory or memcache as configured. The design details of <strong>State Monad</strong> will be explained in another article.</li>\n<li>For every element <em>marketplacesName</em> see if it came out successful (<strong>leftMap</strong>), if not set <strong>ResourceItemNotFound</strong> for this result</li>\n<li>If the result is successsful, then validate its schema that was stored before and keep accumulating the result</li>\n</ul>\n<p><strong>Note:</strong> Here you see that the computation results are to be store in a list of ValidationNels <strong>List[ValidationNel]</strong></p>\n<ul>\n<li>At the end hence we use <strong>fold</strong> using a <strong>Successful accumulator</strong> to get the <strong>head</strong> which contains the results.</li>\n</ul>\n<p>Super cool. eh!</p>\n<p>###Usage of flatMap</p>\n<p>When you receive the result as <code>Validation</code>, the subsequent  computation needs to handle  (Left) or (Right).</p>\n<p>To do so, we use our friend <code>flatMap</code></p>\n<p>In the below code, we marshall a json to a Scala object called models.AccountInput</p>\n<pre><code>(Validation.fromTryCatch[models.AccountInput] {\n  parse(input).extract[AccountInput]\n} leftMap { t: Throwable =&gt; new MalformedBodyError(input, t.getMessage)\n}).toValidationNel.flatMap { m: AccountInput =&gt;\n</code></pre><p>The result of the marshalling can result in an <strong>exception</strong> or <strong>models.AccountInput</strong> object</p>\n<p>If the results are successful then the <strong>flatMap</strong> will provide the <strong>AccountInput</strong> object as seen above.</p>\n<p>###either[T, S]  \\/</p>\n<p>Wait isnt either \\/ disjunction appear like Validation. </p>\n<p><strong>Note</strong> either \\/  is isomorphic to Validation.</p>\n<p>What the heck is isomorphism. ?</p>\n<p>Isomorphism is a very general concept that derives from the Greek iso, meaning equal, and morphosis, meaning to form or to shape.</p>\n<p>Lets take this example and illustrate how either[T,S] differs from Validation.</p>\n<p>For instance - hit the guys head with a nail 10 times and tell the singular result of failure or success by aggregating everything. </p>\n<ul>\n<li>1st hit [Sucess]</li>\n<li>2nd hit [Failure]</li>\n<li>3rd hit [Success]</li>\n</ul>\n<p>Did the guy duck or get it considering even on hit is a failure ? Yes the answer to the above is <em>[Failure]</em></p>\n<p>Lets study by taking an example.</p>\n<pre><code>(for {\n  resp &lt;- eitherT[IO, NonEmptyList[Throwable], Option[AccountResult]] { //disjunction Throwabel \\/ Option with a Function IO.\n    (Accounts.findByEmail(freq.maybeEmail.get).disjunction).pure[IO]\n  }\n  found &lt;- eitherT[IO, NonEmptyList[Throwable], Option[String]] {\n    val fres = resp.get\n    val calculatedHMAC = GoofyCrypto.calculateHMAC(fres.api_key, freq.mkSign)\n    if (calculatedHMAC === freq.clientAPIHmac.get) {\n      ((&quot;&quot;&quot;Authorization successful for &apos;email:&apos; HMAC matches:\n        |%-10s -&gt; %s\n        |%-10s -&gt; %s\n        |%-10s -&gt; %s&quot;&quot;&quot;.format(&quot;email&quot;, fres.email, &quot;api_key&quot;, fres.api_key, &quot;authority&quot;, fres.authority).stripMargin)\n        .some).right[NonEmptyList[Throwable]].pure[IO]\n    } else {\n      (nels((CannotAuthenticateError(&quot;&quot;&quot;Authorization failure for &apos;email:&apos; HMAC doesn&apos;t match: &apos;%s&apos;.&quot;&quot;&quot;\n        .format(fres.email).stripMargin, &quot;&quot;, UNAUTHORIZED))): NonEmptyList[Throwable]).left[Option[String]].pure[IO]\n    }\n  }\n} yield found).run.map(_.validation).unsafePerformIO()\n</code></pre><p>  }</p>\n<p>  In the above there are two computations <strong>resp, found</strong> that are wrapped in  <strong>eitherT[IO, NonEmptyList[Throwable], Option[T]]</strong></p>\n<p>  The first computation returns the results of Account.findByEmail and wraps it in <strong>pure[IO]</strong></p>\n<p>  The second computation takes the success of the find and see if account is valid and can be authenticated.</p>\n<p>  At the end of the computation you will notice that we yield  the <strong>found</strong> where we convert it to a <strong>Validation</strong> and tell scala to run the unsafe mode now.</p>\n<p>I suppose we have given you an overall perspective of just 3 things in the <strong>scalaz</strong> world.</p>\n<ul>\n<li>map, flatMap </li>\n<li>Validation, ValidationNel</li>\n<li>eitherT</li>\n</ul>\n<p>We had applied the same in how this was used in our awesome <code>api server</code> <a href=\"https://github.com/megamsys\">https://github.com/megamsys</a>.</p>\n<h4 id=\"If-you-guys-want-to-learn-more-then-press-a-few-likes-here-functional-conf\"><a href=\"#If-you-guys-want-to-learn-more-then-press-a-few-likes-here-functional-conf\" class=\"headerlink\" title=\"If you guys want to learn more then press a few likes here functional conf\"></a>If you guys want to learn more then <code>press a few likes here</code> <a href=\"http://confengine.com/functional-conf-2015/proposal/1321/building-a-rest-api-with-scalaz\">functional conf</a></h4>"},{"title":"Docker swarm","slug":"2015-08-26-docker-swarm","date_published":"2015-08-26T04:55:24.891Z","date_updated":"2015-08-26T04:55:24.881Z","_content":"\nThis summer [@megamsys](https://www.megam.io) we started implementing micro services (containers) in baremetal for our customer and our public service in [beta](https://console.megam.io) \n\nThe market largely is about 4 kinds + emerging **unikernel** owing to some of the issues posed on security by the famous [docker](https://docker.com)  \n\n* **Containers in a Virtual machine (VM)**. Everybody uses a fancy terminology, and [we](https://www.megam.io) call it a `DockerBox`. The is by far the easiest to do, since you have isolation handled already inside a  VM.\n\n* **Improvements to containers** like [Rocket](https://coreos.com/blog/rocket/), [Flockport](https://flockport.com),[RancherOS](https://github.com/rancherio/os), [Kurma](https://github.com/apcera/kurma), [Jetpack FreeBSD](https://github.com/3ofcoins/jetpack), [systemd-nspawn](http://www.freedesktop.org/software/systemd/man/systemd-nspawn.html) using **LXC** or **systemd-nspawn** or custom build.\n\n* **Container OS** like [Project atomic](http://www.projectatomic.io/), [CoreOS](https://coreos.com), [Snappy](https://developer.ubuntu.com/en/snappy/), [Nano server - Guess who?](https://channel9.msdn.com/Events/Ignite/2015/BRK2461), [photon ? VWware uggh!](https://github.com/vmware/photon) which helps to run containers inside it.\n\n\n* **Containers in baremetal** Install and run containers on bare metal as this provides profound performance.\n\nThe container market is consolidating with *Big brother* docker  taking the lead in coming up [opencontainers.org](https://opencontainers.org). But we believe docker has the undue advantage as their standard will be superimposed as noted in the [CoreOS](https://coreos.com/blog/app-container-and-the-open-container-project/).\n\nThe emerging one are the **Unikernel or library kernel** which run just one app on top of a hypervisor. This is secure and is still nascent. [we](https://www.megam.io) would eventually like to suppor the above.\n\n### Containers in a VM cluster or CoreOS like\n\n<table border=\"1\">\n    <tr>\n         <td bgcolor=\"#ffc107\">Who</td>\n         <td bgcolor=\"#ffc107\">Link</td>\n         <td bgcolor=\"#ffc107\">Where</td>\n    </tr>\n    <tr>\n        <td>Google container engine</td>\n        <td><a href=\"https://cloud.google.com/container-engine/\" target=\"_blank\">Google</a></td>\n        </td>\n        <td>VM</td>\n    </tr>\n    <tr>\n        <td>Elasticbox</td>\n        <td><a href=\"https://elasticbox.com/\" target=\"_blank\">Elasticbox</a></td>\n        <td>VM</td>\n    </tr>\n    <tr>\n        <td>Panamax by centurylink</td>\n        <td><a href=\"http://panamax.io/\" target=\"_blank\">Panamax</a></td>\n        <td>CoreOS</td>\n    </tr>\n    <tr>\n        <td>Apcera by Ericsson</td>\n        <td><a href=\"https://www.apcera.com/\" target=\"_blank\">Apcera</a></td>\n        <td>Kurma</td>\n    </tr>\n    <tr>\n        <td>Engineyard (DEIS)</td>\n        <td><a href=\"https://deis.com/\" target=\"_blank\">Deis</a></td>\n        <td>CoreOS</td>\n    </tr>\n    <tr>\n        <td>Profitbricks</td>\n        <td><a href=\"https://blog.profitbricks.com/profitbricks-docker-hosting-free-early-access/\" target=\"_blank\">Profitbricks</a></td>\n        <td>Bare metal *maybe</td>\n    </tr>\n    <tr>\n        <td>Krane</td>\n        <td><a href=\"https://github.com/krane-io/krane\" target=\"_blank\">Krane</a></td>\n        <td>VM</td>\n    </tr>   \n    <tr>\n        <td>Joyent Triton</td>\n        <td><a href=\"https://www.joyent.com/developers/triton-faq#what\" target=\"_blank\">Triton</a></td>\n        <td>Don't know</td>\n    </tr>\n    <tr>\n        <td>Shipyard</td>\n        <td><a href=\"http://shipyard-project.com/\" target=\"_blank\">Shipyard</a></td>\n        <td>Onpremise bare metal</td>\n    </tr>\n    <tr>\n        <td>Docker machine</td>\n        <td><a href=\"https://github.com/docker/machine\" target=\"_blank\">Docker</a></td>\n        <td>VM</td>\n    </tr>\n    <tr>\n        <td>Openshift</td>\n        <td><a href=\"http://www.openshift.org/\" target=\"_blank\">Atomic</a></td>\n        <td>VM</td>\n    </tr>\n     <tr>\n        <td>Rancher</td>\n        <td><a href=\"https://rancher.io\" target=\"_blank\">Rancher</a></td>\n        <td>Onpremise bare metal</td>\n    </tr>\n     <tr>\n        <td>Cloudfoundry</td>\n        <td><a href=\"https://github.com/cloudfoundry-incubator/garden\" target=\"_blank\">Garden</a></td>\n        <td>Don't know</td>\n    </tr>\n    <tr>\n        <td>IBM Bluemix</td>\n        <td><a href=\"https://console.ng.bluemix.net/\" target=\"_blank\">Bluemix</a></td>\n        <td>Don't know</td>\n    </tr>\n    <tr>\n        <td>Openstack</td>\n        <td><a href=\"https://wiki.openstack.org/wiki/Docker\" target=\"_blank\">Openstack - Docker</a></td>\n        <td>Don't know *confusing</td>\n    </tr>\n    <tr>\n        <td>Cloudify</td>\n        <td><a href=\"https://getcloudify.org\" target=\"_blank\">Cloudify</a></td>\n        <td>Don't know</td>\n    </tr>   \n    <tr>\n        <td>Photon VMWare</td>\n        <td><a href=\"https://vmware.github.io/photon/\" target=\"_blank\">Photon</a></td>\n        <td>CoreOS like - propretitory</td>\n    </tr>   \n    <tr>\n        <td>runC (new kid)</td>\n        <td><a href=\"https://github.com/opencontainers/runc\" target=\"_blank\">Opencontainers</a></td>\n        <td>Opencontainer - baremetal</td>\n    </tr>   \n</table>\n\n> The funny thing in the above take is how everybody royally screws [Openstack](https://wiki.openstack.org/wiki/Docker) in getting into containers when it doesn't need to. \n\nAnyway last year [we](https://github.com/megamsys) had docker running inside a virtual machine. In our [hackathon](https://blog.docker.com/2014/11/announcing-docker-global-hack-day-2-winners/) we demonstrated running containers inside managed VMs. \n\nBut **containers are best utilized on baremetal**. \n\nWe needed a way to run it inside bare metal.\n\nStay with me, Yes we are warming up with the problem now\n\n> **We need a reliable way to run containers in a datacenter with various clustered hosts**\n\n### What do you mean ? \n\nA picture is worth a 1000 words.\n\n![Megam docker](/content/images/2015/08/megam_baremetal_docker.png)\n\n\nTo do that we need schedulers that can orchestarte and compose containers. We use the term micro service and containers in an interchangeable way, they both mean the same.\n\n### Containers orchestrated by schedulers\n\nLets look at the orchestration for *on premise* baremetal cloud.\n\nIn a unanimous way most companies choose \n\n<table border=\"1\">\n    <tr>\n         <td bgcolor=\"#ffc107\">Who</td>\n         <td bgcolor=\"#ffc107\">Link</td>\n         <td bgcolor=\"#ffc107\">Orchestrator</td>\n    </tr>\n    <tr>\n        <td>Openshift</td>\n        <td><a href=\"https://wiki.openstack.org/wiki/Docker\" target=\"_blank\">Origin</a></td>\n        <td>Kubernetes</td>\n    </tr>\n    <tr>\n        <td>Techtonic</td>\n        <td><a href=\"https://tectonic.com/blog/announcing-tectonic/\" target=\"_blank\">Techtonic - CoreOS</a></td>\n        <td>Kubernetes</td>\n    </tr> \n    <tr>\n        <td>Cloudify</td>\n        <td><a href=\"https://getcloudify.org\" target=\"_blank\">Cloudify</a></td>\n        <td>Don't know</td>\n    </tr> \n    <tr>\n        <td>Docker</td>\n        <td><a href=\"https://docs.docker.com/compose/\" target=\"_blank\">Docker compose</a></td>\n        <td>Fig (Docker compose)</td>\n    </tr> \n     <tr>\n        <td>Rancher</td>\n        <td><a href=\"https://rancher.io\" target=\"_blank\">Rancher</a></td>\n        <td>Don't know</td>\n    </tr> \n    <tr>\n        <td>Panamax by centurylink</td>\n        <td><a href=\"https://panamax.io\" target=\"_blank\">Panamax</a></td>\n        <td>Kubernetes</td>\n    </tr> \n    <tr>\n        <td>Cloudfoundry</td>\n        <td><a href=\"https://github.com/cloudfoundry-incubator/garden\" target=\"_blank\">Garden</a></td>\n        <td>Don't know</td>\n    </tr>     \n</table>\n\nMost vendor use the containter orchestration using **Docker compose [fig]** or **Kubernetes**.\n\nWell at [Megam](https://github.com/megamsy) as seen from the picture we have own omni scheduler built using [golang](http://golang.org)\n\n<table border=\"1\">\n    <tr>\n         <td bgcolor=\"#ffc107\">Who</td>\n         <td bgcolor=\"#ffc107\">Link</td>\n         <td bgcolor=\"#ffc107\">Orchestrator</td>\n    </tr>\n    <tr>\n        <td>Megam</td>\n        <td><a href=\"https://github.com/megamsys/megamd.git\" target=\"_blank\">megamd</a></td>\n        <td>Megam</td>\n    </tr>\n</table>\n\n----\n\n## Diving into the problem \n\n> **We need a reliable way to run containers in a datacenter with various clustered hosts**\n\n### [Docker swarm](https://docs.docker.com/swarm/)\n\nWe started looking at [docker swarm](https://docs.docker.com/swarm/), it sounded so sweat that you can have run *swarm* and just join new docker engine into our \"dockercluster\" on the go as your datacenter nodes expand. \n\n###No we were plain WRONG.\n\n\nWhy ? Since if you visit our architecture, we had **docker engines** running in bunch of servers, and a swarm cluster being formed. The **swarm master** will talk to all the **docker engines** and provision containers on bare metal in a load balanced way in all the hosts. \n\n`Eg:`\n\n* As a developer0 lets say i submitted the first container from [our public beta developer edition - console.megam.io](https://console.megam.io] - Oh yeah you have an [onpremise edition](http://docs.megam.io/docs/what-is-megam-cloud-platform-do)  from a marketplace\n* Similarly developer1 - developer2 submit concurrently to the swarm cluster\n* swarm needs to spread and schedule/load balance the containers on all the hosts equally. \n\nWhereas the current swarm is broken by having a mutex lock to a variable that just waits until the first container that you  submitted is complete.\n\nIn the essence it becomes like a serial operation to submit containers.\n\nWe poked the code high, and found this in the code as fixed here [megamsys/swarm](https://github.com/megamsys/swarm). This may be left intentionally as docker intends to support [Apache mesos](mesos.apache.org)\n\n    // CreateContainer aka schedule a brand new container  into the cluster.\n    func (c *Cluster) CreateContainer(config *cluster.ContainerConfig, name string) (*cluster.Container, error) {\n\t    //*MEGAM* https://www.megam.io remove the mutex scheduler lock\n        //c.scheduler.Lock()\n\t    //defer c.scheduler.Unlock()\n\n\n{<2>}![Code fix](/content/images/2015/07/megam_baremetal_docker-1.png)\n\nOnce we fixed the above code and packaged swarm, it worked like a charm.\n\nWe believe Docker doesn't want to open up its default scheduler but force people to use Mesos. We at Megam are allegic to Java (JVM) as it bloats too much memory and we use judicially.\n\n[Setup and give it a try](http://docs.megam.io). \n","source":"_posts/2015-08-26-docker-swarm.md","raw":"---\ntitle: Docker swarm\nslug: docker-swarm\ndate_published: 2015-08-26T10:25:24.891Z\ndate_updated:   2015-08-26T10:25:24.881Z\n---\n\nThis summer [@megamsys](https://www.megam.io) we started implementing micro services (containers) in baremetal for our customer and our public service in [beta](https://console.megam.io) \n\nThe market largely is about 4 kinds + emerging **unikernel** owing to some of the issues posed on security by the famous [docker](https://docker.com)  \n\n* **Containers in a Virtual machine (VM)**. Everybody uses a fancy terminology, and [we](https://www.megam.io) call it a `DockerBox`. The is by far the easiest to do, since you have isolation handled already inside a  VM.\n\n* **Improvements to containers** like [Rocket](https://coreos.com/blog/rocket/), [Flockport](https://flockport.com),[RancherOS](https://github.com/rancherio/os), [Kurma](https://github.com/apcera/kurma), [Jetpack FreeBSD](https://github.com/3ofcoins/jetpack), [systemd-nspawn](http://www.freedesktop.org/software/systemd/man/systemd-nspawn.html) using **LXC** or **systemd-nspawn** or custom build.\n\n* **Container OS** like [Project atomic](http://www.projectatomic.io/), [CoreOS](https://coreos.com), [Snappy](https://developer.ubuntu.com/en/snappy/), [Nano server - Guess who?](https://channel9.msdn.com/Events/Ignite/2015/BRK2461), [photon ? VWware uggh!](https://github.com/vmware/photon) which helps to run containers inside it.\n\n\n* **Containers in baremetal** Install and run containers on bare metal as this provides profound performance.\n\nThe container market is consolidating with *Big brother* docker  taking the lead in coming up [opencontainers.org](https://opencontainers.org). But we believe docker has the undue advantage as their standard will be superimposed as noted in the [CoreOS](https://coreos.com/blog/app-container-and-the-open-container-project/).\n\nThe emerging one are the **Unikernel or library kernel** which run just one app on top of a hypervisor. This is secure and is still nascent. [we](https://www.megam.io) would eventually like to suppor the above.\n\n### Containers in a VM cluster or CoreOS like\n\n<table border=\"1\">\n    <tr>\n         <td bgcolor=\"#ffc107\">Who</td>\n         <td bgcolor=\"#ffc107\">Link</td>\n         <td bgcolor=\"#ffc107\">Where</td>\n    </tr>\n    <tr>\n        <td>Google container engine</td>\n        <td><a href=\"https://cloud.google.com/container-engine/\" target=\"_blank\">Google</a></td>\n        </td>\n        <td>VM</td>\n    </tr>\n    <tr>\n        <td>Elasticbox</td>\n        <td><a href=\"https://elasticbox.com/\" target=\"_blank\">Elasticbox</a></td>\n        <td>VM</td>\n    </tr>\n    <tr>\n        <td>Panamax by centurylink</td>\n        <td><a href=\"http://panamax.io/\" target=\"_blank\">Panamax</a></td>\n        <td>CoreOS</td>\n    </tr>\n    <tr>\n        <td>Apcera by Ericsson</td>\n        <td><a href=\"https://www.apcera.com/\" target=\"_blank\">Apcera</a></td>\n        <td>Kurma</td>\n    </tr>\n    <tr>\n        <td>Engineyard (DEIS)</td>\n        <td><a href=\"https://deis.com/\" target=\"_blank\">Deis</a></td>\n        <td>CoreOS</td>\n    </tr>\n    <tr>\n        <td>Profitbricks</td>\n        <td><a href=\"https://blog.profitbricks.com/profitbricks-docker-hosting-free-early-access/\" target=\"_blank\">Profitbricks</a></td>\n        <td>Bare metal *maybe</td>\n    </tr>\n    <tr>\n        <td>Krane</td>\n        <td><a href=\"https://github.com/krane-io/krane\" target=\"_blank\">Krane</a></td>\n        <td>VM</td>\n    </tr>   \n    <tr>\n        <td>Joyent Triton</td>\n        <td><a href=\"https://www.joyent.com/developers/triton-faq#what\" target=\"_blank\">Triton</a></td>\n        <td>Don't know</td>\n    </tr>\n    <tr>\n        <td>Shipyard</td>\n        <td><a href=\"http://shipyard-project.com/\" target=\"_blank\">Shipyard</a></td>\n        <td>Onpremise bare metal</td>\n    </tr>\n    <tr>\n        <td>Docker machine</td>\n        <td><a href=\"https://github.com/docker/machine\" target=\"_blank\">Docker</a></td>\n        <td>VM</td>\n    </tr>\n    <tr>\n        <td>Openshift</td>\n        <td><a href=\"http://www.openshift.org/\" target=\"_blank\">Atomic</a></td>\n        <td>VM</td>\n    </tr>\n     <tr>\n        <td>Rancher</td>\n        <td><a href=\"https://rancher.io\" target=\"_blank\">Rancher</a></td>\n        <td>Onpremise bare metal</td>\n    </tr>\n     <tr>\n        <td>Cloudfoundry</td>\n        <td><a href=\"https://github.com/cloudfoundry-incubator/garden\" target=\"_blank\">Garden</a></td>\n        <td>Don't know</td>\n    </tr>\n    <tr>\n        <td>IBM Bluemix</td>\n        <td><a href=\"https://console.ng.bluemix.net/\" target=\"_blank\">Bluemix</a></td>\n        <td>Don't know</td>\n    </tr>\n    <tr>\n        <td>Openstack</td>\n        <td><a href=\"https://wiki.openstack.org/wiki/Docker\" target=\"_blank\">Openstack - Docker</a></td>\n        <td>Don't know *confusing</td>\n    </tr>\n    <tr>\n        <td>Cloudify</td>\n        <td><a href=\"https://getcloudify.org\" target=\"_blank\">Cloudify</a></td>\n        <td>Don't know</td>\n    </tr>   \n    <tr>\n        <td>Photon VMWare</td>\n        <td><a href=\"https://vmware.github.io/photon/\" target=\"_blank\">Photon</a></td>\n        <td>CoreOS like - propretitory</td>\n    </tr>   \n    <tr>\n        <td>runC (new kid)</td>\n        <td><a href=\"https://github.com/opencontainers/runc\" target=\"_blank\">Opencontainers</a></td>\n        <td>Opencontainer - baremetal</td>\n    </tr>   \n</table>\n\n> The funny thing in the above take is how everybody royally screws [Openstack](https://wiki.openstack.org/wiki/Docker) in getting into containers when it doesn't need to. \n\nAnyway last year [we](https://github.com/megamsys) had docker running inside a virtual machine. In our [hackathon](https://blog.docker.com/2014/11/announcing-docker-global-hack-day-2-winners/) we demonstrated running containers inside managed VMs. \n\nBut **containers are best utilized on baremetal**. \n\nWe needed a way to run it inside bare metal.\n\nStay with me, Yes we are warming up with the problem now\n\n> **We need a reliable way to run containers in a datacenter with various clustered hosts**\n\n### What do you mean ? \n\nA picture is worth a 1000 words.\n\n![Megam docker](/content/images/2015/08/megam_baremetal_docker.png)\n\n\nTo do that we need schedulers that can orchestarte and compose containers. We use the term micro service and containers in an interchangeable way, they both mean the same.\n\n### Containers orchestrated by schedulers\n\nLets look at the orchestration for *on premise* baremetal cloud.\n\nIn a unanimous way most companies choose \n\n<table border=\"1\">\n    <tr>\n         <td bgcolor=\"#ffc107\">Who</td>\n         <td bgcolor=\"#ffc107\">Link</td>\n         <td bgcolor=\"#ffc107\">Orchestrator</td>\n    </tr>\n    <tr>\n        <td>Openshift</td>\n        <td><a href=\"https://wiki.openstack.org/wiki/Docker\" target=\"_blank\">Origin</a></td>\n        <td>Kubernetes</td>\n    </tr>\n    <tr>\n        <td>Techtonic</td>\n        <td><a href=\"https://tectonic.com/blog/announcing-tectonic/\" target=\"_blank\">Techtonic - CoreOS</a></td>\n        <td>Kubernetes</td>\n    </tr> \n    <tr>\n        <td>Cloudify</td>\n        <td><a href=\"https://getcloudify.org\" target=\"_blank\">Cloudify</a></td>\n        <td>Don't know</td>\n    </tr> \n    <tr>\n        <td>Docker</td>\n        <td><a href=\"https://docs.docker.com/compose/\" target=\"_blank\">Docker compose</a></td>\n        <td>Fig (Docker compose)</td>\n    </tr> \n     <tr>\n        <td>Rancher</td>\n        <td><a href=\"https://rancher.io\" target=\"_blank\">Rancher</a></td>\n        <td>Don't know</td>\n    </tr> \n    <tr>\n        <td>Panamax by centurylink</td>\n        <td><a href=\"https://panamax.io\" target=\"_blank\">Panamax</a></td>\n        <td>Kubernetes</td>\n    </tr> \n    <tr>\n        <td>Cloudfoundry</td>\n        <td><a href=\"https://github.com/cloudfoundry-incubator/garden\" target=\"_blank\">Garden</a></td>\n        <td>Don't know</td>\n    </tr>     \n</table>\n\nMost vendor use the containter orchestration using **Docker compose [fig]** or **Kubernetes**.\n\nWell at [Megam](https://github.com/megamsy) as seen from the picture we have own omni scheduler built using [golang](http://golang.org)\n\n<table border=\"1\">\n    <tr>\n         <td bgcolor=\"#ffc107\">Who</td>\n         <td bgcolor=\"#ffc107\">Link</td>\n         <td bgcolor=\"#ffc107\">Orchestrator</td>\n    </tr>\n    <tr>\n        <td>Megam</td>\n        <td><a href=\"https://github.com/megamsys/megamd.git\" target=\"_blank\">megamd</a></td>\n        <td>Megam</td>\n    </tr>\n</table>\n\n----\n\n## Diving into the problem \n\n> **We need a reliable way to run containers in a datacenter with various clustered hosts**\n\n### [Docker swarm](https://docs.docker.com/swarm/)\n\nWe started looking at [docker swarm](https://docs.docker.com/swarm/), it sounded so sweat that you can have run *swarm* and just join new docker engine into our \"dockercluster\" on the go as your datacenter nodes expand. \n\n###No we were plain WRONG.\n\n\nWhy ? Since if you visit our architecture, we had **docker engines** running in bunch of servers, and a swarm cluster being formed. The **swarm master** will talk to all the **docker engines** and provision containers on bare metal in a load balanced way in all the hosts. \n\n`Eg:`\n\n* As a developer0 lets say i submitted the first container from [our public beta developer edition - console.megam.io](https://console.megam.io] - Oh yeah you have an [onpremise edition](http://docs.megam.io/docs/what-is-megam-cloud-platform-do)  from a marketplace\n* Similarly developer1 - developer2 submit concurrently to the swarm cluster\n* swarm needs to spread and schedule/load balance the containers on all the hosts equally. \n\nWhereas the current swarm is broken by having a mutex lock to a variable that just waits until the first container that you  submitted is complete.\n\nIn the essence it becomes like a serial operation to submit containers.\n\nWe poked the code high, and found this in the code as fixed here [megamsys/swarm](https://github.com/megamsys/swarm). This may be left intentionally as docker intends to support [Apache mesos](mesos.apache.org)\n\n    // CreateContainer aka schedule a brand new container  into the cluster.\n    func (c *Cluster) CreateContainer(config *cluster.ContainerConfig, name string) (*cluster.Container, error) {\n\t    //*MEGAM* https://www.megam.io remove the mutex scheduler lock\n        //c.scheduler.Lock()\n\t    //defer c.scheduler.Unlock()\n\n\n{<2>}![Code fix](/content/images/2015/07/megam_baremetal_docker-1.png)\n\nOnce we fixed the above code and packaged swarm, it worked like a charm.\n\nWe believe Docker doesn't want to open up its default scheduler but force people to use Mesos. We at Megam are allegic to Java (JVM) as it bloats too much memory and we use judicially.\n\n[Setup and give it a try](http://docs.megam.io). \n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzais0000odrgbjnw9dtc5","content":"<p>This summer <a href=\"https://www.megam.io\">@megamsys</a> we started implementing micro services (containers) in baremetal for our customer and our public service in <a href=\"https://console.megam.io\" target=\"_blank\" rel=\"external\">beta</a> </p>\n<p>The market largely is about 4 kinds + emerging <strong>unikernel</strong> owing to some of the issues posed on security by the famous <a href=\"https://docker.com\" target=\"_blank\" rel=\"external\">docker</a>  </p>\n<ul>\n<li><p><strong>Containers in a Virtual machine (VM)</strong>. Everybody uses a fancy terminology, and <a href=\"https://www.megam.io\">we</a> call it a <code>DockerBox</code>. The is by far the easiest to do, since you have isolation handled already inside a  VM.</p>\n</li>\n<li><p><strong>Improvements to containers</strong> like <a href=\"https://coreos.com/blog/rocket/\" target=\"_blank\" rel=\"external\">Rocket</a>, <a href=\"https://flockport.com\" target=\"_blank\" rel=\"external\">Flockport</a>,<a href=\"https://github.com/rancherio/os\" target=\"_blank\" rel=\"external\">RancherOS</a>, <a href=\"https://github.com/apcera/kurma\" target=\"_blank\" rel=\"external\">Kurma</a>, <a href=\"https://github.com/3ofcoins/jetpack\" target=\"_blank\" rel=\"external\">Jetpack FreeBSD</a>, <a href=\"http://www.freedesktop.org/software/systemd/man/systemd-nspawn.html\" target=\"_blank\" rel=\"external\">systemd-nspawn</a> using <strong>LXC</strong> or <strong>systemd-nspawn</strong> or custom build.</p>\n</li>\n<li><p><strong>Container OS</strong> like <a href=\"http://www.projectatomic.io/\" target=\"_blank\" rel=\"external\">Project atomic</a>, <a href=\"https://coreos.com\" target=\"_blank\" rel=\"external\">CoreOS</a>, <a href=\"https://developer.ubuntu.com/en/snappy/\" target=\"_blank\" rel=\"external\">Snappy</a>, <a href=\"https://channel9.msdn.com/Events/Ignite/2015/BRK2461\" target=\"_blank\" rel=\"external\">Nano server - Guess who?</a>, <a href=\"https://github.com/vmware/photon\" target=\"_blank\" rel=\"external\">photon ? VWware uggh!</a> which helps to run containers inside it.</p>\n</li>\n</ul>\n<ul>\n<li><strong>Containers in baremetal</strong> Install and run containers on bare metal as this provides profound performance.</li>\n</ul>\n<p>The container market is consolidating with <em>Big brother</em> docker  taking the lead in coming up <a href=\"https://opencontainers.org\" target=\"_blank\" rel=\"external\">opencontainers.org</a>. But we believe docker has the undue advantage as their standard will be superimposed as noted in the <a href=\"https://coreos.com/blog/app-container-and-the-open-container-project/\" target=\"_blank\" rel=\"external\">CoreOS</a>.</p>\n<p>The emerging one are the <strong>Unikernel or library kernel</strong> which run just one app on top of a hypervisor. This is secure and is still nascent. <a href=\"https://www.megam.io\">we</a> would eventually like to suppor the above.</p>\n<h3 id=\"Containers-in-a-VM-cluster-or-CoreOS-like\"><a href=\"#Containers-in-a-VM-cluster-or-CoreOS-like\" class=\"headerlink\" title=\"Containers in a VM cluster or CoreOS like\"></a>Containers in a VM cluster or CoreOS like</h3><table border=\"1\"><br>    <tr><br>         <td bgcolor=\"#ffc107\">Who</td><br>         <td bgcolor=\"#ffc107\">Link</td><br>         <td bgcolor=\"#ffc107\">Where</td><br>    </tr><br>    <tr><br>        <td>Google container engine</td><br>        <td><a href=\"https://cloud.google.com/container-engine/\" target=\"_blank\">Google</a></td><br>        <br>        <td>VM</td><br>    </tr><br>    <tr><br>        <td>Elasticbox</td><br>        <td><a href=\"https://elasticbox.com/\" target=\"_blank\">Elasticbox</a></td><br>        <td>VM</td><br>    </tr><br>    <tr><br>        <td>Panamax by centurylink</td><br>        <td><a href=\"http://panamax.io/\" target=\"_blank\">Panamax</a></td><br>        <td>CoreOS</td><br>    </tr><br>    <tr><br>        <td>Apcera by Ericsson</td><br>        <td><a href=\"https://www.apcera.com/\" target=\"_blank\">Apcera</a></td><br>        <td>Kurma</td><br>    </tr><br>    <tr><br>        <td>Engineyard (DEIS)</td><br>        <td><a href=\"https://deis.com/\" target=\"_blank\">Deis</a></td><br>        <td>CoreOS</td><br>    </tr><br>    <tr><br>        <td>Profitbricks</td><br>        <td><a href=\"https://blog.profitbricks.com/profitbricks-docker-hosting-free-early-access/\" target=\"_blank\">Profitbricks</a></td><br>        <td>Bare metal <em>maybe</em></td><br>    </tr><br>    <tr><br>        <td>Krane</td><br>        <td><a href=\"https://github.com/krane-io/krane\" target=\"_blank\">Krane</a></td><br>        <td>VM</td><br>    </tr><br>    <tr><br>        <td>Joyent Triton</td><br>        <td><a href=\"https://www.joyent.com/developers/triton-faq#what\" target=\"_blank\">Triton</a></td><br>        <td>Dont know</td><br>    </tr><br>    <tr><br>        <td>Shipyard</td><br>        <td><a href=\"http://shipyard-project.com/\" target=\"_blank\">Shipyard</a></td><br>        <td>Onpremise bare metal</td><br>    </tr><br>    <tr><br>        <td>Docker machine</td><br>        <td><a href=\"https://github.com/docker/machine\" target=\"_blank\">Docker</a></td><br>        <td>VM</td><br>    </tr><br>    <tr><br>        <td>Openshift</td><br>        <td><a href=\"http://www.openshift.org/\" target=\"_blank\">Atomic</a></td><br>        <td>VM</td><br>    </tr><br>     <tr><br>        <td>Rancher</td><br>        <td><a href=\"https://rancher.io\" target=\"_blank\">Rancher</a></td><br>        <td>Onpremise bare metal</td><br>    </tr><br>     <tr><br>        <td>Cloudfoundry</td><br>        <td><a href=\"https://github.com/cloudfoundry-incubator/garden\" target=\"_blank\">Garden</a></td><br>        <td>Dont know</td><br>    </tr><br>    <tr><br>        <td>IBM Bluemix</td><br>        <td><a href=\"https://console.ng.bluemix.net/\" target=\"_blank\">Bluemix</a></td><br>        <td>Dont know</td><br>    </tr><br>    <tr><br>        <td>Openstack</td><br>        <td><a href=\"https://wiki.openstack.org/wiki/Docker\" target=\"_blank\">Openstack - Docker</a></td><br>        <td>Dont know confusing</td><br>    </tr><br>    <tr><br>        <td>Cloudify</td><br>        <td><a href=\"https://getcloudify.org\" target=\"_blank\">Cloudify</a></td><br>        <td>Dont know</td><br>    </tr><br>    <tr><br>        <td>Photon VMWare</td><br>        <td><a href=\"https://vmware.github.io/photon/\" target=\"_blank\">Photon</a></td><br>        <td>CoreOS like - propretitory</td><br>    </tr><br>    <tr><br>        <td>runC (new kid)</td><br>        <td><a href=\"https://github.com/opencontainers/runc\" target=\"_blank\">Opencontainers</a></td><br>        <td>Opencontainer - baremetal</td><br>    </tr><br></table>\n\n<blockquote>\n<p>The funny thing in the above take is how everybody royally screws <a href=\"https://wiki.openstack.org/wiki/Docker\" target=\"_blank\" rel=\"external\">Openstack</a> in getting into containers when it doesnt need to. </p>\n</blockquote>\n<p>Anyway last year <a href=\"https://github.com/megamsys\" target=\"_blank\" rel=\"external\">we</a> had docker running inside a virtual machine. In our <a href=\"https://blog.docker.com/2014/11/announcing-docker-global-hack-day-2-winners/\" target=\"_blank\" rel=\"external\">hackathon</a> we demonstrated running containers inside managed VMs. </p>\n<p>But <strong>containers are best utilized on baremetal</strong>. </p>\n<p>We needed a way to run it inside bare metal.</p>\n<p>Stay with me, Yes we are warming up with the problem now</p>\n<blockquote>\n<p><strong>We need a reliable way to run containers in a datacenter with various clustered hosts</strong></p>\n</blockquote>\n<h3 id=\"What-do-you-mean\"><a href=\"#What-do-you-mean\" class=\"headerlink\" title=\"What do you mean ?\"></a>What do you mean ?</h3><p>A picture is worth a 1000 words.</p>\n<p><img src=\"/content/images/2015/08/megam_baremetal_docker.png\" alt=\"Megam docker\"></p>\n<p>To do that we need schedulers that can orchestarte and compose containers. We use the term micro service and containers in an interchangeable way, they both mean the same.</p>\n<h3 id=\"Containers-orchestrated-by-schedulers\"><a href=\"#Containers-orchestrated-by-schedulers\" class=\"headerlink\" title=\"Containers orchestrated by schedulers\"></a>Containers orchestrated by schedulers</h3><p>Lets look at the orchestration for <em>on premise</em> baremetal cloud.</p>\n<p>In a unanimous way most companies choose </p>\n<table border=\"1\"><br>    <tr><br>         <td bgcolor=\"#ffc107\">Who</td><br>         <td bgcolor=\"#ffc107\">Link</td><br>         <td bgcolor=\"#ffc107\">Orchestrator</td><br>    </tr><br>    <tr><br>        <td>Openshift</td><br>        <td><a href=\"https://wiki.openstack.org/wiki/Docker\" target=\"_blank\">Origin</a></td><br>        <td>Kubernetes</td><br>    </tr><br>    <tr><br>        <td>Techtonic</td><br>        <td><a href=\"https://tectonic.com/blog/announcing-tectonic/\" target=\"_blank\">Techtonic - CoreOS</a></td><br>        <td>Kubernetes</td><br>    </tr><br>    <tr><br>        <td>Cloudify</td><br>        <td><a href=\"https://getcloudify.org\" target=\"_blank\">Cloudify</a></td><br>        <td>Dont know</td><br>    </tr><br>    <tr><br>        <td>Docker</td><br>        <td><a href=\"https://docs.docker.com/compose/\" target=\"_blank\">Docker compose</a></td><br>        <td>Fig (Docker compose)</td><br>    </tr><br>     <tr><br>        <td>Rancher</td><br>        <td><a href=\"https://rancher.io\" target=\"_blank\">Rancher</a></td><br>        <td>Dont know</td><br>    </tr><br>    <tr><br>        <td>Panamax by centurylink</td><br>        <td><a href=\"https://panamax.io\" target=\"_blank\">Panamax</a></td><br>        <td>Kubernetes</td><br>    </tr><br>    <tr><br>        <td>Cloudfoundry</td><br>        <td><a href=\"https://github.com/cloudfoundry-incubator/garden\" target=\"_blank\">Garden</a></td><br>        <td>Dont know</td><br>    </tr><br></table>\n\n<p>Most vendor use the containter orchestration using <strong>Docker compose [fig]</strong> or <strong>Kubernetes</strong>.</p>\n<p>Well at <a href=\"https://github.com/megamsy\" target=\"_blank\" rel=\"external\">Megam</a> as seen from the picture we have own omni scheduler built using <a href=\"http://golang.org\" target=\"_blank\" rel=\"external\">golang</a></p>\n<table border=\"1\"><br>    <tr><br>         <td bgcolor=\"#ffc107\">Who</td><br>         <td bgcolor=\"#ffc107\">Link</td><br>         <td bgcolor=\"#ffc107\">Orchestrator</td><br>    </tr><br>    <tr><br>        <td>Megam</td><br>        <td><a href=\"https://github.com/megamsys/megamd.git\" target=\"_blank\">megamd</a></td><br>        <td>Megam</td><br>    </tr><br></table>\n\n<hr>\n<h2 id=\"Diving-into-the-problem\"><a href=\"#Diving-into-the-problem\" class=\"headerlink\" title=\"Diving into the problem\"></a>Diving into the problem</h2><blockquote>\n<p><strong>We need a reliable way to run containers in a datacenter with various clustered hosts</strong></p>\n</blockquote>\n<h3 id=\"Docker-swarm\"><a href=\"#Docker-swarm\" class=\"headerlink\" title=\"Docker swarm\"></a><a href=\"https://docs.docker.com/swarm/\" target=\"_blank\" rel=\"external\">Docker swarm</a></h3><p>We started looking at <a href=\"https://docs.docker.com/swarm/\" target=\"_blank\" rel=\"external\">docker swarm</a>, it sounded so sweat that you can have run <em>swarm</em> and just join new docker engine into our dockercluster on the go as your datacenter nodes expand. </p>\n<p>###No we were plain WRONG.</p>\n<p>Why ? Since if you visit our architecture, we had <strong>docker engines</strong> running in bunch of servers, and a swarm cluster being formed. The <strong>swarm master</strong> will talk to all the <strong>docker engines</strong> and provision containers on bare metal in a load balanced way in all the hosts. </p>\n<p><code>Eg:</code></p>\n<ul>\n<li>As a developer0 lets say i submitted the first container from <a href=\"https://console.megam.io] - Oh yeah you have an [onpremise edition](http://docs.megam.io/docs/what-is-megam-cloud-platform-do\" target=\"_blank\" rel=\"external\">our public beta developer edition - console.megam.io</a>  from a marketplace</li>\n<li>Similarly developer1 - developer2 submit concurrently to the swarm cluster</li>\n<li>swarm needs to spread and schedule/load balance the containers on all the hosts equally. </li>\n</ul>\n<p>Whereas the current swarm is broken by having a mutex lock to a variable that just waits until the first container that you  submitted is complete.</p>\n<p>In the essence it becomes like a serial operation to submit containers.</p>\n<p>We poked the code high, and found this in the code as fixed here <a href=\"https://github.com/megamsys/swarm\" target=\"_blank\" rel=\"external\">megamsys/swarm</a>. This may be left intentionally as docker intends to support <a href=\"mesos.apache.org\">Apache mesos</a></p>\n<pre><code>// CreateContainer aka schedule a brand new container  into the cluster.\nfunc (c *Cluster) CreateContainer(config *cluster.ContainerConfig, name string) (*cluster.Container, error) {\n    //*MEGAM* https://www.megam.io remove the mutex scheduler lock\n    //c.scheduler.Lock()\n    //defer c.scheduler.Unlock()\n</code></pre><p>{<2>}<img src=\"/content/images/2015/07/megam_baremetal_docker-1.png\" alt=\"Code fix\"></2></p>\n<p>Once we fixed the above code and packaged swarm, it worked like a charm.</p>\n<p>We believe Docker doesnt want to open up its default scheduler but force people to use Mesos. We at Megam are allegic to Java (JVM) as it bloats too much memory and we use judicially.</p>\n<p><a href=\"http://docs.megam.io\" target=\"_blank\" rel=\"external\">Setup and give it a try</a>. </p>\n","excerpt":"","more":"<p>This summer <a href=\"https://www.megam.io\">@megamsys</a> we started implementing micro services (containers) in baremetal for our customer and our public service in <a href=\"https://console.megam.io\">beta</a> </p>\n<p>The market largely is about 4 kinds + emerging <strong>unikernel</strong> owing to some of the issues posed on security by the famous <a href=\"https://docker.com\">docker</a>  </p>\n<ul>\n<li><p><strong>Containers in a Virtual machine (VM)</strong>. Everybody uses a fancy terminology, and <a href=\"https://www.megam.io\">we</a> call it a <code>DockerBox</code>. The is by far the easiest to do, since you have isolation handled already inside a  VM.</p>\n</li>\n<li><p><strong>Improvements to containers</strong> like <a href=\"https://coreos.com/blog/rocket/\">Rocket</a>, <a href=\"https://flockport.com\">Flockport</a>,<a href=\"https://github.com/rancherio/os\">RancherOS</a>, <a href=\"https://github.com/apcera/kurma\">Kurma</a>, <a href=\"https://github.com/3ofcoins/jetpack\">Jetpack FreeBSD</a>, <a href=\"http://www.freedesktop.org/software/systemd/man/systemd-nspawn.html\">systemd-nspawn</a> using <strong>LXC</strong> or <strong>systemd-nspawn</strong> or custom build.</p>\n</li>\n<li><p><strong>Container OS</strong> like <a href=\"http://www.projectatomic.io/\">Project atomic</a>, <a href=\"https://coreos.com\">CoreOS</a>, <a href=\"https://developer.ubuntu.com/en/snappy/\">Snappy</a>, <a href=\"https://channel9.msdn.com/Events/Ignite/2015/BRK2461\">Nano server - Guess who?</a>, <a href=\"https://github.com/vmware/photon\">photon ? VWware uggh!</a> which helps to run containers inside it.</p>\n</li>\n</ul>\n<ul>\n<li><strong>Containers in baremetal</strong> Install and run containers on bare metal as this provides profound performance.</li>\n</ul>\n<p>The container market is consolidating with <em>Big brother</em> docker  taking the lead in coming up <a href=\"https://opencontainers.org\">opencontainers.org</a>. But we believe docker has the undue advantage as their standard will be superimposed as noted in the <a href=\"https://coreos.com/blog/app-container-and-the-open-container-project/\">CoreOS</a>.</p>\n<p>The emerging one are the <strong>Unikernel or library kernel</strong> which run just one app on top of a hypervisor. This is secure and is still nascent. <a href=\"https://www.megam.io\">we</a> would eventually like to suppor the above.</p>\n<h3 id=\"Containers-in-a-VM-cluster-or-CoreOS-like\"><a href=\"#Containers-in-a-VM-cluster-or-CoreOS-like\" class=\"headerlink\" title=\"Containers in a VM cluster or CoreOS like\"></a>Containers in a VM cluster or CoreOS like</h3><table border=\"1\"><br>    <tr><br>         <td bgcolor=\"#ffc107\">Who</td><br>         <td bgcolor=\"#ffc107\">Link</td><br>         <td bgcolor=\"#ffc107\">Where</td><br>    </tr><br>    <tr><br>        <td>Google container engine</td><br>        <td><a href=\"https://cloud.google.com/container-engine/\" target=\"_blank\">Google</a></td><br>        </td><br>        <td>VM</td><br>    </tr><br>    <tr><br>        <td>Elasticbox</td><br>        <td><a href=\"https://elasticbox.com/\" target=\"_blank\">Elasticbox</a></td><br>        <td>VM</td><br>    </tr><br>    <tr><br>        <td>Panamax by centurylink</td><br>        <td><a href=\"http://panamax.io/\" target=\"_blank\">Panamax</a></td><br>        <td>CoreOS</td><br>    </tr><br>    <tr><br>        <td>Apcera by Ericsson</td><br>        <td><a href=\"https://www.apcera.com/\" target=\"_blank\">Apcera</a></td><br>        <td>Kurma</td><br>    </tr><br>    <tr><br>        <td>Engineyard (DEIS)</td><br>        <td><a href=\"https://deis.com/\" target=\"_blank\">Deis</a></td><br>        <td>CoreOS</td><br>    </tr><br>    <tr><br>        <td>Profitbricks</td><br>        <td><a href=\"https://blog.profitbricks.com/profitbricks-docker-hosting-free-early-access/\" target=\"_blank\">Profitbricks</a></td><br>        <td>Bare metal <em>maybe</td><br>    </tr><br>    <tr><br>        <td>Krane</td><br>        <td><a href=\"https://github.com/krane-io/krane\" target=\"_blank\">Krane</a></td><br>        <td>VM</td><br>    </tr><br>    <tr><br>        <td>Joyent Triton</td><br>        <td><a href=\"https://www.joyent.com/developers/triton-faq#what\" target=\"_blank\">Triton</a></td><br>        <td>Dont know</td><br>    </tr><br>    <tr><br>        <td>Shipyard</td><br>        <td><a href=\"http://shipyard-project.com/\" target=\"_blank\">Shipyard</a></td><br>        <td>Onpremise bare metal</td><br>    </tr><br>    <tr><br>        <td>Docker machine</td><br>        <td><a href=\"https://github.com/docker/machine\" target=\"_blank\">Docker</a></td><br>        <td>VM</td><br>    </tr><br>    <tr><br>        <td>Openshift</td><br>        <td><a href=\"http://www.openshift.org/\" target=\"_blank\">Atomic</a></td><br>        <td>VM</td><br>    </tr><br>     <tr><br>        <td>Rancher</td><br>        <td><a href=\"https://rancher.io\" target=\"_blank\">Rancher</a></td><br>        <td>Onpremise bare metal</td><br>    </tr><br>     <tr><br>        <td>Cloudfoundry</td><br>        <td><a href=\"https://github.com/cloudfoundry-incubator/garden\" target=\"_blank\">Garden</a></td><br>        <td>Dont know</td><br>    </tr><br>    <tr><br>        <td>IBM Bluemix</td><br>        <td><a href=\"https://console.ng.bluemix.net/\" target=\"_blank\">Bluemix</a></td><br>        <td>Dont know</td><br>    </tr><br>    <tr><br>        <td>Openstack</td><br>        <td><a href=\"https://wiki.openstack.org/wiki/Docker\" target=\"_blank\">Openstack - Docker</a></td><br>        <td>Dont know </em>confusing</td><br>    </tr><br>    <tr><br>        <td>Cloudify</td><br>        <td><a href=\"https://getcloudify.org\" target=\"_blank\">Cloudify</a></td><br>        <td>Dont know</td><br>    </tr><br>    <tr><br>        <td>Photon VMWare</td><br>        <td><a href=\"https://vmware.github.io/photon/\" target=\"_blank\">Photon</a></td><br>        <td>CoreOS like - propretitory</td><br>    </tr><br>    <tr><br>        <td>runC (new kid)</td><br>        <td><a href=\"https://github.com/opencontainers/runc\" target=\"_blank\">Opencontainers</a></td><br>        <td>Opencontainer - baremetal</td><br>    </tr><br></table>\n\n<blockquote>\n<p>The funny thing in the above take is how everybody royally screws <a href=\"https://wiki.openstack.org/wiki/Docker\">Openstack</a> in getting into containers when it doesnt need to. </p>\n</blockquote>\n<p>Anyway last year <a href=\"https://github.com/megamsys\">we</a> had docker running inside a virtual machine. In our <a href=\"https://blog.docker.com/2014/11/announcing-docker-global-hack-day-2-winners/\">hackathon</a> we demonstrated running containers inside managed VMs. </p>\n<p>But <strong>containers are best utilized on baremetal</strong>. </p>\n<p>We needed a way to run it inside bare metal.</p>\n<p>Stay with me, Yes we are warming up with the problem now</p>\n<blockquote>\n<p><strong>We need a reliable way to run containers in a datacenter with various clustered hosts</strong></p>\n</blockquote>\n<h3 id=\"What-do-you-mean\"><a href=\"#What-do-you-mean\" class=\"headerlink\" title=\"What do you mean ?\"></a>What do you mean ?</h3><p>A picture is worth a 1000 words.</p>\n<p><img src=\"/content/images/2015/08/megam_baremetal_docker.png\" alt=\"Megam docker\"></p>\n<p>To do that we need schedulers that can orchestarte and compose containers. We use the term micro service and containers in an interchangeable way, they both mean the same.</p>\n<h3 id=\"Containers-orchestrated-by-schedulers\"><a href=\"#Containers-orchestrated-by-schedulers\" class=\"headerlink\" title=\"Containers orchestrated by schedulers\"></a>Containers orchestrated by schedulers</h3><p>Lets look at the orchestration for <em>on premise</em> baremetal cloud.</p>\n<p>In a unanimous way most companies choose </p>\n<table border=\"1\"><br>    <tr><br>         <td bgcolor=\"#ffc107\">Who</td><br>         <td bgcolor=\"#ffc107\">Link</td><br>         <td bgcolor=\"#ffc107\">Orchestrator</td><br>    </tr><br>    <tr><br>        <td>Openshift</td><br>        <td><a href=\"https://wiki.openstack.org/wiki/Docker\" target=\"_blank\">Origin</a></td><br>        <td>Kubernetes</td><br>    </tr><br>    <tr><br>        <td>Techtonic</td><br>        <td><a href=\"https://tectonic.com/blog/announcing-tectonic/\" target=\"_blank\">Techtonic - CoreOS</a></td><br>        <td>Kubernetes</td><br>    </tr><br>    <tr><br>        <td>Cloudify</td><br>        <td><a href=\"https://getcloudify.org\" target=\"_blank\">Cloudify</a></td><br>        <td>Dont know</td><br>    </tr><br>    <tr><br>        <td>Docker</td><br>        <td><a href=\"https://docs.docker.com/compose/\" target=\"_blank\">Docker compose</a></td><br>        <td>Fig (Docker compose)</td><br>    </tr><br>     <tr><br>        <td>Rancher</td><br>        <td><a href=\"https://rancher.io\" target=\"_blank\">Rancher</a></td><br>        <td>Dont know</td><br>    </tr><br>    <tr><br>        <td>Panamax by centurylink</td><br>        <td><a href=\"https://panamax.io\" target=\"_blank\">Panamax</a></td><br>        <td>Kubernetes</td><br>    </tr><br>    <tr><br>        <td>Cloudfoundry</td><br>        <td><a href=\"https://github.com/cloudfoundry-incubator/garden\" target=\"_blank\">Garden</a></td><br>        <td>Dont know</td><br>    </tr><br></table>\n\n<p>Most vendor use the containter orchestration using <strong>Docker compose [fig]</strong> or <strong>Kubernetes</strong>.</p>\n<p>Well at <a href=\"https://github.com/megamsy\">Megam</a> as seen from the picture we have own omni scheduler built using <a href=\"http://golang.org\">golang</a></p>\n<table border=\"1\"><br>    <tr><br>         <td bgcolor=\"#ffc107\">Who</td><br>         <td bgcolor=\"#ffc107\">Link</td><br>         <td bgcolor=\"#ffc107\">Orchestrator</td><br>    </tr><br>    <tr><br>        <td>Megam</td><br>        <td><a href=\"https://github.com/megamsys/megamd.git\" target=\"_blank\">megamd</a></td><br>        <td>Megam</td><br>    </tr><br></table>\n\n<hr>\n<h2 id=\"Diving-into-the-problem\"><a href=\"#Diving-into-the-problem\" class=\"headerlink\" title=\"Diving into the problem\"></a>Diving into the problem</h2><blockquote>\n<p><strong>We need a reliable way to run containers in a datacenter with various clustered hosts</strong></p>\n</blockquote>\n<h3 id=\"Docker-swarm\"><a href=\"#Docker-swarm\" class=\"headerlink\" title=\"Docker swarm\"></a><a href=\"https://docs.docker.com/swarm/\">Docker swarm</a></h3><p>We started looking at <a href=\"https://docs.docker.com/swarm/\">docker swarm</a>, it sounded so sweat that you can have run <em>swarm</em> and just join new docker engine into our dockercluster on the go as your datacenter nodes expand. </p>\n<p>###No we were plain WRONG.</p>\n<p>Why ? Since if you visit our architecture, we had <strong>docker engines</strong> running in bunch of servers, and a swarm cluster being formed. The <strong>swarm master</strong> will talk to all the <strong>docker engines</strong> and provision containers on bare metal in a load balanced way in all the hosts. </p>\n<p><code>Eg:</code></p>\n<ul>\n<li>As a developer0 lets say i submitted the first container from <a href=\"https://console.megam.io] - Oh yeah you have an [onpremise edition](http://docs.megam.io/docs/what-is-megam-cloud-platform-do\">our public beta developer edition - console.megam.io</a>  from a marketplace</li>\n<li>Similarly developer1 - developer2 submit concurrently to the swarm cluster</li>\n<li>swarm needs to spread and schedule/load balance the containers on all the hosts equally. </li>\n</ul>\n<p>Whereas the current swarm is broken by having a mutex lock to a variable that just waits until the first container that you  submitted is complete.</p>\n<p>In the essence it becomes like a serial operation to submit containers.</p>\n<p>We poked the code high, and found this in the code as fixed here <a href=\"https://github.com/megamsys/swarm\">megamsys/swarm</a>. This may be left intentionally as docker intends to support <a href=\"mesos.apache.org\">Apache mesos</a></p>\n<pre><code>// CreateContainer aka schedule a brand new container  into the cluster.\nfunc (c *Cluster) CreateContainer(config *cluster.ContainerConfig, name string) (*cluster.Container, error) {\n    //*MEGAM* https://www.megam.io remove the mutex scheduler lock\n    //c.scheduler.Lock()\n    //defer c.scheduler.Unlock()\n</code></pre><p>{<2>}<img src=\"/content/images/2015/07/megam_baremetal_docker-1.png\" alt=\"Code fix\"></p>\n<p>Once we fixed the above code and packaged swarm, it worked like a charm.</p>\n<p>We believe Docker doesnt want to open up its default scheduler but force people to use Mesos. We at Megam are allegic to Java (JVM) as it bloats too much memory and we use judicially.</p>\n<p><a href=\"http://docs.megam.io\">Setup and give it a try</a>. </p>\n"},{"title":"Clustering RabbitMQ","slug":"2015-08-27-rabbitmq-cluster","date_published":"2015-08-27T01:26:17.929Z","date_updated":"2015-12-10T06:36:39.449Z","_content":"\nRabbitMQ is an open source message broker software (sometimes called message-oriented middleware) that implements the Advanced Message Queuing Protocol (AMQP). The RabbitMQ server is written in the Erlang programming language and is built on the Open Telecom Platform framework for clustering and failover.\n\nRabbitMQ clustering simply involves configuring multiple slaves to connect to a master. When RabbitMQ is installed it works as an independent server (and thats just fine, but clustering is recommended for production systems that want High Availability). You need to designate one server as a master, configure it, and then configure slaves to connect to this master. You can read a more thorough clustering guide on their site : https://www.rabbitmq.com/clustering.html. In this post Ive condensed it down to the essentials.\n\n######My cluster setup\n\nEach server is having ubuntu-14.04\n\n\tEach server's hostname should be unique\n    Each server's erlang cookie should be unique\n    \nrabbitmq-master 192.168.1.11\nrabbitmq-slave 192.168.1.12\n\n######Master setup\n\tIPADDRESS is 192.168.1.11\n    Hostname is rabbitmq-master\n    \n1. install rabbitmq-server package\n\n\t\t$ sudo apt-get install rabbitmq-server\n    \n2. Edit `/etc/hosts` and add the entry for slave server\n\n\t\t192.168.1.12 rabbitmq-slave\n3. \nRabbitMQ is built on Erlang. Erlang systems which need to talk to each other must have the same magic cookie. This is a basic security mechanism to prevent unauthorized access to an Erlang system. An Erlang cookie is simply a hash stashed away in a file. \nCopy the file content of \t\n\n\t\t/var/lib/rabbitmq/.erlang.cookie\n\n\n######Slave setup\n\tIPADDRESS is 192.168.1.12\n    Hostname is rabbitmq-slave\n    \n1. install rabbitmq-server package\n\n\t\t$ sudo apt-get install rabbitmq-server\n    \n2. Edit `/etc/hosts` and add the entry for slave server\n\n\t\t192.168.1.11 rabbitmq-master\n3. stop rabbitmq service\n  \n   \t $ sudo service rabbitmq-server stop\n    \n4. Edit the file content of `/var/lib/rabbitmq/.erlang.cookie`\n\n\t\tPaste the content you copied from master server\n    \n5. Create a file \n`$ nano /etc/rabbitmq/rabbitmq.config`\n\n\t\t%%%\n\t\t%% Generated by Chef\n\t\t%%%\n\t\t[\n\t    {kernel, [\n \t    ]},\n      \t{rabbit, [\n\t    {cluster_nodes, ['rabbit@rabbitmq-master','rabbit@rabbitmq-slave']},\n        {tcp_listen_options, [binary, {packet,raw},\n                                  {reuseaddr,true},\n                                  {backlog,128},\n                                  {nodelay,true},\n     \t{exit_on_close,false},\n                                  {keepalive,false}]},\n    \t{default_user, <<\"guest\">>},\n\t    {default_pass, <<\"guest\">>}\n\t    ]}\n\t\t].\n    \n6. Start rabbitmq\n\n\t\t$ sudo service rabbitmq-server start\n\n7. Start the cluster\n\n\t\t$ sudo rabbitmqctl stop_app \n        $ sudo rabbitmqctl reset\n        $ sudo rabbitmqctl start_app\n        \n Taht's it. Now you can check your cluster status\n \n \t\t$ sudo rabbitmqctl cluster_status\n    \n\t\tCluster status of node 'rabbit@rabbitmq-slave' ...\n\t\t[{nodes,[{disc,['rabbit@rabbitmq-master', 'rabbit@rabbitmq-slave']}]},\n\t    {running_nodes,['rabbit@rabbitmq-master', 'rabbit@rabbitmq-slave']},\n\t\t{partitions,[]}]\n\t\t...done.\n        \n\n","source":"_posts/2015-08-27-rabbitmq-cluster.md","raw":"---\ntitle: Clustering RabbitMQ\nslug: rabbitmq-cluster\ndate_published: 2015-08-27T06:56:17.929Z\ndate_updated:   2015-12-10T12:06:39.449Z\n---\n\nRabbitMQ is an open source message broker software (sometimes called message-oriented middleware) that implements the Advanced Message Queuing Protocol (AMQP). The RabbitMQ server is written in the Erlang programming language and is built on the Open Telecom Platform framework for clustering and failover.\n\nRabbitMQ clustering simply involves configuring multiple slaves to connect to a master. When RabbitMQ is installed it works as an independent server (and thats just fine, but clustering is recommended for production systems that want High Availability). You need to designate one server as a master, configure it, and then configure slaves to connect to this master. You can read a more thorough clustering guide on their site : https://www.rabbitmq.com/clustering.html. In this post Ive condensed it down to the essentials.\n\n######My cluster setup\n\nEach server is having ubuntu-14.04\n\n\tEach server's hostname should be unique\n    Each server's erlang cookie should be unique\n    \nrabbitmq-master 192.168.1.11\nrabbitmq-slave 192.168.1.12\n\n######Master setup\n\tIPADDRESS is 192.168.1.11\n    Hostname is rabbitmq-master\n    \n1. install rabbitmq-server package\n\n\t\t$ sudo apt-get install rabbitmq-server\n    \n2. Edit `/etc/hosts` and add the entry for slave server\n\n\t\t192.168.1.12 rabbitmq-slave\n3. \nRabbitMQ is built on Erlang. Erlang systems which need to talk to each other must have the same magic cookie. This is a basic security mechanism to prevent unauthorized access to an Erlang system. An Erlang cookie is simply a hash stashed away in a file. \nCopy the file content of \t\n\n\t\t/var/lib/rabbitmq/.erlang.cookie\n\n\n######Slave setup\n\tIPADDRESS is 192.168.1.12\n    Hostname is rabbitmq-slave\n    \n1. install rabbitmq-server package\n\n\t\t$ sudo apt-get install rabbitmq-server\n    \n2. Edit `/etc/hosts` and add the entry for slave server\n\n\t\t192.168.1.11 rabbitmq-master\n3. stop rabbitmq service\n  \n   \t $ sudo service rabbitmq-server stop\n    \n4. Edit the file content of `/var/lib/rabbitmq/.erlang.cookie`\n\n\t\tPaste the content you copied from master server\n    \n5. Create a file \n`$ nano /etc/rabbitmq/rabbitmq.config`\n\n\t\t%%%\n\t\t%% Generated by Chef\n\t\t%%%\n\t\t[\n\t    {kernel, [\n \t    ]},\n      \t{rabbit, [\n\t    {cluster_nodes, ['rabbit@rabbitmq-master','rabbit@rabbitmq-slave']},\n        {tcp_listen_options, [binary, {packet,raw},\n                                  {reuseaddr,true},\n                                  {backlog,128},\n                                  {nodelay,true},\n     \t{exit_on_close,false},\n                                  {keepalive,false}]},\n    \t{default_user, <<\"guest\">>},\n\t    {default_pass, <<\"guest\">>}\n\t    ]}\n\t\t].\n    \n6. Start rabbitmq\n\n\t\t$ sudo service rabbitmq-server start\n\n7. Start the cluster\n\n\t\t$ sudo rabbitmqctl stop_app \n        $ sudo rabbitmqctl reset\n        $ sudo rabbitmqctl start_app\n        \n Taht's it. Now you can check your cluster status\n \n \t\t$ sudo rabbitmqctl cluster_status\n    \n\t\tCluster status of node 'rabbit@rabbitmq-slave' ...\n\t\t[{nodes,[{disc,['rabbit@rabbitmq-master', 'rabbit@rabbitmq-slave']}]},\n\t    {running_nodes,['rabbit@rabbitmq-master', 'rabbit@rabbitmq-slave']},\n\t\t{partitions,[]}]\n\t\t...done.\n        \n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzais1000pdrgbhdyeg35u","content":"<p>RabbitMQ is an open source message broker software (sometimes called message-oriented middleware) that implements the Advanced Message Queuing Protocol (AMQP). The RabbitMQ server is written in the Erlang programming language and is built on the Open Telecom Platform framework for clustering and failover.</p>\n<p>RabbitMQ clustering simply involves configuring multiple slaves to connect to a master. When RabbitMQ is installed it works as an independent server (and thats just fine, but clustering is recommended for production systems that want High Availability). You need to designate one server as a master, configure it, and then configure slaves to connect to this master. You can read a more thorough clustering guide on their site : <a href=\"https://www.rabbitmq.com/clustering.html\" target=\"_blank\" rel=\"external\">https://www.rabbitmq.com/clustering.html</a>. In this post Ive condensed it down to the essentials.</p>\n<p>######My cluster setup</p>\n<p>Each server is having ubuntu-14.04</p>\n<pre><code>Each server&apos;s hostname should be unique\nEach server&apos;s erlang cookie should be unique\n</code></pre><p>rabbitmq-master 192.168.1.11<br>rabbitmq-slave 192.168.1.12</p>\n<p>######Master setup<br>    IPADDRESS is 192.168.1.11<br>    Hostname is rabbitmq-master</p>\n<ol>\n<li><p>install rabbitmq-server package</p>\n<pre><code>$ sudo apt-get install rabbitmq-server\n</code></pre></li>\n<li><p>Edit <code>/etc/hosts</code> and add the entry for slave server</p>\n<pre><code>192.168.1.12 rabbitmq-slave\n</code></pre></li>\n<li><p>RabbitMQ is built on Erlang. Erlang systems which need to talk to each other must have the same magic cookie. This is a basic security mechanism to prevent unauthorized access to an Erlang system. An Erlang cookie is simply a hash stashed away in a file.<br>Copy the file content of     </p>\n<pre><code>/var/lib/rabbitmq/.erlang.cookie\n</code></pre></li>\n</ol>\n<p>######Slave setup<br>    IPADDRESS is 192.168.1.12<br>    Hostname is rabbitmq-slave</p>\n<ol>\n<li><p>install rabbitmq-server package</p>\n<pre><code>$ sudo apt-get install rabbitmq-server\n</code></pre></li>\n<li><p>Edit <code>/etc/hosts</code> and add the entry for slave server</p>\n<pre><code>192.168.1.11 rabbitmq-master\n</code></pre></li>\n<li><p>stop rabbitmq service</p>\n<pre><code>$ sudo service rabbitmq-server stop\n</code></pre></li>\n<li><p>Edit the file content of <code>/var/lib/rabbitmq/.erlang.cookie</code></p>\n<pre><code>Paste the content you copied from master server\n</code></pre></li>\n<li><p>Create a file<br><code>$ nano /etc/rabbitmq/rabbitmq.config</code></p>\n<pre><code>%%%\n%% Generated by Chef\n%%%\n[\n{kernel, [\n ]},\n  {rabbit, [\n{cluster_nodes, [&apos;rabbit@rabbitmq-master&apos;,&apos;rabbit@rabbitmq-slave&apos;]},\n{tcp_listen_options, [binary, {packet,raw},\n                          {reuseaddr,true},\n                          {backlog,128},\n                          {nodelay,true},\n {exit_on_close,false},\n                          {keepalive,false}]},\n{default_user, &lt;&lt;&quot;guest&quot;&gt;&gt;},\n{default_pass, &lt;&lt;&quot;guest&quot;&gt;&gt;}\n]}\n].\n</code></pre></li>\n<li><p>Start rabbitmq</p>\n<pre><code>$ sudo service rabbitmq-server start\n</code></pre></li>\n<li><p>Start the cluster</p>\n<pre><code>$ sudo rabbitmqctl stop_app \n$ sudo rabbitmqctl reset\n$ sudo rabbitmqctl start_app\n</code></pre><p>Tahts it. Now you can check your cluster status</p>\n<pre><code> $ sudo rabbitmqctl cluster_status\n\nCluster status of node &apos;rabbit@rabbitmq-slave&apos; ...\n[{nodes,[{disc,[&apos;rabbit@rabbitmq-master&apos;, &apos;rabbit@rabbitmq-slave&apos;]}]},\n{running_nodes,[&apos;rabbit@rabbitmq-master&apos;, &apos;rabbit@rabbitmq-slave&apos;]},\n{partitions,[]}]\n...done.\n</code></pre></li>\n</ol>\n","excerpt":"","more":"<p>RabbitMQ is an open source message broker software (sometimes called message-oriented middleware) that implements the Advanced Message Queuing Protocol (AMQP). The RabbitMQ server is written in the Erlang programming language and is built on the Open Telecom Platform framework for clustering and failover.</p>\n<p>RabbitMQ clustering simply involves configuring multiple slaves to connect to a master. When RabbitMQ is installed it works as an independent server (and thats just fine, but clustering is recommended for production systems that want High Availability). You need to designate one server as a master, configure it, and then configure slaves to connect to this master. You can read a more thorough clustering guide on their site : <a href=\"https://www.rabbitmq.com/clustering.html\">https://www.rabbitmq.com/clustering.html</a>. In this post Ive condensed it down to the essentials.</p>\n<p>######My cluster setup</p>\n<p>Each server is having ubuntu-14.04</p>\n<pre><code>Each server&apos;s hostname should be unique\nEach server&apos;s erlang cookie should be unique\n</code></pre><p>rabbitmq-master 192.168.1.11<br>rabbitmq-slave 192.168.1.12</p>\n<p>######Master setup<br>    IPADDRESS is 192.168.1.11<br>    Hostname is rabbitmq-master</p>\n<ol>\n<li><p>install rabbitmq-server package</p>\n<pre><code>$ sudo apt-get install rabbitmq-server\n</code></pre></li>\n<li><p>Edit <code>/etc/hosts</code> and add the entry for slave server</p>\n<pre><code>192.168.1.12 rabbitmq-slave\n</code></pre></li>\n<li><p>RabbitMQ is built on Erlang. Erlang systems which need to talk to each other must have the same magic cookie. This is a basic security mechanism to prevent unauthorized access to an Erlang system. An Erlang cookie is simply a hash stashed away in a file.<br>Copy the file content of     </p>\n<pre><code>/var/lib/rabbitmq/.erlang.cookie\n</code></pre></li>\n</ol>\n<p>######Slave setup<br>    IPADDRESS is 192.168.1.12<br>    Hostname is rabbitmq-slave</p>\n<ol>\n<li><p>install rabbitmq-server package</p>\n<pre><code>$ sudo apt-get install rabbitmq-server\n</code></pre></li>\n<li><p>Edit <code>/etc/hosts</code> and add the entry for slave server</p>\n<pre><code>192.168.1.11 rabbitmq-master\n</code></pre></li>\n<li><p>stop rabbitmq service</p>\n<pre><code>$ sudo service rabbitmq-server stop\n</code></pre></li>\n<li><p>Edit the file content of <code>/var/lib/rabbitmq/.erlang.cookie</code></p>\n<pre><code>Paste the content you copied from master server\n</code></pre></li>\n<li><p>Create a file<br><code>$ nano /etc/rabbitmq/rabbitmq.config</code></p>\n<pre><code>%%%\n%% Generated by Chef\n%%%\n[\n{kernel, [\n ]},\n  {rabbit, [\n{cluster_nodes, [&apos;rabbit@rabbitmq-master&apos;,&apos;rabbit@rabbitmq-slave&apos;]},\n{tcp_listen_options, [binary, {packet,raw},\n                          {reuseaddr,true},\n                          {backlog,128},\n                          {nodelay,true},\n {exit_on_close,false},\n                          {keepalive,false}]},\n{default_user, &lt;&lt;&quot;guest&quot;&gt;&gt;},\n{default_pass, &lt;&lt;&quot;guest&quot;&gt;&gt;}\n]}\n].\n</code></pre></li>\n<li><p>Start rabbitmq</p>\n<pre><code>$ sudo service rabbitmq-server start\n</code></pre></li>\n<li><p>Start the cluster</p>\n<pre><code>$ sudo rabbitmqctl stop_app \n$ sudo rabbitmqctl reset\n$ sudo rabbitmqctl start_app\n</code></pre><p>Tahts it. Now you can check your cluster status</p>\n<pre><code> $ sudo rabbitmqctl cluster_status\n\nCluster status of node &apos;rabbit@rabbitmq-slave&apos; ...\n[{nodes,[{disc,[&apos;rabbit@rabbitmq-master&apos;, &apos;rabbit@rabbitmq-slave&apos;]}]},\n{running_nodes,[&apos;rabbit@rabbitmq-master&apos;, &apos;rabbit@rabbitmq-slave&apos;]},\n{partitions,[]}]\n...done.\n</code></pre></li>\n</ol>\n"},{"title":"Clustering Riak","slug":"2015-08-27-riak-cluster","date_published":"2015-08-27T03:53:06.776Z","date_updated":"2015-11-27T08:58:48.356Z","_content":"\n\n Riak is a distributed NoSQL key-value data store that offers extremely high availability, fault tolerance, operational simplicity and scalability.[2] In addition to the open-source version, it comes in a supported enterprise version and a cloud storage version that is ideal for cloud computing environments. \n \n Written in Erlang, Riak has fault tolerance data replication and automatic data distribution across the cluster for performance and resilience\n \n Riak has a pluggable backend for its core storage, with the default storage backend being Bitcask.[7] LevelDB is also supported.\n \n **System Setup**\n\t\n    \tOS : Ubuntu 14.04.2 LTS\n        Riak : Riak 2.1.1  \nRiak cluster needs atleast two servers. My servers are\n\n\triak1's ip address is 192.168.1.11\n    riak2's ip address is 192.168.1.12\n    \n`Do the installation(install riak step) in all the servers`\n        \n######Install Riak : \nRiak installation in pretty easy. Just wget the debian package from site and dpkg it.\n    \n    $ wget http://s3.amazonaws.com/downloads.basho.com/riak/2.1/2.1.1/ubuntu/trusty/riak_2.1.1-1_amd64.deb\n    $ sudo dpkg -i riak_2.1.1-1_amd64.deb\n    \nAfter installing riak, we need to start it manually. Before starting riak, let's change the riak configuration.\n\nriak's configuraton file is at `/etc/riak/riak.conf`\n\nchange the nodename of riak first,\n\tdefault\n    \n    \tnodename = riak@LOCALHOST_IP\n        \n  Change it as \n  \n  \t\tnodename = riak@SYSTEM_IP_ADDRESS\n        \n  Command to do this change\n  \t\n    \t$ sudo sed -i 's/^[ \\t]*nodename = riak.*/nodename = riak@SYSTEM_IP_ADDRESS/' /etc/riak/riak.conf\n        \n  Where $SYSTEM_IP_ADDRESS is YOUR_LOCAL_SYSTEM_IP\n  \n  In the same way change the http.listner and protobuf.listner ip\n  \n  \t$ sudo sed -i 's/^[ \\t]*listener.http.internal =.*/listener.http.internal = SYSTEM_IP_ADDRESS:8098/' /etc/riak/riak.conf\n  \t$ sudo sed -i 's/^[ \\t]*listener.protobuf.internal =.*/listener.protobuf.internal = SYSTEM_IP_ADDRESS:8087/' /etc/riak/riak.conf\n    \n    \nStart riak in all the servers\n\t\n    $ sudo riak start\n    \nNow you have running riak in all the servers. In my case,\n\n\triak@RIAK1_IP_ADDRESS\n    riak@RIAK2_IP_ADDRESS\nBoth are running without any problem\n\n######Make Cluster\n    \nNow it is time to make cluster\n   \nFrom riak@RIAK1_IP_ADDRESS server, run this commands\n\n\t$ sudo riak-admin cluster join riak@RIAK2_IP_ADDRESS\n    $ sudo riak-admin cluster plan\n\t$ sudo riak-admin cluster commit\n\nThat's it. Servers are clustered. You can check cluster status\n\n\t$ sudo riak-admin cluster status\n    \n\n  The result should be like\n  \n\t  ---- Cluster Status ----\n\tRing ready: true\n\n\t+------------------------+------+-------+-----+-------+\n\t|          node          |status| avail |ring |pending|\n\t+------------------------+------+-------+-----+-------+\n\t|     riak@RIAK1_IP_ADDRESS |valid |  up   | 50.0|  --   |\n\t| (C) riak@RIAK2_IP_ADDRESS |valid |  up   | 50.0|  --   |\n\t+------------------------+------+-------+-----+-------+\n\n\tKey: (C) = Claimant; availability marked with '!' is unexpected\n\n\n","source":"_posts/2015-08-27-riak-cluster.md","raw":"---\ntitle: Clustering Riak\nslug: riak-cluster\ndate_published: 2015-08-27T09:23:06.776Z\ndate_updated:   2015-11-27T14:28:48.356Z\n---\n\n\n Riak is a distributed NoSQL key-value data store that offers extremely high availability, fault tolerance, operational simplicity and scalability.[2] In addition to the open-source version, it comes in a supported enterprise version and a cloud storage version that is ideal for cloud computing environments. \n \n Written in Erlang, Riak has fault tolerance data replication and automatic data distribution across the cluster for performance and resilience\n \n Riak has a pluggable backend for its core storage, with the default storage backend being Bitcask.[7] LevelDB is also supported.\n \n **System Setup**\n\t\n    \tOS : Ubuntu 14.04.2 LTS\n        Riak : Riak 2.1.1  \nRiak cluster needs atleast two servers. My servers are\n\n\triak1's ip address is 192.168.1.11\n    riak2's ip address is 192.168.1.12\n    \n`Do the installation(install riak step) in all the servers`\n        \n######Install Riak : \nRiak installation in pretty easy. Just wget the debian package from site and dpkg it.\n    \n    $ wget http://s3.amazonaws.com/downloads.basho.com/riak/2.1/2.1.1/ubuntu/trusty/riak_2.1.1-1_amd64.deb\n    $ sudo dpkg -i riak_2.1.1-1_amd64.deb\n    \nAfter installing riak, we need to start it manually. Before starting riak, let's change the riak configuration.\n\nriak's configuraton file is at `/etc/riak/riak.conf`\n\nchange the nodename of riak first,\n\tdefault\n    \n    \tnodename = riak@LOCALHOST_IP\n        \n  Change it as \n  \n  \t\tnodename = riak@SYSTEM_IP_ADDRESS\n        \n  Command to do this change\n  \t\n    \t$ sudo sed -i 's/^[ \\t]*nodename = riak.*/nodename = riak@SYSTEM_IP_ADDRESS/' /etc/riak/riak.conf\n        \n  Where $SYSTEM_IP_ADDRESS is YOUR_LOCAL_SYSTEM_IP\n  \n  In the same way change the http.listner and protobuf.listner ip\n  \n  \t$ sudo sed -i 's/^[ \\t]*listener.http.internal =.*/listener.http.internal = SYSTEM_IP_ADDRESS:8098/' /etc/riak/riak.conf\n  \t$ sudo sed -i 's/^[ \\t]*listener.protobuf.internal =.*/listener.protobuf.internal = SYSTEM_IP_ADDRESS:8087/' /etc/riak/riak.conf\n    \n    \nStart riak in all the servers\n\t\n    $ sudo riak start\n    \nNow you have running riak in all the servers. In my case,\n\n\triak@RIAK1_IP_ADDRESS\n    riak@RIAK2_IP_ADDRESS\nBoth are running without any problem\n\n######Make Cluster\n    \nNow it is time to make cluster\n   \nFrom riak@RIAK1_IP_ADDRESS server, run this commands\n\n\t$ sudo riak-admin cluster join riak@RIAK2_IP_ADDRESS\n    $ sudo riak-admin cluster plan\n\t$ sudo riak-admin cluster commit\n\nThat's it. Servers are clustered. You can check cluster status\n\n\t$ sudo riak-admin cluster status\n    \n\n  The result should be like\n  \n\t  ---- Cluster Status ----\n\tRing ready: true\n\n\t+------------------------+------+-------+-----+-------+\n\t|          node          |status| avail |ring |pending|\n\t+------------------------+------+-------+-----+-------+\n\t|     riak@RIAK1_IP_ADDRESS |valid |  up   | 50.0|  --   |\n\t| (C) riak@RIAK2_IP_ADDRESS |valid |  up   | 50.0|  --   |\n\t+------------------------+------+-------+-----+-------+\n\n\tKey: (C) = Claimant; availability marked with '!' is unexpected\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzais4000rdrgbrux38d5k","content":"<p> Riak is a distributed NoSQL key-value data store that offers extremely high availability, fault tolerance, operational simplicity and scalability.[2] In addition to the open-source version, it comes in a supported enterprise version and a cloud storage version that is ideal for cloud computing environments. </p>\n<p> Written in Erlang, Riak has fault tolerance data replication and automatic data distribution across the cluster for performance and resilience</p>\n<p> Riak has a pluggable backend for its core storage, with the default storage backend being Bitcask.[7] LevelDB is also supported.</p>\n<p> <strong>System Setup</strong></p>\n<pre><code>OS : Ubuntu 14.04.2 LTS\nRiak : Riak 2.1.1  \n</code></pre><p>Riak cluster needs atleast two servers. My servers are</p>\n<pre><code>riak1&apos;s ip address is 192.168.1.11\nriak2&apos;s ip address is 192.168.1.12\n</code></pre><p><code>Do the installation(install riak step) in all the servers</code></p>\n<p>######Install Riak :<br>Riak installation in pretty easy. Just wget the debian package from site and dpkg it.</p>\n<pre><code>$ wget http://s3.amazonaws.com/downloads.basho.com/riak/2.1/2.1.1/ubuntu/trusty/riak_2.1.1-1_amd64.deb\n$ sudo dpkg -i riak_2.1.1-1_amd64.deb\n</code></pre><p>After installing riak, we need to start it manually. Before starting riak, lets change the riak configuration.</p>\n<p>riaks configuraton file is at <code>/etc/riak/riak.conf</code></p>\n<p>change the nodename of riak first,<br>    default</p>\n<pre><code>nodename = riak@LOCALHOST_IP\n</code></pre><p>  Change it as </p>\n<pre><code>nodename = riak@SYSTEM_IP_ADDRESS\n</code></pre><p>  Command to do this change</p>\n<pre><code>$ sudo sed -i &apos;s/^[ \\t]*nodename = riak.*/nodename = riak@SYSTEM_IP_ADDRESS/&apos; /etc/riak/riak.conf\n</code></pre><p>  Where $SYSTEM_IP_ADDRESS is YOUR_LOCAL_SYSTEM_IP</p>\n<p>  In the same way change the http.listner and protobuf.listner ip</p>\n<pre><code>$ sudo sed -i &apos;s/^[ \\t]*listener.http.internal =.*/listener.http.internal = SYSTEM_IP_ADDRESS:8098/&apos; /etc/riak/riak.conf\n$ sudo sed -i &apos;s/^[ \\t]*listener.protobuf.internal =.*/listener.protobuf.internal = SYSTEM_IP_ADDRESS:8087/&apos; /etc/riak/riak.conf\n</code></pre><p>Start riak in all the servers</p>\n<pre><code>$ sudo riak start\n</code></pre><p>Now you have running riak in all the servers. In my case,</p>\n<pre><code>riak@RIAK1_IP_ADDRESS\nriak@RIAK2_IP_ADDRESS\n</code></pre><p>Both are running without any problem</p>\n<p>######Make Cluster</p>\n<p>Now it is time to make cluster</p>\n<p>From riak@RIAK1_IP_ADDRESS server, run this commands</p>\n<pre><code>$ sudo riak-admin cluster join riak@RIAK2_IP_ADDRESS\n$ sudo riak-admin cluster plan\n$ sudo riak-admin cluster commit\n</code></pre><p>Thats it. Servers are clustered. You can check cluster status</p>\n<pre><code>$ sudo riak-admin cluster status\n</code></pre><p>  The result should be like</p>\n<pre><code>  ---- Cluster Status ----\nRing ready: true\n\n+------------------------+------+-------+-----+-------+\n|          node          |status| avail |ring |pending|\n+------------------------+------+-------+-----+-------+\n|     riak@RIAK1_IP_ADDRESS |valid |  up   | 50.0|  --   |\n| (C) riak@RIAK2_IP_ADDRESS |valid |  up   | 50.0|  --   |\n+------------------------+------+-------+-----+-------+\n\nKey: (C) = Claimant; availability marked with &apos;!&apos; is unexpected\n</code></pre>","excerpt":"","more":"<p> Riak is a distributed NoSQL key-value data store that offers extremely high availability, fault tolerance, operational simplicity and scalability.[2] In addition to the open-source version, it comes in a supported enterprise version and a cloud storage version that is ideal for cloud computing environments. </p>\n<p> Written in Erlang, Riak has fault tolerance data replication and automatic data distribution across the cluster for performance and resilience</p>\n<p> Riak has a pluggable backend for its core storage, with the default storage backend being Bitcask.[7] LevelDB is also supported.</p>\n<p> <strong>System Setup</strong></p>\n<pre><code>OS : Ubuntu 14.04.2 LTS\nRiak : Riak 2.1.1  \n</code></pre><p>Riak cluster needs atleast two servers. My servers are</p>\n<pre><code>riak1&apos;s ip address is 192.168.1.11\nriak2&apos;s ip address is 192.168.1.12\n</code></pre><p><code>Do the installation(install riak step) in all the servers</code></p>\n<p>######Install Riak :<br>Riak installation in pretty easy. Just wget the debian package from site and dpkg it.</p>\n<pre><code>$ wget http://s3.amazonaws.com/downloads.basho.com/riak/2.1/2.1.1/ubuntu/trusty/riak_2.1.1-1_amd64.deb\n$ sudo dpkg -i riak_2.1.1-1_amd64.deb\n</code></pre><p>After installing riak, we need to start it manually. Before starting riak, lets change the riak configuration.</p>\n<p>riaks configuraton file is at <code>/etc/riak/riak.conf</code></p>\n<p>change the nodename of riak first,<br>    default</p>\n<pre><code>nodename = riak@LOCALHOST_IP\n</code></pre><p>  Change it as </p>\n<pre><code>nodename = riak@SYSTEM_IP_ADDRESS\n</code></pre><p>  Command to do this change</p>\n<pre><code>$ sudo sed -i &apos;s/^[ \\t]*nodename = riak.*/nodename = riak@SYSTEM_IP_ADDRESS/&apos; /etc/riak/riak.conf\n</code></pre><p>  Where $SYSTEM_IP_ADDRESS is YOUR_LOCAL_SYSTEM_IP</p>\n<p>  In the same way change the http.listner and protobuf.listner ip</p>\n<pre><code>$ sudo sed -i &apos;s/^[ \\t]*listener.http.internal =.*/listener.http.internal = SYSTEM_IP_ADDRESS:8098/&apos; /etc/riak/riak.conf\n$ sudo sed -i &apos;s/^[ \\t]*listener.protobuf.internal =.*/listener.protobuf.internal = SYSTEM_IP_ADDRESS:8087/&apos; /etc/riak/riak.conf\n</code></pre><p>Start riak in all the servers</p>\n<pre><code>$ sudo riak start\n</code></pre><p>Now you have running riak in all the servers. In my case,</p>\n<pre><code>riak@RIAK1_IP_ADDRESS\nriak@RIAK2_IP_ADDRESS\n</code></pre><p>Both are running without any problem</p>\n<p>######Make Cluster</p>\n<p>Now it is time to make cluster</p>\n<p>From riak@RIAK1_IP_ADDRESS server, run this commands</p>\n<pre><code>$ sudo riak-admin cluster join riak@RIAK2_IP_ADDRESS\n$ sudo riak-admin cluster plan\n$ sudo riak-admin cluster commit\n</code></pre><p>Thats it. Servers are clustered. You can check cluster status</p>\n<pre><code>$ sudo riak-admin cluster status\n</code></pre><p>  The result should be like</p>\n<pre><code>  ---- Cluster Status ----\nRing ready: true\n\n+------------------------+------+-------+-----+-------+\n|          node          |status| avail |ring |pending|\n+------------------------+------+-------+-----+-------+\n|     riak@RIAK1_IP_ADDRESS |valid |  up   | 50.0|  --   |\n| (C) riak@RIAK2_IP_ADDRESS |valid |  up   | 50.0|  --   |\n+------------------------+------+-------+-----+-------+\n\nKey: (C) = Claimant; availability marked with &apos;!&apos; is unexpected\n</code></pre>"},{"title":"MySQL Master-Slave Replication","slug":"2015-09-08-mysql-master-slave-replication","date_published":"2015-09-08T01:13:00.000Z","date_updated":"2015-09-30T02:01:06.317Z","_content":"\nMySQL is the world's most popular open source database.  MySQL can cost-effectively help you deliver high performance, scalable database applications.\n\n######REPLICATION\n   \n  Master-slave data replication allows for replicated data to be copied to multiple computers for backup and analysis by multiple parties. Needed changes identified by a group member must to be submitted to the designated \"master\" of the node. This differs from Master-Master replication, in which data can be updated by any authorized contributor of the group.\n\nThis article provides information to setting up MySQL master-slave database replication between two cloud servers.\n\n \nSYSTEM SETUP\n\t\t\n        OS\t : Ubuntu 14.04.2\n        MySQL  : MySQL 5.5\n        \nSERVERS\n\t\t    \nMySQL replication needs atleast two servers, one act as master and others act as slaves. Master performs both write and read it replicates in all slaves. Slave also can write but it modified only in it's database.It does not replicate in any slaves.\n\nMy Servers are \n        \n        server1 : 192.168.1.12\n        server2 : 192.168.1.13\n  \n  \n  here we use server1 as master and server2 as slave. \n\n \n######Install and Configure MySQL in Master Server\n \t\t\n        $ sudo apt-get install mysql-server \n        \n    \n After installing MYSQL, have to configure it\n\n\t\t$ nano /etc/mysql/my.cnf\n        \nChange bind-address to point to the Server1 IP address.\n\t\t\n        bind-address   = 192.168.1.12\n\nJust remove the comment for server-id and log_bin and save the file.\n\n\t\tlog_bin        = /var/log/mysql/mysql-bin.log\n\nChange the Server id as an unique positive Integer.\n\t\t\n        server-id      = 1234\n        \n   note: use different id for server2. \nRestart the mysql service.\n\n\t\t$ sudo service mysql restart\n        \n        \n**Grant Replication to Slave** \n\nCreate a mysql user with password identification.\n\n    $ mysql -u root -p pswd\n        \n    mysql> create user 'DBUSERNAME'@'%' IDENTIFIED BY 'slavepass';\n\nGrant Slave replication Permission to that user.\n    \n\t\tmysql> grant replication slave on *.* to 'DBUSERNAME'@'%'\n    \n**Create your own database**\n\nCreate database \n\n    mysql> create database dbnew1\nCreate table\n    \n    mysql> create table dbnew1.student(s_name varchar(20),s_id int);\n    \nInsert data whatever you want \n\n\t\tmysql> insert into dbnew1.student('Devid',1001);\n \nAfter insertion exit mysql\n       \n        mysql> exit\n        \n**Backup the MySql Database and Send to Slave**\n\n\n \"mysqldump\" is an effective tool to backup MySQL database. It creates a *.sql file with DROP table, CREATE table and INSERT into sql-statements of the source database. To restore the database,  execute the *.sql file on destination database. \n     \n     Syntax:  mysqldump -u root -p[root_password] [database_name] > dumpfilename.sql\n\n     $ mysqldump -u root -p pswd --all-databases --master-data >masterdump.sql\n     \n to verify the databases backup\n \n     $grep CHANGE *sql  | head -1 \n    \n    CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=919;\n     \nsend the dumpfile.sql to slave server.\n\n       $ scp masterdump.sql 192.168.1.13:\n                   or\n       $ sftp server2@192.168.1.13            \n     \n######Install and Configure MySQL in Slave Server\n\n   \t $ sudo apt-get install mysql-server \n        \n    \n After install MYSQL, have to configure it,\n\n\t\t$ nano /etc/mysql/my.cnf\n        \nChange bind-address to point to slave-ipaddress.\n\t\t\n        bind-address   = 192.168.1.13\n\nChange the Server id to an unique positive Integer.\n\t\t\n        server-id      = 4321\n        \n    \nJust remove the comment for server-id and log_bin and save the file.\n\n\t\tlog_bin        = /var/log/mysql/mysql-bin.log\n        \nRestart the mysql service.\n\n\t\t$ sudo service mysql restart\n        \n        \n**Inform Slave about the master**\n\n\t$ mysql -u root -p pswd\n    \n    mysql> CHANGE MASTER TO MASTER_HOST='192.168.1.12', MASTER_USER='DBUSERNAME', MASTER_PASSWORD='slavepass';\n\n\tmysql> exit\n    \nverify whether you have received the dupmfile.sql before use the following command.\n \n \t$ mysql -u root < masterdump.sql\n\t\nnow open MySQL and start the Slave.\n\n\tmysql> start slave\n    \n    mysql> show slave status\\G;\n    \nIt show the following attribute's value like  \n\n\tSlave_IO_State: Waiting for master to send event\n                  Master_Host: 192.168.1.12\n                  Master_User: DBUSERNAME\n              Master_Log_File: mysql-bin.000001\n             Slave_IO_Running: Yes\n            Slave_SQL_Running: Yes\n             Master_Server_Id: 1234\n\t\t       MASTER_LOG_POS: 919\n               \nnow your slave started check the master replication  \n\n**insert a new row in master server**\n\n\tmysql> use dbnew1\n    \n   \tmysql> insert into stu values('John',1004);\n    mysql> select * from stu;\n\t+-----------+-------+\n\t| s_name \t| s_id \t|\n\t+----------+--------+\n\t| Devid   \t| 1001 \t|\n\t| mathi\t\t| 1002 \t|\n\t| thomas \t| 1003 \t|\n\t| john     \t| 1004 \t|\n\t+------- ---+-------+\n\t4 rows in set (0.00 sec)\n\n**show table in Slave Server**\n       \n    mysql> use dbnew1   \n\tmysql> select * from stu;\n\t+-----------+-------+\n\t| s_name \t| s_id \t|\n\t+----------+--------+\n\t| Devid   \t| 1001 \t|\n\t| mathi\t\t| 1002 \t|\n\t| thomas \t| 1003 \t|\n\t| john     \t| 1004 \t|\n\t+------- ---+-------+\n\t4 rows in set (0.00 sec)\n\nMySQL Master-slave replication tested.\n\nThank you.\n","source":"_posts/2015-09-08-mysql-master-slave-replication.md","raw":"---\ntitle: MySQL Master-Slave Replication\nslug: mysql-master-slave-replication\ndate_published: 2015-09-08T06:43:00.000Z\ndate_updated:   2015-09-30T07:31:06.317Z\n---\n\nMySQL is the world's most popular open source database.  MySQL can cost-effectively help you deliver high performance, scalable database applications.\n\n######REPLICATION\n   \n  Master-slave data replication allows for replicated data to be copied to multiple computers for backup and analysis by multiple parties. Needed changes identified by a group member must to be submitted to the designated \"master\" of the node. This differs from Master-Master replication, in which data can be updated by any authorized contributor of the group.\n\nThis article provides information to setting up MySQL master-slave database replication between two cloud servers.\n\n \nSYSTEM SETUP\n\t\t\n        OS\t : Ubuntu 14.04.2\n        MySQL  : MySQL 5.5\n        \nSERVERS\n\t\t    \nMySQL replication needs atleast two servers, one act as master and others act as slaves. Master performs both write and read it replicates in all slaves. Slave also can write but it modified only in it's database.It does not replicate in any slaves.\n\nMy Servers are \n        \n        server1 : 192.168.1.12\n        server2 : 192.168.1.13\n  \n  \n  here we use server1 as master and server2 as slave. \n\n \n######Install and Configure MySQL in Master Server\n \t\t\n        $ sudo apt-get install mysql-server \n        \n    \n After installing MYSQL, have to configure it\n\n\t\t$ nano /etc/mysql/my.cnf\n        \nChange bind-address to point to the Server1 IP address.\n\t\t\n        bind-address   = 192.168.1.12\n\nJust remove the comment for server-id and log_bin and save the file.\n\n\t\tlog_bin        = /var/log/mysql/mysql-bin.log\n\nChange the Server id as an unique positive Integer.\n\t\t\n        server-id      = 1234\n        \n   note: use different id for server2. \nRestart the mysql service.\n\n\t\t$ sudo service mysql restart\n        \n        \n**Grant Replication to Slave** \n\nCreate a mysql user with password identification.\n\n    $ mysql -u root -p pswd\n        \n    mysql> create user 'DBUSERNAME'@'%' IDENTIFIED BY 'slavepass';\n\nGrant Slave replication Permission to that user.\n    \n\t\tmysql> grant replication slave on *.* to 'DBUSERNAME'@'%'\n    \n**Create your own database**\n\nCreate database \n\n    mysql> create database dbnew1\nCreate table\n    \n    mysql> create table dbnew1.student(s_name varchar(20),s_id int);\n    \nInsert data whatever you want \n\n\t\tmysql> insert into dbnew1.student('Devid',1001);\n \nAfter insertion exit mysql\n       \n        mysql> exit\n        \n**Backup the MySql Database and Send to Slave**\n\n\n \"mysqldump\" is an effective tool to backup MySQL database. It creates a *.sql file with DROP table, CREATE table and INSERT into sql-statements of the source database. To restore the database,  execute the *.sql file on destination database. \n     \n     Syntax:  mysqldump -u root -p[root_password] [database_name] > dumpfilename.sql\n\n     $ mysqldump -u root -p pswd --all-databases --master-data >masterdump.sql\n     \n to verify the databases backup\n \n     $grep CHANGE *sql  | head -1 \n    \n    CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=919;\n     \nsend the dumpfile.sql to slave server.\n\n       $ scp masterdump.sql 192.168.1.13:\n                   or\n       $ sftp server2@192.168.1.13            \n     \n######Install and Configure MySQL in Slave Server\n\n   \t $ sudo apt-get install mysql-server \n        \n    \n After install MYSQL, have to configure it,\n\n\t\t$ nano /etc/mysql/my.cnf\n        \nChange bind-address to point to slave-ipaddress.\n\t\t\n        bind-address   = 192.168.1.13\n\nChange the Server id to an unique positive Integer.\n\t\t\n        server-id      = 4321\n        \n    \nJust remove the comment for server-id and log_bin and save the file.\n\n\t\tlog_bin        = /var/log/mysql/mysql-bin.log\n        \nRestart the mysql service.\n\n\t\t$ sudo service mysql restart\n        \n        \n**Inform Slave about the master**\n\n\t$ mysql -u root -p pswd\n    \n    mysql> CHANGE MASTER TO MASTER_HOST='192.168.1.12', MASTER_USER='DBUSERNAME', MASTER_PASSWORD='slavepass';\n\n\tmysql> exit\n    \nverify whether you have received the dupmfile.sql before use the following command.\n \n \t$ mysql -u root < masterdump.sql\n\t\nnow open MySQL and start the Slave.\n\n\tmysql> start slave\n    \n    mysql> show slave status\\G;\n    \nIt show the following attribute's value like  \n\n\tSlave_IO_State: Waiting for master to send event\n                  Master_Host: 192.168.1.12\n                  Master_User: DBUSERNAME\n              Master_Log_File: mysql-bin.000001\n             Slave_IO_Running: Yes\n            Slave_SQL_Running: Yes\n             Master_Server_Id: 1234\n\t\t       MASTER_LOG_POS: 919\n               \nnow your slave started check the master replication  \n\n**insert a new row in master server**\n\n\tmysql> use dbnew1\n    \n   \tmysql> insert into stu values('John',1004);\n    mysql> select * from stu;\n\t+-----------+-------+\n\t| s_name \t| s_id \t|\n\t+----------+--------+\n\t| Devid   \t| 1001 \t|\n\t| mathi\t\t| 1002 \t|\n\t| thomas \t| 1003 \t|\n\t| john     \t| 1004 \t|\n\t+------- ---+-------+\n\t4 rows in set (0.00 sec)\n\n**show table in Slave Server**\n       \n    mysql> use dbnew1   \n\tmysql> select * from stu;\n\t+-----------+-------+\n\t| s_name \t| s_id \t|\n\t+----------+--------+\n\t| Devid   \t| 1001 \t|\n\t| mathi\t\t| 1002 \t|\n\t| thomas \t| 1003 \t|\n\t| john     \t| 1004 \t|\n\t+------- ---+-------+\n\t4 rows in set (0.00 sec)\n\nMySQL Master-slave replication tested.\n\nThank you.\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzais6000sdrgbr2wqfa0c","content":"<p>MySQL is the worlds most popular open source database.  MySQL can cost-effectively help you deliver high performance, scalable database applications.</p>\n<p>######REPLICATION</p>\n<p>  Master-slave data replication allows for replicated data to be copied to multiple computers for backup and analysis by multiple parties. Needed changes identified by a group member must to be submitted to the designated master of the node. This differs from Master-Master replication, in which data can be updated by any authorized contributor of the group.</p>\n<p>This article provides information to setting up MySQL master-slave database replication between two cloud servers.</p>\n<p>SYSTEM SETUP</p>\n<pre><code>OS     : Ubuntu 14.04.2\nMySQL  : MySQL 5.5\n</code></pre><p>SERVERS</p>\n<p>MySQL replication needs atleast two servers, one act as master and others act as slaves. Master performs both write and read it replicates in all slaves. Slave also can write but it modified only in its database.It does not replicate in any slaves.</p>\n<p>My Servers are </p>\n<pre><code>server1 : 192.168.1.12\nserver2 : 192.168.1.13\n</code></pre><p>  here we use server1 as master and server2 as slave. </p>\n<p>######Install and Configure MySQL in Master Server</p>\n<pre><code>$ sudo apt-get install mysql-server \n</code></pre><p> After installing MYSQL, have to configure it</p>\n<pre><code>$ nano /etc/mysql/my.cnf\n</code></pre><p>Change bind-address to point to the Server1 IP address.</p>\n<pre><code>bind-address   = 192.168.1.12\n</code></pre><p>Just remove the comment for server-id and log_bin and save the file.</p>\n<pre><code>log_bin        = /var/log/mysql/mysql-bin.log\n</code></pre><p>Change the Server id as an unique positive Integer.</p>\n<pre><code>server-id      = 1234\n</code></pre><p>   note: use different id for server2.<br>Restart the mysql service.</p>\n<pre><code>$ sudo service mysql restart\n</code></pre><p><strong>Grant Replication to Slave</strong> </p>\n<p>Create a mysql user with password identification.</p>\n<pre><code>$ mysql -u root -p pswd\n\nmysql&gt; create user &apos;DBUSERNAME&apos;@&apos;%&apos; IDENTIFIED BY &apos;slavepass&apos;;\n</code></pre><p>Grant Slave replication Permission to that user.</p>\n<pre><code>mysql&gt; grant replication slave on *.* to &apos;DBUSERNAME&apos;@&apos;%&apos;\n</code></pre><p><strong>Create your own database</strong></p>\n<p>Create database </p>\n<pre><code>mysql&gt; create database dbnew1\n</code></pre><p>Create table</p>\n<pre><code>mysql&gt; create table dbnew1.student(s_name varchar(20),s_id int);\n</code></pre><p>Insert data whatever you want </p>\n<pre><code>mysql&gt; insert into dbnew1.student(&apos;Devid&apos;,1001);\n</code></pre><p>After insertion exit mysql</p>\n<pre><code>mysql&gt; exit\n</code></pre><p><strong>Backup the MySql Database and Send to Slave</strong></p>\n<p> mysqldump is an effective tool to backup MySQL database. It creates a <em>.sql file with DROP table, CREATE table and INSERT into sql-statements of the source database. To restore the database,  execute the </em>.sql file on destination database. </p>\n<pre><code>Syntax:  mysqldump -u root -p[root_password] [database_name] &gt; dumpfilename.sql\n\n$ mysqldump -u root -p pswd --all-databases --master-data &gt;masterdump.sql\n</code></pre><p> to verify the databases backup</p>\n<pre><code> $grep CHANGE *sql  | head -1 \n\nCHANGE MASTER TO MASTER_LOG_FILE=&apos;mysql-bin.000001&apos;, MASTER_LOG_POS=919;\n</code></pre><p>send the dumpfile.sql to slave server.</p>\n<pre><code>$ scp masterdump.sql 192.168.1.13:\n            or\n$ sftp server2@192.168.1.13            \n</code></pre><p>######Install and Configure MySQL in Slave Server</p>\n<pre><code>$ sudo apt-get install mysql-server \n</code></pre><p> After install MYSQL, have to configure it,</p>\n<pre><code>$ nano /etc/mysql/my.cnf\n</code></pre><p>Change bind-address to point to slave-ipaddress.</p>\n<pre><code>bind-address   = 192.168.1.13\n</code></pre><p>Change the Server id to an unique positive Integer.</p>\n<pre><code>server-id      = 4321\n</code></pre><p>Just remove the comment for server-id and log_bin and save the file.</p>\n<pre><code>log_bin        = /var/log/mysql/mysql-bin.log\n</code></pre><p>Restart the mysql service.</p>\n<pre><code>$ sudo service mysql restart\n</code></pre><p><strong>Inform Slave about the master</strong></p>\n<pre><code>$ mysql -u root -p pswd\n\nmysql&gt; CHANGE MASTER TO MASTER_HOST=&apos;192.168.1.12&apos;, MASTER_USER=&apos;DBUSERNAME&apos;, MASTER_PASSWORD=&apos;slavepass&apos;;\n\nmysql&gt; exit\n</code></pre><p>verify whether you have received the dupmfile.sql before use the following command.</p>\n<pre><code>$ mysql -u root &lt; masterdump.sql\n</code></pre><p>now open MySQL and start the Slave.</p>\n<pre><code>mysql&gt; start slave\n\nmysql&gt; show slave status\\G;\n</code></pre><p>It show the following attributes value like  </p>\n<pre><code>Slave_IO_State: Waiting for master to send event\n              Master_Host: 192.168.1.12\n              Master_User: DBUSERNAME\n          Master_Log_File: mysql-bin.000001\n         Slave_IO_Running: Yes\n        Slave_SQL_Running: Yes\n         Master_Server_Id: 1234\n           MASTER_LOG_POS: 919\n</code></pre><p>now your slave started check the master replication  </p>\n<p><strong>insert a new row in master server</strong></p>\n<pre><code>mysql&gt; use dbnew1\n\n   mysql&gt; insert into stu values(&apos;John&apos;,1004);\nmysql&gt; select * from stu;\n+-----------+-------+\n| s_name     | s_id     |\n+----------+--------+\n| Devid       | 1001     |\n| mathi        | 1002     |\n| thomas     | 1003     |\n| john         | 1004     |\n+------- ---+-------+\n4 rows in set (0.00 sec)\n</code></pre><p><strong>show table in Slave Server</strong></p>\n<pre><code>mysql&gt; use dbnew1   \nmysql&gt; select * from stu;\n+-----------+-------+\n| s_name     | s_id     |\n+----------+--------+\n| Devid       | 1001     |\n| mathi        | 1002     |\n| thomas     | 1003     |\n| john         | 1004     |\n+------- ---+-------+\n4 rows in set (0.00 sec)\n</code></pre><p>MySQL Master-slave replication tested.</p>\n<p>Thank you.</p>\n","excerpt":"","more":"<p>MySQL is the worlds most popular open source database.  MySQL can cost-effectively help you deliver high performance, scalable database applications.</p>\n<p>######REPLICATION</p>\n<p>  Master-slave data replication allows for replicated data to be copied to multiple computers for backup and analysis by multiple parties. Needed changes identified by a group member must to be submitted to the designated master of the node. This differs from Master-Master replication, in which data can be updated by any authorized contributor of the group.</p>\n<p>This article provides information to setting up MySQL master-slave database replication between two cloud servers.</p>\n<p>SYSTEM SETUP</p>\n<pre><code>OS     : Ubuntu 14.04.2\nMySQL  : MySQL 5.5\n</code></pre><p>SERVERS</p>\n<p>MySQL replication needs atleast two servers, one act as master and others act as slaves. Master performs both write and read it replicates in all slaves. Slave also can write but it modified only in its database.It does not replicate in any slaves.</p>\n<p>My Servers are </p>\n<pre><code>server1 : 192.168.1.12\nserver2 : 192.168.1.13\n</code></pre><p>  here we use server1 as master and server2 as slave. </p>\n<p>######Install and Configure MySQL in Master Server</p>\n<pre><code>$ sudo apt-get install mysql-server \n</code></pre><p> After installing MYSQL, have to configure it</p>\n<pre><code>$ nano /etc/mysql/my.cnf\n</code></pre><p>Change bind-address to point to the Server1 IP address.</p>\n<pre><code>bind-address   = 192.168.1.12\n</code></pre><p>Just remove the comment for server-id and log_bin and save the file.</p>\n<pre><code>log_bin        = /var/log/mysql/mysql-bin.log\n</code></pre><p>Change the Server id as an unique positive Integer.</p>\n<pre><code>server-id      = 1234\n</code></pre><p>   note: use different id for server2.<br>Restart the mysql service.</p>\n<pre><code>$ sudo service mysql restart\n</code></pre><p><strong>Grant Replication to Slave</strong> </p>\n<p>Create a mysql user with password identification.</p>\n<pre><code>$ mysql -u root -p pswd\n\nmysql&gt; create user &apos;DBUSERNAME&apos;@&apos;%&apos; IDENTIFIED BY &apos;slavepass&apos;;\n</code></pre><p>Grant Slave replication Permission to that user.</p>\n<pre><code>mysql&gt; grant replication slave on *.* to &apos;DBUSERNAME&apos;@&apos;%&apos;\n</code></pre><p><strong>Create your own database</strong></p>\n<p>Create database </p>\n<pre><code>mysql&gt; create database dbnew1\n</code></pre><p>Create table</p>\n<pre><code>mysql&gt; create table dbnew1.student(s_name varchar(20),s_id int);\n</code></pre><p>Insert data whatever you want </p>\n<pre><code>mysql&gt; insert into dbnew1.student(&apos;Devid&apos;,1001);\n</code></pre><p>After insertion exit mysql</p>\n<pre><code>mysql&gt; exit\n</code></pre><p><strong>Backup the MySql Database and Send to Slave</strong></p>\n<p> mysqldump is an effective tool to backup MySQL database. It creates a <em>.sql file with DROP table, CREATE table and INSERT into sql-statements of the source database. To restore the database,  execute the </em>.sql file on destination database. </p>\n<pre><code>Syntax:  mysqldump -u root -p[root_password] [database_name] &gt; dumpfilename.sql\n\n$ mysqldump -u root -p pswd --all-databases --master-data &gt;masterdump.sql\n</code></pre><p> to verify the databases backup</p>\n<pre><code> $grep CHANGE *sql  | head -1 \n\nCHANGE MASTER TO MASTER_LOG_FILE=&apos;mysql-bin.000001&apos;, MASTER_LOG_POS=919;\n</code></pre><p>send the dumpfile.sql to slave server.</p>\n<pre><code>$ scp masterdump.sql 192.168.1.13:\n            or\n$ sftp server2@192.168.1.13            \n</code></pre><p>######Install and Configure MySQL in Slave Server</p>\n<pre><code>$ sudo apt-get install mysql-server \n</code></pre><p> After install MYSQL, have to configure it,</p>\n<pre><code>$ nano /etc/mysql/my.cnf\n</code></pre><p>Change bind-address to point to slave-ipaddress.</p>\n<pre><code>bind-address   = 192.168.1.13\n</code></pre><p>Change the Server id to an unique positive Integer.</p>\n<pre><code>server-id      = 4321\n</code></pre><p>Just remove the comment for server-id and log_bin and save the file.</p>\n<pre><code>log_bin        = /var/log/mysql/mysql-bin.log\n</code></pre><p>Restart the mysql service.</p>\n<pre><code>$ sudo service mysql restart\n</code></pre><p><strong>Inform Slave about the master</strong></p>\n<pre><code>$ mysql -u root -p pswd\n\nmysql&gt; CHANGE MASTER TO MASTER_HOST=&apos;192.168.1.12&apos;, MASTER_USER=&apos;DBUSERNAME&apos;, MASTER_PASSWORD=&apos;slavepass&apos;;\n\nmysql&gt; exit\n</code></pre><p>verify whether you have received the dupmfile.sql before use the following command.</p>\n<pre><code>$ mysql -u root &lt; masterdump.sql\n</code></pre><p>now open MySQL and start the Slave.</p>\n<pre><code>mysql&gt; start slave\n\nmysql&gt; show slave status\\G;\n</code></pre><p>It show the following attributes value like  </p>\n<pre><code>Slave_IO_State: Waiting for master to send event\n              Master_Host: 192.168.1.12\n              Master_User: DBUSERNAME\n          Master_Log_File: mysql-bin.000001\n         Slave_IO_Running: Yes\n        Slave_SQL_Running: Yes\n         Master_Server_Id: 1234\n           MASTER_LOG_POS: 919\n</code></pre><p>now your slave started check the master replication  </p>\n<p><strong>insert a new row in master server</strong></p>\n<pre><code>mysql&gt; use dbnew1\n\n   mysql&gt; insert into stu values(&apos;John&apos;,1004);\nmysql&gt; select * from stu;\n+-----------+-------+\n| s_name     | s_id     |\n+----------+--------+\n| Devid       | 1001     |\n| mathi        | 1002     |\n| thomas     | 1003     |\n| john         | 1004     |\n+------- ---+-------+\n4 rows in set (0.00 sec)\n</code></pre><p><strong>show table in Slave Server</strong></p>\n<pre><code>mysql&gt; use dbnew1   \nmysql&gt; select * from stu;\n+-----------+-------+\n| s_name     | s_id     |\n+----------+--------+\n| Devid       | 1001     |\n| mathi        | 1002     |\n| thomas     | 1003     |\n| john         | 1004     |\n+------- ---+-------+\n4 rows in set (0.00 sec)\n</code></pre><p>MySQL Master-slave replication tested.</p>\n<p>Thank you.</p>\n"},{"title":"Codebox Running Procedure","slug":"2015-09-10-codebox-installation-procedure","date_published":"2015-09-10T09:03:08.728Z","date_updated":"2015-09-10T22:58:53.724Z","_content":"\nThe Codebox IDE helps to create powerful development environments in the cloud with a collaborative, online/offline IDE for your collaborators and your teams.This component is available as an open source project (built with web technologies) on GitHub or Stay updated on Twitter. Let we see the installation procedure.\n\n######Fork the codebox.git from your github id.\nFor that logging in github then enter into codebox.git. In right side top corner you can find 'Fork' option. Click on that.\n\n######Clone the codebox.git into your github id.\n\n\n\tgit clone https://github.com/megamsys/codebox.git\n\n######Change the directory to codebox.\n\n\n\tcd codebox\n\n######Install npm software to access codebox dependency files\n\n\n\tnpm install\n\n######Install gulp globally\n\n\n\tnpm install gulp -g\n\n######Build the codebox with the help of installed gulp.\n\n\n\tgulp build\n\n######Create directories codebox and packages under home directory.\n\n\n\tmkdir /home/megam/.codebox\n\tmkdir /home/megam/.codebox/packages\n\n######Set node path\n\n\n \texport NODE_PATH=/home/megam/.codebox/packages\n\n######Run codebox\n\n\n\tnode ./bin/codebox.js -p 3000 -u admin:admin run ~/code/megam/workspace/\n\nHere I run this code box IDE in the port 3000. As per your wish you can set the port and username and password. This is an example to install & run the codebox IDE.\nI have the contents of codebox in the directory code/megam/workspace/. In the same way you can run the codebox IDE using the path where you stored.\n\n","source":"_posts/2015-09-10-codebox-installation-procedure.md","raw":"---\ntitle: Codebox Running Procedure\nslug: codebox-installation-procedure\ndate_published: 2015-09-10T14:33:08.728Z\ndate_updated:   2015-09-11T04:28:53.724Z\n---\n\nThe Codebox IDE helps to create powerful development environments in the cloud with a collaborative, online/offline IDE for your collaborators and your teams.This component is available as an open source project (built with web technologies) on GitHub or Stay updated on Twitter. Let we see the installation procedure.\n\n######Fork the codebox.git from your github id.\nFor that logging in github then enter into codebox.git. In right side top corner you can find 'Fork' option. Click on that.\n\n######Clone the codebox.git into your github id.\n\n\n\tgit clone https://github.com/megamsys/codebox.git\n\n######Change the directory to codebox.\n\n\n\tcd codebox\n\n######Install npm software to access codebox dependency files\n\n\n\tnpm install\n\n######Install gulp globally\n\n\n\tnpm install gulp -g\n\n######Build the codebox with the help of installed gulp.\n\n\n\tgulp build\n\n######Create directories codebox and packages under home directory.\n\n\n\tmkdir /home/megam/.codebox\n\tmkdir /home/megam/.codebox/packages\n\n######Set node path\n\n\n \texport NODE_PATH=/home/megam/.codebox/packages\n\n######Run codebox\n\n\n\tnode ./bin/codebox.js -p 3000 -u admin:admin run ~/code/megam/workspace/\n\nHere I run this code box IDE in the port 3000. As per your wish you can set the port and username and password. This is an example to install & run the codebox IDE.\nI have the contents of codebox in the directory code/megam/workspace/. In the same way you can run the codebox IDE using the path where you stored.\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzais8000tdrgb6m3z4y2s","content":"<p>The Codebox IDE helps to create powerful development environments in the cloud with a collaborative, online/offline IDE for your collaborators and your teams.This component is available as an open source project (built with web technologies) on GitHub or Stay updated on Twitter. Let we see the installation procedure.</p>\n<p>######Fork the codebox.git from your github id.<br>For that logging in github then enter into codebox.git. In right side top corner you can find Fork option. Click on that.</p>\n<p>######Clone the codebox.git into your github id.</p>\n<pre><code>git clone https://github.com/megamsys/codebox.git\n</code></pre><p>######Change the directory to codebox.</p>\n<pre><code>cd codebox\n</code></pre><p>######Install npm software to access codebox dependency files</p>\n<pre><code>npm install\n</code></pre><p>######Install gulp globally</p>\n<pre><code>npm install gulp -g\n</code></pre><p>######Build the codebox with the help of installed gulp.</p>\n<pre><code>gulp build\n</code></pre><p>######Create directories codebox and packages under home directory.</p>\n<pre><code>mkdir /home/megam/.codebox\nmkdir /home/megam/.codebox/packages\n</code></pre><p>######Set node path</p>\n<pre><code>export NODE_PATH=/home/megam/.codebox/packages\n</code></pre><p>######Run codebox</p>\n<pre><code>node ./bin/codebox.js -p 3000 -u admin:admin run ~/code/megam/workspace/\n</code></pre><p>Here I run this code box IDE in the port 3000. As per your wish you can set the port and username and password. This is an example to install &amp; run the codebox IDE.<br>I have the contents of codebox in the directory code/megam/workspace/. In the same way you can run the codebox IDE using the path where you stored.</p>\n","excerpt":"","more":"<p>The Codebox IDE helps to create powerful development environments in the cloud with a collaborative, online/offline IDE for your collaborators and your teams.This component is available as an open source project (built with web technologies) on GitHub or Stay updated on Twitter. Let we see the installation procedure.</p>\n<p>######Fork the codebox.git from your github id.<br>For that logging in github then enter into codebox.git. In right side top corner you can find Fork option. Click on that.</p>\n<p>######Clone the codebox.git into your github id.</p>\n<pre><code>git clone https://github.com/megamsys/codebox.git\n</code></pre><p>######Change the directory to codebox.</p>\n<pre><code>cd codebox\n</code></pre><p>######Install npm software to access codebox dependency files</p>\n<pre><code>npm install\n</code></pre><p>######Install gulp globally</p>\n<pre><code>npm install gulp -g\n</code></pre><p>######Build the codebox with the help of installed gulp.</p>\n<pre><code>gulp build\n</code></pre><p>######Create directories codebox and packages under home directory.</p>\n<pre><code>mkdir /home/megam/.codebox\nmkdir /home/megam/.codebox/packages\n</code></pre><p>######Set node path</p>\n<pre><code>export NODE_PATH=/home/megam/.codebox/packages\n</code></pre><p>######Run codebox</p>\n<pre><code>node ./bin/codebox.js -p 3000 -u admin:admin run ~/code/megam/workspace/\n</code></pre><p>Here I run this code box IDE in the port 3000. As per your wish you can set the port and username and password. This is an example to install &amp; run the codebox IDE.<br>I have the contents of codebox in the directory code/megam/workspace/. In the same way you can run the codebox IDE using the path where you stored.</p>\n"},{"title":"Internationalization in Rails","slug":"2015-09-16-localization-of-nilavu","date_published":"2015-09-16T04:17:34.402Z","date_updated":"2015-09-16T04:17:34.400Z","_content":"\n####What is Internationalization?\nInternationalization means adapting computer software to different languages, regional differences and technical requirements of a target market. Internationalization is the process of designing a software application so that it can potentially be adapted to various languages and regions without engineering changes. \n\nThe process of \"internationalization\" usually means to abstract all strings and other locale specific bits (such as date or currency formats) out of your application. The process of \"localization\" means to provide translations and localized formats for these bits.\n\n#####Setup the Rails Application for Internationalization\n\nRails adds all .rb and .yml files from the config/locales directory to your translations load path, automatically.\n\n######Gemfile and Gemfile.lock setup\n\n\n\n\t#Gemfile\n    \t- gem \"megam_api\", \"~> 0.65\"\n    #Gemfile.lock\n    \t- megam_api (0.65)\n        + rails-i18n (4.0.4)\n\t\t+ i18n (~> 0.6)\n\t\t+ railties (~> 4.0)\n        \n\n\n######ApplicationController setup\n\nYou make a method in app/controllers/application_controller.rb for users to change their language and create a before_filter:\n\n\tbefore_filter :set_user_language\n\t\n\t  def set_user_language\n\t    I18n.locale= 'en'\n\t  end\n\n######En.yml\n\nThe default en.yml locale in this directory contains a sample pair of translation strings:\n\n\ten:\t\t \n   \thello: \"Hello world\"\t\t   \n    \nThen the sample English language loaded en.yml locale directory is,\n\n\tsignup:\n\t   title: \"Sign up\"\n\t   first_name_tag: \"First Name\"\n       last_name_tag: \"Last Name\"\n       phonenumber_tag: \"Phone Number\"\n       email_tag: \"Email\"\n       password_tag: \"Password\"\n \t  login_here: \"Login here\"\n\nAnd the reference in our view file (apps/views/index.html.erb):\n\n\t<%= t('signup.title') %></u>&nbsp;&nbsp; <a href=\"signin\"><u class=\"colr-denimblue\"><%= t('signup.login_here') %></u></a>\n    \n    \n#####Conclusion    \n  \nInternalization now easy to convert any standard localized language through create new _.yml format file for required language.(Ex. ru.yml for Russian language)\n","source":"_posts/2015-09-16-localization-of-nilavu.md","raw":"---\ntitle: Internationalization in Rails\nslug: localization-of-nilavu\ndate_published: 2015-09-16T09:47:34.402Z\ndate_updated:   2015-09-16T09:47:34.400Z\n---\n\n####What is Internationalization?\nInternationalization means adapting computer software to different languages, regional differences and technical requirements of a target market. Internationalization is the process of designing a software application so that it can potentially be adapted to various languages and regions without engineering changes. \n\nThe process of \"internationalization\" usually means to abstract all strings and other locale specific bits (such as date or currency formats) out of your application. The process of \"localization\" means to provide translations and localized formats for these bits.\n\n#####Setup the Rails Application for Internationalization\n\nRails adds all .rb and .yml files from the config/locales directory to your translations load path, automatically.\n\n######Gemfile and Gemfile.lock setup\n\n\n\n\t#Gemfile\n    \t- gem \"megam_api\", \"~> 0.65\"\n    #Gemfile.lock\n    \t- megam_api (0.65)\n        + rails-i18n (4.0.4)\n\t\t+ i18n (~> 0.6)\n\t\t+ railties (~> 4.0)\n        \n\n\n######ApplicationController setup\n\nYou make a method in app/controllers/application_controller.rb for users to change their language and create a before_filter:\n\n\tbefore_filter :set_user_language\n\t\n\t  def set_user_language\n\t    I18n.locale= 'en'\n\t  end\n\n######En.yml\n\nThe default en.yml locale in this directory contains a sample pair of translation strings:\n\n\ten:\t\t \n   \thello: \"Hello world\"\t\t   \n    \nThen the sample English language loaded en.yml locale directory is,\n\n\tsignup:\n\t   title: \"Sign up\"\n\t   first_name_tag: \"First Name\"\n       last_name_tag: \"Last Name\"\n       phonenumber_tag: \"Phone Number\"\n       email_tag: \"Email\"\n       password_tag: \"Password\"\n \t  login_here: \"Login here\"\n\nAnd the reference in our view file (apps/views/index.html.erb):\n\n\t<%= t('signup.title') %></u>&nbsp;&nbsp; <a href=\"signin\"><u class=\"colr-denimblue\"><%= t('signup.login_here') %></u></a>\n    \n    \n#####Conclusion    \n  \nInternalization now easy to convert any standard localized language through create new _.yml format file for required language.(Ex. ru.yml for Russian language)\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzais9000udrgbppa2p7z5","content":"<p>####What is Internationalization?<br>Internationalization means adapting computer software to different languages, regional differences and technical requirements of a target market. Internationalization is the process of designing a software application so that it can potentially be adapted to various languages and regions without engineering changes. </p>\n<p>The process of internationalization usually means to abstract all strings and other locale specific bits (such as date or currency formats) out of your application. The process of localization means to provide translations and localized formats for these bits.</p>\n<p>#####Setup the Rails Application for Internationalization</p>\n<p>Rails adds all .rb and .yml files from the config/locales directory to your translations load path, automatically.</p>\n<p>######Gemfile and Gemfile.lock setup</p>\n<pre><code>#Gemfile\n    - gem &quot;megam_api&quot;, &quot;~&gt; 0.65&quot;\n#Gemfile.lock\n    - megam_api (0.65)\n    + rails-i18n (4.0.4)\n    + i18n (~&gt; 0.6)\n    + railties (~&gt; 4.0)\n</code></pre><p>######ApplicationController setup</p>\n<p>You make a method in app/controllers/application_controller.rb for users to change their language and create a before_filter:</p>\n<pre><code>before_filter :set_user_language\n\n  def set_user_language\n    I18n.locale= &apos;en&apos;\n  end\n</code></pre><p>######En.yml</p>\n<p>The default en.yml locale in this directory contains a sample pair of translation strings:</p>\n<pre><code>en:         \n   hello: &quot;Hello world&quot;           \n</code></pre><p>Then the sample English language loaded en.yml locale directory is,</p>\n<pre><code>signup:\n   title: &quot;Sign up&quot;\n   first_name_tag: &quot;First Name&quot;\n   last_name_tag: &quot;Last Name&quot;\n   phonenumber_tag: &quot;Phone Number&quot;\n   email_tag: &quot;Email&quot;\n   password_tag: &quot;Password&quot;\n   login_here: &quot;Login here&quot;\n</code></pre><p>And the reference in our view file (apps/views/index.html.erb):</p>\n<pre><code>&lt;%= t(&apos;signup.title&apos;) %&gt;&lt;/u&gt;&amp;nbsp;&amp;nbsp; &lt;a href=&quot;signin&quot;&gt;&lt;u class=&quot;colr-denimblue&quot;&gt;&lt;%= t(&apos;signup.login_here&apos;) %&gt;&lt;/u&gt;&lt;/a&gt;\n</code></pre><p>#####Conclusion    </p>\n<p>Internalization now easy to convert any standard localized language through create new _.yml format file for required language.(Ex. ru.yml for Russian language)</p>\n","excerpt":"","more":"<p>####What is Internationalization?<br>Internationalization means adapting computer software to different languages, regional differences and technical requirements of a target market. Internationalization is the process of designing a software application so that it can potentially be adapted to various languages and regions without engineering changes. </p>\n<p>The process of internationalization usually means to abstract all strings and other locale specific bits (such as date or currency formats) out of your application. The process of localization means to provide translations and localized formats for these bits.</p>\n<p>#####Setup the Rails Application for Internationalization</p>\n<p>Rails adds all .rb and .yml files from the config/locales directory to your translations load path, automatically.</p>\n<p>######Gemfile and Gemfile.lock setup</p>\n<pre><code>#Gemfile\n    - gem &quot;megam_api&quot;, &quot;~&gt; 0.65&quot;\n#Gemfile.lock\n    - megam_api (0.65)\n    + rails-i18n (4.0.4)\n    + i18n (~&gt; 0.6)\n    + railties (~&gt; 4.0)\n</code></pre><p>######ApplicationController setup</p>\n<p>You make a method in app/controllers/application_controller.rb for users to change their language and create a before_filter:</p>\n<pre><code>before_filter :set_user_language\n\n  def set_user_language\n    I18n.locale= &apos;en&apos;\n  end\n</code></pre><p>######En.yml</p>\n<p>The default en.yml locale in this directory contains a sample pair of translation strings:</p>\n<pre><code>en:         \n   hello: &quot;Hello world&quot;           \n</code></pre><p>Then the sample English language loaded en.yml locale directory is,</p>\n<pre><code>signup:\n   title: &quot;Sign up&quot;\n   first_name_tag: &quot;First Name&quot;\n   last_name_tag: &quot;Last Name&quot;\n   phonenumber_tag: &quot;Phone Number&quot;\n   email_tag: &quot;Email&quot;\n   password_tag: &quot;Password&quot;\n   login_here: &quot;Login here&quot;\n</code></pre><p>And the reference in our view file (apps/views/index.html.erb):</p>\n<pre><code>&lt;%= t(&apos;signup.title&apos;) %&gt;&lt;/u&gt;&amp;nbsp;&amp;nbsp; &lt;a href=&quot;signin&quot;&gt;&lt;u class=&quot;colr-denimblue&quot;&gt;&lt;%= t(&apos;signup.login_here&apos;) %&gt;&lt;/u&gt;&lt;/a&gt;\n</code></pre><p>#####Conclusion    </p>\n<p>Internalization now easy to convert any standard localized language through create new _.yml format file for required language.(Ex. ru.yml for Russian language)</p>\n"},{"title":"test-kitchen using OpenNebula","slug":"2015-09-30-ch","date_published":"2015-09-30T03:40:31.770Z","date_updated":"2015-09-30T03:46:01.162Z","_content":"\n\n#Introduction\n\n   Test Kitchen is a test harness tool to execute your configured code on one or more platforms in isolation. \n   \n   We're going to use Test Kitchen to help us write a simple Chef cookbook, complete with tests that verify that the cookbook does what it's supposed to do.\n    \n  To initialize the opennebula driver that it has a static and declarative configuration in `.kitchen.yml` file.\n         \n####Installing Test Kitchen \n      \nInstalling Test Kitchen from RubyGems goes like this:\n           \n    $ gem install test-kitchen\n\n\nNow let's verify that Test Kitchen is installed. To get the currently installed version we type:\n\n    $ kitchen version\n    \nTest Kitchen version 1.0.0\n\n\n\n####Creating a Cookbook\n      \n We already have some cookbooks in github repository.\n\n    $ git clone https://github.com/megamsys/chef-repo.git\n       \nWe can create a cookbook by using knife. `knife` is a tool used to configure most interactions with the Chef system. We can use it to perform work on our workstation and also to connect with the Chef server or individual nodes.\n\nThe general syntax for creating a cookbook is:\n\n    $ knife cookbook create cookbook_name\n\n###Kitchen::Opennebula\n\n  A Test Kitchen Driver for Opennebula.\n  \n#####Installation\n\nDownload and install latest ChefDK.\n\n\t$ wget https://opscode-omnibus-packages.s3.amazonaws.com/ubuntu/12.04/x86_64/chefdk_0.8.0-1_amd64.deb\n    \nInstall chefdk\n\t\n    $ sudo dpkg -i chefdk_0.8.0-1_amd64.deb\n\nPlease add bin locations to your PATH:\n\n\t/opt/chefdk/bin/:/opt/chefdk/embedded/bin (unix)\n\n`NOTE :` Reopen console or reload your env PATH\n\nInstall kitchen with opennebula driver: \n \n \t$ gem install kitchen-opennebula --no-user-install --no-ri --no-rdoc\n\n####Configuration\n\n**opennebula_endpoint**\n\nURL where the OpenNebula daemon is listening. The default value is taken from the ONE_XMLRPC environment variable, or http://127.0.0.1:2633/RPC2 if unset.\n\n**oneauth_file**\n\nPath to the file containing OpenNebula authentication information. It should contain a single line stating \"username:password\". The default value is taken from the ONE_AUTH environment variable, or $HOME/.one/one_auth if unset.\n\n**template_name**\n\nName of the VM definition file (OpenNebula template) registered with OpenNebula. Only one of template_name or template_id must be specified in the .kitchen.yml file. The default value is unset, or nil.\n\n**vm_hostname**\n\nHostname to set for the newly created VM. The default value is driver.instance.name. For example vm_hostname :xxxx\n\n**username**\n\nThis is the username used for SSH authentication to the new VM. The default value is local.\n\n**memory**\n\nThe amount of memory to provision for the new VM. This parameter will override the memory settings provided in the VM template. The default value is 512MB.\n\n**wait_for**\n\nThis variable is used to override timeout for Fog's common wait_for method which states that it \"takes a block and waits for either the block to return true for the object or for a timeout (defaults to 10 minutes)\".\n \n For more details to visit [testkitchen/kitchen-opennebula](https://github.com/test-kitchen/kitchen-opennebula)\n\nNow we'll add Test Kitchen to our project by using the init subcommand:\n    \n\n    $ kitchen init --driver=kitchen-opennebula\n      create  .kitchen.yml\n      create  chefignore\n      create  test/integration/default\n     Successfully installed kitchen-opennebula-0.1.2\n     Parsing documentation for kitchen-opennebula-0.1.2\n     Done installing documentation for kitchen-    opennebula after 0 seconds\n    1 gem installed\n\n\n   The kitchen init subcommand will create an initial configuration file for Test Kitchen called `.kitchen.yml`.\n   \n   While Test Kitchen may have created the initial file automatically, it's expected that you will read and edit this file.\n   \n     driver:\n       name: opennebula\n       opennebula_endpoint: 'http://127.0.0.1:2633/RPC2'\n       oneauth_file: ./.one_auth\n       template_name: TEMPLATE_NAME\n       vm_hostname: HOSTNAME\n       username: USERNAME\n       memory: 2048\n       wait_for: 1000\n    \n    provisioner:\n       name: chef_solo\n\n     platforms:\n       - name: ubuntu-14.04\n       - name: centos-7.0\n\n     suites:\n       - name: default\n       run_list:\n        - recipe[git::default]\n   \n  \n  To see the results of our work, let's run the kitchen list subcommand:\n     \n    $ kitchen list\n        Instance            Driver      Provisioner  Last Action\n        default-ubuntu-1404  opennebula  ChefSolo     <Not Created>\n        \n   \n   Test Kitchen calls this the **Create Action**. We're going to be painfully explicit and ask Test Kitchen to only create the default-ubuntu-1404 instance:\n     \n    $ kitchen create default-ubuntu-1404\n     \n     \n   Let's check the status of our instance now: \n            \n    $ kitchen list\n        Instance                 Driver     Provisioner   Last Action\n         default-ubuntu-1404      opennebula  ChefSolo     Created\n         \n         \n#####Running Kitchen Converge        \n \n  Now start Test Kitchen to test the cookbook\n          \n    $ kitchen converge default-ubuntu-1404\n         \n  It will create a opennebula VM and run the cookbooks in run_list\n  \n","source":"_posts/2015-09-30-ch.md","raw":"---\ntitle: test-kitchen using OpenNebula\nslug: ch\ndate_published: 2015-09-30T09:10:31.770Z\ndate_updated:   2015-09-30T09:16:01.162Z\n---\n\n\n#Introduction\n\n   Test Kitchen is a test harness tool to execute your configured code on one or more platforms in isolation. \n   \n   We're going to use Test Kitchen to help us write a simple Chef cookbook, complete with tests that verify that the cookbook does what it's supposed to do.\n    \n  To initialize the opennebula driver that it has a static and declarative configuration in `.kitchen.yml` file.\n         \n####Installing Test Kitchen \n      \nInstalling Test Kitchen from RubyGems goes like this:\n           \n    $ gem install test-kitchen\n\n\nNow let's verify that Test Kitchen is installed. To get the currently installed version we type:\n\n    $ kitchen version\n    \nTest Kitchen version 1.0.0\n\n\n\n####Creating a Cookbook\n      \n We already have some cookbooks in github repository.\n\n    $ git clone https://github.com/megamsys/chef-repo.git\n       \nWe can create a cookbook by using knife. `knife` is a tool used to configure most interactions with the Chef system. We can use it to perform work on our workstation and also to connect with the Chef server or individual nodes.\n\nThe general syntax for creating a cookbook is:\n\n    $ knife cookbook create cookbook_name\n\n###Kitchen::Opennebula\n\n  A Test Kitchen Driver for Opennebula.\n  \n#####Installation\n\nDownload and install latest ChefDK.\n\n\t$ wget https://opscode-omnibus-packages.s3.amazonaws.com/ubuntu/12.04/x86_64/chefdk_0.8.0-1_amd64.deb\n    \nInstall chefdk\n\t\n    $ sudo dpkg -i chefdk_0.8.0-1_amd64.deb\n\nPlease add bin locations to your PATH:\n\n\t/opt/chefdk/bin/:/opt/chefdk/embedded/bin (unix)\n\n`NOTE :` Reopen console or reload your env PATH\n\nInstall kitchen with opennebula driver: \n \n \t$ gem install kitchen-opennebula --no-user-install --no-ri --no-rdoc\n\n####Configuration\n\n**opennebula_endpoint**\n\nURL where the OpenNebula daemon is listening. The default value is taken from the ONE_XMLRPC environment variable, or http://127.0.0.1:2633/RPC2 if unset.\n\n**oneauth_file**\n\nPath to the file containing OpenNebula authentication information. It should contain a single line stating \"username:password\". The default value is taken from the ONE_AUTH environment variable, or $HOME/.one/one_auth if unset.\n\n**template_name**\n\nName of the VM definition file (OpenNebula template) registered with OpenNebula. Only one of template_name or template_id must be specified in the .kitchen.yml file. The default value is unset, or nil.\n\n**vm_hostname**\n\nHostname to set for the newly created VM. The default value is driver.instance.name. For example vm_hostname :xxxx\n\n**username**\n\nThis is the username used for SSH authentication to the new VM. The default value is local.\n\n**memory**\n\nThe amount of memory to provision for the new VM. This parameter will override the memory settings provided in the VM template. The default value is 512MB.\n\n**wait_for**\n\nThis variable is used to override timeout for Fog's common wait_for method which states that it \"takes a block and waits for either the block to return true for the object or for a timeout (defaults to 10 minutes)\".\n \n For more details to visit [testkitchen/kitchen-opennebula](https://github.com/test-kitchen/kitchen-opennebula)\n\nNow we'll add Test Kitchen to our project by using the init subcommand:\n    \n\n    $ kitchen init --driver=kitchen-opennebula\n      create  .kitchen.yml\n      create  chefignore\n      create  test/integration/default\n     Successfully installed kitchen-opennebula-0.1.2\n     Parsing documentation for kitchen-opennebula-0.1.2\n     Done installing documentation for kitchen-    opennebula after 0 seconds\n    1 gem installed\n\n\n   The kitchen init subcommand will create an initial configuration file for Test Kitchen called `.kitchen.yml`.\n   \n   While Test Kitchen may have created the initial file automatically, it's expected that you will read and edit this file.\n   \n     driver:\n       name: opennebula\n       opennebula_endpoint: 'http://127.0.0.1:2633/RPC2'\n       oneauth_file: ./.one_auth\n       template_name: TEMPLATE_NAME\n       vm_hostname: HOSTNAME\n       username: USERNAME\n       memory: 2048\n       wait_for: 1000\n    \n    provisioner:\n       name: chef_solo\n\n     platforms:\n       - name: ubuntu-14.04\n       - name: centos-7.0\n\n     suites:\n       - name: default\n       run_list:\n        - recipe[git::default]\n   \n  \n  To see the results of our work, let's run the kitchen list subcommand:\n     \n    $ kitchen list\n        Instance            Driver      Provisioner  Last Action\n        default-ubuntu-1404  opennebula  ChefSolo     <Not Created>\n        \n   \n   Test Kitchen calls this the **Create Action**. We're going to be painfully explicit and ask Test Kitchen to only create the default-ubuntu-1404 instance:\n     \n    $ kitchen create default-ubuntu-1404\n     \n     \n   Let's check the status of our instance now: \n            \n    $ kitchen list\n        Instance                 Driver     Provisioner   Last Action\n         default-ubuntu-1404      opennebula  ChefSolo     Created\n         \n         \n#####Running Kitchen Converge        \n \n  Now start Test Kitchen to test the cookbook\n          \n    $ kitchen converge default-ubuntu-1404\n         \n  It will create a opennebula VM and run the cookbooks in run_list\n  \n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaisb000vdrgbl3ldcpy0","content":"<p>#Introduction</p>\n<p>   Test Kitchen is a test harness tool to execute your configured code on one or more platforms in isolation. </p>\n<p>   Were going to use Test Kitchen to help us write a simple Chef cookbook, complete with tests that verify that the cookbook does what its supposed to do.</p>\n<p>  To initialize the opennebula driver that it has a static and declarative configuration in <code>.kitchen.yml</code> file.</p>\n<p>####Installing Test Kitchen </p>\n<p>Installing Test Kitchen from RubyGems goes like this:</p>\n<pre><code>$ gem install test-kitchen\n</code></pre><p>Now lets verify that Test Kitchen is installed. To get the currently installed version we type:</p>\n<pre><code>$ kitchen version\n</code></pre><p>Test Kitchen version 1.0.0</p>\n<p>####Creating a Cookbook</p>\n<p> We already have some cookbooks in github repository.</p>\n<pre><code>$ git clone https://github.com/megamsys/chef-repo.git\n</code></pre><p>We can create a cookbook by using knife. <code>knife</code> is a tool used to configure most interactions with the Chef system. We can use it to perform work on our workstation and also to connect with the Chef server or individual nodes.</p>\n<p>The general syntax for creating a cookbook is:</p>\n<pre><code>$ knife cookbook create cookbook_name\n</code></pre><p>###Kitchen::Opennebula</p>\n<p>  A Test Kitchen Driver for Opennebula.</p>\n<p>#####Installation</p>\n<p>Download and install latest ChefDK.</p>\n<pre><code>$ wget https://opscode-omnibus-packages.s3.amazonaws.com/ubuntu/12.04/x86_64/chefdk_0.8.0-1_amd64.deb\n</code></pre><p>Install chefdk</p>\n<pre><code>$ sudo dpkg -i chefdk_0.8.0-1_amd64.deb\n</code></pre><p>Please add bin locations to your PATH:</p>\n<pre><code>/opt/chefdk/bin/:/opt/chefdk/embedded/bin (unix)\n</code></pre><p><code>NOTE :</code> Reopen console or reload your env PATH</p>\n<p>Install kitchen with opennebula driver: </p>\n<pre><code>$ gem install kitchen-opennebula --no-user-install --no-ri --no-rdoc\n</code></pre><p>####Configuration</p>\n<p><strong>opennebula_endpoint</strong></p>\n<p>URL where the OpenNebula daemon is listening. The default value is taken from the ONE_XMLRPC environment variable, or <a href=\"http://127.0.0.1:2633/RPC2\" target=\"_blank\" rel=\"external\">http://127.0.0.1:2633/RPC2</a> if unset.</p>\n<p><strong>oneauth_file</strong></p>\n<p>Path to the file containing OpenNebula authentication information. It should contain a single line stating username:password. The default value is taken from the ONE_AUTH environment variable, or $HOME/.one/one_auth if unset.</p>\n<p><strong>template_name</strong></p>\n<p>Name of the VM definition file (OpenNebula template) registered with OpenNebula. Only one of template_name or template_id must be specified in the .kitchen.yml file. The default value is unset, or nil.</p>\n<p><strong>vm_hostname</strong></p>\n<p>Hostname to set for the newly created VM. The default value is driver.instance.name. For example vm_hostname :xxxx</p>\n<p><strong>username</strong></p>\n<p>This is the username used for SSH authentication to the new VM. The default value is local.</p>\n<p><strong>memory</strong></p>\n<p>The amount of memory to provision for the new VM. This parameter will override the memory settings provided in the VM template. The default value is 512MB.</p>\n<p><strong>wait_for</strong></p>\n<p>This variable is used to override timeout for Fogs common wait_for method which states that it takes a block and waits for either the block to return true for the object or for a timeout (defaults to 10 minutes).</p>\n<p> For more details to visit <a href=\"https://github.com/test-kitchen/kitchen-opennebula\" target=\"_blank\" rel=\"external\">testkitchen/kitchen-opennebula</a></p>\n<p>Now well add Test Kitchen to our project by using the init subcommand:</p>\n<pre><code>$ kitchen init --driver=kitchen-opennebula\n  create  .kitchen.yml\n  create  chefignore\n  create  test/integration/default\n Successfully installed kitchen-opennebula-0.1.2\n Parsing documentation for kitchen-opennebula-0.1.2\n Done installing documentation for kitchen-    opennebula after 0 seconds\n1 gem installed\n</code></pre><p>   The kitchen init subcommand will create an initial configuration file for Test Kitchen called <code>.kitchen.yml</code>.</p>\n<p>   While Test Kitchen may have created the initial file automatically, its expected that you will read and edit this file.</p>\n<pre><code> driver:\n   name: opennebula\n   opennebula_endpoint: &apos;http://127.0.0.1:2633/RPC2&apos;\n   oneauth_file: ./.one_auth\n   template_name: TEMPLATE_NAME\n   vm_hostname: HOSTNAME\n   username: USERNAME\n   memory: 2048\n   wait_for: 1000\n\nprovisioner:\n   name: chef_solo\n\n platforms:\n   - name: ubuntu-14.04\n   - name: centos-7.0\n\n suites:\n   - name: default\n   run_list:\n    - recipe[git::default]\n</code></pre><p>  To see the results of our work, lets run the kitchen list subcommand:</p>\n<pre><code>$ kitchen list\n    Instance            Driver      Provisioner  Last Action\n    default-ubuntu-1404  opennebula  ChefSolo     &lt;Not Created&gt;\n</code></pre><p>   Test Kitchen calls this the <strong>Create Action</strong>. Were going to be painfully explicit and ask Test Kitchen to only create the default-ubuntu-1404 instance:</p>\n<pre><code>$ kitchen create default-ubuntu-1404\n</code></pre><p>   Lets check the status of our instance now: </p>\n<pre><code>$ kitchen list\n    Instance                 Driver     Provisioner   Last Action\n     default-ubuntu-1404      opennebula  ChefSolo     Created\n</code></pre><p>#####Running Kitchen Converge        </p>\n<p>  Now start Test Kitchen to test the cookbook</p>\n<pre><code>$ kitchen converge default-ubuntu-1404\n</code></pre><p>  It will create a opennebula VM and run the cookbooks in run_list</p>\n","excerpt":"","more":"<p>#Introduction</p>\n<p>   Test Kitchen is a test harness tool to execute your configured code on one or more platforms in isolation. </p>\n<p>   Were going to use Test Kitchen to help us write a simple Chef cookbook, complete with tests that verify that the cookbook does what its supposed to do.</p>\n<p>  To initialize the opennebula driver that it has a static and declarative configuration in <code>.kitchen.yml</code> file.</p>\n<p>####Installing Test Kitchen </p>\n<p>Installing Test Kitchen from RubyGems goes like this:</p>\n<pre><code>$ gem install test-kitchen\n</code></pre><p>Now lets verify that Test Kitchen is installed. To get the currently installed version we type:</p>\n<pre><code>$ kitchen version\n</code></pre><p>Test Kitchen version 1.0.0</p>\n<p>####Creating a Cookbook</p>\n<p> We already have some cookbooks in github repository.</p>\n<pre><code>$ git clone https://github.com/megamsys/chef-repo.git\n</code></pre><p>We can create a cookbook by using knife. <code>knife</code> is a tool used to configure most interactions with the Chef system. We can use it to perform work on our workstation and also to connect with the Chef server or individual nodes.</p>\n<p>The general syntax for creating a cookbook is:</p>\n<pre><code>$ knife cookbook create cookbook_name\n</code></pre><p>###Kitchen::Opennebula</p>\n<p>  A Test Kitchen Driver for Opennebula.</p>\n<p>#####Installation</p>\n<p>Download and install latest ChefDK.</p>\n<pre><code>$ wget https://opscode-omnibus-packages.s3.amazonaws.com/ubuntu/12.04/x86_64/chefdk_0.8.0-1_amd64.deb\n</code></pre><p>Install chefdk</p>\n<pre><code>$ sudo dpkg -i chefdk_0.8.0-1_amd64.deb\n</code></pre><p>Please add bin locations to your PATH:</p>\n<pre><code>/opt/chefdk/bin/:/opt/chefdk/embedded/bin (unix)\n</code></pre><p><code>NOTE :</code> Reopen console or reload your env PATH</p>\n<p>Install kitchen with opennebula driver: </p>\n<pre><code>$ gem install kitchen-opennebula --no-user-install --no-ri --no-rdoc\n</code></pre><p>####Configuration</p>\n<p><strong>opennebula_endpoint</strong></p>\n<p>URL where the OpenNebula daemon is listening. The default value is taken from the ONE_XMLRPC environment variable, or <a href=\"http://127.0.0.1:2633/RPC2\">http://127.0.0.1:2633/RPC2</a> if unset.</p>\n<p><strong>oneauth_file</strong></p>\n<p>Path to the file containing OpenNebula authentication information. It should contain a single line stating username:password. The default value is taken from the ONE_AUTH environment variable, or $HOME/.one/one_auth if unset.</p>\n<p><strong>template_name</strong></p>\n<p>Name of the VM definition file (OpenNebula template) registered with OpenNebula. Only one of template_name or template_id must be specified in the .kitchen.yml file. The default value is unset, or nil.</p>\n<p><strong>vm_hostname</strong></p>\n<p>Hostname to set for the newly created VM. The default value is driver.instance.name. For example vm_hostname :xxxx</p>\n<p><strong>username</strong></p>\n<p>This is the username used for SSH authentication to the new VM. The default value is local.</p>\n<p><strong>memory</strong></p>\n<p>The amount of memory to provision for the new VM. This parameter will override the memory settings provided in the VM template. The default value is 512MB.</p>\n<p><strong>wait_for</strong></p>\n<p>This variable is used to override timeout for Fogs common wait_for method which states that it takes a block and waits for either the block to return true for the object or for a timeout (defaults to 10 minutes).</p>\n<p> For more details to visit <a href=\"https://github.com/test-kitchen/kitchen-opennebula\">testkitchen/kitchen-opennebula</a></p>\n<p>Now well add Test Kitchen to our project by using the init subcommand:</p>\n<pre><code>$ kitchen init --driver=kitchen-opennebula\n  create  .kitchen.yml\n  create  chefignore\n  create  test/integration/default\n Successfully installed kitchen-opennebula-0.1.2\n Parsing documentation for kitchen-opennebula-0.1.2\n Done installing documentation for kitchen-    opennebula after 0 seconds\n1 gem installed\n</code></pre><p>   The kitchen init subcommand will create an initial configuration file for Test Kitchen called <code>.kitchen.yml</code>.</p>\n<p>   While Test Kitchen may have created the initial file automatically, its expected that you will read and edit this file.</p>\n<pre><code> driver:\n   name: opennebula\n   opennebula_endpoint: &apos;http://127.0.0.1:2633/RPC2&apos;\n   oneauth_file: ./.one_auth\n   template_name: TEMPLATE_NAME\n   vm_hostname: HOSTNAME\n   username: USERNAME\n   memory: 2048\n   wait_for: 1000\n\nprovisioner:\n   name: chef_solo\n\n platforms:\n   - name: ubuntu-14.04\n   - name: centos-7.0\n\n suites:\n   - name: default\n   run_list:\n    - recipe[git::default]\n</code></pre><p>  To see the results of our work, lets run the kitchen list subcommand:</p>\n<pre><code>$ kitchen list\n    Instance            Driver      Provisioner  Last Action\n    default-ubuntu-1404  opennebula  ChefSolo     &lt;Not Created&gt;\n</code></pre><p>   Test Kitchen calls this the <strong>Create Action</strong>. Were going to be painfully explicit and ask Test Kitchen to only create the default-ubuntu-1404 instance:</p>\n<pre><code>$ kitchen create default-ubuntu-1404\n</code></pre><p>   Lets check the status of our instance now: </p>\n<pre><code>$ kitchen list\n    Instance                 Driver     Provisioner   Last Action\n     default-ubuntu-1404      opennebula  ChefSolo     Created\n</code></pre><p>#####Running Kitchen Converge        </p>\n<p>  Now start Test Kitchen to test the cookbook</p>\n<pre><code>$ kitchen converge default-ubuntu-1404\n</code></pre><p>  It will create a opennebula VM and run the cookbooks in run_list</p>\n"},{"title":"Ceph Object Gateway","slug":"2015-10-13-ceph-gateway","date_published":"2015-10-13T09:12:40.417Z","date_updated":"2016-06-02T07:40:33.920Z","_content":"\n**Ceph Object Gateway** is an object storage interface built on top of librados to provide applications with a RESTful gateway to Ceph Storage Clusters. Ceph Object Storage supports two interfaces:\n\n***S3-compatible:*** Provides object storage functionality with an interface that is compatible with a large subset of the Amazon S3 RESTful API.\n\n**Swift-compatible:** Provides object storage functionality with an interface that is compatible with a large subset of the OpenStack Swift API.\n\n**My ceph cluster setup**\n\t\n    mon and gateway\t- mon-server(192.168.1.10)\n    osd1 and osd2 \t - osd1(192.168.1.11)\n    osd3 \t\t\t  - osd2(192.168.1.12)\n    OS\t\t\t\t - Ubuntu Trusty(14.04.2 LTS)\n\nTo run the Ceph object gateway service on Ubuntu 14.04 (Trusty), you should have a running Ceph cluster and the gateway host should have access to storage and public networks.\n\n\n\tIn my case, I've done the follwing in mon-server(192.168.1.10)\n    \n**INSTALL APACHE/FASTCGI**\n\nOn Ubuntu Ubuntu 14.04, multiverse needs to be enabled in the package resource list file \n\nuncomment the following lines in /etc/apt/sources.list:\n\n\t# deb http://archive.ubuntu.com/ubuntu trusty multiverse\n\t# deb-src http://archive.ubuntu.com/ubuntu trusty multiverse\n\t# deb http://archive.ubuntu.com/ubuntu trusty-updates multiverse\n\t# deb-src http://archive.ubuntu.com/ubuntu trusty-updates multiverse\n\nUpdate the package resource list:\n\n\t$ sudo apt-get update\n    \nInstall Apache and FastCGI:\n\n\t$ sudo apt-get install apache2 libapache2-mod-fastcgi\n    \n**Configure APACHE**\n\nAdd a line for the ServerName in the /etc/apache2/apache2.conf. Provide the fully qualified domain name of the server machine (e.g., hostname -f):\n\n\tServerName mon-server\n\nEnable the URL rewrite modules for Apache and FastCGI\nExecute the following:\n\n\t$ sudo a2enmod rewrite\n\t$ sudo a2enmod fastcgi\n\nRestart Apache service\n\n\t$sudo service apache2 start\n    \n**INSTALL CEPH OBJECT GATEWAY DAEMON**\n\nCeph Object Storage services use the Ceph Object Gateway daemon (radosgw) to enable the gateway.\n\nTo install the Ceph Object Gateway daemon on the gateway host, execute the following:\n\n\t$ sudo apt-get install radosgw\n    \nOnce you have installed the Ceph Object Gateway packages, the next step is to configure your Ceph Object Gateway. There are two approaches: `simple` and `FEDERATED`. I used `simple` in my system\n\nSimple: A simple Ceph Object Gateway configuration implies that you are running a Ceph Object Storage service in a single data center. So you can configure the Ceph Object Gateway without regard to regions and zones.\n\nThe Ceph Object Gateway is a client of the Ceph Storage Cluster. As a Ceph Storage Cluster client, it requires:\n\n\t1. A name for the gateway instance. We use 'admin' in this guide.\n\t2. A storage cluster user name with appropriate permissions in a keyring.\n\t3. Pools to store its data.\n\t4. A data directory for the gateway instance.\n\t5. An instance entry in the Ceph Configuration file.\n\t6. A configuration file for the web server to interact with FastCGI.\n    \nThe configuration steps are as follows:\n\n**Execute the following steps on the admin node of your cluster:**\n\nCreate a keyring for the gateway:\n\n\t$ sudo ceph-authtool --create-keyring /etc/ceph/ceph.client.radosgw.keyring\n\tsudo chmod +r /etc/ceph/ceph.client.radosgw.keyring\n    \nGenerate a Ceph Object Gateway user name and key for each instance. For exemplary purposes, we will use the name 'admin' after client.radosgw:\n\n\t$ sudo ceph-authtool /etc/ceph/ceph.client.radosgw.keyring -n client.radosgw.admin --gen-key\n    \nAdd capabilities to the key:\n\n\t$ sudo ceph-authtool -n client.radosgw.admin --cap osd 'allow rwx' --cap mon 'allow rwx' /etc/ceph/ceph.client.radosgw.keyring\n    \nOnce you have created a keyring and key to enable the Ceph Object Gateway with access to the Ceph Storage Cluster, add the key to your Ceph Storage Cluster. For example:\n\n\t$ sudo ceph -k /etc/ceph/ceph.client.admin.keyring auth add client.radosgw.admin -i /etc/ceph/ceph.client.radosgw.keyring\n    \nDistribute the keyring to the gateway host:\n\n\t$ sudo scp /etc/ceph/ceph.client.radosgw.keyring  USERNAME@GATEWAY_IP:/home/ceph\n    $ ssh USERNAME@GATEWAY_IP 'sudo mv ceph.client.radosgw.keyring /etc/ceph/ceph.client.radosgw.keyring'\n\nNOTE\nThe last step is optional if admin node is the gateway host.\n\n**CREATE POOLS**\n\nIf pools already exist, no problem. If not, create all the pools listed below\n\n\t$ ceph osd pool create .rgw.buckets 16 16\n    \n\t.rgw\n\t.rgw.root\n\t.rgw.control\n\t.rgw.gc\n\t.rgw.buckets\n\t.rgw.buckets.index\n\t.log\n\t.intent-log\n\t.usage\n\t.users\n\t.users.email\n\t.users.swift\n\t.users.uid\n\n`NOTE`\nif write permission is given, Ceph Object Gateway will create pools automatically.\n\n`NOTE` When adding a large number of pools, it may take some time for your cluster to return to a active + clean state.\n\nWhen you have completed this step, execute the following to ensure that you have created all of the foregoing pools:\n\n\t$ rados lspools\n\n\n**ADD A GATEWAY CONFIGURATION TO CEPH** \n\nAdd the Ceph Object Gateway configuration to your Ceph Configuration file in admin node. The Ceph Object Gateway configuration requires you to identify the Ceph Object Gateway instance. Then, you must specify the host name where you installed the Ceph Object Gateway daemon, a keyring (for use with cephx), the socket path for FastCGI and a log file.\n\nAppend the following configuration to `/etc/ceph/ceph.conf` in your admin node:\n\n\t[client.radosgw.admin]\n\thost = {hostname}\n\tkeyring = /etc/ceph/ceph.client.radosgw.keyring\n\trgw socket path = \t/var/run/ceph/ceph.radosgw.admin.fastcgi.sock\n\tlog file = /var/log/radosgw/client.radosgw.admin.log\n    \n`NOTE`\nHere, {hostname} is the short hostname (output of command hostname -s) of the node that is going to provide the gateway service i.e, the gateway host.\n\n`NOTE` The [client.radosgw.admin] portion of the gateway instance identifies this portion of the Ceph configuration file as configuring a Ceph Storage Cluster client where the client type is a Ceph Object Gateway (i.e., radosgw).\n\n**DISTRIBUTE UPDATED CEPH CONFIGURATION FILE**\n\n\t$ ceph-deploy --overwrite-conf config pull {gateway_hostname}\n    $ ceph-deploy --overwrite-conf config push osd1 osd2 \n    \n    \n**COPY CEPH.CLIENT.ADMIN.KEYRING FROM ADMIN NODE TO GATEWAY HOST**\n\n\t$ sudo scp /etc/ceph/ceph.client.admin.keyring  USERNAME@GATEWAY_IP:/home/USERNAME\n    $ ssh USERNAME@GATEWAY_IP 'sudo mv ceph.client.admin.keyring /etc/ceph/ceph.client.admin.keyring'\n    \n`NOTE` The above step need not be executed if admin node is the gateway host\n\n**CREATE A CGI WRAPPER SCRIPT**\n\nThe wrapper script provides the interface between the webserver and the radosgw process. This script needs to be in a web accessible location and should be executable.\n\nExecute the following steps on the gateway host:\n\nCreate the script:\n\n\t$ sudo vi /var/www/html/s3gw.fcgi\nAdd the following content to the script:\n\n\t#!/bin/sh\n\texec /usr/bin/radosgw -c /etc/ceph/ceph.conf -n client.radosgw.admin\n\t\nProvide execute permissions to the script:\n\nChange file permission\n\n\t$ sudo chmod +x /var/www/html/s3gw.fcgi\n\nCreate Data Directory\n\t\n    $ sudo mkdir -p /var/lib/ceph/radosgw/ceph-radosgw.admin\n    \nStart rados gateway service\n\n\t$ sudo /etc/init.d/radosgw start\n    \n\nCREATE A GATEWAY CONFIGURATION FILE\n\n\t$ sudo vi /etc/apache2/sites-available/rgw.conf\n    \nAdd the following contents to the file:\n\n\tFastCgiExternalServer /var/www/html/s3gw.fcgi -socket /var/run/ceph/ceph.radosgw.admin.fastcgi.sock\n\n\t<VirtualHost *:80>\n\tServerName localhost\n\tDocumentRoot /var/www/html\n\n\tErrorLog /var/log/apache2/rgw_error.log\n\tCustomLog /var/log/apache2/rgw_access.log combined\n\n\t# LogLevel debug\n\n\tRewriteEngine On\n\n\tRewriteRule ^/([a-zA-Z0-9-_.]*)([/]?.*) /s3gw.fcgi?page=$1&params=$2&%{QUERY_STRING} [E=HTTP_AUTHORIZATION:%{HTTP:Authorization},L]\n\n\t<IfModule mod_fastcgi.c>\n\t\t<Directory /var/www/html>\n\t\tOptions +ExecCGI\n\t\tAllowOverride All\n\t\tSetHandler fastcgi-script\n\t\tOrder allow,deny\n\t\tAllow from all\n\t\tAuthBasicAuthoritative Off\n\t\t</Directory>\n\t</IfModule>\n\n\tAllowEncodedSlashes On\n\tServerSignature Off\n\n\t</VirtualHost>\n\nDisable the default site:\n\n\t$ sudo a2dissite 000-default\n\n\nEnable the configuration file\n\n\t$ sudo a2ensite rgw.conf\n\nRestart apache2 service\n\n\t$ sudo service apache2 restart\n    \n\n**USING THE GATEWAY**\n\nCREATE A RADOSGW USER FOR S3 ACCESS\n\n\t$ sudo radosgw-admin user create --uid=\"testuser\" --display-name=\"First User\"\n\nThe output of the command will be something like the following:\n\n\t{\"user_id\": \"testuser\",\n\t\"display_name\": \"First User\",\n\t\"email\": \"\",\n\t\"suspended\": 0,\n\t\"max_buckets\": 1000,\n\t\"auid\": 0,\n\t\"subusers\": [],\n\t\"keys\": [\n\t{ \"user\": \"testuser\",\n\t\"access_key\": \"I0PJDPCIYZ665MW88W9R\",\n\t\"secret_key\": \t\"dxaXZ8U90SXydYzyS5ivamEP20hkLSUViiaR+ZDA\"}],\n\t\"swift_keys\": [],\n\t\"caps\": [],\n\t\"op_mask\": \"read, write, delete\",\n\t\"default_placement\": \"\",\n\t\"placement_tags\": [],\n\t\"bucket_quota\": { \"enabled\": false,\n\t\"max_size_kb\": -1,\n\t\"max_objects\": -1},\n\t\"user_quota\": { \"enabled\": false,\n\t\"max_size_kb\": -1,\n\t\"max_objects\": -1},\n\t\"temp_url_keys\": []}\n\n`NOTE` The values of keys->access_key and keys->secret_key are needed for access validation.\n\n**ACCESS VERIFICATION**\n\ninstall the python-boto package\n\n\t$ sudo apt-get install python-boto\n\nCreate the Python script:\n\n\t$ nano s3.py\n   \n\timport boto\n\timport boto.s3.connection\n\taccess_key = 'YOUR_ACCESS_KEY'\n\tsecret_key = 'YOUR_SECRET_KEY'\n\tconn = boto.connect_s3(\n\taws_access_key_id = access_key,\n\taws_secret_access_key = secret_key,\n\thost = '{FQDN}',\n\tis_secure=False,\n\tcalling_format = boto.s3.connection.OrdinaryCallingFormat(),)\n    bucket = conn.create_bucket('my-new-bucket')\n\tfor bucket in conn.get_all_buckets():\n\t\tprint \"{name}\\t{created}\".format(\n\t\t\tname = bucket.name,\n\t\t\tcreated = bucket.creation_date,\n\t)\n\t\nRun the script:\n\n\t$ python s3test.py   \n    \nThe output will be something like the following:\n\n\tmy-new-bucket 2015-02-16T17:09:10.000Z\n    \n\n**Test in ruby language**\n\nTo test ceph-gateway, we have use rubygem `s3`. Source code is in https://github.com/thomasalrin/s3\n\nEdit https://github.com/thomasalrin/s3/blob/master/lib/s3.rb to point to your gateway_host\n\n######Revert installation\n\nThere are useful commands to purge the Ceph gateway nstallation and configuration from every node so that one can start over again from a clean state.\n\nThis will remove Ceph configuration and keys\n\n\tceph-deploy purgedata mon-server\n\nThis will also remove Ceph packages\n\n\tceph-deploy purge mon-server\n\nIF you received the below error when you attempt to install radosgw again\n\tclient.radosgw.admin exists but key does not match\n \nExecute this to fix the error \n    ceph auth del client.radosgw.gateway\n\n\n \n","source":"_posts/2015-10-13-ceph-gateway.md","raw":"---\ntitle: Ceph Object Gateway\nslug: ceph-gateway\ndate_published: 2015-10-13T14:42:40.417Z\ndate_updated:   2016-06-02T13:10:33.920Z\n---\n\n**Ceph Object Gateway** is an object storage interface built on top of librados to provide applications with a RESTful gateway to Ceph Storage Clusters. Ceph Object Storage supports two interfaces:\n\n***S3-compatible:*** Provides object storage functionality with an interface that is compatible with a large subset of the Amazon S3 RESTful API.\n\n**Swift-compatible:** Provides object storage functionality with an interface that is compatible with a large subset of the OpenStack Swift API.\n\n**My ceph cluster setup**\n\t\n    mon and gateway\t- mon-server(192.168.1.10)\n    osd1 and osd2 \t - osd1(192.168.1.11)\n    osd3 \t\t\t  - osd2(192.168.1.12)\n    OS\t\t\t\t - Ubuntu Trusty(14.04.2 LTS)\n\nTo run the Ceph object gateway service on Ubuntu 14.04 (Trusty), you should have a running Ceph cluster and the gateway host should have access to storage and public networks.\n\n\n\tIn my case, I've done the follwing in mon-server(192.168.1.10)\n    \n**INSTALL APACHE/FASTCGI**\n\nOn Ubuntu Ubuntu 14.04, multiverse needs to be enabled in the package resource list file \n\nuncomment the following lines in /etc/apt/sources.list:\n\n\t# deb http://archive.ubuntu.com/ubuntu trusty multiverse\n\t# deb-src http://archive.ubuntu.com/ubuntu trusty multiverse\n\t# deb http://archive.ubuntu.com/ubuntu trusty-updates multiverse\n\t# deb-src http://archive.ubuntu.com/ubuntu trusty-updates multiverse\n\nUpdate the package resource list:\n\n\t$ sudo apt-get update\n    \nInstall Apache and FastCGI:\n\n\t$ sudo apt-get install apache2 libapache2-mod-fastcgi\n    \n**Configure APACHE**\n\nAdd a line for the ServerName in the /etc/apache2/apache2.conf. Provide the fully qualified domain name of the server machine (e.g., hostname -f):\n\n\tServerName mon-server\n\nEnable the URL rewrite modules for Apache and FastCGI\nExecute the following:\n\n\t$ sudo a2enmod rewrite\n\t$ sudo a2enmod fastcgi\n\nRestart Apache service\n\n\t$sudo service apache2 start\n    \n**INSTALL CEPH OBJECT GATEWAY DAEMON**\n\nCeph Object Storage services use the Ceph Object Gateway daemon (radosgw) to enable the gateway.\n\nTo install the Ceph Object Gateway daemon on the gateway host, execute the following:\n\n\t$ sudo apt-get install radosgw\n    \nOnce you have installed the Ceph Object Gateway packages, the next step is to configure your Ceph Object Gateway. There are two approaches: `simple` and `FEDERATED`. I used `simple` in my system\n\nSimple: A simple Ceph Object Gateway configuration implies that you are running a Ceph Object Storage service in a single data center. So you can configure the Ceph Object Gateway without regard to regions and zones.\n\nThe Ceph Object Gateway is a client of the Ceph Storage Cluster. As a Ceph Storage Cluster client, it requires:\n\n\t1. A name for the gateway instance. We use 'admin' in this guide.\n\t2. A storage cluster user name with appropriate permissions in a keyring.\n\t3. Pools to store its data.\n\t4. A data directory for the gateway instance.\n\t5. An instance entry in the Ceph Configuration file.\n\t6. A configuration file for the web server to interact with FastCGI.\n    \nThe configuration steps are as follows:\n\n**Execute the following steps on the admin node of your cluster:**\n\nCreate a keyring for the gateway:\n\n\t$ sudo ceph-authtool --create-keyring /etc/ceph/ceph.client.radosgw.keyring\n\tsudo chmod +r /etc/ceph/ceph.client.radosgw.keyring\n    \nGenerate a Ceph Object Gateway user name and key for each instance. For exemplary purposes, we will use the name 'admin' after client.radosgw:\n\n\t$ sudo ceph-authtool /etc/ceph/ceph.client.radosgw.keyring -n client.radosgw.admin --gen-key\n    \nAdd capabilities to the key:\n\n\t$ sudo ceph-authtool -n client.radosgw.admin --cap osd 'allow rwx' --cap mon 'allow rwx' /etc/ceph/ceph.client.radosgw.keyring\n    \nOnce you have created a keyring and key to enable the Ceph Object Gateway with access to the Ceph Storage Cluster, add the key to your Ceph Storage Cluster. For example:\n\n\t$ sudo ceph -k /etc/ceph/ceph.client.admin.keyring auth add client.radosgw.admin -i /etc/ceph/ceph.client.radosgw.keyring\n    \nDistribute the keyring to the gateway host:\n\n\t$ sudo scp /etc/ceph/ceph.client.radosgw.keyring  USERNAME@GATEWAY_IP:/home/ceph\n    $ ssh USERNAME@GATEWAY_IP 'sudo mv ceph.client.radosgw.keyring /etc/ceph/ceph.client.radosgw.keyring'\n\nNOTE\nThe last step is optional if admin node is the gateway host.\n\n**CREATE POOLS**\n\nIf pools already exist, no problem. If not, create all the pools listed below\n\n\t$ ceph osd pool create .rgw.buckets 16 16\n    \n\t.rgw\n\t.rgw.root\n\t.rgw.control\n\t.rgw.gc\n\t.rgw.buckets\n\t.rgw.buckets.index\n\t.log\n\t.intent-log\n\t.usage\n\t.users\n\t.users.email\n\t.users.swift\n\t.users.uid\n\n`NOTE`\nif write permission is given, Ceph Object Gateway will create pools automatically.\n\n`NOTE` When adding a large number of pools, it may take some time for your cluster to return to a active + clean state.\n\nWhen you have completed this step, execute the following to ensure that you have created all of the foregoing pools:\n\n\t$ rados lspools\n\n\n**ADD A GATEWAY CONFIGURATION TO CEPH** \n\nAdd the Ceph Object Gateway configuration to your Ceph Configuration file in admin node. The Ceph Object Gateway configuration requires you to identify the Ceph Object Gateway instance. Then, you must specify the host name where you installed the Ceph Object Gateway daemon, a keyring (for use with cephx), the socket path for FastCGI and a log file.\n\nAppend the following configuration to `/etc/ceph/ceph.conf` in your admin node:\n\n\t[client.radosgw.admin]\n\thost = {hostname}\n\tkeyring = /etc/ceph/ceph.client.radosgw.keyring\n\trgw socket path = \t/var/run/ceph/ceph.radosgw.admin.fastcgi.sock\n\tlog file = /var/log/radosgw/client.radosgw.admin.log\n    \n`NOTE`\nHere, {hostname} is the short hostname (output of command hostname -s) of the node that is going to provide the gateway service i.e, the gateway host.\n\n`NOTE` The [client.radosgw.admin] portion of the gateway instance identifies this portion of the Ceph configuration file as configuring a Ceph Storage Cluster client where the client type is a Ceph Object Gateway (i.e., radosgw).\n\n**DISTRIBUTE UPDATED CEPH CONFIGURATION FILE**\n\n\t$ ceph-deploy --overwrite-conf config pull {gateway_hostname}\n    $ ceph-deploy --overwrite-conf config push osd1 osd2 \n    \n    \n**COPY CEPH.CLIENT.ADMIN.KEYRING FROM ADMIN NODE TO GATEWAY HOST**\n\n\t$ sudo scp /etc/ceph/ceph.client.admin.keyring  USERNAME@GATEWAY_IP:/home/USERNAME\n    $ ssh USERNAME@GATEWAY_IP 'sudo mv ceph.client.admin.keyring /etc/ceph/ceph.client.admin.keyring'\n    \n`NOTE` The above step need not be executed if admin node is the gateway host\n\n**CREATE A CGI WRAPPER SCRIPT**\n\nThe wrapper script provides the interface between the webserver and the radosgw process. This script needs to be in a web accessible location and should be executable.\n\nExecute the following steps on the gateway host:\n\nCreate the script:\n\n\t$ sudo vi /var/www/html/s3gw.fcgi\nAdd the following content to the script:\n\n\t#!/bin/sh\n\texec /usr/bin/radosgw -c /etc/ceph/ceph.conf -n client.radosgw.admin\n\t\nProvide execute permissions to the script:\n\nChange file permission\n\n\t$ sudo chmod +x /var/www/html/s3gw.fcgi\n\nCreate Data Directory\n\t\n    $ sudo mkdir -p /var/lib/ceph/radosgw/ceph-radosgw.admin\n    \nStart rados gateway service\n\n\t$ sudo /etc/init.d/radosgw start\n    \n\nCREATE A GATEWAY CONFIGURATION FILE\n\n\t$ sudo vi /etc/apache2/sites-available/rgw.conf\n    \nAdd the following contents to the file:\n\n\tFastCgiExternalServer /var/www/html/s3gw.fcgi -socket /var/run/ceph/ceph.radosgw.admin.fastcgi.sock\n\n\t<VirtualHost *:80>\n\tServerName localhost\n\tDocumentRoot /var/www/html\n\n\tErrorLog /var/log/apache2/rgw_error.log\n\tCustomLog /var/log/apache2/rgw_access.log combined\n\n\t# LogLevel debug\n\n\tRewriteEngine On\n\n\tRewriteRule ^/([a-zA-Z0-9-_.]*)([/]?.*) /s3gw.fcgi?page=$1&params=$2&%{QUERY_STRING} [E=HTTP_AUTHORIZATION:%{HTTP:Authorization},L]\n\n\t<IfModule mod_fastcgi.c>\n\t\t<Directory /var/www/html>\n\t\tOptions +ExecCGI\n\t\tAllowOverride All\n\t\tSetHandler fastcgi-script\n\t\tOrder allow,deny\n\t\tAllow from all\n\t\tAuthBasicAuthoritative Off\n\t\t</Directory>\n\t</IfModule>\n\n\tAllowEncodedSlashes On\n\tServerSignature Off\n\n\t</VirtualHost>\n\nDisable the default site:\n\n\t$ sudo a2dissite 000-default\n\n\nEnable the configuration file\n\n\t$ sudo a2ensite rgw.conf\n\nRestart apache2 service\n\n\t$ sudo service apache2 restart\n    \n\n**USING THE GATEWAY**\n\nCREATE A RADOSGW USER FOR S3 ACCESS\n\n\t$ sudo radosgw-admin user create --uid=\"testuser\" --display-name=\"First User\"\n\nThe output of the command will be something like the following:\n\n\t{\"user_id\": \"testuser\",\n\t\"display_name\": \"First User\",\n\t\"email\": \"\",\n\t\"suspended\": 0,\n\t\"max_buckets\": 1000,\n\t\"auid\": 0,\n\t\"subusers\": [],\n\t\"keys\": [\n\t{ \"user\": \"testuser\",\n\t\"access_key\": \"I0PJDPCIYZ665MW88W9R\",\n\t\"secret_key\": \t\"dxaXZ8U90SXydYzyS5ivamEP20hkLSUViiaR+ZDA\"}],\n\t\"swift_keys\": [],\n\t\"caps\": [],\n\t\"op_mask\": \"read, write, delete\",\n\t\"default_placement\": \"\",\n\t\"placement_tags\": [],\n\t\"bucket_quota\": { \"enabled\": false,\n\t\"max_size_kb\": -1,\n\t\"max_objects\": -1},\n\t\"user_quota\": { \"enabled\": false,\n\t\"max_size_kb\": -1,\n\t\"max_objects\": -1},\n\t\"temp_url_keys\": []}\n\n`NOTE` The values of keys->access_key and keys->secret_key are needed for access validation.\n\n**ACCESS VERIFICATION**\n\ninstall the python-boto package\n\n\t$ sudo apt-get install python-boto\n\nCreate the Python script:\n\n\t$ nano s3.py\n   \n\timport boto\n\timport boto.s3.connection\n\taccess_key = 'YOUR_ACCESS_KEY'\n\tsecret_key = 'YOUR_SECRET_KEY'\n\tconn = boto.connect_s3(\n\taws_access_key_id = access_key,\n\taws_secret_access_key = secret_key,\n\thost = '{FQDN}',\n\tis_secure=False,\n\tcalling_format = boto.s3.connection.OrdinaryCallingFormat(),)\n    bucket = conn.create_bucket('my-new-bucket')\n\tfor bucket in conn.get_all_buckets():\n\t\tprint \"{name}\\t{created}\".format(\n\t\t\tname = bucket.name,\n\t\t\tcreated = bucket.creation_date,\n\t)\n\t\nRun the script:\n\n\t$ python s3test.py   \n    \nThe output will be something like the following:\n\n\tmy-new-bucket 2015-02-16T17:09:10.000Z\n    \n\n**Test in ruby language**\n\nTo test ceph-gateway, we have use rubygem `s3`. Source code is in https://github.com/thomasalrin/s3\n\nEdit https://github.com/thomasalrin/s3/blob/master/lib/s3.rb to point to your gateway_host\n\n######Revert installation\n\nThere are useful commands to purge the Ceph gateway nstallation and configuration from every node so that one can start over again from a clean state.\n\nThis will remove Ceph configuration and keys\n\n\tceph-deploy purgedata mon-server\n\nThis will also remove Ceph packages\n\n\tceph-deploy purge mon-server\n\nIF you received the below error when you attempt to install radosgw again\n\tclient.radosgw.admin exists but key does not match\n \nExecute this to fix the error \n    ceph auth del client.radosgw.gateway\n\n\n \n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaisc000wdrgb2di6slw4","content":"<p><strong>Ceph Object Gateway</strong> is an object storage interface built on top of librados to provide applications with a RESTful gateway to Ceph Storage Clusters. Ceph Object Storage supports two interfaces:</p>\n<p><strong><em>S3-compatible:</em></strong> Provides object storage functionality with an interface that is compatible with a large subset of the Amazon S3 RESTful API.</p>\n<p><strong>Swift-compatible:</strong> Provides object storage functionality with an interface that is compatible with a large subset of the OpenStack Swift API.</p>\n<p><strong>My ceph cluster setup</strong></p>\n<pre><code>mon and gateway    - mon-server(192.168.1.10)\nosd1 and osd2      - osd1(192.168.1.11)\nosd3               - osd2(192.168.1.12)\nOS                 - Ubuntu Trusty(14.04.2 LTS)\n</code></pre><p>To run the Ceph object gateway service on Ubuntu 14.04 (Trusty), you should have a running Ceph cluster and the gateway host should have access to storage and public networks.</p>\n<pre><code>In my case, I&apos;ve done the follwing in mon-server(192.168.1.10)\n</code></pre><p><strong>INSTALL APACHE/FASTCGI</strong></p>\n<p>On Ubuntu Ubuntu 14.04, multiverse needs to be enabled in the package resource list file </p>\n<p>uncomment the following lines in /etc/apt/sources.list:</p>\n<pre><code># deb http://archive.ubuntu.com/ubuntu trusty multiverse\n# deb-src http://archive.ubuntu.com/ubuntu trusty multiverse\n# deb http://archive.ubuntu.com/ubuntu trusty-updates multiverse\n# deb-src http://archive.ubuntu.com/ubuntu trusty-updates multiverse\n</code></pre><p>Update the package resource list:</p>\n<pre><code>$ sudo apt-get update\n</code></pre><p>Install Apache and FastCGI:</p>\n<pre><code>$ sudo apt-get install apache2 libapache2-mod-fastcgi\n</code></pre><p><strong>Configure APACHE</strong></p>\n<p>Add a line for the ServerName in the /etc/apache2/apache2.conf. Provide the fully qualified domain name of the server machine (e.g., hostname -f):</p>\n<pre><code>ServerName mon-server\n</code></pre><p>Enable the URL rewrite modules for Apache and FastCGI<br>Execute the following:</p>\n<pre><code>$ sudo a2enmod rewrite\n$ sudo a2enmod fastcgi\n</code></pre><p>Restart Apache service</p>\n<pre><code>$sudo service apache2 start\n</code></pre><p><strong>INSTALL CEPH OBJECT GATEWAY DAEMON</strong></p>\n<p>Ceph Object Storage services use the Ceph Object Gateway daemon (radosgw) to enable the gateway.</p>\n<p>To install the Ceph Object Gateway daemon on the gateway host, execute the following:</p>\n<pre><code>$ sudo apt-get install radosgw\n</code></pre><p>Once you have installed the Ceph Object Gateway packages, the next step is to configure your Ceph Object Gateway. There are two approaches: <code>simple</code> and <code>FEDERATED</code>. I used <code>simple</code> in my system</p>\n<p>Simple: A simple Ceph Object Gateway configuration implies that you are running a Ceph Object Storage service in a single data center. So you can configure the Ceph Object Gateway without regard to regions and zones.</p>\n<p>The Ceph Object Gateway is a client of the Ceph Storage Cluster. As a Ceph Storage Cluster client, it requires:</p>\n<pre><code>1. A name for the gateway instance. We use &apos;admin&apos; in this guide.\n2. A storage cluster user name with appropriate permissions in a keyring.\n3. Pools to store its data.\n4. A data directory for the gateway instance.\n5. An instance entry in the Ceph Configuration file.\n6. A configuration file for the web server to interact with FastCGI.\n</code></pre><p>The configuration steps are as follows:</p>\n<p><strong>Execute the following steps on the admin node of your cluster:</strong></p>\n<p>Create a keyring for the gateway:</p>\n<pre><code>$ sudo ceph-authtool --create-keyring /etc/ceph/ceph.client.radosgw.keyring\nsudo chmod +r /etc/ceph/ceph.client.radosgw.keyring\n</code></pre><p>Generate a Ceph Object Gateway user name and key for each instance. For exemplary purposes, we will use the name admin after client.radosgw:</p>\n<pre><code>$ sudo ceph-authtool /etc/ceph/ceph.client.radosgw.keyring -n client.radosgw.admin --gen-key\n</code></pre><p>Add capabilities to the key:</p>\n<pre><code>$ sudo ceph-authtool -n client.radosgw.admin --cap osd &apos;allow rwx&apos; --cap mon &apos;allow rwx&apos; /etc/ceph/ceph.client.radosgw.keyring\n</code></pre><p>Once you have created a keyring and key to enable the Ceph Object Gateway with access to the Ceph Storage Cluster, add the key to your Ceph Storage Cluster. For example:</p>\n<pre><code>$ sudo ceph -k /etc/ceph/ceph.client.admin.keyring auth add client.radosgw.admin -i /etc/ceph/ceph.client.radosgw.keyring\n</code></pre><p>Distribute the keyring to the gateway host:</p>\n<pre><code>$ sudo scp /etc/ceph/ceph.client.radosgw.keyring  USERNAME@GATEWAY_IP:/home/ceph\n$ ssh USERNAME@GATEWAY_IP &apos;sudo mv ceph.client.radosgw.keyring /etc/ceph/ceph.client.radosgw.keyring&apos;\n</code></pre><p>NOTE<br>The last step is optional if admin node is the gateway host.</p>\n<p><strong>CREATE POOLS</strong></p>\n<p>If pools already exist, no problem. If not, create all the pools listed below</p>\n<pre><code>$ ceph osd pool create .rgw.buckets 16 16\n\n.rgw\n.rgw.root\n.rgw.control\n.rgw.gc\n.rgw.buckets\n.rgw.buckets.index\n.log\n.intent-log\n.usage\n.users\n.users.email\n.users.swift\n.users.uid\n</code></pre><p><code>NOTE</code><br>if write permission is given, Ceph Object Gateway will create pools automatically.</p>\n<p><code>NOTE</code> When adding a large number of pools, it may take some time for your cluster to return to a active + clean state.</p>\n<p>When you have completed this step, execute the following to ensure that you have created all of the foregoing pools:</p>\n<pre><code>$ rados lspools\n</code></pre><p><strong>ADD A GATEWAY CONFIGURATION TO CEPH</strong> </p>\n<p>Add the Ceph Object Gateway configuration to your Ceph Configuration file in admin node. The Ceph Object Gateway configuration requires you to identify the Ceph Object Gateway instance. Then, you must specify the host name where you installed the Ceph Object Gateway daemon, a keyring (for use with cephx), the socket path for FastCGI and a log file.</p>\n<p>Append the following configuration to <code>/etc/ceph/ceph.conf</code> in your admin node:</p>\n<pre><code>[client.radosgw.admin]\nhost = {hostname}\nkeyring = /etc/ceph/ceph.client.radosgw.keyring\nrgw socket path =     /var/run/ceph/ceph.radosgw.admin.fastcgi.sock\nlog file = /var/log/radosgw/client.radosgw.admin.log\n</code></pre><p><code>NOTE</code><br>Here, {hostname} is the short hostname (output of command hostname -s) of the node that is going to provide the gateway service i.e, the gateway host.</p>\n<p><code>NOTE</code> The [client.radosgw.admin] portion of the gateway instance identifies this portion of the Ceph configuration file as configuring a Ceph Storage Cluster client where the client type is a Ceph Object Gateway (i.e., radosgw).</p>\n<p><strong>DISTRIBUTE UPDATED CEPH CONFIGURATION FILE</strong></p>\n<pre><code>$ ceph-deploy --overwrite-conf config pull {gateway_hostname}\n$ ceph-deploy --overwrite-conf config push osd1 osd2 \n</code></pre><p><strong>COPY CEPH.CLIENT.ADMIN.KEYRING FROM ADMIN NODE TO GATEWAY HOST</strong></p>\n<pre><code>$ sudo scp /etc/ceph/ceph.client.admin.keyring  USERNAME@GATEWAY_IP:/home/USERNAME\n$ ssh USERNAME@GATEWAY_IP &apos;sudo mv ceph.client.admin.keyring /etc/ceph/ceph.client.admin.keyring&apos;\n</code></pre><p><code>NOTE</code> The above step need not be executed if admin node is the gateway host</p>\n<p><strong>CREATE A CGI WRAPPER SCRIPT</strong></p>\n<p>The wrapper script provides the interface between the webserver and the radosgw process. This script needs to be in a web accessible location and should be executable.</p>\n<p>Execute the following steps on the gateway host:</p>\n<p>Create the script:</p>\n<pre><code>$ sudo vi /var/www/html/s3gw.fcgi\n</code></pre><p>Add the following content to the script:</p>\n<pre><code>#!/bin/sh\nexec /usr/bin/radosgw -c /etc/ceph/ceph.conf -n client.radosgw.admin\n</code></pre><p>Provide execute permissions to the script:</p>\n<p>Change file permission</p>\n<pre><code>$ sudo chmod +x /var/www/html/s3gw.fcgi\n</code></pre><p>Create Data Directory</p>\n<pre><code>$ sudo mkdir -p /var/lib/ceph/radosgw/ceph-radosgw.admin\n</code></pre><p>Start rados gateway service</p>\n<pre><code>$ sudo /etc/init.d/radosgw start\n</code></pre><p>CREATE A GATEWAY CONFIGURATION FILE</p>\n<pre><code>$ sudo vi /etc/apache2/sites-available/rgw.conf\n</code></pre><p>Add the following contents to the file:</p>\n<pre><code>FastCgiExternalServer /var/www/html/s3gw.fcgi -socket /var/run/ceph/ceph.radosgw.admin.fastcgi.sock\n\n&lt;VirtualHost *:80&gt;\nServerName localhost\nDocumentRoot /var/www/html\n\nErrorLog /var/log/apache2/rgw_error.log\nCustomLog /var/log/apache2/rgw_access.log combined\n\n# LogLevel debug\n\nRewriteEngine On\n\nRewriteRule ^/([a-zA-Z0-9-_.]*)([/]?.*) /s3gw.fcgi?page=$1&amp;params=$2&amp;%{QUERY_STRING} [E=HTTP_AUTHORIZATION:%{HTTP:Authorization},L]\n\n&lt;IfModule mod_fastcgi.c&gt;\n    &lt;Directory /var/www/html&gt;\n    Options +ExecCGI\n    AllowOverride All\n    SetHandler fastcgi-script\n    Order allow,deny\n    Allow from all\n    AuthBasicAuthoritative Off\n    &lt;/Directory&gt;\n&lt;/IfModule&gt;\n\nAllowEncodedSlashes On\nServerSignature Off\n\n&lt;/VirtualHost&gt;\n</code></pre><p>Disable the default site:</p>\n<pre><code>$ sudo a2dissite 000-default\n</code></pre><p>Enable the configuration file</p>\n<pre><code>$ sudo a2ensite rgw.conf\n</code></pre><p>Restart apache2 service</p>\n<pre><code>$ sudo service apache2 restart\n</code></pre><p><strong>USING THE GATEWAY</strong></p>\n<p>CREATE A RADOSGW USER FOR S3 ACCESS</p>\n<pre><code>$ sudo radosgw-admin user create --uid=&quot;testuser&quot; --display-name=&quot;First User&quot;\n</code></pre><p>The output of the command will be something like the following:</p>\n<pre><code>{&quot;user_id&quot;: &quot;testuser&quot;,\n&quot;display_name&quot;: &quot;First User&quot;,\n&quot;email&quot;: &quot;&quot;,\n&quot;suspended&quot;: 0,\n&quot;max_buckets&quot;: 1000,\n&quot;auid&quot;: 0,\n&quot;subusers&quot;: [],\n&quot;keys&quot;: [\n{ &quot;user&quot;: &quot;testuser&quot;,\n&quot;access_key&quot;: &quot;I0PJDPCIYZ665MW88W9R&quot;,\n&quot;secret_key&quot;:     &quot;dxaXZ8U90SXydYzyS5ivamEP20hkLSUViiaR+ZDA&quot;}],\n&quot;swift_keys&quot;: [],\n&quot;caps&quot;: [],\n&quot;op_mask&quot;: &quot;read, write, delete&quot;,\n&quot;default_placement&quot;: &quot;&quot;,\n&quot;placement_tags&quot;: [],\n&quot;bucket_quota&quot;: { &quot;enabled&quot;: false,\n&quot;max_size_kb&quot;: -1,\n&quot;max_objects&quot;: -1},\n&quot;user_quota&quot;: { &quot;enabled&quot;: false,\n&quot;max_size_kb&quot;: -1,\n&quot;max_objects&quot;: -1},\n&quot;temp_url_keys&quot;: []}\n</code></pre><p><code>NOTE</code> The values of keys-&gt;access_key and keys-&gt;secret_key are needed for access validation.</p>\n<p><strong>ACCESS VERIFICATION</strong></p>\n<p>install the python-boto package</p>\n<pre><code>$ sudo apt-get install python-boto\n</code></pre><p>Create the Python script:</p>\n<pre><code>$ nano s3.py\n\nimport boto\nimport boto.s3.connection\naccess_key = &apos;YOUR_ACCESS_KEY&apos;\nsecret_key = &apos;YOUR_SECRET_KEY&apos;\nconn = boto.connect_s3(\naws_access_key_id = access_key,\naws_secret_access_key = secret_key,\nhost = &apos;{FQDN}&apos;,\nis_secure=False,\ncalling_format = boto.s3.connection.OrdinaryCallingFormat(),)\nbucket = conn.create_bucket(&apos;my-new-bucket&apos;)\nfor bucket in conn.get_all_buckets():\n    print &quot;{name}\\t{created}&quot;.format(\n        name = bucket.name,\n        created = bucket.creation_date,\n)\n</code></pre><p>Run the script:</p>\n<pre><code>$ python s3test.py   \n</code></pre><p>The output will be something like the following:</p>\n<pre><code>my-new-bucket 2015-02-16T17:09:10.000Z\n</code></pre><p><strong>Test in ruby language</strong></p>\n<p>To test ceph-gateway, we have use rubygem <code>s3</code>. Source code is in <a href=\"https://github.com/thomasalrin/s3\" target=\"_blank\" rel=\"external\">https://github.com/thomasalrin/s3</a></p>\n<p>Edit <a href=\"https://github.com/thomasalrin/s3/blob/master/lib/s3.rb\" target=\"_blank\" rel=\"external\">https://github.com/thomasalrin/s3/blob/master/lib/s3.rb</a> to point to your gateway_host</p>\n<p>######Revert installation</p>\n<p>There are useful commands to purge the Ceph gateway nstallation and configuration from every node so that one can start over again from a clean state.</p>\n<p>This will remove Ceph configuration and keys</p>\n<pre><code>ceph-deploy purgedata mon-server\n</code></pre><p>This will also remove Ceph packages</p>\n<pre><code>ceph-deploy purge mon-server\n</code></pre><p>IF you received the below error when you attempt to install radosgw again<br>    client.radosgw.admin exists but key does not match</p>\n<p>Execute this to fix the error<br>    ceph auth del client.radosgw.gateway</p>\n","excerpt":"","more":"<p><strong>Ceph Object Gateway</strong> is an object storage interface built on top of librados to provide applications with a RESTful gateway to Ceph Storage Clusters. Ceph Object Storage supports two interfaces:</p>\n<p><strong><em>S3-compatible:</em></strong> Provides object storage functionality with an interface that is compatible with a large subset of the Amazon S3 RESTful API.</p>\n<p><strong>Swift-compatible:</strong> Provides object storage functionality with an interface that is compatible with a large subset of the OpenStack Swift API.</p>\n<p><strong>My ceph cluster setup</strong></p>\n<pre><code>mon and gateway    - mon-server(192.168.1.10)\nosd1 and osd2      - osd1(192.168.1.11)\nosd3               - osd2(192.168.1.12)\nOS                 - Ubuntu Trusty(14.04.2 LTS)\n</code></pre><p>To run the Ceph object gateway service on Ubuntu 14.04 (Trusty), you should have a running Ceph cluster and the gateway host should have access to storage and public networks.</p>\n<pre><code>In my case, I&apos;ve done the follwing in mon-server(192.168.1.10)\n</code></pre><p><strong>INSTALL APACHE/FASTCGI</strong></p>\n<p>On Ubuntu Ubuntu 14.04, multiverse needs to be enabled in the package resource list file </p>\n<p>uncomment the following lines in /etc/apt/sources.list:</p>\n<pre><code># deb http://archive.ubuntu.com/ubuntu trusty multiverse\n# deb-src http://archive.ubuntu.com/ubuntu trusty multiverse\n# deb http://archive.ubuntu.com/ubuntu trusty-updates multiverse\n# deb-src http://archive.ubuntu.com/ubuntu trusty-updates multiverse\n</code></pre><p>Update the package resource list:</p>\n<pre><code>$ sudo apt-get update\n</code></pre><p>Install Apache and FastCGI:</p>\n<pre><code>$ sudo apt-get install apache2 libapache2-mod-fastcgi\n</code></pre><p><strong>Configure APACHE</strong></p>\n<p>Add a line for the ServerName in the /etc/apache2/apache2.conf. Provide the fully qualified domain name of the server machine (e.g., hostname -f):</p>\n<pre><code>ServerName mon-server\n</code></pre><p>Enable the URL rewrite modules for Apache and FastCGI<br>Execute the following:</p>\n<pre><code>$ sudo a2enmod rewrite\n$ sudo a2enmod fastcgi\n</code></pre><p>Restart Apache service</p>\n<pre><code>$sudo service apache2 start\n</code></pre><p><strong>INSTALL CEPH OBJECT GATEWAY DAEMON</strong></p>\n<p>Ceph Object Storage services use the Ceph Object Gateway daemon (radosgw) to enable the gateway.</p>\n<p>To install the Ceph Object Gateway daemon on the gateway host, execute the following:</p>\n<pre><code>$ sudo apt-get install radosgw\n</code></pre><p>Once you have installed the Ceph Object Gateway packages, the next step is to configure your Ceph Object Gateway. There are two approaches: <code>simple</code> and <code>FEDERATED</code>. I used <code>simple</code> in my system</p>\n<p>Simple: A simple Ceph Object Gateway configuration implies that you are running a Ceph Object Storage service in a single data center. So you can configure the Ceph Object Gateway without regard to regions and zones.</p>\n<p>The Ceph Object Gateway is a client of the Ceph Storage Cluster. As a Ceph Storage Cluster client, it requires:</p>\n<pre><code>1. A name for the gateway instance. We use &apos;admin&apos; in this guide.\n2. A storage cluster user name with appropriate permissions in a keyring.\n3. Pools to store its data.\n4. A data directory for the gateway instance.\n5. An instance entry in the Ceph Configuration file.\n6. A configuration file for the web server to interact with FastCGI.\n</code></pre><p>The configuration steps are as follows:</p>\n<p><strong>Execute the following steps on the admin node of your cluster:</strong></p>\n<p>Create a keyring for the gateway:</p>\n<pre><code>$ sudo ceph-authtool --create-keyring /etc/ceph/ceph.client.radosgw.keyring\nsudo chmod +r /etc/ceph/ceph.client.radosgw.keyring\n</code></pre><p>Generate a Ceph Object Gateway user name and key for each instance. For exemplary purposes, we will use the name admin after client.radosgw:</p>\n<pre><code>$ sudo ceph-authtool /etc/ceph/ceph.client.radosgw.keyring -n client.radosgw.admin --gen-key\n</code></pre><p>Add capabilities to the key:</p>\n<pre><code>$ sudo ceph-authtool -n client.radosgw.admin --cap osd &apos;allow rwx&apos; --cap mon &apos;allow rwx&apos; /etc/ceph/ceph.client.radosgw.keyring\n</code></pre><p>Once you have created a keyring and key to enable the Ceph Object Gateway with access to the Ceph Storage Cluster, add the key to your Ceph Storage Cluster. For example:</p>\n<pre><code>$ sudo ceph -k /etc/ceph/ceph.client.admin.keyring auth add client.radosgw.admin -i /etc/ceph/ceph.client.radosgw.keyring\n</code></pre><p>Distribute the keyring to the gateway host:</p>\n<pre><code>$ sudo scp /etc/ceph/ceph.client.radosgw.keyring  USERNAME@GATEWAY_IP:/home/ceph\n$ ssh USERNAME@GATEWAY_IP &apos;sudo mv ceph.client.radosgw.keyring /etc/ceph/ceph.client.radosgw.keyring&apos;\n</code></pre><p>NOTE<br>The last step is optional if admin node is the gateway host.</p>\n<p><strong>CREATE POOLS</strong></p>\n<p>If pools already exist, no problem. If not, create all the pools listed below</p>\n<pre><code>$ ceph osd pool create .rgw.buckets 16 16\n\n.rgw\n.rgw.root\n.rgw.control\n.rgw.gc\n.rgw.buckets\n.rgw.buckets.index\n.log\n.intent-log\n.usage\n.users\n.users.email\n.users.swift\n.users.uid\n</code></pre><p><code>NOTE</code><br>if write permission is given, Ceph Object Gateway will create pools automatically.</p>\n<p><code>NOTE</code> When adding a large number of pools, it may take some time for your cluster to return to a active + clean state.</p>\n<p>When you have completed this step, execute the following to ensure that you have created all of the foregoing pools:</p>\n<pre><code>$ rados lspools\n</code></pre><p><strong>ADD A GATEWAY CONFIGURATION TO CEPH</strong> </p>\n<p>Add the Ceph Object Gateway configuration to your Ceph Configuration file in admin node. The Ceph Object Gateway configuration requires you to identify the Ceph Object Gateway instance. Then, you must specify the host name where you installed the Ceph Object Gateway daemon, a keyring (for use with cephx), the socket path for FastCGI and a log file.</p>\n<p>Append the following configuration to <code>/etc/ceph/ceph.conf</code> in your admin node:</p>\n<pre><code>[client.radosgw.admin]\nhost = {hostname}\nkeyring = /etc/ceph/ceph.client.radosgw.keyring\nrgw socket path =     /var/run/ceph/ceph.radosgw.admin.fastcgi.sock\nlog file = /var/log/radosgw/client.radosgw.admin.log\n</code></pre><p><code>NOTE</code><br>Here, {hostname} is the short hostname (output of command hostname -s) of the node that is going to provide the gateway service i.e, the gateway host.</p>\n<p><code>NOTE</code> The [client.radosgw.admin] portion of the gateway instance identifies this portion of the Ceph configuration file as configuring a Ceph Storage Cluster client where the client type is a Ceph Object Gateway (i.e., radosgw).</p>\n<p><strong>DISTRIBUTE UPDATED CEPH CONFIGURATION FILE</strong></p>\n<pre><code>$ ceph-deploy --overwrite-conf config pull {gateway_hostname}\n$ ceph-deploy --overwrite-conf config push osd1 osd2 \n</code></pre><p><strong>COPY CEPH.CLIENT.ADMIN.KEYRING FROM ADMIN NODE TO GATEWAY HOST</strong></p>\n<pre><code>$ sudo scp /etc/ceph/ceph.client.admin.keyring  USERNAME@GATEWAY_IP:/home/USERNAME\n$ ssh USERNAME@GATEWAY_IP &apos;sudo mv ceph.client.admin.keyring /etc/ceph/ceph.client.admin.keyring&apos;\n</code></pre><p><code>NOTE</code> The above step need not be executed if admin node is the gateway host</p>\n<p><strong>CREATE A CGI WRAPPER SCRIPT</strong></p>\n<p>The wrapper script provides the interface between the webserver and the radosgw process. This script needs to be in a web accessible location and should be executable.</p>\n<p>Execute the following steps on the gateway host:</p>\n<p>Create the script:</p>\n<pre><code>$ sudo vi /var/www/html/s3gw.fcgi\n</code></pre><p>Add the following content to the script:</p>\n<pre><code>#!/bin/sh\nexec /usr/bin/radosgw -c /etc/ceph/ceph.conf -n client.radosgw.admin\n</code></pre><p>Provide execute permissions to the script:</p>\n<p>Change file permission</p>\n<pre><code>$ sudo chmod +x /var/www/html/s3gw.fcgi\n</code></pre><p>Create Data Directory</p>\n<pre><code>$ sudo mkdir -p /var/lib/ceph/radosgw/ceph-radosgw.admin\n</code></pre><p>Start rados gateway service</p>\n<pre><code>$ sudo /etc/init.d/radosgw start\n</code></pre><p>CREATE A GATEWAY CONFIGURATION FILE</p>\n<pre><code>$ sudo vi /etc/apache2/sites-available/rgw.conf\n</code></pre><p>Add the following contents to the file:</p>\n<pre><code>FastCgiExternalServer /var/www/html/s3gw.fcgi -socket /var/run/ceph/ceph.radosgw.admin.fastcgi.sock\n\n&lt;VirtualHost *:80&gt;\nServerName localhost\nDocumentRoot /var/www/html\n\nErrorLog /var/log/apache2/rgw_error.log\nCustomLog /var/log/apache2/rgw_access.log combined\n\n# LogLevel debug\n\nRewriteEngine On\n\nRewriteRule ^/([a-zA-Z0-9-_.]*)([/]?.*) /s3gw.fcgi?page=$1&amp;params=$2&amp;%{QUERY_STRING} [E=HTTP_AUTHORIZATION:%{HTTP:Authorization},L]\n\n&lt;IfModule mod_fastcgi.c&gt;\n    &lt;Directory /var/www/html&gt;\n    Options +ExecCGI\n    AllowOverride All\n    SetHandler fastcgi-script\n    Order allow,deny\n    Allow from all\n    AuthBasicAuthoritative Off\n    &lt;/Directory&gt;\n&lt;/IfModule&gt;\n\nAllowEncodedSlashes On\nServerSignature Off\n\n&lt;/VirtualHost&gt;\n</code></pre><p>Disable the default site:</p>\n<pre><code>$ sudo a2dissite 000-default\n</code></pre><p>Enable the configuration file</p>\n<pre><code>$ sudo a2ensite rgw.conf\n</code></pre><p>Restart apache2 service</p>\n<pre><code>$ sudo service apache2 restart\n</code></pre><p><strong>USING THE GATEWAY</strong></p>\n<p>CREATE A RADOSGW USER FOR S3 ACCESS</p>\n<pre><code>$ sudo radosgw-admin user create --uid=&quot;testuser&quot; --display-name=&quot;First User&quot;\n</code></pre><p>The output of the command will be something like the following:</p>\n<pre><code>{&quot;user_id&quot;: &quot;testuser&quot;,\n&quot;display_name&quot;: &quot;First User&quot;,\n&quot;email&quot;: &quot;&quot;,\n&quot;suspended&quot;: 0,\n&quot;max_buckets&quot;: 1000,\n&quot;auid&quot;: 0,\n&quot;subusers&quot;: [],\n&quot;keys&quot;: [\n{ &quot;user&quot;: &quot;testuser&quot;,\n&quot;access_key&quot;: &quot;I0PJDPCIYZ665MW88W9R&quot;,\n&quot;secret_key&quot;:     &quot;dxaXZ8U90SXydYzyS5ivamEP20hkLSUViiaR+ZDA&quot;}],\n&quot;swift_keys&quot;: [],\n&quot;caps&quot;: [],\n&quot;op_mask&quot;: &quot;read, write, delete&quot;,\n&quot;default_placement&quot;: &quot;&quot;,\n&quot;placement_tags&quot;: [],\n&quot;bucket_quota&quot;: { &quot;enabled&quot;: false,\n&quot;max_size_kb&quot;: -1,\n&quot;max_objects&quot;: -1},\n&quot;user_quota&quot;: { &quot;enabled&quot;: false,\n&quot;max_size_kb&quot;: -1,\n&quot;max_objects&quot;: -1},\n&quot;temp_url_keys&quot;: []}\n</code></pre><p><code>NOTE</code> The values of keys-&gt;access_key and keys-&gt;secret_key are needed for access validation.</p>\n<p><strong>ACCESS VERIFICATION</strong></p>\n<p>install the python-boto package</p>\n<pre><code>$ sudo apt-get install python-boto\n</code></pre><p>Create the Python script:</p>\n<pre><code>$ nano s3.py\n\nimport boto\nimport boto.s3.connection\naccess_key = &apos;YOUR_ACCESS_KEY&apos;\nsecret_key = &apos;YOUR_SECRET_KEY&apos;\nconn = boto.connect_s3(\naws_access_key_id = access_key,\naws_secret_access_key = secret_key,\nhost = &apos;{FQDN}&apos;,\nis_secure=False,\ncalling_format = boto.s3.connection.OrdinaryCallingFormat(),)\nbucket = conn.create_bucket(&apos;my-new-bucket&apos;)\nfor bucket in conn.get_all_buckets():\n    print &quot;{name}\\t{created}&quot;.format(\n        name = bucket.name,\n        created = bucket.creation_date,\n)\n</code></pre><p>Run the script:</p>\n<pre><code>$ python s3test.py   \n</code></pre><p>The output will be something like the following:</p>\n<pre><code>my-new-bucket 2015-02-16T17:09:10.000Z\n</code></pre><p><strong>Test in ruby language</strong></p>\n<p>To test ceph-gateway, we have use rubygem <code>s3</code>. Source code is in <a href=\"https://github.com/thomasalrin/s3\">https://github.com/thomasalrin/s3</a></p>\n<p>Edit <a href=\"https://github.com/thomasalrin/s3/blob/master/lib/s3.rb\">https://github.com/thomasalrin/s3/blob/master/lib/s3.rb</a> to point to your gateway_host</p>\n<p>######Revert installation</p>\n<p>There are useful commands to purge the Ceph gateway nstallation and configuration from every node so that one can start over again from a clean state.</p>\n<p>This will remove Ceph configuration and keys</p>\n<pre><code>ceph-deploy purgedata mon-server\n</code></pre><p>This will also remove Ceph packages</p>\n<pre><code>ceph-deploy purge mon-server\n</code></pre><p>IF you received the below error when you attempt to install radosgw again<br>    client.radosgw.admin exists but key does not match</p>\n<p>Execute this to fix the error<br>    ceph auth del client.radosgw.gateway</p>\n"},{"title":"Data Center using OpenNebula Federation","slug":"2015-11-27-datacenter-using-opennebula-federation","date_published":"2015-11-27T03:49:06.150Z","date_updated":"2015-12-09T01:29:19.652Z","_content":"\nThe federation is performed by OpenNebula platform. The OpenNebula is an Open-source software for manage virtualized data centers.The data centers are oversees private clouds, public clouds and hybrid clouds. It provides the service as High availability.\n\nHere we are federating two already replicated Master Slave servers. to know how to replicate two servers refer the following article \n\t\n    http://devcenter.megam.io/2015/09/08/mysql-master-slave-replication/\n       \n\n######Installing OpenNebula \n\nbefore start to install OpenNebula verify the ruby installed with appropreate version for the Operating System \n\n**My System Configuration :**\n\n\tOS \t\t\t\t: \tUbuntu 14.04\n    OpenNebula \t :\t Version 4.12\t\n    \n    My Servers\n    \n    \t\tServer 1: 192.168.1.12  (Master)\n            Server 2: 192.168.1.13  (Slave)\n\nthe below Steps for Install OpenNebula occurding to my system configuration.\n\nfor Ubuntu 14.04 we need to install some packages before and after install opennebula that are \n\n\truby2.0,ruby2.0-dev and ruby-dev \n \n packages to be install.\n\nBefore install           \n\n\tapt-get -y install build-essential autoconf libtool make\n        \n\tapt-get -y install lvm2 ssh iproute iputils-arping\n\n\t\nInstall Opennebula\n\n\twget -q -O- http://downloads.opennebula.org/repo/Ubuntu/repo.key | apt-key add -\n\n\techo \"deb http://downloads.opennebula.org/repo/4.12/Ubuntu/14.04 stable opennebula\" > /etc/apt/sources.list.d/opennebula.list\n\n\tapt-get -y update\n\n\tapt-get -y install opennebula opennebula-sunstone \n\n\t\nAfter install\n\n\techo \"oneadmin ALL = (root) NOPASSWD:ALL\" | sudo tee /etc/sudoers.d/oneadmin\n\n\tapt-get -y install ntp\n\n\tapt-get -y install ruby-dev\n\n\tchmod 0440 /etc/sudoers.d/oneadmin\t\t\n\n\tchmod 755 /usr/share/one/install_gems\n    \n    sudo /usr/share/one/install_gems sunstone\n\nAdd ip and port of sunstone-server in conf\n\t\n    sed -i \"s/^[ \\t]*:host:.*/:host: $ipaddr/\" /etc/one/sunstone-server.conf\n\nstart the Opennebula services\n\n\tsunstone-server start  \n\n\tecone-server start\n\t\n\tocci-server restart\n\t\n\tonegate-server restart\n\n\tsudo -H -u oneadmin bash -c \"one restart\"     \n\n\tservice opennebula restart\n\nrestart the Opennebula services\n\n\tsunstone-server restart \n\tecone-server restart \n\tocci-server restart \n\tonegate-server restart \n\tsudo -H -u oneadmin bash -c \"one restart\" \n\tsudo service opennebula restart \n\nthe above are installation process of OpenNebula\n\n\n######Configuration of OpenNebula Federation Master\n\nOpenNebula uses the database sqllite by default but I use MySQL So I have to configure the OpenNebula database to MySQL Database. \n\nFirst Install MySQL Server in your both server hosts\n\nthen create an user for OpenNebula federation\n\n\t$ mysql -u root -p pswd\n        \n       mysql> create user 'oneadmin'@'%' IDENTIFIED BY 'oneadmin';\n    \n   \tmysql> GRANT ALL PRIVILEGES ON opennebula.* TO 'oneadmin' IDENTIFIED BY 'oneadmin';\n    \nConfigure OpenNebula to MySQL Database and set Federation Master and Zone id \n\n\t$ nano  /etc/one/oned.conf\n\n\t\t#DB = [ backend = \"sqlite\" ]  >> Change as follow\n\n\t\t# Sample configuration for MySQL\n\t\t DB = [ backend = \"mysql\",\n   \t\t     server  = \"192.168.1.12\",\n    \t\t    port    = 0,\n        \t\tuser    = \"oneadmin\",\n        \t\tpasswd  = \"oneadmin\",\n        \t\tdb_name = \"opennebula\" ]\n\n\t\tFEDERATION = [\n    \t\t\tMODE = \"MASTER\",\n    \t\t\tZONE_ID = 123,\n    \t\t\tMASTER_ONED = \"\"\n\t\t\t]\n            \nSave the conf file, after configuration \n\nRemove the all auth files except one_auth, Before that you have to backup all the auth file.\n\n\tBack up the all auth files form /var/lib/one/.one/ and remove all auth files except one_auth file.\n    \n\nRestart the service to get the new keys generated again:\n    \n After remove the file restart the services\n  \t\n    sunstone-server restart \n\tecone-server restart \n\tocci-server restart \n\tonegate-server restart \n\tsudo -H -u oneadmin bash -c \"one restart\" \n\tsudo service opennebula restart \n  \nEdit the local (master) Zone Endpoint by using the onezone command. You can also done this via your Sunstone UI.\n\n\n\t$ onezone update 0 \n    \n    ENDPOINT = http://<192.168.1.12>:2633/RPC2\n\nCreate a Zone for each one of the slaves, and note down the new Zone ID. \n\n$ nano /tmp/zone.tmpl\n\n        NAME          = slave-one13\n\t\tENDPOINT \t  = http://<192.168.1.13>:2633/RPC2\n        \ncreate your slave zone id by zone template file using blow command         \n\t\n    $ onezone create /tmp/zone.tmpl  \n   \t\tID: 100\n        \nTo list your Zones \n\n   \n   \t$ onezone list\n    ID \t NAME  \t\t    ENDPOINT\n    123\t OpenNebula  \n    100     slave-one13           \n    \n######Configure the OpenNebula Federation Slave\n\nFor each slave, follow these steps.\n\nIf it is a new installation, install OpenNebula as menstioned in above the installing OpenNebula guide. \n\nTo Configure OpenNebula Slave Server Use below steps: \n\n\t$mysql -u root -p\n\tmysql> GRANT ALL PRIVILEGES ON opennebula.* TO 'oneadmin' IDENTIFIED BY 'oneadmin';\n\nand update oned.conf to use these values:\n\t\n    $ nano /etc/one/oned.conf\n\t\t# DB = [ backend = \"sqlite\" ] change as\n\n\t\t# Sample configuration for MySQL\n \t\tDB = [ backend = \"mysql\",\n        \tserver  = \"192.168.1.13\",\n        \tport    = 0,\n        \tuser    = \"oneadmin\",\n        \tpasswd  = \"oneadmin\",\n        \tdb_name = \"opennebula\" ]\n\nConfigure OpenNebula to act as a federation slave. Don't forget to use the Zone ID as you obtained when the zone was created. \n\n\tFEDERATION = [\n    \tMODE = \"SLAVE\",\n    \tZONE_ID = 100,\n    MASTER_ONED = \"http://<192.168.1.12>:2633/RPC2\"\n\t\t]\n\nCopy the directory /var/lib/one/.one from the master host server to the slave host server. This directory and its contents must have oneadmin as owner. The directory should contain these files: \n\t\n    $ ls -1 /var/lib/one/.one\n\tec2_auth\n    occi_auth\n\tone_auth\n\toneflow_auth\n\tonegate_auth\n    one_key\n\tsunstone_auth\n\nMake sure one_auth (the oneadmin credentials) is present. If its not, copy it from master oneadmins /var/lib/one/.one/ to the slave oneadmins /var/lib/one/.one/. \n\n\tStart the slave OpenNebula services. \n\n\n","source":"_posts/2015-11-27-datacenter-using-opennebula-federation.md","raw":"---\ntitle: Data Center using OpenNebula Federation\nslug: datacenter-using-opennebula-federation\ndate_published: 2015-11-27T09:19:06.150Z\ndate_updated:   2015-12-09T06:59:19.652Z\n---\n\nThe federation is performed by OpenNebula platform. The OpenNebula is an Open-source software for manage virtualized data centers.The data centers are oversees private clouds, public clouds and hybrid clouds. It provides the service as High availability.\n\nHere we are federating two already replicated Master Slave servers. to know how to replicate two servers refer the following article \n\t\n    http://devcenter.megam.io/2015/09/08/mysql-master-slave-replication/\n       \n\n######Installing OpenNebula \n\nbefore start to install OpenNebula verify the ruby installed with appropreate version for the Operating System \n\n**My System Configuration :**\n\n\tOS \t\t\t\t: \tUbuntu 14.04\n    OpenNebula \t :\t Version 4.12\t\n    \n    My Servers\n    \n    \t\tServer 1: 192.168.1.12  (Master)\n            Server 2: 192.168.1.13  (Slave)\n\nthe below Steps for Install OpenNebula occurding to my system configuration.\n\nfor Ubuntu 14.04 we need to install some packages before and after install opennebula that are \n\n\truby2.0,ruby2.0-dev and ruby-dev \n \n packages to be install.\n\nBefore install           \n\n\tapt-get -y install build-essential autoconf libtool make\n        \n\tapt-get -y install lvm2 ssh iproute iputils-arping\n\n\t\nInstall Opennebula\n\n\twget -q -O- http://downloads.opennebula.org/repo/Ubuntu/repo.key | apt-key add -\n\n\techo \"deb http://downloads.opennebula.org/repo/4.12/Ubuntu/14.04 stable opennebula\" > /etc/apt/sources.list.d/opennebula.list\n\n\tapt-get -y update\n\n\tapt-get -y install opennebula opennebula-sunstone \n\n\t\nAfter install\n\n\techo \"oneadmin ALL = (root) NOPASSWD:ALL\" | sudo tee /etc/sudoers.d/oneadmin\n\n\tapt-get -y install ntp\n\n\tapt-get -y install ruby-dev\n\n\tchmod 0440 /etc/sudoers.d/oneadmin\t\t\n\n\tchmod 755 /usr/share/one/install_gems\n    \n    sudo /usr/share/one/install_gems sunstone\n\nAdd ip and port of sunstone-server in conf\n\t\n    sed -i \"s/^[ \\t]*:host:.*/:host: $ipaddr/\" /etc/one/sunstone-server.conf\n\nstart the Opennebula services\n\n\tsunstone-server start  \n\n\tecone-server start\n\t\n\tocci-server restart\n\t\n\tonegate-server restart\n\n\tsudo -H -u oneadmin bash -c \"one restart\"     \n\n\tservice opennebula restart\n\nrestart the Opennebula services\n\n\tsunstone-server restart \n\tecone-server restart \n\tocci-server restart \n\tonegate-server restart \n\tsudo -H -u oneadmin bash -c \"one restart\" \n\tsudo service opennebula restart \n\nthe above are installation process of OpenNebula\n\n\n######Configuration of OpenNebula Federation Master\n\nOpenNebula uses the database sqllite by default but I use MySQL So I have to configure the OpenNebula database to MySQL Database. \n\nFirst Install MySQL Server in your both server hosts\n\nthen create an user for OpenNebula federation\n\n\t$ mysql -u root -p pswd\n        \n       mysql> create user 'oneadmin'@'%' IDENTIFIED BY 'oneadmin';\n    \n   \tmysql> GRANT ALL PRIVILEGES ON opennebula.* TO 'oneadmin' IDENTIFIED BY 'oneadmin';\n    \nConfigure OpenNebula to MySQL Database and set Federation Master and Zone id \n\n\t$ nano  /etc/one/oned.conf\n\n\t\t#DB = [ backend = \"sqlite\" ]  >> Change as follow\n\n\t\t# Sample configuration for MySQL\n\t\t DB = [ backend = \"mysql\",\n   \t\t     server  = \"192.168.1.12\",\n    \t\t    port    = 0,\n        \t\tuser    = \"oneadmin\",\n        \t\tpasswd  = \"oneadmin\",\n        \t\tdb_name = \"opennebula\" ]\n\n\t\tFEDERATION = [\n    \t\t\tMODE = \"MASTER\",\n    \t\t\tZONE_ID = 123,\n    \t\t\tMASTER_ONED = \"\"\n\t\t\t]\n            \nSave the conf file, after configuration \n\nRemove the all auth files except one_auth, Before that you have to backup all the auth file.\n\n\tBack up the all auth files form /var/lib/one/.one/ and remove all auth files except one_auth file.\n    \n\nRestart the service to get the new keys generated again:\n    \n After remove the file restart the services\n  \t\n    sunstone-server restart \n\tecone-server restart \n\tocci-server restart \n\tonegate-server restart \n\tsudo -H -u oneadmin bash -c \"one restart\" \n\tsudo service opennebula restart \n  \nEdit the local (master) Zone Endpoint by using the onezone command. You can also done this via your Sunstone UI.\n\n\n\t$ onezone update 0 \n    \n    ENDPOINT = http://<192.168.1.12>:2633/RPC2\n\nCreate a Zone for each one of the slaves, and note down the new Zone ID. \n\n$ nano /tmp/zone.tmpl\n\n        NAME          = slave-one13\n\t\tENDPOINT \t  = http://<192.168.1.13>:2633/RPC2\n        \ncreate your slave zone id by zone template file using blow command         \n\t\n    $ onezone create /tmp/zone.tmpl  \n   \t\tID: 100\n        \nTo list your Zones \n\n   \n   \t$ onezone list\n    ID \t NAME  \t\t    ENDPOINT\n    123\t OpenNebula  \n    100     slave-one13           \n    \n######Configure the OpenNebula Federation Slave\n\nFor each slave, follow these steps.\n\nIf it is a new installation, install OpenNebula as menstioned in above the installing OpenNebula guide. \n\nTo Configure OpenNebula Slave Server Use below steps: \n\n\t$mysql -u root -p\n\tmysql> GRANT ALL PRIVILEGES ON opennebula.* TO 'oneadmin' IDENTIFIED BY 'oneadmin';\n\nand update oned.conf to use these values:\n\t\n    $ nano /etc/one/oned.conf\n\t\t# DB = [ backend = \"sqlite\" ] change as\n\n\t\t# Sample configuration for MySQL\n \t\tDB = [ backend = \"mysql\",\n        \tserver  = \"192.168.1.13\",\n        \tport    = 0,\n        \tuser    = \"oneadmin\",\n        \tpasswd  = \"oneadmin\",\n        \tdb_name = \"opennebula\" ]\n\nConfigure OpenNebula to act as a federation slave. Don't forget to use the Zone ID as you obtained when the zone was created. \n\n\tFEDERATION = [\n    \tMODE = \"SLAVE\",\n    \tZONE_ID = 100,\n    MASTER_ONED = \"http://<192.168.1.12>:2633/RPC2\"\n\t\t]\n\nCopy the directory /var/lib/one/.one from the master host server to the slave host server. This directory and its contents must have oneadmin as owner. The directory should contain these files: \n\t\n    $ ls -1 /var/lib/one/.one\n\tec2_auth\n    occi_auth\n\tone_auth\n\toneflow_auth\n\tonegate_auth\n    one_key\n\tsunstone_auth\n\nMake sure one_auth (the oneadmin credentials) is present. If its not, copy it from master oneadmins /var/lib/one/.one/ to the slave oneadmins /var/lib/one/.one/. \n\n\tStart the slave OpenNebula services. \n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaise000xdrgbnys1a6ks","content":"<p>The federation is performed by OpenNebula platform. The OpenNebula is an Open-source software for manage virtualized data centers.The data centers are oversees private clouds, public clouds and hybrid clouds. It provides the service as High availability.</p>\n<p>Here we are federating two already replicated Master Slave servers. to know how to replicate two servers refer the following article </p>\n<pre><code>http://devcenter.megam.io/2015/09/08/mysql-master-slave-replication/\n</code></pre><p>######Installing OpenNebula </p>\n<p>before start to install OpenNebula verify the ruby installed with appropreate version for the Operating System </p>\n<p><strong>My System Configuration :</strong></p>\n<pre><code>OS                 :     Ubuntu 14.04\nOpenNebula      :     Version 4.12    \n\nMy Servers\n\n        Server 1: 192.168.1.12  (Master)\n        Server 2: 192.168.1.13  (Slave)\n</code></pre><p>the below Steps for Install OpenNebula occurding to my system configuration.</p>\n<p>for Ubuntu 14.04 we need to install some packages before and after install opennebula that are </p>\n<pre><code>ruby2.0,ruby2.0-dev and ruby-dev \n</code></pre><p> packages to be install.</p>\n<p>Before install           </p>\n<pre><code>apt-get -y install build-essential autoconf libtool make\n\napt-get -y install lvm2 ssh iproute iputils-arping\n</code></pre><p>Install Opennebula</p>\n<pre><code>wget -q -O- http://downloads.opennebula.org/repo/Ubuntu/repo.key | apt-key add -\n\necho &quot;deb http://downloads.opennebula.org/repo/4.12/Ubuntu/14.04 stable opennebula&quot; &gt; /etc/apt/sources.list.d/opennebula.list\n\napt-get -y update\n\napt-get -y install opennebula opennebula-sunstone \n</code></pre><p>After install</p>\n<pre><code>echo &quot;oneadmin ALL = (root) NOPASSWD:ALL&quot; | sudo tee /etc/sudoers.d/oneadmin\n\napt-get -y install ntp\n\napt-get -y install ruby-dev\n\nchmod 0440 /etc/sudoers.d/oneadmin        \n\nchmod 755 /usr/share/one/install_gems\n\nsudo /usr/share/one/install_gems sunstone\n</code></pre><p>Add ip and port of sunstone-server in conf</p>\n<pre><code>sed -i &quot;s/^[ \\t]*:host:.*/:host: $ipaddr/&quot; /etc/one/sunstone-server.conf\n</code></pre><p>start the Opennebula services</p>\n<pre><code>sunstone-server start  \n\necone-server start\n\nocci-server restart\n\nonegate-server restart\n\nsudo -H -u oneadmin bash -c &quot;one restart&quot;     \n\nservice opennebula restart\n</code></pre><p>restart the Opennebula services</p>\n<pre><code>sunstone-server restart \necone-server restart \nocci-server restart \nonegate-server restart \nsudo -H -u oneadmin bash -c &quot;one restart&quot; \nsudo service opennebula restart \n</code></pre><p>the above are installation process of OpenNebula</p>\n<p>######Configuration of OpenNebula Federation Master</p>\n<p>OpenNebula uses the database sqllite by default but I use MySQL So I have to configure the OpenNebula database to MySQL Database. </p>\n<p>First Install MySQL Server in your both server hosts</p>\n<p>then create an user for OpenNebula federation</p>\n<pre><code>$ mysql -u root -p pswd\n\n   mysql&gt; create user &apos;oneadmin&apos;@&apos;%&apos; IDENTIFIED BY &apos;oneadmin&apos;;\n\n   mysql&gt; GRANT ALL PRIVILEGES ON opennebula.* TO &apos;oneadmin&apos; IDENTIFIED BY &apos;oneadmin&apos;;\n</code></pre><p>Configure OpenNebula to MySQL Database and set Federation Master and Zone id </p>\n<pre><code>$ nano  /etc/one/oned.conf\n\n    #DB = [ backend = &quot;sqlite&quot; ]  &gt;&gt; Change as follow\n\n    # Sample configuration for MySQL\n     DB = [ backend = &quot;mysql&quot;,\n            server  = &quot;192.168.1.12&quot;,\n            port    = 0,\n            user    = &quot;oneadmin&quot;,\n            passwd  = &quot;oneadmin&quot;,\n            db_name = &quot;opennebula&quot; ]\n\n    FEDERATION = [\n            MODE = &quot;MASTER&quot;,\n            ZONE_ID = 123,\n            MASTER_ONED = &quot;&quot;\n        ]\n</code></pre><p>Save the conf file, after configuration </p>\n<p>Remove the all auth files except one_auth, Before that you have to backup all the auth file.</p>\n<pre><code>Back up the all auth files form /var/lib/one/.one/ and remove all auth files except one_auth file.\n</code></pre><p>Restart the service to get the new keys generated again:</p>\n<p> After remove the file restart the services</p>\n<pre><code>sunstone-server restart \necone-server restart \nocci-server restart \nonegate-server restart \nsudo -H -u oneadmin bash -c &quot;one restart&quot; \nsudo service opennebula restart \n</code></pre><p>Edit the local (master) Zone Endpoint by using the onezone command. You can also done this via your Sunstone UI.</p>\n<pre><code>$ onezone update 0 \n\nENDPOINT = http://&lt;192.168.1.12&gt;:2633/RPC2\n</code></pre><p>Create a Zone for each one of the slaves, and note down the new Zone ID. </p>\n<p>$ nano /tmp/zone.tmpl</p>\n<pre><code>NAME          = slave-one13\nENDPOINT       = http://&lt;192.168.1.13&gt;:2633/RPC2\n</code></pre><p>create your slave zone id by zone template file using blow command         </p>\n<pre><code>$ onezone create /tmp/zone.tmpl  \n       ID: 100\n</code></pre><p>To list your Zones </p>\n<pre><code>   $ onezone list\nID      NAME              ENDPOINT\n123     OpenNebula  \n100     slave-one13           \n</code></pre><p>######Configure the OpenNebula Federation Slave</p>\n<p>For each slave, follow these steps.</p>\n<p>If it is a new installation, install OpenNebula as menstioned in above the installing OpenNebula guide. </p>\n<p>To Configure OpenNebula Slave Server Use below steps: </p>\n<pre><code>$mysql -u root -p\nmysql&gt; GRANT ALL PRIVILEGES ON opennebula.* TO &apos;oneadmin&apos; IDENTIFIED BY &apos;oneadmin&apos;;\n</code></pre><p>and update oned.conf to use these values:</p>\n<pre><code>$ nano /etc/one/oned.conf\n    # DB = [ backend = &quot;sqlite&quot; ] change as\n\n    # Sample configuration for MySQL\n     DB = [ backend = &quot;mysql&quot;,\n        server  = &quot;192.168.1.13&quot;,\n        port    = 0,\n        user    = &quot;oneadmin&quot;,\n        passwd  = &quot;oneadmin&quot;,\n        db_name = &quot;opennebula&quot; ]\n</code></pre><p>Configure OpenNebula to act as a federation slave. Dont forget to use the Zone ID as you obtained when the zone was created. </p>\n<pre><code>FEDERATION = [\n    MODE = &quot;SLAVE&quot;,\n    ZONE_ID = 100,\nMASTER_ONED = &quot;http://&lt;192.168.1.12&gt;:2633/RPC2&quot;\n    ]\n</code></pre><p>Copy the directory /var/lib/one/.one from the master host server to the slave host server. This directory and its contents must have oneadmin as owner. The directory should contain these files: </p>\n<pre><code>$ ls -1 /var/lib/one/.one\nec2_auth\nocci_auth\none_auth\noneflow_auth\nonegate_auth\none_key\nsunstone_auth\n</code></pre><p>Make sure one_auth (the oneadmin credentials) is present. If its not, copy it from master oneadmins /var/lib/one/.one/ to the slave oneadmins /var/lib/one/.one/. </p>\n<pre><code>Start the slave OpenNebula services. \n</code></pre>","excerpt":"","more":"<p>The federation is performed by OpenNebula platform. The OpenNebula is an Open-source software for manage virtualized data centers.The data centers are oversees private clouds, public clouds and hybrid clouds. It provides the service as High availability.</p>\n<p>Here we are federating two already replicated Master Slave servers. to know how to replicate two servers refer the following article </p>\n<pre><code>http://devcenter.megam.io/2015/09/08/mysql-master-slave-replication/\n</code></pre><p>######Installing OpenNebula </p>\n<p>before start to install OpenNebula verify the ruby installed with appropreate version for the Operating System </p>\n<p><strong>My System Configuration :</strong></p>\n<pre><code>OS                 :     Ubuntu 14.04\nOpenNebula      :     Version 4.12    \n\nMy Servers\n\n        Server 1: 192.168.1.12  (Master)\n        Server 2: 192.168.1.13  (Slave)\n</code></pre><p>the below Steps for Install OpenNebula occurding to my system configuration.</p>\n<p>for Ubuntu 14.04 we need to install some packages before and after install opennebula that are </p>\n<pre><code>ruby2.0,ruby2.0-dev and ruby-dev \n</code></pre><p> packages to be install.</p>\n<p>Before install           </p>\n<pre><code>apt-get -y install build-essential autoconf libtool make\n\napt-get -y install lvm2 ssh iproute iputils-arping\n</code></pre><p>Install Opennebula</p>\n<pre><code>wget -q -O- http://downloads.opennebula.org/repo/Ubuntu/repo.key | apt-key add -\n\necho &quot;deb http://downloads.opennebula.org/repo/4.12/Ubuntu/14.04 stable opennebula&quot; &gt; /etc/apt/sources.list.d/opennebula.list\n\napt-get -y update\n\napt-get -y install opennebula opennebula-sunstone \n</code></pre><p>After install</p>\n<pre><code>echo &quot;oneadmin ALL = (root) NOPASSWD:ALL&quot; | sudo tee /etc/sudoers.d/oneadmin\n\napt-get -y install ntp\n\napt-get -y install ruby-dev\n\nchmod 0440 /etc/sudoers.d/oneadmin        \n\nchmod 755 /usr/share/one/install_gems\n\nsudo /usr/share/one/install_gems sunstone\n</code></pre><p>Add ip and port of sunstone-server in conf</p>\n<pre><code>sed -i &quot;s/^[ \\t]*:host:.*/:host: $ipaddr/&quot; /etc/one/sunstone-server.conf\n</code></pre><p>start the Opennebula services</p>\n<pre><code>sunstone-server start  \n\necone-server start\n\nocci-server restart\n\nonegate-server restart\n\nsudo -H -u oneadmin bash -c &quot;one restart&quot;     \n\nservice opennebula restart\n</code></pre><p>restart the Opennebula services</p>\n<pre><code>sunstone-server restart \necone-server restart \nocci-server restart \nonegate-server restart \nsudo -H -u oneadmin bash -c &quot;one restart&quot; \nsudo service opennebula restart \n</code></pre><p>the above are installation process of OpenNebula</p>\n<p>######Configuration of OpenNebula Federation Master</p>\n<p>OpenNebula uses the database sqllite by default but I use MySQL So I have to configure the OpenNebula database to MySQL Database. </p>\n<p>First Install MySQL Server in your both server hosts</p>\n<p>then create an user for OpenNebula federation</p>\n<pre><code>$ mysql -u root -p pswd\n\n   mysql&gt; create user &apos;oneadmin&apos;@&apos;%&apos; IDENTIFIED BY &apos;oneadmin&apos;;\n\n   mysql&gt; GRANT ALL PRIVILEGES ON opennebula.* TO &apos;oneadmin&apos; IDENTIFIED BY &apos;oneadmin&apos;;\n</code></pre><p>Configure OpenNebula to MySQL Database and set Federation Master and Zone id </p>\n<pre><code>$ nano  /etc/one/oned.conf\n\n    #DB = [ backend = &quot;sqlite&quot; ]  &gt;&gt; Change as follow\n\n    # Sample configuration for MySQL\n     DB = [ backend = &quot;mysql&quot;,\n            server  = &quot;192.168.1.12&quot;,\n            port    = 0,\n            user    = &quot;oneadmin&quot;,\n            passwd  = &quot;oneadmin&quot;,\n            db_name = &quot;opennebula&quot; ]\n\n    FEDERATION = [\n            MODE = &quot;MASTER&quot;,\n            ZONE_ID = 123,\n            MASTER_ONED = &quot;&quot;\n        ]\n</code></pre><p>Save the conf file, after configuration </p>\n<p>Remove the all auth files except one_auth, Before that you have to backup all the auth file.</p>\n<pre><code>Back up the all auth files form /var/lib/one/.one/ and remove all auth files except one_auth file.\n</code></pre><p>Restart the service to get the new keys generated again:</p>\n<p> After remove the file restart the services</p>\n<pre><code>sunstone-server restart \necone-server restart \nocci-server restart \nonegate-server restart \nsudo -H -u oneadmin bash -c &quot;one restart&quot; \nsudo service opennebula restart \n</code></pre><p>Edit the local (master) Zone Endpoint by using the onezone command. You can also done this via your Sunstone UI.</p>\n<pre><code>$ onezone update 0 \n\nENDPOINT = http://&lt;192.168.1.12&gt;:2633/RPC2\n</code></pre><p>Create a Zone for each one of the slaves, and note down the new Zone ID. </p>\n<p>$ nano /tmp/zone.tmpl</p>\n<pre><code>NAME          = slave-one13\nENDPOINT       = http://&lt;192.168.1.13&gt;:2633/RPC2\n</code></pre><p>create your slave zone id by zone template file using blow command         </p>\n<pre><code>$ onezone create /tmp/zone.tmpl  \n       ID: 100\n</code></pre><p>To list your Zones </p>\n<pre><code>   $ onezone list\nID      NAME              ENDPOINT\n123     OpenNebula  \n100     slave-one13           \n</code></pre><p>######Configure the OpenNebula Federation Slave</p>\n<p>For each slave, follow these steps.</p>\n<p>If it is a new installation, install OpenNebula as menstioned in above the installing OpenNebula guide. </p>\n<p>To Configure OpenNebula Slave Server Use below steps: </p>\n<pre><code>$mysql -u root -p\nmysql&gt; GRANT ALL PRIVILEGES ON opennebula.* TO &apos;oneadmin&apos; IDENTIFIED BY &apos;oneadmin&apos;;\n</code></pre><p>and update oned.conf to use these values:</p>\n<pre><code>$ nano /etc/one/oned.conf\n    # DB = [ backend = &quot;sqlite&quot; ] change as\n\n    # Sample configuration for MySQL\n     DB = [ backend = &quot;mysql&quot;,\n        server  = &quot;192.168.1.13&quot;,\n        port    = 0,\n        user    = &quot;oneadmin&quot;,\n        passwd  = &quot;oneadmin&quot;,\n        db_name = &quot;opennebula&quot; ]\n</code></pre><p>Configure OpenNebula to act as a federation slave. Dont forget to use the Zone ID as you obtained when the zone was created. </p>\n<pre><code>FEDERATION = [\n    MODE = &quot;SLAVE&quot;,\n    ZONE_ID = 100,\nMASTER_ONED = &quot;http://&lt;192.168.1.12&gt;:2633/RPC2&quot;\n    ]\n</code></pre><p>Copy the directory /var/lib/one/.one from the master host server to the slave host server. This directory and its contents must have oneadmin as owner. The directory should contain these files: </p>\n<pre><code>$ ls -1 /var/lib/one/.one\nec2_auth\nocci_auth\none_auth\noneflow_auth\nonegate_auth\none_key\nsunstone_auth\n</code></pre><p>Make sure one_auth (the oneadmin credentials) is present. If its not, copy it from master oneadmins /var/lib/one/.one/ to the slave oneadmins /var/lib/one/.one/. </p>\n<pre><code>Start the slave OpenNebula services. \n</code></pre>"},{"title":"Gradle for scala","slug":"2015-12-08-gradle-for-scala","date_published":"2015-12-08T09:22:33.715Z","date_updated":"2016-04-16T08:42:45.536Z","_content":"\n### Installing gradle\n\nWe have decided to gradually migrate all our projects to gradle from `sbt` due to its performance.\n\nIn our recent [sparkbuilder](https://github.com/megamsys/sparkbuilder.git) project we found a need to **natively build jars** for our analytic prediction templates - We call us  Yonpi [**Y**et **AN**other **P**lug**I**n]\n\nHere we will look at installing gradle and setting up a scala project and publishing it to bintray.\n\n#### Download grade\n\nDowload and untar the zip [gradle](http://gradle.org/gradle-download/)\n\n\n### Environment variable \n\nSetup the PATH environment variable by appending *GRADLE_HOME/bin*\n\nThere may be packages for your distro (ubuntu, or archlinux)\n\n#### In Archlinux \n\n```\n\nyaourt gradle\n\n```\n\n### Your first scala project [sparkbuilder](https://github.com/megamsys/sparkbuilder.git)\n\n> *build.gradle*\n\nThe build recipe for gradle resides here.\n\n>*src/main/scala:* \n\nContains the scala source code.\n\nGradle provide a plugin for scala projects, just include the line in your build.gradle as  `apply plugin: scala`\n\n```\n\napply plugin: scala\n\n```\n\nHere is our full gradle file.\n\n```\n\napply plugin: 'scala'\n\nrepositories {\n    maven {\n      url 'https://repo.gradle.org/gradle/libs-releases-local'\n    }\n\n    maven {\n      url 'http://dl.bintray.com/megamsys/scala'\n    }\n\n    mavenCentral()\n}\n\ndependencies {\n  compile 'org.scala-lang:scala-library:2.11.7'\n}\n\ndef toolingApiVersion = gradle.gradleVersion\n\ndependencies {\n    compile \"org.gradle:gradle-tooling-api:${toolingApiVersion}\"\n    compile 'io.megam:libcommon_2.11:0.20'\n    compile 'org.scalaz:scalaz-core_2.11:7.1.5'\n    testCompile 'junit:junit:4.5'\n    testCompile 'org.specs2:specs2-core_2.11:3.6.5-20151112214348-18646b2'\n    testCompile 'org.specs2:specs2-junit_2.11:3.6.5-20151112214348-18646b2'\n    testCompile 'org.specs2:specs2-matcher-extra_2.11:3.6.5-20151112214348-18646b2'\n    runtime 'org.slf4j:slf4j-simple:1.7.10'\n}\n\n\n```\n\nTo start from the top.\n\n>*repositories*\n\nAdd the repositories you want *gradle* to download jars\n\n```\n\nrepositories {\n    maven {\n      url 'https://repo.gradle.org/gradle/libs-releases-local'\n    }\n\n    maven {\n      url 'http://dl.bintray.com/megamsys/scala'\n    }\n\n    mavenCentral()\n}\n\n```\n\nIn the above we use a library from bintray.com/megamsys/scala, and also will be using `gradle tooling api` to build scala code (yonpi)\n\n>*dependencies*\n\nAdd the dependencies you want *sparkbuilder* to use. We will use the following apis.\n\n- gradle-tooling\n- scalaz\n- megam:libcommon\n\nFor *tests* we will use \n\n-  junit\n-  specs2\n\n```\n\ndependencies {\n    compile \"org.gradle:gradle-tooling-api:${toolingApiVersion}\"\n    compile 'io.megam:libcommon_2.11:0.20'\n    compile 'org.scalaz:scalaz-core_2.11:7.1.5'\n    testCompile 'junit:junit:4.5'\n    testCompile 'org.specs2:specs2-core_2.11:3.6.5-20151112214348-18646b2'\n    testCompile 'org.specs2:specs2-junit_2.11:3.6.5-20151112214348-18646b2'\n    testCompile 'org.specs2:specs2-matcher-extra_2.11:3.6.5-20151112214348-18646b2'\n    runtime 'org.slf4j:slf4j-simple:1.7.10'\n}\n\n```\n\n### CompileScala\n\nLets compile our source code.\n\n```\n\ngradle build\n\n```\n\nThe above does a compile and test of scala code.\n\n### Testing using spec2 and gradle\n\nspecs2 isn't quite friendly as in [sbt](https://scala-sbt.org)\n\nSo to make it work we will need to add these dependencies for using **specs2**\n\nYes, **JUnit** is needed\n\n```\n\ntestCompile 'junit:junit:4.5'\n    testCompile 'org.specs2:specs2-core_2.11:3.6.5-20151112214348-18646b2'\n    testCompile 'org.specs2:specs2-junit_2.11:3.6.5-20151112214348-18646b2'\n    testCompile 'org.specs2:specs2-matcher-extra_2.11:3.6.5-20151112214348-18646b2'\n\n```\n\nLet us create our first `YonpiRawSpecs.scala` file. You'll notice that on top of the class you will need   `@RunWith(classOf[JUnitRunner])` to run your specs2.\n\n\n```\n\npackage test\n\nimport org.specs2.mutable._\nimport org.specs2.Specification\nimport java.net.URL\nimport org.specs2.matcher.MatchResult\nimport org.specs2.execute.{ Result => SpecsResult }\n\nimport io.megam.gradle._\nimport org.megam.common.git._\nimport org.junit.runner.RunWith\nimport org.specs2.mutable.SpecificationWithJUnit\nimport org.specs2.runner.JUnitRunner\nimport org.slf4j.LoggerFactory\n\n@RunWith(classOf[JUnitRunner])\nclass YanpiRawSpec extends Specification {\n\n  def is =\n    \"YanpiRawSpec\".title ^ end ^ \"\"\"\n  YanpiRawSpec is the implementation that build the git repo\n  \"\"\" ^ end ^\n      \"The Client Should\" ^\n      \"Correctly build Yonpis for a git repo\" ! Yanpi.succeeds ^\n      end\n\n  case object Yanpi {\n\n      def succeeds: SpecsResult = {\n      val yp =   YanpiProject(new GitRepo(\"local\", \"https://github.com/megamsys/sparkbuilder.git\"))\n      println (\"yp.name0 =\"+yp.name0)\n      println (\"yp.root0 =\"+yp.root0)\n      println (\"yp.jar0 =\"+yp.jar0)\n\n      yp.name0  == \"sparkbuilder\"\n      yp.root0  == \"/home/megam/code/megam/home/megamgateway/sparkbuilder\"\n      yp.jar0 == \"/home/megam/code/megam/home/megamgateway/sparkbuilder/build/sparkbuilder.jar\"\n    }\n  }\n\n}\n\n\n```\n\n### Running tests\n\nKickoff the specs to see if they pass\n\n```\n\ngradle test\n\n```\n\n![Megam spec passes](/content/images/2015/12/megam_spec_pass.png)\n\n### Publishing to bintray\n\nRegister and get the credentials of bintray. \n\nCreate ./bintray/credentials with the following value. Your password might be different.\n\n```\nrealm = Bintray API Realm\nhost = api.bintray.com\nuser = megamio\npassword = fake8080808080808080\n\n```\n\nModify your build.gradle to load the properties file\n\n```\n\n   \napply plugin: 'com.jfrog.bintray'\n\next.bintray = new Properties()\nbintray.load(new FileInputStream(\"$System.env.HOME\" + \"/.bintray/.credentials\"))\n\ngroup = \"io.megam\"\n\nbintray {\n\tuser = bintray['user']\n\tkey =  bintray['password']\n  dryRun = false\n  publish =  true\n  publications =['sparkbb']\n\tpkg {\n\t\trepo = 'scala'\n\t\tname = 'sparkbuilder_2.11'\n    userOrg = 'megamsys'\n    group = 'io.megam'\n\t\tdesc = 'Automated spark yonpijar builder using gradle tool for any git repo. Yonpis are templated machine learning scala code residing as separate Git.'\n\t\tlicenses = ['Apache-2.0']\n    websiteUrl = \"https://www.megam.io\"\n\t\tvcsUrl = 'https://github.com/megamsys/sparkbuilder.git'\n\t\tlabels = ['spark', 'builder', 'gradle', 'spark']\n\t\tpublicDownloadNumbers = true\n\n\t}\n}\n\n```\n\nRefer [sparkbuilder](https://github.com/megamsys/sparkbuilder.git) for the details on build.gradle\n\nNow that we have loaded our bintray config, let publish jars to bintray.\n\n```\n\ngradle clean\n\ngradle build\n\ngradle bintrayUpload\n\n```\n\nOk, verify the link [https://dl.bintray.com/megamsys/scala/io/megam/sparkbuilder_2.11](https://dl.bintray.com/megamsys/scala/io/megam/sparkbuilder_2.11), \n\nCool the project is up there in bintray.\n\nYou can use it to your hearts content.\n","source":"_posts/2015-12-08-gradle-for-scala.md","raw":"---\ntitle: Gradle for scala\nslug: gradle-for-scala\ndate_published: 2015-12-08T14:52:33.715Z\ndate_updated:   2016-04-16T14:12:45.536Z\n---\n\n### Installing gradle\n\nWe have decided to gradually migrate all our projects to gradle from `sbt` due to its performance.\n\nIn our recent [sparkbuilder](https://github.com/megamsys/sparkbuilder.git) project we found a need to **natively build jars** for our analytic prediction templates - We call us  Yonpi [**Y**et **AN**other **P**lug**I**n]\n\nHere we will look at installing gradle and setting up a scala project and publishing it to bintray.\n\n#### Download grade\n\nDowload and untar the zip [gradle](http://gradle.org/gradle-download/)\n\n\n### Environment variable \n\nSetup the PATH environment variable by appending *GRADLE_HOME/bin*\n\nThere may be packages for your distro (ubuntu, or archlinux)\n\n#### In Archlinux \n\n```\n\nyaourt gradle\n\n```\n\n### Your first scala project [sparkbuilder](https://github.com/megamsys/sparkbuilder.git)\n\n> *build.gradle*\n\nThe build recipe for gradle resides here.\n\n>*src/main/scala:* \n\nContains the scala source code.\n\nGradle provide a plugin for scala projects, just include the line in your build.gradle as  `apply plugin: scala`\n\n```\n\napply plugin: scala\n\n```\n\nHere is our full gradle file.\n\n```\n\napply plugin: 'scala'\n\nrepositories {\n    maven {\n      url 'https://repo.gradle.org/gradle/libs-releases-local'\n    }\n\n    maven {\n      url 'http://dl.bintray.com/megamsys/scala'\n    }\n\n    mavenCentral()\n}\n\ndependencies {\n  compile 'org.scala-lang:scala-library:2.11.7'\n}\n\ndef toolingApiVersion = gradle.gradleVersion\n\ndependencies {\n    compile \"org.gradle:gradle-tooling-api:${toolingApiVersion}\"\n    compile 'io.megam:libcommon_2.11:0.20'\n    compile 'org.scalaz:scalaz-core_2.11:7.1.5'\n    testCompile 'junit:junit:4.5'\n    testCompile 'org.specs2:specs2-core_2.11:3.6.5-20151112214348-18646b2'\n    testCompile 'org.specs2:specs2-junit_2.11:3.6.5-20151112214348-18646b2'\n    testCompile 'org.specs2:specs2-matcher-extra_2.11:3.6.5-20151112214348-18646b2'\n    runtime 'org.slf4j:slf4j-simple:1.7.10'\n}\n\n\n```\n\nTo start from the top.\n\n>*repositories*\n\nAdd the repositories you want *gradle* to download jars\n\n```\n\nrepositories {\n    maven {\n      url 'https://repo.gradle.org/gradle/libs-releases-local'\n    }\n\n    maven {\n      url 'http://dl.bintray.com/megamsys/scala'\n    }\n\n    mavenCentral()\n}\n\n```\n\nIn the above we use a library from bintray.com/megamsys/scala, and also will be using `gradle tooling api` to build scala code (yonpi)\n\n>*dependencies*\n\nAdd the dependencies you want *sparkbuilder* to use. We will use the following apis.\n\n- gradle-tooling\n- scalaz\n- megam:libcommon\n\nFor *tests* we will use \n\n-  junit\n-  specs2\n\n```\n\ndependencies {\n    compile \"org.gradle:gradle-tooling-api:${toolingApiVersion}\"\n    compile 'io.megam:libcommon_2.11:0.20'\n    compile 'org.scalaz:scalaz-core_2.11:7.1.5'\n    testCompile 'junit:junit:4.5'\n    testCompile 'org.specs2:specs2-core_2.11:3.6.5-20151112214348-18646b2'\n    testCompile 'org.specs2:specs2-junit_2.11:3.6.5-20151112214348-18646b2'\n    testCompile 'org.specs2:specs2-matcher-extra_2.11:3.6.5-20151112214348-18646b2'\n    runtime 'org.slf4j:slf4j-simple:1.7.10'\n}\n\n```\n\n### CompileScala\n\nLets compile our source code.\n\n```\n\ngradle build\n\n```\n\nThe above does a compile and test of scala code.\n\n### Testing using spec2 and gradle\n\nspecs2 isn't quite friendly as in [sbt](https://scala-sbt.org)\n\nSo to make it work we will need to add these dependencies for using **specs2**\n\nYes, **JUnit** is needed\n\n```\n\ntestCompile 'junit:junit:4.5'\n    testCompile 'org.specs2:specs2-core_2.11:3.6.5-20151112214348-18646b2'\n    testCompile 'org.specs2:specs2-junit_2.11:3.6.5-20151112214348-18646b2'\n    testCompile 'org.specs2:specs2-matcher-extra_2.11:3.6.5-20151112214348-18646b2'\n\n```\n\nLet us create our first `YonpiRawSpecs.scala` file. You'll notice that on top of the class you will need   `@RunWith(classOf[JUnitRunner])` to run your specs2.\n\n\n```\n\npackage test\n\nimport org.specs2.mutable._\nimport org.specs2.Specification\nimport java.net.URL\nimport org.specs2.matcher.MatchResult\nimport org.specs2.execute.{ Result => SpecsResult }\n\nimport io.megam.gradle._\nimport org.megam.common.git._\nimport org.junit.runner.RunWith\nimport org.specs2.mutable.SpecificationWithJUnit\nimport org.specs2.runner.JUnitRunner\nimport org.slf4j.LoggerFactory\n\n@RunWith(classOf[JUnitRunner])\nclass YanpiRawSpec extends Specification {\n\n  def is =\n    \"YanpiRawSpec\".title ^ end ^ \"\"\"\n  YanpiRawSpec is the implementation that build the git repo\n  \"\"\" ^ end ^\n      \"The Client Should\" ^\n      \"Correctly build Yonpis for a git repo\" ! Yanpi.succeeds ^\n      end\n\n  case object Yanpi {\n\n      def succeeds: SpecsResult = {\n      val yp =   YanpiProject(new GitRepo(\"local\", \"https://github.com/megamsys/sparkbuilder.git\"))\n      println (\"yp.name0 =\"+yp.name0)\n      println (\"yp.root0 =\"+yp.root0)\n      println (\"yp.jar0 =\"+yp.jar0)\n\n      yp.name0  == \"sparkbuilder\"\n      yp.root0  == \"/home/megam/code/megam/home/megamgateway/sparkbuilder\"\n      yp.jar0 == \"/home/megam/code/megam/home/megamgateway/sparkbuilder/build/sparkbuilder.jar\"\n    }\n  }\n\n}\n\n\n```\n\n### Running tests\n\nKickoff the specs to see if they pass\n\n```\n\ngradle test\n\n```\n\n![Megam spec passes](/content/images/2015/12/megam_spec_pass.png)\n\n### Publishing to bintray\n\nRegister and get the credentials of bintray. \n\nCreate ./bintray/credentials with the following value. Your password might be different.\n\n```\nrealm = Bintray API Realm\nhost = api.bintray.com\nuser = megamio\npassword = fake8080808080808080\n\n```\n\nModify your build.gradle to load the properties file\n\n```\n\n   \napply plugin: 'com.jfrog.bintray'\n\next.bintray = new Properties()\nbintray.load(new FileInputStream(\"$System.env.HOME\" + \"/.bintray/.credentials\"))\n\ngroup = \"io.megam\"\n\nbintray {\n\tuser = bintray['user']\n\tkey =  bintray['password']\n  dryRun = false\n  publish =  true\n  publications =['sparkbb']\n\tpkg {\n\t\trepo = 'scala'\n\t\tname = 'sparkbuilder_2.11'\n    userOrg = 'megamsys'\n    group = 'io.megam'\n\t\tdesc = 'Automated spark yonpijar builder using gradle tool for any git repo. Yonpis are templated machine learning scala code residing as separate Git.'\n\t\tlicenses = ['Apache-2.0']\n    websiteUrl = \"https://www.megam.io\"\n\t\tvcsUrl = 'https://github.com/megamsys/sparkbuilder.git'\n\t\tlabels = ['spark', 'builder', 'gradle', 'spark']\n\t\tpublicDownloadNumbers = true\n\n\t}\n}\n\n```\n\nRefer [sparkbuilder](https://github.com/megamsys/sparkbuilder.git) for the details on build.gradle\n\nNow that we have loaded our bintray config, let publish jars to bintray.\n\n```\n\ngradle clean\n\ngradle build\n\ngradle bintrayUpload\n\n```\n\nOk, verify the link [https://dl.bintray.com/megamsys/scala/io/megam/sparkbuilder_2.11](https://dl.bintray.com/megamsys/scala/io/megam/sparkbuilder_2.11), \n\nCool the project is up there in bintray.\n\nYou can use it to your hearts content.\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaisf000ydrgb6f87aiio","content":"<h3 id=\"Installing-gradle\"><a href=\"#Installing-gradle\" class=\"headerlink\" title=\"Installing gradle\"></a>Installing gradle</h3><p>We have decided to gradually migrate all our projects to gradle from <code>sbt</code> due to its performance.</p>\n<p>In our recent <a href=\"https://github.com/megamsys/sparkbuilder.git\" target=\"_blank\" rel=\"external\">sparkbuilder</a> project we found a need to <strong>natively build jars</strong> for our analytic prediction templates - We call us  Yonpi [<strong>Y</strong>et <strong>AN</strong>other <strong>P</strong>lug<strong>I</strong>n]</p>\n<p>Here we will look at installing gradle and setting up a scala project and publishing it to bintray.</p>\n<h4 id=\"Download-grade\"><a href=\"#Download-grade\" class=\"headerlink\" title=\"Download grade\"></a>Download grade</h4><p>Dowload and untar the zip <a href=\"http://gradle.org/gradle-download/\" target=\"_blank\" rel=\"external\">gradle</a></p>\n<h3 id=\"Environment-variable\"><a href=\"#Environment-variable\" class=\"headerlink\" title=\"Environment variable\"></a>Environment variable</h3><p>Setup the PATH environment variable by appending <em>GRADLE_HOME/bin</em></p>\n<p>There may be packages for your distro (ubuntu, or archlinux)</p>\n<h4 id=\"In-Archlinux\"><a href=\"#In-Archlinux\" class=\"headerlink\" title=\"In Archlinux\"></a>In Archlinux</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">yaourt gradle</div></pre></td></tr></table></figure>\n<h3 id=\"Your-first-scala-project-sparkbuilder\"><a href=\"#Your-first-scala-project-sparkbuilder\" class=\"headerlink\" title=\"Your first scala project sparkbuilder\"></a>Your first scala project <a href=\"https://github.com/megamsys/sparkbuilder.git\" target=\"_blank\" rel=\"external\">sparkbuilder</a></h3><blockquote>\n<p><em>build.gradle</em></p>\n</blockquote>\n<p>The build recipe for gradle resides here.</p>\n<blockquote>\n<p><em>src/main/scala:</em> </p>\n</blockquote>\n<p>Contains the scala source code.</p>\n<p>Gradle provide a plugin for scala projects, just include the line in your build.gradle as  <code>apply plugin: scala</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">apply plugin: scala</div></pre></td></tr></table></figure>\n<p>Here is our full gradle file.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">apply plugin: &apos;scala&apos;</div><div class=\"line\"></div><div class=\"line\">repositories &#123;</div><div class=\"line\">    maven &#123;</div><div class=\"line\">      url &apos;https://repo.gradle.org/gradle/libs-releases-local&apos;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    maven &#123;</div><div class=\"line\">      url &apos;http://dl.bintray.com/megamsys/scala&apos;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    mavenCentral()</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">dependencies &#123;</div><div class=\"line\">  compile &apos;org.scala-lang:scala-library:2.11.7&apos;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">def toolingApiVersion = gradle.gradleVersion</div><div class=\"line\"></div><div class=\"line\">dependencies &#123;</div><div class=\"line\">    compile &quot;org.gradle:gradle-tooling-api:$&#123;toolingApiVersion&#125;&quot;</div><div class=\"line\">    compile &apos;io.megam:libcommon_2.11:0.20&apos;</div><div class=\"line\">    compile &apos;org.scalaz:scalaz-core_2.11:7.1.5&apos;</div><div class=\"line\">    testCompile &apos;junit:junit:4.5&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-core_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-junit_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-matcher-extra_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    runtime &apos;org.slf4j:slf4j-simple:1.7.10&apos;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>To start from the top.</p>\n<blockquote>\n<p><em>repositories</em></p>\n</blockquote>\n<p>Add the repositories you want <em>gradle</em> to download jars</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">repositories &#123;</div><div class=\"line\">    maven &#123;</div><div class=\"line\">      url &apos;https://repo.gradle.org/gradle/libs-releases-local&apos;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    maven &#123;</div><div class=\"line\">      url &apos;http://dl.bintray.com/megamsys/scala&apos;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    mavenCentral()</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>In the above we use a library from bintray.com/megamsys/scala, and also will be using <code>gradle tooling api</code> to build scala code (yonpi)</p>\n<blockquote>\n<p><em>dependencies</em></p>\n</blockquote>\n<p>Add the dependencies you want <em>sparkbuilder</em> to use. We will use the following apis.</p>\n<ul>\n<li>gradle-tooling</li>\n<li>scalaz</li>\n<li>megam:libcommon</li>\n</ul>\n<p>For <em>tests</em> we will use </p>\n<ul>\n<li>junit</li>\n<li>specs2</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">dependencies &#123;</div><div class=\"line\">    compile &quot;org.gradle:gradle-tooling-api:$&#123;toolingApiVersion&#125;&quot;</div><div class=\"line\">    compile &apos;io.megam:libcommon_2.11:0.20&apos;</div><div class=\"line\">    compile &apos;org.scalaz:scalaz-core_2.11:7.1.5&apos;</div><div class=\"line\">    testCompile &apos;junit:junit:4.5&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-core_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-junit_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-matcher-extra_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    runtime &apos;org.slf4j:slf4j-simple:1.7.10&apos;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h3 id=\"CompileScala\"><a href=\"#CompileScala\" class=\"headerlink\" title=\"CompileScala\"></a>CompileScala</h3><p>Lets compile our source code.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">gradle build</div></pre></td></tr></table></figure>\n<p>The above does a compile and test of scala code.</p>\n<h3 id=\"Testing-using-spec2-and-gradle\"><a href=\"#Testing-using-spec2-and-gradle\" class=\"headerlink\" title=\"Testing using spec2 and gradle\"></a>Testing using spec2 and gradle</h3><p>specs2 isnt quite friendly as in <a href=\"https://scala-sbt.org\" target=\"_blank\" rel=\"external\">sbt</a></p>\n<p>So to make it work we will need to add these dependencies for using <strong>specs2</strong></p>\n<p>Yes, <strong>JUnit</strong> is needed</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">testCompile &apos;junit:junit:4.5&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-core_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-junit_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-matcher-extra_2.11:3.6.5-20151112214348-18646b2&apos;</div></pre></td></tr></table></figure>\n<p>Let us create our first <code>YonpiRawSpecs.scala</code> file. Youll notice that on top of the class you will need   <code>@RunWith(classOf[JUnitRunner])</code> to run your specs2.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">package test</div><div class=\"line\"></div><div class=\"line\">import org.specs2.mutable._</div><div class=\"line\">import org.specs2.Specification</div><div class=\"line\">import java.net.URL</div><div class=\"line\">import org.specs2.matcher.MatchResult</div><div class=\"line\">import org.specs2.execute.&#123; Result =&gt; SpecsResult &#125;</div><div class=\"line\"></div><div class=\"line\">import io.megam.gradle._</div><div class=\"line\">import org.megam.common.git._</div><div class=\"line\">import org.junit.runner.RunWith</div><div class=\"line\">import org.specs2.mutable.SpecificationWithJUnit</div><div class=\"line\">import org.specs2.runner.JUnitRunner</div><div class=\"line\">import org.slf4j.LoggerFactory</div><div class=\"line\"></div><div class=\"line\">@RunWith(classOf[JUnitRunner])</div><div class=\"line\">class YanpiRawSpec extends Specification &#123;</div><div class=\"line\"></div><div class=\"line\">  def is =</div><div class=\"line\">    &quot;YanpiRawSpec&quot;.title ^ end ^ &quot;&quot;&quot;</div><div class=\"line\">  YanpiRawSpec is the implementation that build the git repo</div><div class=\"line\">  &quot;&quot;&quot; ^ end ^</div><div class=\"line\">      &quot;The Client Should&quot; ^</div><div class=\"line\">      &quot;Correctly build Yonpis for a git repo&quot; ! Yanpi.succeeds ^</div><div class=\"line\">      end</div><div class=\"line\"></div><div class=\"line\">  case object Yanpi &#123;</div><div class=\"line\"></div><div class=\"line\">      def succeeds: SpecsResult = &#123;</div><div class=\"line\">      val yp =   YanpiProject(new GitRepo(&quot;local&quot;, &quot;https://github.com/megamsys/sparkbuilder.git&quot;))</div><div class=\"line\">      println (&quot;yp.name0 =&quot;+yp.name0)</div><div class=\"line\">      println (&quot;yp.root0 =&quot;+yp.root0)</div><div class=\"line\">      println (&quot;yp.jar0 =&quot;+yp.jar0)</div><div class=\"line\"></div><div class=\"line\">      yp.name0  == &quot;sparkbuilder&quot;</div><div class=\"line\">      yp.root0  == &quot;/home/megam/code/megam/home/megamgateway/sparkbuilder&quot;</div><div class=\"line\">      yp.jar0 == &quot;/home/megam/code/megam/home/megamgateway/sparkbuilder/build/sparkbuilder.jar&quot;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h3 id=\"Running-tests\"><a href=\"#Running-tests\" class=\"headerlink\" title=\"Running tests\"></a>Running tests</h3><p>Kickoff the specs to see if they pass</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">gradle test</div></pre></td></tr></table></figure>\n<p><img src=\"/content/images/2015/12/megam_spec_pass.png\" alt=\"Megam spec passes\"></p>\n<h3 id=\"Publishing-to-bintray\"><a href=\"#Publishing-to-bintray\" class=\"headerlink\" title=\"Publishing to bintray\"></a>Publishing to bintray</h3><p>Register and get the credentials of bintray. </p>\n<p>Create ./bintray/credentials with the following value. Your password might be different.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">realm = Bintray API Realm</div><div class=\"line\">host = api.bintray.com</div><div class=\"line\">user = megamio</div><div class=\"line\">password = fake8080808080808080</div></pre></td></tr></table></figure>\n<p>Modify your build.gradle to load the properties file</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">   </div><div class=\"line\">apply plugin: &apos;com.jfrog.bintray&apos;</div><div class=\"line\"></div><div class=\"line\">ext.bintray = new Properties()</div><div class=\"line\">bintray.load(new FileInputStream(&quot;$System.env.HOME&quot; + &quot;/.bintray/.credentials&quot;))</div><div class=\"line\"></div><div class=\"line\">group = &quot;io.megam&quot;</div><div class=\"line\"></div><div class=\"line\">bintray &#123;</div><div class=\"line\">\tuser = bintray[&apos;user&apos;]</div><div class=\"line\">\tkey =  bintray[&apos;password&apos;]</div><div class=\"line\">  dryRun = false</div><div class=\"line\">  publish =  true</div><div class=\"line\">  publications =[&apos;sparkbb&apos;]</div><div class=\"line\">\tpkg &#123;</div><div class=\"line\">\t\trepo = &apos;scala&apos;</div><div class=\"line\">\t\tname = &apos;sparkbuilder_2.11&apos;</div><div class=\"line\">    userOrg = &apos;megamsys&apos;</div><div class=\"line\">    group = &apos;io.megam&apos;</div><div class=\"line\">\t\tdesc = &apos;Automated spark yonpijar builder using gradle tool for any git repo. Yonpis are templated machine learning scala code residing as separate Git.&apos;</div><div class=\"line\">\t\tlicenses = [&apos;Apache-2.0&apos;]</div><div class=\"line\">    websiteUrl = &quot;https://www.megam.io&quot;</div><div class=\"line\">\t\tvcsUrl = &apos;https://github.com/megamsys/sparkbuilder.git&apos;</div><div class=\"line\">\t\tlabels = [&apos;spark&apos;, &apos;builder&apos;, &apos;gradle&apos;, &apos;spark&apos;]</div><div class=\"line\">\t\tpublicDownloadNumbers = true</div><div class=\"line\"></div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>Refer <a href=\"https://github.com/megamsys/sparkbuilder.git\" target=\"_blank\" rel=\"external\">sparkbuilder</a> for the details on build.gradle</p>\n<p>Now that we have loaded our bintray config, let publish jars to bintray.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">gradle clean</div><div class=\"line\"></div><div class=\"line\">gradle build</div><div class=\"line\"></div><div class=\"line\">gradle bintrayUpload</div></pre></td></tr></table></figure>\n<p>Ok, verify the link <a href=\"https://dl.bintray.com/megamsys/scala/io/megam/sparkbuilder_2.11\" target=\"_blank\" rel=\"external\">https://dl.bintray.com/megamsys/scala/io/megam/sparkbuilder_2.11</a>, </p>\n<p>Cool the project is up there in bintray.</p>\n<p>You can use it to your hearts content.</p>\n","excerpt":"","more":"<h3 id=\"Installing-gradle\"><a href=\"#Installing-gradle\" class=\"headerlink\" title=\"Installing gradle\"></a>Installing gradle</h3><p>We have decided to gradually migrate all our projects to gradle from <code>sbt</code> due to its performance.</p>\n<p>In our recent <a href=\"https://github.com/megamsys/sparkbuilder.git\">sparkbuilder</a> project we found a need to <strong>natively build jars</strong> for our analytic prediction templates - We call us  Yonpi [<strong>Y</strong>et <strong>AN</strong>other <strong>P</strong>lug<strong>I</strong>n]</p>\n<p>Here we will look at installing gradle and setting up a scala project and publishing it to bintray.</p>\n<h4 id=\"Download-grade\"><a href=\"#Download-grade\" class=\"headerlink\" title=\"Download grade\"></a>Download grade</h4><p>Dowload and untar the zip <a href=\"http://gradle.org/gradle-download/\">gradle</a></p>\n<h3 id=\"Environment-variable\"><a href=\"#Environment-variable\" class=\"headerlink\" title=\"Environment variable\"></a>Environment variable</h3><p>Setup the PATH environment variable by appending <em>GRADLE_HOME/bin</em></p>\n<p>There may be packages for your distro (ubuntu, or archlinux)</p>\n<h4 id=\"In-Archlinux\"><a href=\"#In-Archlinux\" class=\"headerlink\" title=\"In Archlinux\"></a>In Archlinux</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">yaourt gradle</div></pre></td></tr></table></figure>\n<h3 id=\"Your-first-scala-project-sparkbuilder\"><a href=\"#Your-first-scala-project-sparkbuilder\" class=\"headerlink\" title=\"Your first scala project sparkbuilder\"></a>Your first scala project <a href=\"https://github.com/megamsys/sparkbuilder.git\">sparkbuilder</a></h3><blockquote>\n<p><em>build.gradle</em></p>\n</blockquote>\n<p>The build recipe for gradle resides here.</p>\n<blockquote>\n<p><em>src/main/scala:</em> </p>\n</blockquote>\n<p>Contains the scala source code.</p>\n<p>Gradle provide a plugin for scala projects, just include the line in your build.gradle as  <code>apply plugin: scala</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">apply plugin: scala</div></pre></td></tr></table></figure>\n<p>Here is our full gradle file.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">apply plugin: &apos;scala&apos;</div><div class=\"line\"></div><div class=\"line\">repositories &#123;</div><div class=\"line\">    maven &#123;</div><div class=\"line\">      url &apos;https://repo.gradle.org/gradle/libs-releases-local&apos;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    maven &#123;</div><div class=\"line\">      url &apos;http://dl.bintray.com/megamsys/scala&apos;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    mavenCentral()</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">dependencies &#123;</div><div class=\"line\">  compile &apos;org.scala-lang:scala-library:2.11.7&apos;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">def toolingApiVersion = gradle.gradleVersion</div><div class=\"line\"></div><div class=\"line\">dependencies &#123;</div><div class=\"line\">    compile &quot;org.gradle:gradle-tooling-api:$&#123;toolingApiVersion&#125;&quot;</div><div class=\"line\">    compile &apos;io.megam:libcommon_2.11:0.20&apos;</div><div class=\"line\">    compile &apos;org.scalaz:scalaz-core_2.11:7.1.5&apos;</div><div class=\"line\">    testCompile &apos;junit:junit:4.5&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-core_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-junit_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-matcher-extra_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    runtime &apos;org.slf4j:slf4j-simple:1.7.10&apos;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>To start from the top.</p>\n<blockquote>\n<p><em>repositories</em></p>\n</blockquote>\n<p>Add the repositories you want <em>gradle</em> to download jars</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">repositories &#123;</div><div class=\"line\">    maven &#123;</div><div class=\"line\">      url &apos;https://repo.gradle.org/gradle/libs-releases-local&apos;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    maven &#123;</div><div class=\"line\">      url &apos;http://dl.bintray.com/megamsys/scala&apos;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    mavenCentral()</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>In the above we use a library from bintray.com/megamsys/scala, and also will be using <code>gradle tooling api</code> to build scala code (yonpi)</p>\n<blockquote>\n<p><em>dependencies</em></p>\n</blockquote>\n<p>Add the dependencies you want <em>sparkbuilder</em> to use. We will use the following apis.</p>\n<ul>\n<li>gradle-tooling</li>\n<li>scalaz</li>\n<li>megam:libcommon</li>\n</ul>\n<p>For <em>tests</em> we will use </p>\n<ul>\n<li>junit</li>\n<li>specs2</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">dependencies &#123;</div><div class=\"line\">    compile &quot;org.gradle:gradle-tooling-api:$&#123;toolingApiVersion&#125;&quot;</div><div class=\"line\">    compile &apos;io.megam:libcommon_2.11:0.20&apos;</div><div class=\"line\">    compile &apos;org.scalaz:scalaz-core_2.11:7.1.5&apos;</div><div class=\"line\">    testCompile &apos;junit:junit:4.5&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-core_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-junit_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-matcher-extra_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    runtime &apos;org.slf4j:slf4j-simple:1.7.10&apos;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h3 id=\"CompileScala\"><a href=\"#CompileScala\" class=\"headerlink\" title=\"CompileScala\"></a>CompileScala</h3><p>Lets compile our source code.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">gradle build</div></pre></td></tr></table></figure>\n<p>The above does a compile and test of scala code.</p>\n<h3 id=\"Testing-using-spec2-and-gradle\"><a href=\"#Testing-using-spec2-and-gradle\" class=\"headerlink\" title=\"Testing using spec2 and gradle\"></a>Testing using spec2 and gradle</h3><p>specs2 isnt quite friendly as in <a href=\"https://scala-sbt.org\">sbt</a></p>\n<p>So to make it work we will need to add these dependencies for using <strong>specs2</strong></p>\n<p>Yes, <strong>JUnit</strong> is needed</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">testCompile &apos;junit:junit:4.5&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-core_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-junit_2.11:3.6.5-20151112214348-18646b2&apos;</div><div class=\"line\">    testCompile &apos;org.specs2:specs2-matcher-extra_2.11:3.6.5-20151112214348-18646b2&apos;</div></pre></td></tr></table></figure>\n<p>Let us create our first <code>YonpiRawSpecs.scala</code> file. Youll notice that on top of the class you will need   <code>@RunWith(classOf[JUnitRunner])</code> to run your specs2.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">package test</div><div class=\"line\"></div><div class=\"line\">import org.specs2.mutable._</div><div class=\"line\">import org.specs2.Specification</div><div class=\"line\">import java.net.URL</div><div class=\"line\">import org.specs2.matcher.MatchResult</div><div class=\"line\">import org.specs2.execute.&#123; Result =&gt; SpecsResult &#125;</div><div class=\"line\"></div><div class=\"line\">import io.megam.gradle._</div><div class=\"line\">import org.megam.common.git._</div><div class=\"line\">import org.junit.runner.RunWith</div><div class=\"line\">import org.specs2.mutable.SpecificationWithJUnit</div><div class=\"line\">import org.specs2.runner.JUnitRunner</div><div class=\"line\">import org.slf4j.LoggerFactory</div><div class=\"line\"></div><div class=\"line\">@RunWith(classOf[JUnitRunner])</div><div class=\"line\">class YanpiRawSpec extends Specification &#123;</div><div class=\"line\"></div><div class=\"line\">  def is =</div><div class=\"line\">    &quot;YanpiRawSpec&quot;.title ^ end ^ &quot;&quot;&quot;</div><div class=\"line\">  YanpiRawSpec is the implementation that build the git repo</div><div class=\"line\">  &quot;&quot;&quot; ^ end ^</div><div class=\"line\">      &quot;The Client Should&quot; ^</div><div class=\"line\">      &quot;Correctly build Yonpis for a git repo&quot; ! Yanpi.succeeds ^</div><div class=\"line\">      end</div><div class=\"line\"></div><div class=\"line\">  case object Yanpi &#123;</div><div class=\"line\"></div><div class=\"line\">      def succeeds: SpecsResult = &#123;</div><div class=\"line\">      val yp =   YanpiProject(new GitRepo(&quot;local&quot;, &quot;https://github.com/megamsys/sparkbuilder.git&quot;))</div><div class=\"line\">      println (&quot;yp.name0 =&quot;+yp.name0)</div><div class=\"line\">      println (&quot;yp.root0 =&quot;+yp.root0)</div><div class=\"line\">      println (&quot;yp.jar0 =&quot;+yp.jar0)</div><div class=\"line\"></div><div class=\"line\">      yp.name0  == &quot;sparkbuilder&quot;</div><div class=\"line\">      yp.root0  == &quot;/home/megam/code/megam/home/megamgateway/sparkbuilder&quot;</div><div class=\"line\">      yp.jar0 == &quot;/home/megam/code/megam/home/megamgateway/sparkbuilder/build/sparkbuilder.jar&quot;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h3 id=\"Running-tests\"><a href=\"#Running-tests\" class=\"headerlink\" title=\"Running tests\"></a>Running tests</h3><p>Kickoff the specs to see if they pass</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">gradle test</div></pre></td></tr></table></figure>\n<p><img src=\"/content/images/2015/12/megam_spec_pass.png\" alt=\"Megam spec passes\"></p>\n<h3 id=\"Publishing-to-bintray\"><a href=\"#Publishing-to-bintray\" class=\"headerlink\" title=\"Publishing to bintray\"></a>Publishing to bintray</h3><p>Register and get the credentials of bintray. </p>\n<p>Create ./bintray/credentials with the following value. Your password might be different.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">realm = Bintray API Realm</div><div class=\"line\">host = api.bintray.com</div><div class=\"line\">user = megamio</div><div class=\"line\">password = fake8080808080808080</div></pre></td></tr></table></figure>\n<p>Modify your build.gradle to load the properties file</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">   </div><div class=\"line\">apply plugin: &apos;com.jfrog.bintray&apos;</div><div class=\"line\"></div><div class=\"line\">ext.bintray = new Properties()</div><div class=\"line\">bintray.load(new FileInputStream(&quot;$System.env.HOME&quot; + &quot;/.bintray/.credentials&quot;))</div><div class=\"line\"></div><div class=\"line\">group = &quot;io.megam&quot;</div><div class=\"line\"></div><div class=\"line\">bintray &#123;</div><div class=\"line\">\tuser = bintray[&apos;user&apos;]</div><div class=\"line\">\tkey =  bintray[&apos;password&apos;]</div><div class=\"line\">  dryRun = false</div><div class=\"line\">  publish =  true</div><div class=\"line\">  publications =[&apos;sparkbb&apos;]</div><div class=\"line\">\tpkg &#123;</div><div class=\"line\">\t\trepo = &apos;scala&apos;</div><div class=\"line\">\t\tname = &apos;sparkbuilder_2.11&apos;</div><div class=\"line\">    userOrg = &apos;megamsys&apos;</div><div class=\"line\">    group = &apos;io.megam&apos;</div><div class=\"line\">\t\tdesc = &apos;Automated spark yonpijar builder using gradle tool for any git repo. Yonpis are templated machine learning scala code residing as separate Git.&apos;</div><div class=\"line\">\t\tlicenses = [&apos;Apache-2.0&apos;]</div><div class=\"line\">    websiteUrl = &quot;https://www.megam.io&quot;</div><div class=\"line\">\t\tvcsUrl = &apos;https://github.com/megamsys/sparkbuilder.git&apos;</div><div class=\"line\">\t\tlabels = [&apos;spark&apos;, &apos;builder&apos;, &apos;gradle&apos;, &apos;spark&apos;]</div><div class=\"line\">\t\tpublicDownloadNumbers = true</div><div class=\"line\"></div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>Refer <a href=\"https://github.com/megamsys/sparkbuilder.git\">sparkbuilder</a> for the details on build.gradle</p>\n<p>Now that we have loaded our bintray config, let publish jars to bintray.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">gradle clean</div><div class=\"line\"></div><div class=\"line\">gradle build</div><div class=\"line\"></div><div class=\"line\">gradle bintrayUpload</div></pre></td></tr></table></figure>\n<p>Ok, verify the link <a href=\"https://dl.bintray.com/megamsys/scala/io/megam/sparkbuilder_2.11\">https://dl.bintray.com/megamsys/scala/io/megam/sparkbuilder_2.11</a>, </p>\n<p>Cool the project is up there in bintray.</p>\n<p>You can use it to your hearts content.</p>\n"},{"title":"How to build a Gem!","slug":"2015-12-08-how-to-build-a-gem","date_published":"2015-12-07T23:58:38.330Z","date_updated":"2015-12-08T00:03:31.589Z","_content":"\n##WHAT IS A RUBY GEM?\nA gem is essentially a Ruby plugin. RubyGems is a package manager for the Ruby programming language that provides a standard format for distributing Ruby programs and libraries, a tool designed to easily manage the installation of gems, and a server for distributing them. \n\n###WHY USE GEM? \n(Interesting question. Let's see why.)\n\nBefore we get into the \"how\" of creating a gem, **let's first consider why you might want to do so.** \n\nOne of the most obvious reasons relates to **code reuse**. \n\nIf you find yourself implementing the same feature over and over again across projects, there's a good chance that you've found the need for a gem. \n\nAdditionally, **releasing a gem as open-source provides others the opportunity to contribute** by adding features, addressing issues that you might have overlooked, and generally making your gem provide an all-around better experience for its users.\n\n###HOW DO YOU BUILD A GEM?\n\nTo help us create the gem, well use the popular  *bundler*\n\n    bundler gem <gem_name>\n  \nBundler is primarily designed to **help you manage a projects dependencies**. \n\nIf youve not used it before, then dont worry because well be taking advantage of a lesser known feature anyway, which is its ability to generate a gem boilerplate. (\n\nIt also provides some other tools that will help us manage our gems packaging).\n\n**Lets begin by installing bundler:**\n\n    gem install bundler\n\nOnce Bundler is installed, we can use it to create our gem. \n\nTo begin to create a gem using Bundler named **[megam_api](https://github.com/megamsys/megam_api.git)**, use the bundle gem command like this:\n\n    bundle gem megam_api\n\n![create gem megam_api](/content/images/2015/12/bundler_gem_megam.png)\n\n**We call our gem megam_api** because this gem is going to do a couple of things around [Megam cloud platfom](https://www.megam.io) such as magically launch an app in cloud or \"suck in cloud!\". \n\n**This command creates a scaffold directory for our new gem.**\nThe **files generated** are:\n>**[Gemfile](https://github.com/megamsys/megam_api/blob/0.9/Gemfile):** Used to manage gem dependencies for our library's development. This file contains a gemspec line meaning that Bundler will include dependencies specified in megam_api.gemspec too.\n\n>**[Rakefile](https://github.com/megamsys/megam_api/blob/0.9/Rakefile):** Requires Bundler and adds the build, install and release Rake tasks by way of calling Bundler::GemHelper.install_tasks. The build task will build the current version of the gem and store it under the pkg folder, the install task will build and install the gem to our system (just like it would do if we gem install'd it) and release will push the gem to Rubygems for consumption by the public.\n\n>**.gitignore:** (only if we have Git). This ignores anything in the pkg directory (generally files put there by rake build), anything with a .gem extension and the .bundle directory.\n\n>**[megam_api.gemspec](https://github.com/megamsys/megam_api/blob/0.9/megam_api.gemspec):** The Gem Specification file. This is where we provide information for Rubygems' consumption such as the name, description and homepage of our gem. This is also where we specify the dependencies our gem needs to run.\n\n>**[lib/megam_api.rb](https://github.com/megamsys/megam_api/blob/0.9/lib/megam_api.rb):** The main file to define our gem's code. This is the file that will be required by Bundler (or any similarly smart system) when our gem is loaded. This file defines a module which we can use as a namespace for all our gem's code. It's best practice to put our code in...\n\n>**[lib/megam](https://github.com/megamsys/megam_api/tree/0.9/lib/megam):** here. This folder should contain all the code (classes, etc.) for our gem. The lib/megam_apie.rb file is there for setting up our gem's environment, whilst all the parts of it go in this folder. If our gem has multiple uses, separating this out so that people can require one class/file at a time can be really helpful.\n\n>**[lib/megam/api/version.rb](https://github.com/megamsys/megam_api/blob/0.9/lib/megam/api/version.rb):** Defines a Megam api module and in it, a VERSION constant. This file is loaded by the megam_api.gemspec to specify a version for the gem specification. When we release a new version of the gem we will increment a part of this version number to indicate to Rubygems that we're releasing a new version.\n\n**There's our base and our layout, now get developing!**\n\n###TESTING YOUR GEM:\n\nWe're going to use **minitest** to test our gem.\n\n-**We write tests to ensure that everything goes according to plan** and to prevent future-us from building a time machine to come back and kick our asses.\n\n-To get started with writing our tests, we'll **create a test directory at the root of gem** by using the command:\n\n    mkdir test\n\n-Next, we'll specify in our **megam_api.gemspec** file that minitest is a development dependency by adding this line inside theGem::Specification block:\n\n    spec.add_development_dependency \"minitest\", \"~> 5.8\"\n\n-Because we have the gemspec method call in our Gemfile, bundler will automatically add this gem to a group called \"development\" which then we can reference any time we want to load these gems with the following line:\n\n     Bundler.require(:default, :development)`\n\n-The benefit of putting this dependency specification inside of megam_api.gemspec rather than the Gemfile is that anybody who runs \n   \n\t  gem install megam_api --dev \n   \n will get these development dependencies installed too. \n \nThis command is used for when people wish to test a gem without having to fork it or clone it from GitHub.\n\n-When we run `bundle install`, **minitest** will be installed for this library and any other library we use with bundler, but not for the system. This is an important distinction to make: any gem installed by Bundler will not muck about with gems installed by gem install. It is effectively a sandboxed environment. \n\n-By running `bundle install`, bundler will generate the extremely important **Gemfile.lock** file. This file is responsible for ensuring that every system this library is developed on has the exact same gems so it should always be checked into version control.Additionally in the bundle install output, we will see this line:\n\n    Using megam_api (0.99) from source at /path/to/megam_api`\n\n\nBundler detects our gem, loads the gemspec and bundles our gem just like every other gem.\n\nWe can **write our first test with this framework** now in place. \n\nFor testing, create a new test file for every api (accounts to startwith) we want to test at the root of the test directory. \n\nWhen we **run `ruby test_accounts.rb`** \n\n```\nrequire File.expand_path(\"#{File.dirname(__FILE__)}/test_helper\")\n\nclass TestAccounts < MiniTest::Unit::TestCase\n\n  $admin = \"admin-tom\"\n  $normal = \"normal-tom\"\n  $tom_email = \"tom@gomegam.com\"\n  $bob_email = \"bob@gomegam.com\"\n\n  def test_get_accounts_good\n    response =megams.get_accounts(sandbox_email)\n    response.body.to_s\n    assert_equal(200, response.status)\n  end\n\n  def test_post_accounts_good\n    tmp_hash = {\n      \"id\" => \"000099090909000\",\n      \"first_name\" => \"Darth\",\n      \"last_name\" => \"Vader\",\n      \"email\" => \"coolvader@iamswag.com\",\n      \"phone\" => \"19090909090\",\n      \"api_key\" => \"IamAtlas{74}NobdyCanSedfefdeME#07\",\n      \"authority\" => \"admin\",\n      \"password\" => \"\",\n      \"password_reset_key\" => \"\",\n      \"password_reset_sent_at\" => \"\",\n      \"created_at\" => \"2014-10-29 13:24:06 +0000\"\n      }\n    response =megams.post_accounts(tmp_hash)\n    response.body.to_s\n    assert_equal(201, response.status)\n  end\n\nend\n```\n\n\nTo load this file, we'll need to add a require line to lib/megam_api.rb for it:\nrequire 'megam_api/api/accounts'\n\nWhen we run our specs with ruby test_accounts.rb this test will pass:\n2 example, 0 failures\n\n\nGreat success! If we're using Git (or any other source control system), this is a great checkpoint to commit our code. Always remember to commit often!\nIt's all well and dandy that we can write our own code.\n\n###PUBLISHING TO RUBYGEMS.ORG\n\nThe simplest way to distribute a gem for public consumption is to use RubyGems.org. \n\nGems that are published to RubyGems.org can be installed via the gem install command or through the use of tools such as Isolate or Bundler.\n\n>**Create an account with rubygems.org**\n\nRegister at [rubygems.org](https://rubygems.\n\n>**Create a credentials file with the api_key**\n\n```\nram@ramwork:.gem]$ pwd\n/home/ram/.gem\n\n[ram@ramwork:.gem]$ ls\ncredentials  ruby/  specs/\n\n[ram@ramwork:.gem]$ cat credentials\n---\n:rubygems_api_key: 8690909090909090909090afdasfasdf90\n\n```\n\n>**Build a gem**\n\n```\ncd megam_api\n\ngem build megam_api.gemspec\n\nSuccessfully built RubyGem\nName: megam_api\nVersion: 0.90\nFile: megam_api-0.90.gem\n\n```\n\n>**Push your gem to rubygems.org**\n\n```\n\ngem push megam_api-0.99.gem\n\n```\n\n###Voila\n\nYou are done. Go ahead and hack your own gem.\n\n\n\n\n","source":"_posts/2015-12-08-how-to-build-a-gem.md","raw":"---\ntitle: How to build a Gem!\nslug: how-to-build-a-gem\ndate_published: 2015-12-08T05:28:38.330Z\ndate_updated:   2015-12-08T05:33:31.589Z\n---\n\n##WHAT IS A RUBY GEM?\nA gem is essentially a Ruby plugin. RubyGems is a package manager for the Ruby programming language that provides a standard format for distributing Ruby programs and libraries, a tool designed to easily manage the installation of gems, and a server for distributing them. \n\n###WHY USE GEM? \n(Interesting question. Let's see why.)\n\nBefore we get into the \"how\" of creating a gem, **let's first consider why you might want to do so.** \n\nOne of the most obvious reasons relates to **code reuse**. \n\nIf you find yourself implementing the same feature over and over again across projects, there's a good chance that you've found the need for a gem. \n\nAdditionally, **releasing a gem as open-source provides others the opportunity to contribute** by adding features, addressing issues that you might have overlooked, and generally making your gem provide an all-around better experience for its users.\n\n###HOW DO YOU BUILD A GEM?\n\nTo help us create the gem, well use the popular  *bundler*\n\n    bundler gem <gem_name>\n  \nBundler is primarily designed to **help you manage a projects dependencies**. \n\nIf youve not used it before, then dont worry because well be taking advantage of a lesser known feature anyway, which is its ability to generate a gem boilerplate. (\n\nIt also provides some other tools that will help us manage our gems packaging).\n\n**Lets begin by installing bundler:**\n\n    gem install bundler\n\nOnce Bundler is installed, we can use it to create our gem. \n\nTo begin to create a gem using Bundler named **[megam_api](https://github.com/megamsys/megam_api.git)**, use the bundle gem command like this:\n\n    bundle gem megam_api\n\n![create gem megam_api](/content/images/2015/12/bundler_gem_megam.png)\n\n**We call our gem megam_api** because this gem is going to do a couple of things around [Megam cloud platfom](https://www.megam.io) such as magically launch an app in cloud or \"suck in cloud!\". \n\n**This command creates a scaffold directory for our new gem.**\nThe **files generated** are:\n>**[Gemfile](https://github.com/megamsys/megam_api/blob/0.9/Gemfile):** Used to manage gem dependencies for our library's development. This file contains a gemspec line meaning that Bundler will include dependencies specified in megam_api.gemspec too.\n\n>**[Rakefile](https://github.com/megamsys/megam_api/blob/0.9/Rakefile):** Requires Bundler and adds the build, install and release Rake tasks by way of calling Bundler::GemHelper.install_tasks. The build task will build the current version of the gem and store it under the pkg folder, the install task will build and install the gem to our system (just like it would do if we gem install'd it) and release will push the gem to Rubygems for consumption by the public.\n\n>**.gitignore:** (only if we have Git). This ignores anything in the pkg directory (generally files put there by rake build), anything with a .gem extension and the .bundle directory.\n\n>**[megam_api.gemspec](https://github.com/megamsys/megam_api/blob/0.9/megam_api.gemspec):** The Gem Specification file. This is where we provide information for Rubygems' consumption such as the name, description and homepage of our gem. This is also where we specify the dependencies our gem needs to run.\n\n>**[lib/megam_api.rb](https://github.com/megamsys/megam_api/blob/0.9/lib/megam_api.rb):** The main file to define our gem's code. This is the file that will be required by Bundler (or any similarly smart system) when our gem is loaded. This file defines a module which we can use as a namespace for all our gem's code. It's best practice to put our code in...\n\n>**[lib/megam](https://github.com/megamsys/megam_api/tree/0.9/lib/megam):** here. This folder should contain all the code (classes, etc.) for our gem. The lib/megam_apie.rb file is there for setting up our gem's environment, whilst all the parts of it go in this folder. If our gem has multiple uses, separating this out so that people can require one class/file at a time can be really helpful.\n\n>**[lib/megam/api/version.rb](https://github.com/megamsys/megam_api/blob/0.9/lib/megam/api/version.rb):** Defines a Megam api module and in it, a VERSION constant. This file is loaded by the megam_api.gemspec to specify a version for the gem specification. When we release a new version of the gem we will increment a part of this version number to indicate to Rubygems that we're releasing a new version.\n\n**There's our base and our layout, now get developing!**\n\n###TESTING YOUR GEM:\n\nWe're going to use **minitest** to test our gem.\n\n-**We write tests to ensure that everything goes according to plan** and to prevent future-us from building a time machine to come back and kick our asses.\n\n-To get started with writing our tests, we'll **create a test directory at the root of gem** by using the command:\n\n    mkdir test\n\n-Next, we'll specify in our **megam_api.gemspec** file that minitest is a development dependency by adding this line inside theGem::Specification block:\n\n    spec.add_development_dependency \"minitest\", \"~> 5.8\"\n\n-Because we have the gemspec method call in our Gemfile, bundler will automatically add this gem to a group called \"development\" which then we can reference any time we want to load these gems with the following line:\n\n     Bundler.require(:default, :development)`\n\n-The benefit of putting this dependency specification inside of megam_api.gemspec rather than the Gemfile is that anybody who runs \n   \n\t  gem install megam_api --dev \n   \n will get these development dependencies installed too. \n \nThis command is used for when people wish to test a gem without having to fork it or clone it from GitHub.\n\n-When we run `bundle install`, **minitest** will be installed for this library and any other library we use with bundler, but not for the system. This is an important distinction to make: any gem installed by Bundler will not muck about with gems installed by gem install. It is effectively a sandboxed environment. \n\n-By running `bundle install`, bundler will generate the extremely important **Gemfile.lock** file. This file is responsible for ensuring that every system this library is developed on has the exact same gems so it should always be checked into version control.Additionally in the bundle install output, we will see this line:\n\n    Using megam_api (0.99) from source at /path/to/megam_api`\n\n\nBundler detects our gem, loads the gemspec and bundles our gem just like every other gem.\n\nWe can **write our first test with this framework** now in place. \n\nFor testing, create a new test file for every api (accounts to startwith) we want to test at the root of the test directory. \n\nWhen we **run `ruby test_accounts.rb`** \n\n```\nrequire File.expand_path(\"#{File.dirname(__FILE__)}/test_helper\")\n\nclass TestAccounts < MiniTest::Unit::TestCase\n\n  $admin = \"admin-tom\"\n  $normal = \"normal-tom\"\n  $tom_email = \"tom@gomegam.com\"\n  $bob_email = \"bob@gomegam.com\"\n\n  def test_get_accounts_good\n    response =megams.get_accounts(sandbox_email)\n    response.body.to_s\n    assert_equal(200, response.status)\n  end\n\n  def test_post_accounts_good\n    tmp_hash = {\n      \"id\" => \"000099090909000\",\n      \"first_name\" => \"Darth\",\n      \"last_name\" => \"Vader\",\n      \"email\" => \"coolvader@iamswag.com\",\n      \"phone\" => \"19090909090\",\n      \"api_key\" => \"IamAtlas{74}NobdyCanSedfefdeME#07\",\n      \"authority\" => \"admin\",\n      \"password\" => \"\",\n      \"password_reset_key\" => \"\",\n      \"password_reset_sent_at\" => \"\",\n      \"created_at\" => \"2014-10-29 13:24:06 +0000\"\n      }\n    response =megams.post_accounts(tmp_hash)\n    response.body.to_s\n    assert_equal(201, response.status)\n  end\n\nend\n```\n\n\nTo load this file, we'll need to add a require line to lib/megam_api.rb for it:\nrequire 'megam_api/api/accounts'\n\nWhen we run our specs with ruby test_accounts.rb this test will pass:\n2 example, 0 failures\n\n\nGreat success! If we're using Git (or any other source control system), this is a great checkpoint to commit our code. Always remember to commit often!\nIt's all well and dandy that we can write our own code.\n\n###PUBLISHING TO RUBYGEMS.ORG\n\nThe simplest way to distribute a gem for public consumption is to use RubyGems.org. \n\nGems that are published to RubyGems.org can be installed via the gem install command or through the use of tools such as Isolate or Bundler.\n\n>**Create an account with rubygems.org**\n\nRegister at [rubygems.org](https://rubygems.\n\n>**Create a credentials file with the api_key**\n\n```\nram@ramwork:.gem]$ pwd\n/home/ram/.gem\n\n[ram@ramwork:.gem]$ ls\ncredentials  ruby/  specs/\n\n[ram@ramwork:.gem]$ cat credentials\n---\n:rubygems_api_key: 8690909090909090909090afdasfasdf90\n\n```\n\n>**Build a gem**\n\n```\ncd megam_api\n\ngem build megam_api.gemspec\n\nSuccessfully built RubyGem\nName: megam_api\nVersion: 0.90\nFile: megam_api-0.90.gem\n\n```\n\n>**Push your gem to rubygems.org**\n\n```\n\ngem push megam_api-0.99.gem\n\n```\n\n###Voila\n\nYou are done. Go ahead and hack your own gem.\n\n\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:52.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaish000zdrgbk5yb0rud","content":"<p>##WHAT IS A RUBY GEM?<br>A gem is essentially a Ruby plugin. RubyGems is a package manager for the Ruby programming language that provides a standard format for distributing Ruby programs and libraries, a tool designed to easily manage the installation of gems, and a server for distributing them. </p>\n<p>###WHY USE GEM?<br>(Interesting question. Lets see why.)</p>\n<p>Before we get into the how of creating a gem, <strong>lets first consider why you might want to do so.</strong> </p>\n<p>One of the most obvious reasons relates to <strong>code reuse</strong>. </p>\n<p>If you find yourself implementing the same feature over and over again across projects, theres a good chance that youve found the need for a gem. </p>\n<p>Additionally, <strong>releasing a gem as open-source provides others the opportunity to contribute</strong> by adding features, addressing issues that you might have overlooked, and generally making your gem provide an all-around better experience for its users.</p>\n<p>###HOW DO YOU BUILD A GEM?</p>\n<p>To help us create the gem, well use the popular  <em>bundler</em></p>\n<pre><code>bundler gem &lt;gem_name&gt;\n</code></pre><p>Bundler is primarily designed to <strong>help you manage a projects dependencies</strong>. </p>\n<p>If youve not used it before, then dont worry because well be taking advantage of a lesser known feature anyway, which is its ability to generate a gem boilerplate. (</p>\n<p>It also provides some other tools that will help us manage our gems packaging).</p>\n<p><strong>Lets begin by installing bundler:</strong></p>\n<pre><code>gem install bundler\n</code></pre><p>Once Bundler is installed, we can use it to create our gem. </p>\n<p>To begin to create a gem using Bundler named <strong><a href=\"https://github.com/megamsys/megam_api.git\" target=\"_blank\" rel=\"external\">megam_api</a></strong>, use the bundle gem command like this:</p>\n<pre><code>bundle gem megam_api\n</code></pre><p><img src=\"/content/images/2015/12/bundler_gem_megam.png\" alt=\"create gem megam_api\"></p>\n<p><strong>We call our gem megam_api</strong> because this gem is going to do a couple of things around <a href=\"https://www.megam.io\">Megam cloud platfom</a> such as magically launch an app in cloud or suck in cloud!. </p>\n<p><strong>This command creates a scaffold directory for our new gem.</strong><br>The <strong>files generated</strong> are:</p>\n<blockquote>\n<p><strong><a href=\"https://github.com/megamsys/megam_api/blob/0.9/Gemfile\" target=\"_blank\" rel=\"external\">Gemfile</a>:</strong> Used to manage gem dependencies for our librarys development. This file contains a gemspec line meaning that Bundler will include dependencies specified in megam_api.gemspec too.</p>\n<p><strong><a href=\"https://github.com/megamsys/megam_api/blob/0.9/Rakefile\" target=\"_blank\" rel=\"external\">Rakefile</a>:</strong> Requires Bundler and adds the build, install and release Rake tasks by way of calling Bundler::GemHelper.install_tasks. The build task will build the current version of the gem and store it under the pkg folder, the install task will build and install the gem to our system (just like it would do if we gem installd it) and release will push the gem to Rubygems for consumption by the public.</p>\n<p><strong>.gitignore:</strong> (only if we have Git). This ignores anything in the pkg directory (generally files put there by rake build), anything with a .gem extension and the .bundle directory.</p>\n<p><strong><a href=\"https://github.com/megamsys/megam_api/blob/0.9/megam_api.gemspec\" target=\"_blank\" rel=\"external\">megam_api.gemspec</a>:</strong> The Gem Specification file. This is where we provide information for Rubygems consumption such as the name, description and homepage of our gem. This is also where we specify the dependencies our gem needs to run.</p>\n<p><strong><a href=\"https://github.com/megamsys/megam_api/blob/0.9/lib/megam_api.rb\" target=\"_blank\" rel=\"external\">lib/megam_api.rb</a>:</strong> The main file to define our gems code. This is the file that will be required by Bundler (or any similarly smart system) when our gem is loaded. This file defines a module which we can use as a namespace for all our gems code. Its best practice to put our code in</p>\n<p><strong><a href=\"https://github.com/megamsys/megam_api/tree/0.9/lib/megam\" target=\"_blank\" rel=\"external\">lib/megam</a>:</strong> here. This folder should contain all the code (classes, etc.) for our gem. The lib/megam_apie.rb file is there for setting up our gems environment, whilst all the parts of it go in this folder. If our gem has multiple uses, separating this out so that people can require one class/file at a time can be really helpful.</p>\n<p><strong><a href=\"https://github.com/megamsys/megam_api/blob/0.9/lib/megam/api/version.rb\" target=\"_blank\" rel=\"external\">lib/megam/api/version.rb</a>:</strong> Defines a Megam api module and in it, a VERSION constant. This file is loaded by the megam_api.gemspec to specify a version for the gem specification. When we release a new version of the gem we will increment a part of this version number to indicate to Rubygems that were releasing a new version.</p>\n</blockquote>\n<p><strong>Theres our base and our layout, now get developing!</strong></p>\n<p>###TESTING YOUR GEM:</p>\n<p>Were going to use <strong>minitest</strong> to test our gem.</p>\n<p>-<strong>We write tests to ensure that everything goes according to plan</strong> and to prevent future-us from building a time machine to come back and kick our asses.</p>\n<p>-To get started with writing our tests, well <strong>create a test directory at the root of gem</strong> by using the command:</p>\n<pre><code>mkdir test\n</code></pre><p>-Next, well specify in our <strong>megam_api.gemspec</strong> file that minitest is a development dependency by adding this line inside theGem::Specification block:</p>\n<pre><code>spec.add_development_dependency &quot;minitest&quot;, &quot;~&gt; 5.8&quot;\n</code></pre><p>-Because we have the gemspec method call in our Gemfile, bundler will automatically add this gem to a group called development which then we can reference any time we want to load these gems with the following line:</p>\n<pre><code>Bundler.require(:default, :development)`\n</code></pre><p>-The benefit of putting this dependency specification inside of megam_api.gemspec rather than the Gemfile is that anybody who runs </p>\n<pre><code>gem install megam_api --dev \n</code></pre><p> will get these development dependencies installed too. </p>\n<p>This command is used for when people wish to test a gem without having to fork it or clone it from GitHub.</p>\n<p>-When we run <code>bundle install</code>, <strong>minitest</strong> will be installed for this library and any other library we use with bundler, but not for the system. This is an important distinction to make: any gem installed by Bundler will not muck about with gems installed by gem install. It is effectively a sandboxed environment. </p>\n<p>-By running <code>bundle install</code>, bundler will generate the extremely important <strong>Gemfile.lock</strong> file. This file is responsible for ensuring that every system this library is developed on has the exact same gems so it should always be checked into version control.Additionally in the bundle install output, we will see this line:</p>\n<pre><code>Using megam_api (0.99) from source at /path/to/megam_api`\n</code></pre><p>Bundler detects our gem, loads the gemspec and bundles our gem just like every other gem.</p>\n<p>We can <strong>write our first test with this framework</strong> now in place. </p>\n<p>For testing, create a new test file for every api (accounts to startwith) we want to test at the root of the test directory. </p>\n<p>When we <strong>run <code>ruby test_accounts.rb</code></strong> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div></pre></td><td class=\"code\"><pre><div class=\"line\">require File.expand_path(&quot;#&#123;File.dirname(__FILE__)&#125;/test_helper&quot;)</div><div class=\"line\"></div><div class=\"line\">class TestAccounts &lt; MiniTest::Unit::TestCase</div><div class=\"line\"></div><div class=\"line\">  $admin = &quot;admin-tom&quot;</div><div class=\"line\">  $normal = &quot;normal-tom&quot;</div><div class=\"line\">  $tom_email = &quot;tom@gomegam.com&quot;</div><div class=\"line\">  $bob_email = &quot;bob@gomegam.com&quot;</div><div class=\"line\"></div><div class=\"line\">  def test_get_accounts_good</div><div class=\"line\">    response =megams.get_accounts(sandbox_email)</div><div class=\"line\">    response.body.to_s</div><div class=\"line\">    assert_equal(200, response.status)</div><div class=\"line\">  end</div><div class=\"line\"></div><div class=\"line\">  def test_post_accounts_good</div><div class=\"line\">    tmp_hash = &#123;</div><div class=\"line\">      &quot;id&quot; =&gt; &quot;000099090909000&quot;,</div><div class=\"line\">      &quot;first_name&quot; =&gt; &quot;Darth&quot;,</div><div class=\"line\">      &quot;last_name&quot; =&gt; &quot;Vader&quot;,</div><div class=\"line\">      &quot;email&quot; =&gt; &quot;coolvader@iamswag.com&quot;,</div><div class=\"line\">      &quot;phone&quot; =&gt; &quot;19090909090&quot;,</div><div class=\"line\">      &quot;api_key&quot; =&gt; &quot;IamAtlas&#123;74&#125;NobdyCanSedfefdeME#07&quot;,</div><div class=\"line\">      &quot;authority&quot; =&gt; &quot;admin&quot;,</div><div class=\"line\">      &quot;password&quot; =&gt; &quot;&quot;,</div><div class=\"line\">      &quot;password_reset_key&quot; =&gt; &quot;&quot;,</div><div class=\"line\">      &quot;password_reset_sent_at&quot; =&gt; &quot;&quot;,</div><div class=\"line\">      &quot;created_at&quot; =&gt; &quot;2014-10-29 13:24:06 +0000&quot;</div><div class=\"line\">      &#125;</div><div class=\"line\">    response =megams.post_accounts(tmp_hash)</div><div class=\"line\">    response.body.to_s</div><div class=\"line\">    assert_equal(201, response.status)</div><div class=\"line\">  end</div><div class=\"line\"></div><div class=\"line\">end</div></pre></td></tr></table></figure>\n<p>To load this file, well need to add a require line to lib/megam_api.rb for it:<br>require megam_api/api/accounts</p>\n<p>When we run our specs with ruby test_accounts.rb this test will pass:<br>2 example, 0 failures</p>\n<p>Great success! If were using Git (or any other source control system), this is a great checkpoint to commit our code. Always remember to commit often!<br>Its all well and dandy that we can write our own code.</p>\n<p>###PUBLISHING TO RUBYGEMS.ORG</p>\n<p>The simplest way to distribute a gem for public consumption is to use RubyGems.org. </p>\n<p>Gems that are published to RubyGems.org can be installed via the gem install command or through the use of tools such as Isolate or Bundler.</p>\n<blockquote>\n<p><strong>Create an account with rubygems.org</strong></p>\n</blockquote>\n<p>Register at [rubygems.org](<a href=\"https://rubygems\" target=\"_blank\" rel=\"external\">https://rubygems</a>.</p>\n<blockquote>\n<p><strong>Create a credentials file with the api_key</strong></p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">ram@ramwork:.gem]$ pwd</div><div class=\"line\">/home/ram/.gem</div><div class=\"line\"></div><div class=\"line\">[ram@ramwork:.gem]$ ls</div><div class=\"line\">credentials  ruby/  specs/</div><div class=\"line\"></div><div class=\"line\">[ram@ramwork:.gem]$ cat credentials</div><div class=\"line\">---</div><div class=\"line\">:rubygems_api_key: 8690909090909090909090afdasfasdf90</div></pre></td></tr></table></figure>\n<blockquote>\n<p><strong>Build a gem</strong></p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd megam_api</div><div class=\"line\"></div><div class=\"line\">gem build megam_api.gemspec</div><div class=\"line\"></div><div class=\"line\">Successfully built RubyGem</div><div class=\"line\">Name: megam_api</div><div class=\"line\">Version: 0.90</div><div class=\"line\">File: megam_api-0.90.gem</div></pre></td></tr></table></figure>\n<blockquote>\n<p><strong>Push your gem to rubygems.org</strong></p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">gem push megam_api-0.99.gem</div></pre></td></tr></table></figure>\n<p>###Voila</p>\n<p>You are done. Go ahead and hack your own gem.</p>\n","excerpt":"","more":"<p>##WHAT IS A RUBY GEM?<br>A gem is essentially a Ruby plugin. RubyGems is a package manager for the Ruby programming language that provides a standard format for distributing Ruby programs and libraries, a tool designed to easily manage the installation of gems, and a server for distributing them. </p>\n<p>###WHY USE GEM?<br>(Interesting question. Lets see why.)</p>\n<p>Before we get into the how of creating a gem, <strong>lets first consider why you might want to do so.</strong> </p>\n<p>One of the most obvious reasons relates to <strong>code reuse</strong>. </p>\n<p>If you find yourself implementing the same feature over and over again across projects, theres a good chance that youve found the need for a gem. </p>\n<p>Additionally, <strong>releasing a gem as open-source provides others the opportunity to contribute</strong> by adding features, addressing issues that you might have overlooked, and generally making your gem provide an all-around better experience for its users.</p>\n<p>###HOW DO YOU BUILD A GEM?</p>\n<p>To help us create the gem, well use the popular  <em>bundler</em></p>\n<pre><code>bundler gem &lt;gem_name&gt;\n</code></pre><p>Bundler is primarily designed to <strong>help you manage a projects dependencies</strong>. </p>\n<p>If youve not used it before, then dont worry because well be taking advantage of a lesser known feature anyway, which is its ability to generate a gem boilerplate. (</p>\n<p>It also provides some other tools that will help us manage our gems packaging).</p>\n<p><strong>Lets begin by installing bundler:</strong></p>\n<pre><code>gem install bundler\n</code></pre><p>Once Bundler is installed, we can use it to create our gem. </p>\n<p>To begin to create a gem using Bundler named <strong><a href=\"https://github.com/megamsys/megam_api.git\">megam_api</a></strong>, use the bundle gem command like this:</p>\n<pre><code>bundle gem megam_api\n</code></pre><p><img src=\"/content/images/2015/12/bundler_gem_megam.png\" alt=\"create gem megam_api\"></p>\n<p><strong>We call our gem megam_api</strong> because this gem is going to do a couple of things around <a href=\"https://www.megam.io\">Megam cloud platfom</a> such as magically launch an app in cloud or suck in cloud!. </p>\n<p><strong>This command creates a scaffold directory for our new gem.</strong><br>The <strong>files generated</strong> are:</p>\n<blockquote>\n<p><strong><a href=\"https://github.com/megamsys/megam_api/blob/0.9/Gemfile\">Gemfile</a>:</strong> Used to manage gem dependencies for our librarys development. This file contains a gemspec line meaning that Bundler will include dependencies specified in megam_api.gemspec too.</p>\n<p><strong><a href=\"https://github.com/megamsys/megam_api/blob/0.9/Rakefile\">Rakefile</a>:</strong> Requires Bundler and adds the build, install and release Rake tasks by way of calling Bundler::GemHelper.install_tasks. The build task will build the current version of the gem and store it under the pkg folder, the install task will build and install the gem to our system (just like it would do if we gem installd it) and release will push the gem to Rubygems for consumption by the public.</p>\n<p><strong>.gitignore:</strong> (only if we have Git). This ignores anything in the pkg directory (generally files put there by rake build), anything with a .gem extension and the .bundle directory.</p>\n<p><strong><a href=\"https://github.com/megamsys/megam_api/blob/0.9/megam_api.gemspec\">megam_api.gemspec</a>:</strong> The Gem Specification file. This is where we provide information for Rubygems consumption such as the name, description and homepage of our gem. This is also where we specify the dependencies our gem needs to run.</p>\n<p><strong><a href=\"https://github.com/megamsys/megam_api/blob/0.9/lib/megam_api.rb\">lib/megam_api.rb</a>:</strong> The main file to define our gems code. This is the file that will be required by Bundler (or any similarly smart system) when our gem is loaded. This file defines a module which we can use as a namespace for all our gems code. Its best practice to put our code in</p>\n<p><strong><a href=\"https://github.com/megamsys/megam_api/tree/0.9/lib/megam\">lib/megam</a>:</strong> here. This folder should contain all the code (classes, etc.) for our gem. The lib/megam_apie.rb file is there for setting up our gems environment, whilst all the parts of it go in this folder. If our gem has multiple uses, separating this out so that people can require one class/file at a time can be really helpful.</p>\n<p><strong><a href=\"https://github.com/megamsys/megam_api/blob/0.9/lib/megam/api/version.rb\">lib/megam/api/version.rb</a>:</strong> Defines a Megam api module and in it, a VERSION constant. This file is loaded by the megam_api.gemspec to specify a version for the gem specification. When we release a new version of the gem we will increment a part of this version number to indicate to Rubygems that were releasing a new version.</p>\n</blockquote>\n<p><strong>Theres our base and our layout, now get developing!</strong></p>\n<p>###TESTING YOUR GEM:</p>\n<p>Were going to use <strong>minitest</strong> to test our gem.</p>\n<p>-<strong>We write tests to ensure that everything goes according to plan</strong> and to prevent future-us from building a time machine to come back and kick our asses.</p>\n<p>-To get started with writing our tests, well <strong>create a test directory at the root of gem</strong> by using the command:</p>\n<pre><code>mkdir test\n</code></pre><p>-Next, well specify in our <strong>megam_api.gemspec</strong> file that minitest is a development dependency by adding this line inside theGem::Specification block:</p>\n<pre><code>spec.add_development_dependency &quot;minitest&quot;, &quot;~&gt; 5.8&quot;\n</code></pre><p>-Because we have the gemspec method call in our Gemfile, bundler will automatically add this gem to a group called development which then we can reference any time we want to load these gems with the following line:</p>\n<pre><code>Bundler.require(:default, :development)`\n</code></pre><p>-The benefit of putting this dependency specification inside of megam_api.gemspec rather than the Gemfile is that anybody who runs </p>\n<pre><code>gem install megam_api --dev \n</code></pre><p> will get these development dependencies installed too. </p>\n<p>This command is used for when people wish to test a gem without having to fork it or clone it from GitHub.</p>\n<p>-When we run <code>bundle install</code>, <strong>minitest</strong> will be installed for this library and any other library we use with bundler, but not for the system. This is an important distinction to make: any gem installed by Bundler will not muck about with gems installed by gem install. It is effectively a sandboxed environment. </p>\n<p>-By running <code>bundle install</code>, bundler will generate the extremely important <strong>Gemfile.lock</strong> file. This file is responsible for ensuring that every system this library is developed on has the exact same gems so it should always be checked into version control.Additionally in the bundle install output, we will see this line:</p>\n<pre><code>Using megam_api (0.99) from source at /path/to/megam_api`\n</code></pre><p>Bundler detects our gem, loads the gemspec and bundles our gem just like every other gem.</p>\n<p>We can <strong>write our first test with this framework</strong> now in place. </p>\n<p>For testing, create a new test file for every api (accounts to startwith) we want to test at the root of the test directory. </p>\n<p>When we <strong>run <code>ruby test_accounts.rb</code></strong> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div></pre></td><td class=\"code\"><pre><div class=\"line\">require File.expand_path(&quot;#&#123;File.dirname(__FILE__)&#125;/test_helper&quot;)</div><div class=\"line\"></div><div class=\"line\">class TestAccounts &lt; MiniTest::Unit::TestCase</div><div class=\"line\"></div><div class=\"line\">  $admin = &quot;admin-tom&quot;</div><div class=\"line\">  $normal = &quot;normal-tom&quot;</div><div class=\"line\">  $tom_email = &quot;tom@gomegam.com&quot;</div><div class=\"line\">  $bob_email = &quot;bob@gomegam.com&quot;</div><div class=\"line\"></div><div class=\"line\">  def test_get_accounts_good</div><div class=\"line\">    response =megams.get_accounts(sandbox_email)</div><div class=\"line\">    response.body.to_s</div><div class=\"line\">    assert_equal(200, response.status)</div><div class=\"line\">  end</div><div class=\"line\"></div><div class=\"line\">  def test_post_accounts_good</div><div class=\"line\">    tmp_hash = &#123;</div><div class=\"line\">      &quot;id&quot; =&gt; &quot;000099090909000&quot;,</div><div class=\"line\">      &quot;first_name&quot; =&gt; &quot;Darth&quot;,</div><div class=\"line\">      &quot;last_name&quot; =&gt; &quot;Vader&quot;,</div><div class=\"line\">      &quot;email&quot; =&gt; &quot;coolvader@iamswag.com&quot;,</div><div class=\"line\">      &quot;phone&quot; =&gt; &quot;19090909090&quot;,</div><div class=\"line\">      &quot;api_key&quot; =&gt; &quot;IamAtlas&#123;74&#125;NobdyCanSedfefdeME#07&quot;,</div><div class=\"line\">      &quot;authority&quot; =&gt; &quot;admin&quot;,</div><div class=\"line\">      &quot;password&quot; =&gt; &quot;&quot;,</div><div class=\"line\">      &quot;password_reset_key&quot; =&gt; &quot;&quot;,</div><div class=\"line\">      &quot;password_reset_sent_at&quot; =&gt; &quot;&quot;,</div><div class=\"line\">      &quot;created_at&quot; =&gt; &quot;2014-10-29 13:24:06 +0000&quot;</div><div class=\"line\">      &#125;</div><div class=\"line\">    response =megams.post_accounts(tmp_hash)</div><div class=\"line\">    response.body.to_s</div><div class=\"line\">    assert_equal(201, response.status)</div><div class=\"line\">  end</div><div class=\"line\"></div><div class=\"line\">end</div></pre></td></tr></table></figure>\n<p>To load this file, well need to add a require line to lib/megam_api.rb for it:<br>require megam_api/api/accounts</p>\n<p>When we run our specs with ruby test_accounts.rb this test will pass:<br>2 example, 0 failures</p>\n<p>Great success! If were using Git (or any other source control system), this is a great checkpoint to commit our code. Always remember to commit often!<br>Its all well and dandy that we can write our own code.</p>\n<p>###PUBLISHING TO RUBYGEMS.ORG</p>\n<p>The simplest way to distribute a gem for public consumption is to use RubyGems.org. </p>\n<p>Gems that are published to RubyGems.org can be installed via the gem install command or through the use of tools such as Isolate or Bundler.</p>\n<blockquote>\n<p><strong>Create an account with rubygems.org</strong></p>\n</blockquote>\n<p>Register at [rubygems.org](<a href=\"https://rubygems\">https://rubygems</a>.</p>\n<blockquote>\n<p><strong>Create a credentials file with the api_key</strong></p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">ram@ramwork:.gem]$ pwd</div><div class=\"line\">/home/ram/.gem</div><div class=\"line\"></div><div class=\"line\">[ram@ramwork:.gem]$ ls</div><div class=\"line\">credentials  ruby/  specs/</div><div class=\"line\"></div><div class=\"line\">[ram@ramwork:.gem]$ cat credentials</div><div class=\"line\">---</div><div class=\"line\">:rubygems_api_key: 8690909090909090909090afdasfasdf90</div></pre></td></tr></table></figure>\n<blockquote>\n<p><strong>Build a gem</strong></p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd megam_api</div><div class=\"line\"></div><div class=\"line\">gem build megam_api.gemspec</div><div class=\"line\"></div><div class=\"line\">Successfully built RubyGem</div><div class=\"line\">Name: megam_api</div><div class=\"line\">Version: 0.90</div><div class=\"line\">File: megam_api-0.90.gem</div></pre></td></tr></table></figure>\n<blockquote>\n<p><strong>Push your gem to rubygems.org</strong></p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">gem push megam_api-0.99.gem</div></pre></td></tr></table></figure>\n<p>###Voila</p>\n<p>You are done. Go ahead and hack your own gem.</p>\n"},{"title":"Hetzner networking in ubuntu opennebula host","slug":"2015-12-15-hetzner-networking-in-ubuntu-host","date_published":"2015-12-15T06:33:45.564Z","date_updated":"2016-06-02T07:25:33.174Z","_content":"\nOur need is to setup `opennebula` in `hetzner`, so we have two servers, one is for opennebula-frontend and another one is for opennebula-host. We don't face any problem in opennebula front-end.\n\nBut in opennebula-host server, we face some `networking problems`. \n\nWe have a local working server for opennbula-host with `openvswitch`. But in hetzner openvswitch makes some problem.\n\nAfter trying many configuration, we succeed with the following configurations,\n\nOS : Ubuntu-14.04(trusty)\n\n`NOTE`\nActually we have public ips, but for security issues i documented local ips\n\t\n    Host ip : 192.168.1.100\n\nFor vms, i got subnet ips\n\n\tSubnet: 192.168.2.96/27\n    Useable ips : 192.168.2.97 to 192.168.2.126\n\n`NOTE` Create bridge (one) after adding the below configuration in the interface file\n\nMy Host server network configuration\n\n\t# cat /etc/network/interfaces\n\t### Hetzner Online GmbH - installimage\n\t# Loopback device:\n\tauto lo\n\tiface lo inet loopback\n\n\t# device: eth0\n\tauto  eth0\n\tiface eth0 inet static\n\t  address   192.168.1.100\n\t  netmask   255.255.255.224\n\t  gateway   192.168.1.1\n\t  up route add -net 192.168.1.0 netmask 255.255.255.224 gw 192.168.1.1 eth0\n\n\tiface eth0 inet6 static\n\t  address 2xxx:xx:xxx:xxxx::x\n\t  netmask 64\n\t  gateway fe80::1\n\t\n\tauto one\n\tiface one inet static\n\t  address   192.168.1.100\n\t  netmask   255.255.255.224\n\t  bridge_ports none\n\t  bridge_stp off\n\t  bridge_fd 1\n\t  bridge_hello 2\n\t  bridge_maxage 12\n\t\n\t  #subnet\n\t  up ip route add 192.168.2.96/27 dev one\n\t  up ip route add 192.168.2.97/27 dev one\n\t  up ip route add 192.168.2.98/27 dev one\n\t  up ip route add 192.168.2.99/27 dev one\n\t  up ip route add 192.168.2.100/27 dev one\n\t  up ip route add 192.168.2.101/27 dev one\n\t  up ip route add 192.168.2.102/27 dev one\n\t  up ip route add 192.168.2.103/27 dev one\n\t  up ip route add 192.168.2.104/27 dev one\n\t\nRouting table for host server\n\n\troot@ec2 ~ # route\n\tKernel IP routing table\n\tDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n\tdefault         static.1.1.168. 0.0.0.0         UG    0      0        0 eth0\n\t192.168.1.0     static.1.1.168. 255.255.255.224 UG    0      0        0 eth0\n\t192.168.1.0     *               255.255.255.224 U     0      0        0 eth0\n\t192.168.1.0     *               255.255.255.224 U     0      0        0 one\n\t192.168.2.96  *               255.255.255.224 U     0      0        0 one\n    \nIP routes\n\n\troot@ec2 ~ # ip route show\n\tdefault via 192.168.1.1 dev eth0 \n\t192.168.1.0/27 via 144.xx.xx.1 dev eth0 \n\t192.168.1.0/27 dev eth0  proto kernel  scope link  src 192.168.1.100 \n\t192.168.1.0/27 dev one  proto kernel  scope link  src 192.168.1.100\n\t192.168.2.96/27 dev one  scope link \n    \n    \nopen /etc/sysctl.conf and uncomment these lines\n\n\tnet.ipv4.conf.all.rp_filter=1 \n    net.ipv4.ip_forward=1 \n    net.ipv6.conf.all.forwarding=1\n\n\nDelete default bridge virbr0\n\n\t$ virsh net-destroy default\n\t$ virsh net-undefine default\n\t$ service libvirtd restart\n    \nFirst we tried openvswitch, then we remove all ports & bridges from openvswitch\n\n\troot@ec2 ~ # ovs-vsctl show\n\t835b086b-286b-448c-83f4-1d7526a9954e\n\t    ovs_version: \"2.0.2\"\n        \n Then we tried normal linux-bridge. After launching vm, our linux bridge status\n \n \troot@ec2 ~ # brctl show\n\tbridge name\tbridge id\t\tSTP enabled\tinterfaces\n\tone\t\t8000.fe0094fbd663\tno\t\tvnet0\n    \n    root@ec2 ~ # ifconfig\n\teth0      Link encap:Ethernet  HWaddr 8c:89:a5:15:6f:e4  \n          inet addr:192.168.1.100  Bcast:192.168.1.31  Mask:255.255.255.224\n          inet6 addr: 2xxx:xx:xxx:xxxx::x/64 Scope:Global\n          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:10285 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:11418 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:2408774 (2.4 MB)  TX bytes:3191410 (3.1 MB)\n\n\tlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:588417 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:588417 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:1387023327 (1.3 GB)  TX bytes:1387023327 (1.3 GB)\n\n\tone      Link encap:Ethernet  HWaddr 8c:89:a5:15:6f:e4  \n          inet addr:192.168.1.100  Bcast:192.168.1.31  Mask:255.255.255.224\n          inet6 addr: 2xxx:xx:xxx:xxxx::x/64 Scope:Global\n          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:2098 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:983 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:167718 (167.7 KB)  TX bytes:44679 (44.6 KB)\n\n\tvnet0     Link encap:Ethernet  HWaddr fe:00:94:fb:d6:63  \n          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxx/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:2098 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:749 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:500 \n          RX bytes:197090 (197.0 KB)  TX bytes:34851 (34.8 KB)\n\n\n\nThats it for opennebula host server's network configuration.\n\nNow launch a vm from opennebula\n\n######VM's network configuration for Ubuntu\n\n\troot@vm1:~# cat /etc/network/interfaces\n\tauto lo\n\tiface lo inet loopback\n\n\tauto eth0\n\tiface eth0 inet static\n\t  address 192.168.2.97\n\t  network 192.168.2.0\n\t  netmask 255.255.255.224\n\t  gateway 192.168.1.100\n\t  pointopoint 192.168.1.100\n\n\nVm's routing table\n\n\troot@vm1:~# route\n\tKernel IP routing table\n\tDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n\tdefault         100.1.168.192.in 0.0.0.0         UG    0      0        0 eth0\n\t100.1.168.192.in *               255.255.255.255 UH    0      0        0 eth0\n    \n\nip route\n\n\troot@vm1:~# ip route show\n\tdefault via 192.168.1.100 dev eth0 \n\t192.168.1.100 dev eth0  proto kernel  scope link  src 192.168.2.97\n\nNow i can connect with my vm from anywhere.\n\n\n######VM's network configuration for CoreOS\n\nVirutal Machine OS : CoreOS-835.13.0\n\nVM's network configuration\n\n\troot@vm1:~# cat  /etc/systemd/network/static.network \n\t[Match]\n\tName=ens3\n\n\t[Network]\n\tAddress=192.168.3.99/27\n\tGateway=192.168.1.100\n\tDNS=8.8.8.8\n\tDNS=8.8.4.4\n\n\t[Address]\n\tAddress=192.168.2.99/27\n\tPeer=192.168.1.100\n\nVm's routing table\n\n\troot@vm1:~# route \n\tKernel IP routing table\n\tDestination     Gateway         Genmask         Flags \tMetric Ref    Use Iface\n\tdefault         192.168.1.100  0.0.0.0         UG    0      0        0 ens3\n\t192.168.1.100  *        255.255.255.255 UH    0      0        0 ens3\n\t192.168.2.0    *         255.255.255.224 U     0      0        0 ens3\n\t172.17.0.0     *         255.255.0.0     U     0      0        0 docker0\n\n\troot@vm1:~# ip route show\n\tdefault via 192.168.1.100 dev ens3 \n\t192.168.1.100 dev ens3  scope link \n\t192.168.2.0/27 dev ens3  proto kernel  scope link  src 192.168.2.99 \n\t172.17.0.0/16 dev docker0  proto kernel  scope link  src 172.17.0.1 \n\n","source":"_posts/2015-12-15-hetzner-networking-in-ubuntu-host.md","raw":"---\ntitle: Hetzner networking in ubuntu opennebula host\nslug: hetzner-networking-in-ubuntu-host\ndate_published: 2015-12-15T12:03:45.564Z\ndate_updated:   2016-06-02T12:55:33.174Z\n---\n\nOur need is to setup `opennebula` in `hetzner`, so we have two servers, one is for opennebula-frontend and another one is for opennebula-host. We don't face any problem in opennebula front-end.\n\nBut in opennebula-host server, we face some `networking problems`. \n\nWe have a local working server for opennbula-host with `openvswitch`. But in hetzner openvswitch makes some problem.\n\nAfter trying many configuration, we succeed with the following configurations,\n\nOS : Ubuntu-14.04(trusty)\n\n`NOTE`\nActually we have public ips, but for security issues i documented local ips\n\t\n    Host ip : 192.168.1.100\n\nFor vms, i got subnet ips\n\n\tSubnet: 192.168.2.96/27\n    Useable ips : 192.168.2.97 to 192.168.2.126\n\n`NOTE` Create bridge (one) after adding the below configuration in the interface file\n\nMy Host server network configuration\n\n\t# cat /etc/network/interfaces\n\t### Hetzner Online GmbH - installimage\n\t# Loopback device:\n\tauto lo\n\tiface lo inet loopback\n\n\t# device: eth0\n\tauto  eth0\n\tiface eth0 inet static\n\t  address   192.168.1.100\n\t  netmask   255.255.255.224\n\t  gateway   192.168.1.1\n\t  up route add -net 192.168.1.0 netmask 255.255.255.224 gw 192.168.1.1 eth0\n\n\tiface eth0 inet6 static\n\t  address 2xxx:xx:xxx:xxxx::x\n\t  netmask 64\n\t  gateway fe80::1\n\t\n\tauto one\n\tiface one inet static\n\t  address   192.168.1.100\n\t  netmask   255.255.255.224\n\t  bridge_ports none\n\t  bridge_stp off\n\t  bridge_fd 1\n\t  bridge_hello 2\n\t  bridge_maxage 12\n\t\n\t  #subnet\n\t  up ip route add 192.168.2.96/27 dev one\n\t  up ip route add 192.168.2.97/27 dev one\n\t  up ip route add 192.168.2.98/27 dev one\n\t  up ip route add 192.168.2.99/27 dev one\n\t  up ip route add 192.168.2.100/27 dev one\n\t  up ip route add 192.168.2.101/27 dev one\n\t  up ip route add 192.168.2.102/27 dev one\n\t  up ip route add 192.168.2.103/27 dev one\n\t  up ip route add 192.168.2.104/27 dev one\n\t\nRouting table for host server\n\n\troot@ec2 ~ # route\n\tKernel IP routing table\n\tDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n\tdefault         static.1.1.168. 0.0.0.0         UG    0      0        0 eth0\n\t192.168.1.0     static.1.1.168. 255.255.255.224 UG    0      0        0 eth0\n\t192.168.1.0     *               255.255.255.224 U     0      0        0 eth0\n\t192.168.1.0     *               255.255.255.224 U     0      0        0 one\n\t192.168.2.96  *               255.255.255.224 U     0      0        0 one\n    \nIP routes\n\n\troot@ec2 ~ # ip route show\n\tdefault via 192.168.1.1 dev eth0 \n\t192.168.1.0/27 via 144.xx.xx.1 dev eth0 \n\t192.168.1.0/27 dev eth0  proto kernel  scope link  src 192.168.1.100 \n\t192.168.1.0/27 dev one  proto kernel  scope link  src 192.168.1.100\n\t192.168.2.96/27 dev one  scope link \n    \n    \nopen /etc/sysctl.conf and uncomment these lines\n\n\tnet.ipv4.conf.all.rp_filter=1 \n    net.ipv4.ip_forward=1 \n    net.ipv6.conf.all.forwarding=1\n\n\nDelete default bridge virbr0\n\n\t$ virsh net-destroy default\n\t$ virsh net-undefine default\n\t$ service libvirtd restart\n    \nFirst we tried openvswitch, then we remove all ports & bridges from openvswitch\n\n\troot@ec2 ~ # ovs-vsctl show\n\t835b086b-286b-448c-83f4-1d7526a9954e\n\t    ovs_version: \"2.0.2\"\n        \n Then we tried normal linux-bridge. After launching vm, our linux bridge status\n \n \troot@ec2 ~ # brctl show\n\tbridge name\tbridge id\t\tSTP enabled\tinterfaces\n\tone\t\t8000.fe0094fbd663\tno\t\tvnet0\n    \n    root@ec2 ~ # ifconfig\n\teth0      Link encap:Ethernet  HWaddr 8c:89:a5:15:6f:e4  \n          inet addr:192.168.1.100  Bcast:192.168.1.31  Mask:255.255.255.224\n          inet6 addr: 2xxx:xx:xxx:xxxx::x/64 Scope:Global\n          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:10285 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:11418 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:2408774 (2.4 MB)  TX bytes:3191410 (3.1 MB)\n\n\tlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:588417 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:588417 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:1387023327 (1.3 GB)  TX bytes:1387023327 (1.3 GB)\n\n\tone      Link encap:Ethernet  HWaddr 8c:89:a5:15:6f:e4  \n          inet addr:192.168.1.100  Bcast:192.168.1.31  Mask:255.255.255.224\n          inet6 addr: 2xxx:xx:xxx:xxxx::x/64 Scope:Global\n          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:2098 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:983 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:167718 (167.7 KB)  TX bytes:44679 (44.6 KB)\n\n\tvnet0     Link encap:Ethernet  HWaddr fe:00:94:fb:d6:63  \n          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxx/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:2098 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:749 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:500 \n          RX bytes:197090 (197.0 KB)  TX bytes:34851 (34.8 KB)\n\n\n\nThats it for opennebula host server's network configuration.\n\nNow launch a vm from opennebula\n\n######VM's network configuration for Ubuntu\n\n\troot@vm1:~# cat /etc/network/interfaces\n\tauto lo\n\tiface lo inet loopback\n\n\tauto eth0\n\tiface eth0 inet static\n\t  address 192.168.2.97\n\t  network 192.168.2.0\n\t  netmask 255.255.255.224\n\t  gateway 192.168.1.100\n\t  pointopoint 192.168.1.100\n\n\nVm's routing table\n\n\troot@vm1:~# route\n\tKernel IP routing table\n\tDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n\tdefault         100.1.168.192.in 0.0.0.0         UG    0      0        0 eth0\n\t100.1.168.192.in *               255.255.255.255 UH    0      0        0 eth0\n    \n\nip route\n\n\troot@vm1:~# ip route show\n\tdefault via 192.168.1.100 dev eth0 \n\t192.168.1.100 dev eth0  proto kernel  scope link  src 192.168.2.97\n\nNow i can connect with my vm from anywhere.\n\n\n######VM's network configuration for CoreOS\n\nVirutal Machine OS : CoreOS-835.13.0\n\nVM's network configuration\n\n\troot@vm1:~# cat  /etc/systemd/network/static.network \n\t[Match]\n\tName=ens3\n\n\t[Network]\n\tAddress=192.168.3.99/27\n\tGateway=192.168.1.100\n\tDNS=8.8.8.8\n\tDNS=8.8.4.4\n\n\t[Address]\n\tAddress=192.168.2.99/27\n\tPeer=192.168.1.100\n\nVm's routing table\n\n\troot@vm1:~# route \n\tKernel IP routing table\n\tDestination     Gateway         Genmask         Flags \tMetric Ref    Use Iface\n\tdefault         192.168.1.100  0.0.0.0         UG    0      0        0 ens3\n\t192.168.1.100  *        255.255.255.255 UH    0      0        0 ens3\n\t192.168.2.0    *         255.255.255.224 U     0      0        0 ens3\n\t172.17.0.0     *         255.255.0.0     U     0      0        0 docker0\n\n\troot@vm1:~# ip route show\n\tdefault via 192.168.1.100 dev ens3 \n\t192.168.1.100 dev ens3  scope link \n\t192.168.2.0/27 dev ens3  proto kernel  scope link  src 192.168.2.99 \n\t172.17.0.0/16 dev docker0  proto kernel  scope link  src 172.17.0.1 \n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaisi0010drgb9v69ebwv","content":"<p>Our need is to setup <code>opennebula</code> in <code>hetzner</code>, so we have two servers, one is for opennebula-frontend and another one is for opennebula-host. We dont face any problem in opennebula front-end.</p>\n<p>But in opennebula-host server, we face some <code>networking problems</code>. </p>\n<p>We have a local working server for opennbula-host with <code>openvswitch</code>. But in hetzner openvswitch makes some problem.</p>\n<p>After trying many configuration, we succeed with the following configurations,</p>\n<p>OS : Ubuntu-14.04(trusty)</p>\n<p><code>NOTE</code><br>Actually we have public ips, but for security issues i documented local ips</p>\n<pre><code>Host ip : 192.168.1.100\n</code></pre><p>For vms, i got subnet ips</p>\n<pre><code>Subnet: 192.168.2.96/27\nUseable ips : 192.168.2.97 to 192.168.2.126\n</code></pre><p><code>NOTE</code> Create bridge (one) after adding the below configuration in the interface file</p>\n<p>My Host server network configuration</p>\n<pre><code># cat /etc/network/interfaces\n### Hetzner Online GmbH - installimage\n# Loopback device:\nauto lo\niface lo inet loopback\n\n# device: eth0\nauto  eth0\niface eth0 inet static\n  address   192.168.1.100\n  netmask   255.255.255.224\n  gateway   192.168.1.1\n  up route add -net 192.168.1.0 netmask 255.255.255.224 gw 192.168.1.1 eth0\n\niface eth0 inet6 static\n  address 2xxx:xx:xxx:xxxx::x\n  netmask 64\n  gateway fe80::1\n\nauto one\niface one inet static\n  address   192.168.1.100\n  netmask   255.255.255.224\n  bridge_ports none\n  bridge_stp off\n  bridge_fd 1\n  bridge_hello 2\n  bridge_maxage 12\n\n  #subnet\n  up ip route add 192.168.2.96/27 dev one\n  up ip route add 192.168.2.97/27 dev one\n  up ip route add 192.168.2.98/27 dev one\n  up ip route add 192.168.2.99/27 dev one\n  up ip route add 192.168.2.100/27 dev one\n  up ip route add 192.168.2.101/27 dev one\n  up ip route add 192.168.2.102/27 dev one\n  up ip route add 192.168.2.103/27 dev one\n  up ip route add 192.168.2.104/27 dev one\n</code></pre><p>Routing table for host server</p>\n<pre><code>root@ec2 ~ # route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\ndefault         static.1.1.168. 0.0.0.0         UG    0      0        0 eth0\n192.168.1.0     static.1.1.168. 255.255.255.224 UG    0      0        0 eth0\n192.168.1.0     *               255.255.255.224 U     0      0        0 eth0\n192.168.1.0     *               255.255.255.224 U     0      0        0 one\n192.168.2.96  *               255.255.255.224 U     0      0        0 one\n</code></pre><p>IP routes</p>\n<pre><code>root@ec2 ~ # ip route show\ndefault via 192.168.1.1 dev eth0 \n192.168.1.0/27 via 144.xx.xx.1 dev eth0 \n192.168.1.0/27 dev eth0  proto kernel  scope link  src 192.168.1.100 \n192.168.1.0/27 dev one  proto kernel  scope link  src 192.168.1.100\n192.168.2.96/27 dev one  scope link \n</code></pre><p>open /etc/sysctl.conf and uncomment these lines</p>\n<pre><code>net.ipv4.conf.all.rp_filter=1 \nnet.ipv4.ip_forward=1 \nnet.ipv6.conf.all.forwarding=1\n</code></pre><p>Delete default bridge virbr0</p>\n<pre><code>$ virsh net-destroy default\n$ virsh net-undefine default\n$ service libvirtd restart\n</code></pre><p>First we tried openvswitch, then we remove all ports &amp; bridges from openvswitch</p>\n<pre><code>root@ec2 ~ # ovs-vsctl show\n835b086b-286b-448c-83f4-1d7526a9954e\n    ovs_version: &quot;2.0.2&quot;\n</code></pre><p> Then we tried normal linux-bridge. After launching vm, our linux bridge status</p>\n<pre><code> root@ec2 ~ # brctl show\nbridge name    bridge id        STP enabled    interfaces\none        8000.fe0094fbd663    no        vnet0\n\nroot@ec2 ~ # ifconfig\neth0      Link encap:Ethernet  HWaddr 8c:89:a5:15:6f:e4  \n      inet addr:192.168.1.100  Bcast:192.168.1.31  Mask:255.255.255.224\n      inet6 addr: 2xxx:xx:xxx:xxxx::x/64 Scope:Global\n      inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n      UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n      RX packets:10285 errors:0 dropped:0 overruns:0 frame:0\n      TX packets:11418 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 txqueuelen:1000 \n      RX bytes:2408774 (2.4 MB)  TX bytes:3191410 (3.1 MB)\n\nlo        Link encap:Local Loopback  \n      inet addr:127.0.0.1  Mask:255.0.0.0\n      inet6 addr: ::1/128 Scope:Host\n      UP LOOPBACK RUNNING  MTU:65536  Metric:1\n      RX packets:588417 errors:0 dropped:0 overruns:0 frame:0\n      TX packets:588417 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 txqueuelen:0 \n      RX bytes:1387023327 (1.3 GB)  TX bytes:1387023327 (1.3 GB)\n\none      Link encap:Ethernet  HWaddr 8c:89:a5:15:6f:e4  \n      inet addr:192.168.1.100  Bcast:192.168.1.31  Mask:255.255.255.224\n      inet6 addr: 2xxx:xx:xxx:xxxx::x/64 Scope:Global\n      inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n      UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n      RX packets:2098 errors:0 dropped:0 overruns:0 frame:0\n      TX packets:983 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 txqueuelen:0 \n      RX bytes:167718 (167.7 KB)  TX bytes:44679 (44.6 KB)\n\nvnet0     Link encap:Ethernet  HWaddr fe:00:94:fb:d6:63  \n      inet6 addr: xxxx::xxxx:xxxx:xxxx:xxx/64 Scope:Link\n      UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n      RX packets:2098 errors:0 dropped:0 overruns:0 frame:0\n      TX packets:749 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 txqueuelen:500 \n      RX bytes:197090 (197.0 KB)  TX bytes:34851 (34.8 KB)\n</code></pre><p>Thats it for opennebula host servers network configuration.</p>\n<p>Now launch a vm from opennebula</p>\n<p>######VMs network configuration for Ubuntu</p>\n<pre><code>root@vm1:~# cat /etc/network/interfaces\nauto lo\niface lo inet loopback\n\nauto eth0\niface eth0 inet static\n  address 192.168.2.97\n  network 192.168.2.0\n  netmask 255.255.255.224\n  gateway 192.168.1.100\n  pointopoint 192.168.1.100\n</code></pre><p>Vms routing table</p>\n<pre><code>root@vm1:~# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\ndefault         100.1.168.192.in 0.0.0.0         UG    0      0        0 eth0\n100.1.168.192.in *               255.255.255.255 UH    0      0        0 eth0\n</code></pre><p>ip route</p>\n<pre><code>root@vm1:~# ip route show\ndefault via 192.168.1.100 dev eth0 \n192.168.1.100 dev eth0  proto kernel  scope link  src 192.168.2.97\n</code></pre><p>Now i can connect with my vm from anywhere.</p>\n<p>######VMs network configuration for CoreOS</p>\n<p>Virutal Machine OS : CoreOS-835.13.0</p>\n<p>VMs network configuration</p>\n<pre><code>root@vm1:~# cat  /etc/systemd/network/static.network \n[Match]\nName=ens3\n\n[Network]\nAddress=192.168.3.99/27\nGateway=192.168.1.100\nDNS=8.8.8.8\nDNS=8.8.4.4\n\n[Address]\nAddress=192.168.2.99/27\nPeer=192.168.1.100\n</code></pre><p>Vms routing table</p>\n<pre><code>root@vm1:~# route \nKernel IP routing table\nDestination     Gateway         Genmask         Flags     Metric Ref    Use Iface\ndefault         192.168.1.100  0.0.0.0         UG    0      0        0 ens3\n192.168.1.100  *        255.255.255.255 UH    0      0        0 ens3\n192.168.2.0    *         255.255.255.224 U     0      0        0 ens3\n172.17.0.0     *         255.255.0.0     U     0      0        0 docker0\n\nroot@vm1:~# ip route show\ndefault via 192.168.1.100 dev ens3 \n192.168.1.100 dev ens3  scope link \n192.168.2.0/27 dev ens3  proto kernel  scope link  src 192.168.2.99 \n172.17.0.0/16 dev docker0  proto kernel  scope link  src 172.17.0.1 \n</code></pre>","excerpt":"","more":"<p>Our need is to setup <code>opennebula</code> in <code>hetzner</code>, so we have two servers, one is for opennebula-frontend and another one is for opennebula-host. We dont face any problem in opennebula front-end.</p>\n<p>But in opennebula-host server, we face some <code>networking problems</code>. </p>\n<p>We have a local working server for opennbula-host with <code>openvswitch</code>. But in hetzner openvswitch makes some problem.</p>\n<p>After trying many configuration, we succeed with the following configurations,</p>\n<p>OS : Ubuntu-14.04(trusty)</p>\n<p><code>NOTE</code><br>Actually we have public ips, but for security issues i documented local ips</p>\n<pre><code>Host ip : 192.168.1.100\n</code></pre><p>For vms, i got subnet ips</p>\n<pre><code>Subnet: 192.168.2.96/27\nUseable ips : 192.168.2.97 to 192.168.2.126\n</code></pre><p><code>NOTE</code> Create bridge (one) after adding the below configuration in the interface file</p>\n<p>My Host server network configuration</p>\n<pre><code># cat /etc/network/interfaces\n### Hetzner Online GmbH - installimage\n# Loopback device:\nauto lo\niface lo inet loopback\n\n# device: eth0\nauto  eth0\niface eth0 inet static\n  address   192.168.1.100\n  netmask   255.255.255.224\n  gateway   192.168.1.1\n  up route add -net 192.168.1.0 netmask 255.255.255.224 gw 192.168.1.1 eth0\n\niface eth0 inet6 static\n  address 2xxx:xx:xxx:xxxx::x\n  netmask 64\n  gateway fe80::1\n\nauto one\niface one inet static\n  address   192.168.1.100\n  netmask   255.255.255.224\n  bridge_ports none\n  bridge_stp off\n  bridge_fd 1\n  bridge_hello 2\n  bridge_maxage 12\n\n  #subnet\n  up ip route add 192.168.2.96/27 dev one\n  up ip route add 192.168.2.97/27 dev one\n  up ip route add 192.168.2.98/27 dev one\n  up ip route add 192.168.2.99/27 dev one\n  up ip route add 192.168.2.100/27 dev one\n  up ip route add 192.168.2.101/27 dev one\n  up ip route add 192.168.2.102/27 dev one\n  up ip route add 192.168.2.103/27 dev one\n  up ip route add 192.168.2.104/27 dev one\n</code></pre><p>Routing table for host server</p>\n<pre><code>root@ec2 ~ # route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\ndefault         static.1.1.168. 0.0.0.0         UG    0      0        0 eth0\n192.168.1.0     static.1.1.168. 255.255.255.224 UG    0      0        0 eth0\n192.168.1.0     *               255.255.255.224 U     0      0        0 eth0\n192.168.1.0     *               255.255.255.224 U     0      0        0 one\n192.168.2.96  *               255.255.255.224 U     0      0        0 one\n</code></pre><p>IP routes</p>\n<pre><code>root@ec2 ~ # ip route show\ndefault via 192.168.1.1 dev eth0 \n192.168.1.0/27 via 144.xx.xx.1 dev eth0 \n192.168.1.0/27 dev eth0  proto kernel  scope link  src 192.168.1.100 \n192.168.1.0/27 dev one  proto kernel  scope link  src 192.168.1.100\n192.168.2.96/27 dev one  scope link \n</code></pre><p>open /etc/sysctl.conf and uncomment these lines</p>\n<pre><code>net.ipv4.conf.all.rp_filter=1 \nnet.ipv4.ip_forward=1 \nnet.ipv6.conf.all.forwarding=1\n</code></pre><p>Delete default bridge virbr0</p>\n<pre><code>$ virsh net-destroy default\n$ virsh net-undefine default\n$ service libvirtd restart\n</code></pre><p>First we tried openvswitch, then we remove all ports &amp; bridges from openvswitch</p>\n<pre><code>root@ec2 ~ # ovs-vsctl show\n835b086b-286b-448c-83f4-1d7526a9954e\n    ovs_version: &quot;2.0.2&quot;\n</code></pre><p> Then we tried normal linux-bridge. After launching vm, our linux bridge status</p>\n<pre><code> root@ec2 ~ # brctl show\nbridge name    bridge id        STP enabled    interfaces\none        8000.fe0094fbd663    no        vnet0\n\nroot@ec2 ~ # ifconfig\neth0      Link encap:Ethernet  HWaddr 8c:89:a5:15:6f:e4  \n      inet addr:192.168.1.100  Bcast:192.168.1.31  Mask:255.255.255.224\n      inet6 addr: 2xxx:xx:xxx:xxxx::x/64 Scope:Global\n      inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n      UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n      RX packets:10285 errors:0 dropped:0 overruns:0 frame:0\n      TX packets:11418 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 txqueuelen:1000 \n      RX bytes:2408774 (2.4 MB)  TX bytes:3191410 (3.1 MB)\n\nlo        Link encap:Local Loopback  \n      inet addr:127.0.0.1  Mask:255.0.0.0\n      inet6 addr: ::1/128 Scope:Host\n      UP LOOPBACK RUNNING  MTU:65536  Metric:1\n      RX packets:588417 errors:0 dropped:0 overruns:0 frame:0\n      TX packets:588417 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 txqueuelen:0 \n      RX bytes:1387023327 (1.3 GB)  TX bytes:1387023327 (1.3 GB)\n\none      Link encap:Ethernet  HWaddr 8c:89:a5:15:6f:e4  \n      inet addr:192.168.1.100  Bcast:192.168.1.31  Mask:255.255.255.224\n      inet6 addr: 2xxx:xx:xxx:xxxx::x/64 Scope:Global\n      inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n      UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n      RX packets:2098 errors:0 dropped:0 overruns:0 frame:0\n      TX packets:983 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 txqueuelen:0 \n      RX bytes:167718 (167.7 KB)  TX bytes:44679 (44.6 KB)\n\nvnet0     Link encap:Ethernet  HWaddr fe:00:94:fb:d6:63  \n      inet6 addr: xxxx::xxxx:xxxx:xxxx:xxx/64 Scope:Link\n      UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n      RX packets:2098 errors:0 dropped:0 overruns:0 frame:0\n      TX packets:749 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 txqueuelen:500 \n      RX bytes:197090 (197.0 KB)  TX bytes:34851 (34.8 KB)\n</code></pre><p>Thats it for opennebula host servers network configuration.</p>\n<p>Now launch a vm from opennebula</p>\n<p>######VMs network configuration for Ubuntu</p>\n<pre><code>root@vm1:~# cat /etc/network/interfaces\nauto lo\niface lo inet loopback\n\nauto eth0\niface eth0 inet static\n  address 192.168.2.97\n  network 192.168.2.0\n  netmask 255.255.255.224\n  gateway 192.168.1.100\n  pointopoint 192.168.1.100\n</code></pre><p>Vms routing table</p>\n<pre><code>root@vm1:~# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\ndefault         100.1.168.192.in 0.0.0.0         UG    0      0        0 eth0\n100.1.168.192.in *               255.255.255.255 UH    0      0        0 eth0\n</code></pre><p>ip route</p>\n<pre><code>root@vm1:~# ip route show\ndefault via 192.168.1.100 dev eth0 \n192.168.1.100 dev eth0  proto kernel  scope link  src 192.168.2.97\n</code></pre><p>Now i can connect with my vm from anywhere.</p>\n<p>######VMs network configuration for CoreOS</p>\n<p>Virutal Machine OS : CoreOS-835.13.0</p>\n<p>VMs network configuration</p>\n<pre><code>root@vm1:~# cat  /etc/systemd/network/static.network \n[Match]\nName=ens3\n\n[Network]\nAddress=192.168.3.99/27\nGateway=192.168.1.100\nDNS=8.8.8.8\nDNS=8.8.4.4\n\n[Address]\nAddress=192.168.2.99/27\nPeer=192.168.1.100\n</code></pre><p>Vms routing table</p>\n<pre><code>root@vm1:~# route \nKernel IP routing table\nDestination     Gateway         Genmask         Flags     Metric Ref    Use Iface\ndefault         192.168.1.100  0.0.0.0         UG    0      0        0 ens3\n192.168.1.100  *        255.255.255.255 UH    0      0        0 ens3\n192.168.2.0    *         255.255.255.224 U     0      0        0 ens3\n172.17.0.0     *         255.255.0.0     U     0      0        0 docker0\n\nroot@vm1:~# ip route show\ndefault via 192.168.1.100 dev ens3 \n192.168.1.100 dev ens3  scope link \n192.168.2.0/27 dev ens3  proto kernel  scope link  src 192.168.2.99 \n172.17.0.0/16 dev docker0  proto kernel  scope link  src 172.17.0.1 \n</code></pre>"},{"title":"NSQ messaging","slug":"2015-12-26-nsqd-messaging-server","date_published":"2015-12-26T09:54:58.696Z","date_updated":"2016-04-01T11:35:13.313Z","_content":"\n[NSQd](https://nsdq.io) A reatime distributed light weight messaging platform. \n\nWe have used [RabbitMQ](https://www.rabbitmq.com) heavily in clustered mode. Lately we have found issues with file description(fd) limit getting reached even after bumping the `ulimit` or closing sockets after publishing in the queue. \n\nWe have tried single publisher to reuse socket connection but [RabbitMQ](https://www.rabbitmq.com) hangs periodically.\n\nWe set out to cleanup our code and hunt for a new pub sub guy.\n\nNo wonder several players in the cloud market invent their own queue system, choices like [nats](http://nats.io/) pioneered by [apcera](https://www.apcera.com), [zeromq](http://zeromq.org/), [nsq.io](https://nsqio) by [bit.ly](https://bit.ly)\n\nWe choose [nsq](nsq.io) for it distributed realtime platform with no single point of failure (SPOF), it has its own service discovery mechanism and its written in [golang](https://golang.org), has drivers for every language. \n\nWe wrote our own wrappers for [NSQ - scala](https://github.com/megamsys/megam_common.git) and [NSQ - golang by crackcom](https://github.com/crackcomm/nsqueue)\n\n##Installation\n\nThis is pretty quick for your local setup\n\n    $ wget https://s3.amazonaws.com/bitly-downloads/nsq/nsq-0.3.6.linux-amd64.go1.5.1.tar.gz\n    \n   \n**Untar the tarball into ~/bin folder**\nUpon untarring ensure that the ~/bin folder has all the files named *nsq_*\n\n**Start the following daemons**\n\n\t$ nsqlookupd &\n    \n    $ nsqd --lookupd-tcp-address=127.0.0.1:4160\n    \n    $ nsqadmin --lookupd-http-address=127.0.0.1:4161\n    \n    $ curl -d 'hello world 1' 'http://127.0.0.1:4151/put?topic=test'\n    \n**Watch topic 'test'**\n\n    $ nsq_to_tail --topic=test --lookupd-http-address=127.0.0.1:4161\n    \n**Dump topic 'test' in a file**\n\n    $ nsq_to_file --topic=test --output-dir=/tmp --lookupd-http-address=127.0.0.1:4161\n    \n##Running nsq in production\n\nDefinitely clustering and adding more `nsqds` becomes a need using a service discovery mechanism. \n\nWe have built packages to handle them `megamnsqd`.\n\nThe topology we will use is a service discovery daemon `nsqlookupd` clustered using mutiple `nsqd`\n\n##Machine 1\nDo the due deligence by adding [get.megam.io](http://get.megam.io) repo.\n\n     $ apt-get install megamnsqd\n     \nThere are two services  `nsqd` and `nslookupd` we will use.  \n\nAt the end of the install the **services are not running**.\n\n**A private ip shall be present in /var/lib/megam/env.sh named MEGAM_NSQLOOKUP_IP**\n\nAs you noticed from the above `nsqd` needs the `nsqlookupd's` ip addresss during clustering.\n\nStart the daemons\n\n\t$ service start nslookupd\n    \n    $ service start nsqd\n    \nAs a webui is optional, there is not upstart or systemd file for it.  \n\nYou can even run `nsqadmin` poiting to the `lookupd` address from  your local laptop.\n\n\n    $ nsqadmin --lookupd-http-address=<MACHINE1_IP:4161>\n    \nType [http://MACHINE1_IP:4171](http://MACHINE1_IP:4171) for the web ui.    \n\n    \n##Machine 2\nDo the due deligence by adding [get.megam.io](http://get.megam.io) repo.\n\n     $ apt-get install megamnsqd\n     \nWe will use only `nsqd` here\n\nAt the end of the install the **service isn't running** and needs manual start.\n\n**A private ip shall be present in /var/lib/megam/env.sh named MEGAM_NSQLOOKUP_IP**\n\nAs you noticed from the above `nsqd` needs the `nsqlookupd's` ip addresses during clustering.\n\n**Change the MEGAM_NSQLOOKUP_IP=MACHINE1_IP in /var/lib/megam/env.sh**\n\nStart the daemon\n\t\n    $ service start nsqd\n    \nAs a webui is optional, there is not upstart or systemd file for it. \n\n     \nType [http://MACHINE1_IP:4171](http://MACHINE1_IP:4171) for the web ui in your local machine.\n\nYou will see two machines in the UI. \n\nYou might see a line `ERR <number> IO Error EOF` in our  daemons `megamd` or `gulpd` then indicate that the readLoop in `go-nsq` detected an end of file, which can be safely ignored.\n\n## Redudant nslookupd\nThis is something the `infra team` can investigate to scale and avoid SPOF for the service discovery mechanism.\n\nThe performance is sweet and pretty good. \n\nThe moral of the story is language virtual machines are a legacy (Erlang, Java ...) and nimble native daemons can be a bold/better choice for performance and scalability.\n    \n\n\n\n\n     \n     \n    \n    \n    \n\n\n\n\n\n    \n","source":"_posts/2015-12-26-nsqd-messaging-server.md","raw":"---\ntitle: NSQ messaging\nslug: nsqd-messaging-server\ndate_published: 2015-12-26T15:24:58.696Z\ndate_updated:   2016-04-01T17:05:13.313Z\n---\n\n[NSQd](https://nsdq.io) A reatime distributed light weight messaging platform. \n\nWe have used [RabbitMQ](https://www.rabbitmq.com) heavily in clustered mode. Lately we have found issues with file description(fd) limit getting reached even after bumping the `ulimit` or closing sockets after publishing in the queue. \n\nWe have tried single publisher to reuse socket connection but [RabbitMQ](https://www.rabbitmq.com) hangs periodically.\n\nWe set out to cleanup our code and hunt for a new pub sub guy.\n\nNo wonder several players in the cloud market invent their own queue system, choices like [nats](http://nats.io/) pioneered by [apcera](https://www.apcera.com), [zeromq](http://zeromq.org/), [nsq.io](https://nsqio) by [bit.ly](https://bit.ly)\n\nWe choose [nsq](nsq.io) for it distributed realtime platform with no single point of failure (SPOF), it has its own service discovery mechanism and its written in [golang](https://golang.org), has drivers for every language. \n\nWe wrote our own wrappers for [NSQ - scala](https://github.com/megamsys/megam_common.git) and [NSQ - golang by crackcom](https://github.com/crackcomm/nsqueue)\n\n##Installation\n\nThis is pretty quick for your local setup\n\n    $ wget https://s3.amazonaws.com/bitly-downloads/nsq/nsq-0.3.6.linux-amd64.go1.5.1.tar.gz\n    \n   \n**Untar the tarball into ~/bin folder**\nUpon untarring ensure that the ~/bin folder has all the files named *nsq_*\n\n**Start the following daemons**\n\n\t$ nsqlookupd &\n    \n    $ nsqd --lookupd-tcp-address=127.0.0.1:4160\n    \n    $ nsqadmin --lookupd-http-address=127.0.0.1:4161\n    \n    $ curl -d 'hello world 1' 'http://127.0.0.1:4151/put?topic=test'\n    \n**Watch topic 'test'**\n\n    $ nsq_to_tail --topic=test --lookupd-http-address=127.0.0.1:4161\n    \n**Dump topic 'test' in a file**\n\n    $ nsq_to_file --topic=test --output-dir=/tmp --lookupd-http-address=127.0.0.1:4161\n    \n##Running nsq in production\n\nDefinitely clustering and adding more `nsqds` becomes a need using a service discovery mechanism. \n\nWe have built packages to handle them `megamnsqd`.\n\nThe topology we will use is a service discovery daemon `nsqlookupd` clustered using mutiple `nsqd`\n\n##Machine 1\nDo the due deligence by adding [get.megam.io](http://get.megam.io) repo.\n\n     $ apt-get install megamnsqd\n     \nThere are two services  `nsqd` and `nslookupd` we will use.  \n\nAt the end of the install the **services are not running**.\n\n**A private ip shall be present in /var/lib/megam/env.sh named MEGAM_NSQLOOKUP_IP**\n\nAs you noticed from the above `nsqd` needs the `nsqlookupd's` ip addresss during clustering.\n\nStart the daemons\n\n\t$ service start nslookupd\n    \n    $ service start nsqd\n    \nAs a webui is optional, there is not upstart or systemd file for it.  \n\nYou can even run `nsqadmin` poiting to the `lookupd` address from  your local laptop.\n\n\n    $ nsqadmin --lookupd-http-address=<MACHINE1_IP:4161>\n    \nType [http://MACHINE1_IP:4171](http://MACHINE1_IP:4171) for the web ui.    \n\n    \n##Machine 2\nDo the due deligence by adding [get.megam.io](http://get.megam.io) repo.\n\n     $ apt-get install megamnsqd\n     \nWe will use only `nsqd` here\n\nAt the end of the install the **service isn't running** and needs manual start.\n\n**A private ip shall be present in /var/lib/megam/env.sh named MEGAM_NSQLOOKUP_IP**\n\nAs you noticed from the above `nsqd` needs the `nsqlookupd's` ip addresses during clustering.\n\n**Change the MEGAM_NSQLOOKUP_IP=MACHINE1_IP in /var/lib/megam/env.sh**\n\nStart the daemon\n\t\n    $ service start nsqd\n    \nAs a webui is optional, there is not upstart or systemd file for it. \n\n     \nType [http://MACHINE1_IP:4171](http://MACHINE1_IP:4171) for the web ui in your local machine.\n\nYou will see two machines in the UI. \n\nYou might see a line `ERR <number> IO Error EOF` in our  daemons `megamd` or `gulpd` then indicate that the readLoop in `go-nsq` detected an end of file, which can be safely ignored.\n\n## Redudant nslookupd\nThis is something the `infra team` can investigate to scale and avoid SPOF for the service discovery mechanism.\n\nThe performance is sweet and pretty good. \n\nThe moral of the story is language virtual machines are a legacy (Erlang, Java ...) and nimble native daemons can be a bold/better choice for performance and scalability.\n    \n\n\n\n\n     \n     \n    \n    \n    \n\n\n\n\n\n    \n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaism0011drgb8ov1qcvn","content":"<p><a href=\"https://nsdq.io\" target=\"_blank\" rel=\"external\">NSQd</a> A reatime distributed light weight messaging platform. </p>\n<p>We have used <a href=\"https://www.rabbitmq.com\" target=\"_blank\" rel=\"external\">RabbitMQ</a> heavily in clustered mode. Lately we have found issues with file description(fd) limit getting reached even after bumping the <code>ulimit</code> or closing sockets after publishing in the queue. </p>\n<p>We have tried single publisher to reuse socket connection but <a href=\"https://www.rabbitmq.com\" target=\"_blank\" rel=\"external\">RabbitMQ</a> hangs periodically.</p>\n<p>We set out to cleanup our code and hunt for a new pub sub guy.</p>\n<p>No wonder several players in the cloud market invent their own queue system, choices like <a href=\"http://nats.io/\" target=\"_blank\" rel=\"external\">nats</a> pioneered by <a href=\"https://www.apcera.com\" target=\"_blank\" rel=\"external\">apcera</a>, <a href=\"http://zeromq.org/\" target=\"_blank\" rel=\"external\">zeromq</a>, <a href=\"https://nsqio\" target=\"_blank\" rel=\"external\">nsq.io</a> by <a href=\"https://bit.ly\" target=\"_blank\" rel=\"external\">bit.ly</a></p>\n<p>We choose <a href=\"nsq.io\">nsq</a> for it distributed realtime platform with no single point of failure (SPOF), it has its own service discovery mechanism and its written in <a href=\"https://golang.org\" target=\"_blank\" rel=\"external\">golang</a>, has drivers for every language. </p>\n<p>We wrote our own wrappers for <a href=\"https://github.com/megamsys/megam_common.git\" target=\"_blank\" rel=\"external\">NSQ - scala</a> and <a href=\"https://github.com/crackcomm/nsqueue\" target=\"_blank\" rel=\"external\">NSQ - golang by crackcom</a></p>\n<p>##Installation</p>\n<p>This is pretty quick for your local setup</p>\n<pre><code>$ wget https://s3.amazonaws.com/bitly-downloads/nsq/nsq-0.3.6.linux-amd64.go1.5.1.tar.gz\n</code></pre><p><strong>Untar the tarball into ~/bin folder</strong><br>Upon untarring ensure that the ~/bin folder has all the files named <em>nsq_</em></p>\n<p><strong>Start the following daemons</strong></p>\n<pre><code>$ nsqlookupd &amp;\n\n$ nsqd --lookupd-tcp-address=127.0.0.1:4160\n\n$ nsqadmin --lookupd-http-address=127.0.0.1:4161\n\n$ curl -d &apos;hello world 1&apos; &apos;http://127.0.0.1:4151/put?topic=test&apos;\n</code></pre><p><strong>Watch topic test</strong></p>\n<pre><code>$ nsq_to_tail --topic=test --lookupd-http-address=127.0.0.1:4161\n</code></pre><p><strong>Dump topic test in a file</strong></p>\n<pre><code>$ nsq_to_file --topic=test --output-dir=/tmp --lookupd-http-address=127.0.0.1:4161\n</code></pre><p>##Running nsq in production</p>\n<p>Definitely clustering and adding more <code>nsqds</code> becomes a need using a service discovery mechanism. </p>\n<p>We have built packages to handle them <code>megamnsqd</code>.</p>\n<p>The topology we will use is a service discovery daemon <code>nsqlookupd</code> clustered using mutiple <code>nsqd</code></p>\n<p>##Machine 1<br>Do the due deligence by adding <a href=\"http://get.megam.io\" target=\"_blank\" rel=\"external\">get.megam.io</a> repo.</p>\n<pre><code>$ apt-get install megamnsqd\n</code></pre><p>There are two services  <code>nsqd</code> and <code>nslookupd</code> we will use.  </p>\n<p>At the end of the install the <strong>services are not running</strong>.</p>\n<p><strong>A private ip shall be present in /var/lib/megam/env.sh named MEGAM_NSQLOOKUP_IP</strong></p>\n<p>As you noticed from the above <code>nsqd</code> needs the <code>nsqlookupd&#39;s</code> ip addresss during clustering.</p>\n<p>Start the daemons</p>\n<pre><code>$ service start nslookupd\n\n$ service start nsqd\n</code></pre><p>As a webui is optional, there is not upstart or systemd file for it.  </p>\n<p>You can even run <code>nsqadmin</code> poiting to the <code>lookupd</code> address from  your local laptop.</p>\n<pre><code>$ nsqadmin --lookupd-http-address=&lt;MACHINE1_IP:4161&gt;\n</code></pre><p>Type <a href=\"http://MACHINE1_IP:4171\" target=\"_blank\" rel=\"external\">http://MACHINE1_IP:4171</a> for the web ui.    </p>\n<p>##Machine 2<br>Do the due deligence by adding <a href=\"http://get.megam.io\" target=\"_blank\" rel=\"external\">get.megam.io</a> repo.</p>\n<pre><code>$ apt-get install megamnsqd\n</code></pre><p>We will use only <code>nsqd</code> here</p>\n<p>At the end of the install the <strong>service isnt running</strong> and needs manual start.</p>\n<p><strong>A private ip shall be present in /var/lib/megam/env.sh named MEGAM_NSQLOOKUP_IP</strong></p>\n<p>As you noticed from the above <code>nsqd</code> needs the <code>nsqlookupd&#39;s</code> ip addresses during clustering.</p>\n<p><strong>Change the MEGAM_NSQLOOKUP_IP=MACHINE1_IP in /var/lib/megam/env.sh</strong></p>\n<p>Start the daemon</p>\n<pre><code>$ service start nsqd\n</code></pre><p>As a webui is optional, there is not upstart or systemd file for it. </p>\n<p>Type <a href=\"http://MACHINE1_IP:4171\" target=\"_blank\" rel=\"external\">http://MACHINE1_IP:4171</a> for the web ui in your local machine.</p>\n<p>You will see two machines in the UI. </p>\n<p>You might see a line <code>ERR &lt;number&gt; IO Error EOF</code> in our  daemons <code>megamd</code> or <code>gulpd</code> then indicate that the readLoop in <code>go-nsq</code> detected an end of file, which can be safely ignored.</p>\n<h2 id=\"Redudant-nslookupd\"><a href=\"#Redudant-nslookupd\" class=\"headerlink\" title=\"Redudant nslookupd\"></a>Redudant nslookupd</h2><p>This is something the <code>infra team</code> can investigate to scale and avoid SPOF for the service discovery mechanism.</p>\n<p>The performance is sweet and pretty good. </p>\n<p>The moral of the story is language virtual machines are a legacy (Erlang, Java ) and nimble native daemons can be a bold/better choice for performance and scalability.</p>\n","excerpt":"","more":"<p><a href=\"https://nsdq.io\">NSQd</a> A reatime distributed light weight messaging platform. </p>\n<p>We have used <a href=\"https://www.rabbitmq.com\">RabbitMQ</a> heavily in clustered mode. Lately we have found issues with file description(fd) limit getting reached even after bumping the <code>ulimit</code> or closing sockets after publishing in the queue. </p>\n<p>We have tried single publisher to reuse socket connection but <a href=\"https://www.rabbitmq.com\">RabbitMQ</a> hangs periodically.</p>\n<p>We set out to cleanup our code and hunt for a new pub sub guy.</p>\n<p>No wonder several players in the cloud market invent their own queue system, choices like <a href=\"http://nats.io/\">nats</a> pioneered by <a href=\"https://www.apcera.com\">apcera</a>, <a href=\"http://zeromq.org/\">zeromq</a>, <a href=\"https://nsqio\">nsq.io</a> by <a href=\"https://bit.ly\">bit.ly</a></p>\n<p>We choose <a href=\"nsq.io\">nsq</a> for it distributed realtime platform with no single point of failure (SPOF), it has its own service discovery mechanism and its written in <a href=\"https://golang.org\">golang</a>, has drivers for every language. </p>\n<p>We wrote our own wrappers for <a href=\"https://github.com/megamsys/megam_common.git\">NSQ - scala</a> and <a href=\"https://github.com/crackcomm/nsqueue\">NSQ - golang by crackcom</a></p>\n<p>##Installation</p>\n<p>This is pretty quick for your local setup</p>\n<pre><code>$ wget https://s3.amazonaws.com/bitly-downloads/nsq/nsq-0.3.6.linux-amd64.go1.5.1.tar.gz\n</code></pre><p><strong>Untar the tarball into ~/bin folder</strong><br>Upon untarring ensure that the ~/bin folder has all the files named <em>nsq_</em></p>\n<p><strong>Start the following daemons</strong></p>\n<pre><code>$ nsqlookupd &amp;\n\n$ nsqd --lookupd-tcp-address=127.0.0.1:4160\n\n$ nsqadmin --lookupd-http-address=127.0.0.1:4161\n\n$ curl -d &apos;hello world 1&apos; &apos;http://127.0.0.1:4151/put?topic=test&apos;\n</code></pre><p><strong>Watch topic test</strong></p>\n<pre><code>$ nsq_to_tail --topic=test --lookupd-http-address=127.0.0.1:4161\n</code></pre><p><strong>Dump topic test in a file</strong></p>\n<pre><code>$ nsq_to_file --topic=test --output-dir=/tmp --lookupd-http-address=127.0.0.1:4161\n</code></pre><p>##Running nsq in production</p>\n<p>Definitely clustering and adding more <code>nsqds</code> becomes a need using a service discovery mechanism. </p>\n<p>We have built packages to handle them <code>megamnsqd</code>.</p>\n<p>The topology we will use is a service discovery daemon <code>nsqlookupd</code> clustered using mutiple <code>nsqd</code></p>\n<p>##Machine 1<br>Do the due deligence by adding <a href=\"http://get.megam.io\">get.megam.io</a> repo.</p>\n<pre><code>$ apt-get install megamnsqd\n</code></pre><p>There are two services  <code>nsqd</code> and <code>nslookupd</code> we will use.  </p>\n<p>At the end of the install the <strong>services are not running</strong>.</p>\n<p><strong>A private ip shall be present in /var/lib/megam/env.sh named MEGAM_NSQLOOKUP_IP</strong></p>\n<p>As you noticed from the above <code>nsqd</code> needs the <code>nsqlookupd&#39;s</code> ip addresss during clustering.</p>\n<p>Start the daemons</p>\n<pre><code>$ service start nslookupd\n\n$ service start nsqd\n</code></pre><p>As a webui is optional, there is not upstart or systemd file for it.  </p>\n<p>You can even run <code>nsqadmin</code> poiting to the <code>lookupd</code> address from  your local laptop.</p>\n<pre><code>$ nsqadmin --lookupd-http-address=&lt;MACHINE1_IP:4161&gt;\n</code></pre><p>Type <a href=\"http://MACHINE1_IP:4171\">http://MACHINE1_IP:4171</a> for the web ui.    </p>\n<p>##Machine 2<br>Do the due deligence by adding <a href=\"http://get.megam.io\">get.megam.io</a> repo.</p>\n<pre><code>$ apt-get install megamnsqd\n</code></pre><p>We will use only <code>nsqd</code> here</p>\n<p>At the end of the install the <strong>service isnt running</strong> and needs manual start.</p>\n<p><strong>A private ip shall be present in /var/lib/megam/env.sh named MEGAM_NSQLOOKUP_IP</strong></p>\n<p>As you noticed from the above <code>nsqd</code> needs the <code>nsqlookupd&#39;s</code> ip addresses during clustering.</p>\n<p><strong>Change the MEGAM_NSQLOOKUP_IP=MACHINE1_IP in /var/lib/megam/env.sh</strong></p>\n<p>Start the daemon</p>\n<pre><code>$ service start nsqd\n</code></pre><p>As a webui is optional, there is not upstart or systemd file for it. </p>\n<p>Type <a href=\"http://MACHINE1_IP:4171\">http://MACHINE1_IP:4171</a> for the web ui in your local machine.</p>\n<p>You will see two machines in the UI. </p>\n<p>You might see a line <code>ERR &lt;number&gt; IO Error EOF</code> in our  daemons <code>megamd</code> or <code>gulpd</code> then indicate that the readLoop in <code>go-nsq</code> detected an end of file, which can be safely ignored.</p>\n<h2 id=\"Redudant-nslookupd\"><a href=\"#Redudant-nslookupd\" class=\"headerlink\" title=\"Redudant nslookupd\"></a>Redudant nslookupd</h2><p>This is something the <code>infra team</code> can investigate to scale and avoid SPOF for the service discovery mechanism.</p>\n<p>The performance is sweet and pretty good. </p>\n<p>The moral of the story is language virtual machines are a legacy (Erlang, Java ) and nimble native daemons can be a bold/better choice for performance and scalability.</p>\n"},{"title":"Getting started with spark-jobserver","slug":"2016-02-02-getting-started-with-spark-jobserver","date_published":"2016-02-02T01:00:01.719Z","date_updated":"2016-02-02T01:09:23.602Z","_content":"\n[Spark-jobserver](https://github.com/spark-jobserver/spark-jobserver) is a really cool RESTful interface for submitting and managing Apache Spark jobs, jars, and job contexts. At [megam](http://www.megam.io) our analytics platform [Meglytics](http://www.meglytics.com) is powered by apache spark and we leverage spark-jobserver to execute spark jobs. This blog post we will see how to get started with apache spark jobserver. Before we go ahead, a big thanks to the Ooyala folks for making the spark-jobserver opensource.\nLets get started.\n\n***Note: Make sure you have spark installed locally***\n\n###1. Running spark-jobserver\nFor sanity check...\n     \n     $sudo apt-get update\n     \n     \n Now clone the [spark-jobserver] project \n      \n      $git clone https://github.com/spark-jobserver/spark-jobserver\n      \n To run it, \n  \n      $export VER=`sbt version | tail -1 | cut -f2`\n      >reStart\n     \n Your dev setup is done, fire up your browser and point it to `localhost:8090` and you can see a not-so-quagmire kinda UI.\n\n*Note: For proper deployment you can find the conf and scripts [here](https://github.com/spark-jobserver/spark-jobserver/tree/master/job-server/config)*\n\n###2. Building and deploying a jar:\n\nThe fundamental steps in setting up and working in SJS is that, \n\n* First build jar(like duh!) with your sparkContext(s) and you push it to SJS where your spark Master is also running(in our case, it is local).\n\n* Then run the jar by providing the **classPath** and the **name** of the jar. \n\nLet us look at the simple wordCount example for now to get all the missing pieces together.\n\ncd into spark-jobserver and run this,\n\n    sbt job-server-tests/package\n    \n They are examples that you can find [here](https://github.com/spark-jobserver/spark-jobserver/tree/master/job-server-tests/src/spark.jobserver). Now your wordcount example is built. Lets push the jar to SJS `/jar` API\n \n     curl --data-binary @job-server-tests/target/scala-2.10/job-server-tests.jar localhost:8090/jars/firsttest\n\n###3. Submitting a job:\n\nLets run it and get the output,\n\n    curl -d \"input.string = a b c a b see\" 'localhost:8090/jobs?appName=test&classPath=spark.jobserver.WordCountExample'\n\nWe send a request to `/jobs` api with the `appName` and `classPath`. Upon every job submission SJS gives you an jobID `    \"jobId\": \"5453779a-f004-45fc-a11d-a39dae0f9bf4\"`\n\n###4. Getting the status of the job:\n\nCall the `/jobs` api with the key to get the status/result and also the duration of your job.\nAlso, fire up the spark master UI to see the job getting exectuted. \n\n    curl localhost:8090/jobs/5453779a-f004-45fc-a11d-a39dae0f9bf4\n    \nSJS is a really nice project which makes a ton easy to work with apache spark and the production cases looks promising aswell. There is also a gitter chat room where all the SJS folks hang out and solve any kind of queries.\n\n\nThats it for now. If I find time I will write about spark-jobserver in production and using sqlContext and dataframes with spark-jobserver.  Any questions regarding spark-jobserver comment below or shoot me an email.\n\n\n\n\n     \n     \n","source":"_posts/2016-02-02-getting-started-with-spark-jobserver.md","raw":"---\ntitle: Getting started with spark-jobserver\nslug: getting-started-with-spark-jobserver\ndate_published: 2016-02-02T06:30:01.719Z\ndate_updated:   2016-02-02T06:39:23.602Z\n---\n\n[Spark-jobserver](https://github.com/spark-jobserver/spark-jobserver) is a really cool RESTful interface for submitting and managing Apache Spark jobs, jars, and job contexts. At [megam](http://www.megam.io) our analytics platform [Meglytics](http://www.meglytics.com) is powered by apache spark and we leverage spark-jobserver to execute spark jobs. This blog post we will see how to get started with apache spark jobserver. Before we go ahead, a big thanks to the Ooyala folks for making the spark-jobserver opensource.\nLets get started.\n\n***Note: Make sure you have spark installed locally***\n\n###1. Running spark-jobserver\nFor sanity check...\n     \n     $sudo apt-get update\n     \n     \n Now clone the [spark-jobserver] project \n      \n      $git clone https://github.com/spark-jobserver/spark-jobserver\n      \n To run it, \n  \n      $export VER=`sbt version | tail -1 | cut -f2`\n      >reStart\n     \n Your dev setup is done, fire up your browser and point it to `localhost:8090` and you can see a not-so-quagmire kinda UI.\n\n*Note: For proper deployment you can find the conf and scripts [here](https://github.com/spark-jobserver/spark-jobserver/tree/master/job-server/config)*\n\n###2. Building and deploying a jar:\n\nThe fundamental steps in setting up and working in SJS is that, \n\n* First build jar(like duh!) with your sparkContext(s) and you push it to SJS where your spark Master is also running(in our case, it is local).\n\n* Then run the jar by providing the **classPath** and the **name** of the jar. \n\nLet us look at the simple wordCount example for now to get all the missing pieces together.\n\ncd into spark-jobserver and run this,\n\n    sbt job-server-tests/package\n    \n They are examples that you can find [here](https://github.com/spark-jobserver/spark-jobserver/tree/master/job-server-tests/src/spark.jobserver). Now your wordcount example is built. Lets push the jar to SJS `/jar` API\n \n     curl --data-binary @job-server-tests/target/scala-2.10/job-server-tests.jar localhost:8090/jars/firsttest\n\n###3. Submitting a job:\n\nLets run it and get the output,\n\n    curl -d \"input.string = a b c a b see\" 'localhost:8090/jobs?appName=test&classPath=spark.jobserver.WordCountExample'\n\nWe send a request to `/jobs` api with the `appName` and `classPath`. Upon every job submission SJS gives you an jobID `    \"jobId\": \"5453779a-f004-45fc-a11d-a39dae0f9bf4\"`\n\n###4. Getting the status of the job:\n\nCall the `/jobs` api with the key to get the status/result and also the duration of your job.\nAlso, fire up the spark master UI to see the job getting exectuted. \n\n    curl localhost:8090/jobs/5453779a-f004-45fc-a11d-a39dae0f9bf4\n    \nSJS is a really nice project which makes a ton easy to work with apache spark and the production cases looks promising aswell. There is also a gitter chat room where all the SJS folks hang out and solve any kind of queries.\n\n\nThats it for now. If I find time I will write about spark-jobserver in production and using sqlContext and dataframes with spark-jobserver.  Any questions regarding spark-jobserver comment below or shoot me an email.\n\n\n\n\n     \n     \n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaisn0012drgbyqpnc6ig","content":"<p><a href=\"https://github.com/spark-jobserver/spark-jobserver\" target=\"_blank\" rel=\"external\">Spark-jobserver</a> is a really cool RESTful interface for submitting and managing Apache Spark jobs, jars, and job contexts. At <a href=\"http://www.megam.io\">megam</a> our analytics platform <a href=\"http://www.meglytics.com\" target=\"_blank\" rel=\"external\">Meglytics</a> is powered by apache spark and we leverage spark-jobserver to execute spark jobs. This blog post we will see how to get started with apache spark jobserver. Before we go ahead, a big thanks to the Ooyala folks for making the spark-jobserver opensource.<br>Lets get started.</p>\n<p><strong><em>Note: Make sure you have spark installed locally</em></strong></p>\n<p>###1. Running spark-jobserver<br>For sanity check</p>\n<pre><code>$sudo apt-get update\n</code></pre><p> Now clone the [spark-jobserver] project </p>\n<pre><code>$git clone https://github.com/spark-jobserver/spark-jobserver\n</code></pre><p> To run it, </p>\n<pre><code>$export VER=`sbt version | tail -1 | cut -f2`\n&gt;reStart\n</code></pre><p> Your dev setup is done, fire up your browser and point it to <code>localhost:8090</code> and you can see a not-so-quagmire kinda UI.</p>\n<p><em>Note: For proper deployment you can find the conf and scripts <a href=\"https://github.com/spark-jobserver/spark-jobserver/tree/master/job-server/config\" target=\"_blank\" rel=\"external\">here</a></em></p>\n<p>###2. Building and deploying a jar:</p>\n<p>The fundamental steps in setting up and working in SJS is that, </p>\n<ul>\n<li><p>First build jar(like duh!) with your sparkContext(s) and you push it to SJS where your spark Master is also running(in our case, it is local).</p>\n</li>\n<li><p>Then run the jar by providing the <strong>classPath</strong> and the <strong>name</strong> of the jar. </p>\n</li>\n</ul>\n<p>Let us look at the simple wordCount example for now to get all the missing pieces together.</p>\n<p>cd into spark-jobserver and run this,</p>\n<pre><code>sbt job-server-tests/package\n</code></pre><p> They are examples that you can find <a href=\"https://github.com/spark-jobserver/spark-jobserver/tree/master/job-server-tests/src/spark.jobserver\" target=\"_blank\" rel=\"external\">here</a>. Now your wordcount example is built. Lets push the jar to SJS <code>/jar</code> API</p>\n<pre><code>curl --data-binary @job-server-tests/target/scala-2.10/job-server-tests.jar localhost:8090/jars/firsttest\n</code></pre><p>###3. Submitting a job:</p>\n<p>Lets run it and get the output,</p>\n<pre><code>curl -d &quot;input.string = a b c a b see&quot; &apos;localhost:8090/jobs?appName=test&amp;classPath=spark.jobserver.WordCountExample&apos;\n</code></pre><p>We send a request to <code>/jobs</code> api with the <code>appName</code> and <code>classPath</code>. Upon every job submission SJS gives you an jobID <code>&quot;jobId&quot;: &quot;5453779a-f004-45fc-a11d-a39dae0f9bf4&quot;</code></p>\n<p>###4. Getting the status of the job:</p>\n<p>Call the <code>/jobs</code> api with the key to get the status/result and also the duration of your job.<br>Also, fire up the spark master UI to see the job getting exectuted. </p>\n<pre><code>curl localhost:8090/jobs/5453779a-f004-45fc-a11d-a39dae0f9bf4\n</code></pre><p>SJS is a really nice project which makes a ton easy to work with apache spark and the production cases looks promising aswell. There is also a gitter chat room where all the SJS folks hang out and solve any kind of queries.</p>\n<p>Thats it for now. If I find time I will write about spark-jobserver in production and using sqlContext and dataframes with spark-jobserver.  Any questions regarding spark-jobserver comment below or shoot me an email.</p>\n","excerpt":"","more":"<p><a href=\"https://github.com/spark-jobserver/spark-jobserver\">Spark-jobserver</a> is a really cool RESTful interface for submitting and managing Apache Spark jobs, jars, and job contexts. At <a href=\"http://www.megam.io\">megam</a> our analytics platform <a href=\"http://www.meglytics.com\">Meglytics</a> is powered by apache spark and we leverage spark-jobserver to execute spark jobs. This blog post we will see how to get started with apache spark jobserver. Before we go ahead, a big thanks to the Ooyala folks for making the spark-jobserver opensource.<br>Lets get started.</p>\n<p><strong><em>Note: Make sure you have spark installed locally</em></strong></p>\n<p>###1. Running spark-jobserver<br>For sanity check</p>\n<pre><code>$sudo apt-get update\n</code></pre><p> Now clone the [spark-jobserver] project </p>\n<pre><code>$git clone https://github.com/spark-jobserver/spark-jobserver\n</code></pre><p> To run it, </p>\n<pre><code>$export VER=`sbt version | tail -1 | cut -f2`\n&gt;reStart\n</code></pre><p> Your dev setup is done, fire up your browser and point it to <code>localhost:8090</code> and you can see a not-so-quagmire kinda UI.</p>\n<p><em>Note: For proper deployment you can find the conf and scripts <a href=\"https://github.com/spark-jobserver/spark-jobserver/tree/master/job-server/config\">here</a></em></p>\n<p>###2. Building and deploying a jar:</p>\n<p>The fundamental steps in setting up and working in SJS is that, </p>\n<ul>\n<li><p>First build jar(like duh!) with your sparkContext(s) and you push it to SJS where your spark Master is also running(in our case, it is local).</p>\n</li>\n<li><p>Then run the jar by providing the <strong>classPath</strong> and the <strong>name</strong> of the jar. </p>\n</li>\n</ul>\n<p>Let us look at the simple wordCount example for now to get all the missing pieces together.</p>\n<p>cd into spark-jobserver and run this,</p>\n<pre><code>sbt job-server-tests/package\n</code></pre><p> They are examples that you can find <a href=\"https://github.com/spark-jobserver/spark-jobserver/tree/master/job-server-tests/src/spark.jobserver\">here</a>. Now your wordcount example is built. Lets push the jar to SJS <code>/jar</code> API</p>\n<pre><code>curl --data-binary @job-server-tests/target/scala-2.10/job-server-tests.jar localhost:8090/jars/firsttest\n</code></pre><p>###3. Submitting a job:</p>\n<p>Lets run it and get the output,</p>\n<pre><code>curl -d &quot;input.string = a b c a b see&quot; &apos;localhost:8090/jobs?appName=test&amp;classPath=spark.jobserver.WordCountExample&apos;\n</code></pre><p>We send a request to <code>/jobs</code> api with the <code>appName</code> and <code>classPath</code>. Upon every job submission SJS gives you an jobID <code>&quot;jobId&quot;: &quot;5453779a-f004-45fc-a11d-a39dae0f9bf4&quot;</code></p>\n<p>###4. Getting the status of the job:</p>\n<p>Call the <code>/jobs</code> api with the key to get the status/result and also the duration of your job.<br>Also, fire up the spark master UI to see the job getting exectuted. </p>\n<pre><code>curl localhost:8090/jobs/5453779a-f004-45fc-a11d-a39dae0f9bf4\n</code></pre><p>SJS is a really nice project which makes a ton easy to work with apache spark and the production cases looks promising aswell. There is also a gitter chat room where all the SJS folks hang out and solve any kind of queries.</p>\n<p>Thats it for now. If I find time I will write about spark-jobserver in production and using sqlContext and dataframes with spark-jobserver.  Any questions regarding spark-jobserver comment below or shoot me an email.</p>\n"},{"title":"Build and release management for go(godep)","slug":"2016-02-05-build-and-release-management-for-gogodep","date_published":"2016-02-05T00:21:16.879Z","date_updated":"2016-02-05T00:21:16.877Z","_content":"\n##Introduction\nIf you are using 3rd party packages, (packages that you don't own or control), you will want a way to create a reproducible build every time you build your projects. If you use 3rd party packages directly and the package authors change things, your projects could break. Even if things don't break, code changes could create inconsistent behavior and bugs.\n\n>**godep tool is a great step in the right direction for managing 3rd party dependencies and creating reproducible builds.**\n\n####Downloading Godep\nDownload godep using go get and make sure your $GOPATH/bin directory is in your PATH.\n\n\tgo get github.com/tools/godep\n\texport PATH=$PATH:$GOPATH/bin\n    \n####How Godep Works\nA **godep save** command will copy all imported packages in their entirety from your current **GOPATH** into a vendored workspace folder in **./Godeps/_workspace**. A list of those packages will be stored with relevant version information in a master file, **Godeps/Godeps.json**. This is done not just for the packages your project directly imports but also for any imported by your dependencies.\n\nUsing Godep is as simple as prepending your normal Go commands like go test or go build with the godep command. This uses a temporarily extended **GOPATH** which prioritizes the Godep vendor directory.\n\n>saves your GOPATH to the Godep folder \n>\n\t$ godep save ./  \n\n>builds using the Godep vendored dependencies\n>\n\t$ godep go build ./   \n\n>tests using the Godep vendored dependencies\n>\n\t$ godep go test ./\n\n\nFrom here, should you apply a change to your **GOPATH**, your project will be isolated.\n\n>update a dependency\n>\n\tgo get -u github.com/golang/protobuf/\n   \n>build using standard GOPATH\n>\n\t$ go build ./                         \n\n>build using Godep vendored version\n>\n\t$ godep go build ./     \n    \n    \n####godep update versus godep save\n**godep update** takes a specific dependency package and updates the vendored instance of that package with the version in your **GOPATH**. This will update files with changes, add new files, remove old ones, and update the version SHA listed in the **Godeps.json** file.\n\n\t$ go get -u github.com/golang/protobuf/\n\t$ godep update github.com/golang/protobuf/\n    \nThis will not add or remove sub-packages from dependency management, nor will it update any other dependencies recursively. Only previously imported packages are listed in the **Godeps.json** file and only those listed are updated.\n\nUpdating the entire package will update any references to sub-packages; however no new packages will be added, nor old ones removed. Similarly, if your dependency update is dependent upon another change elsewhere in your dependency stack, you may run into issues. **godep update** only touches the packages listed in Godeps.json, which match the provided package pattern.\n\nIn contrast, **godep save** applies the entire relevant GOPATH to the Godeps folder and will add/remove packages as needed. Because its based off of your **GOPATH, godep save** can also check for build errors and non-clean repositories before applying changes, enforcing dependency cohesion.\n\nGiven the dangers of using **godep update** (missing packages and dependencies), its much safer to use **godep save**. The only situation where its safe to use godep update are when both of these conditions are satisfied:\n\n>No dependencies of your target dependency need to be updated.\n\n>No imports were added to or removed from your target dependency.\n\nIf the dependency is external to your organization, it can be difficult to determine what changes are taking place, so it is safer to never use **godep update** on anything third-party.\n\n####When to Use Godep\nNot every project may require the broad dependency control as provided by Godep.\n\nUnlike import path-based vendoring, Godep vendors the entire set of dependencies regardless of a specific desire to version them. This does mean that no dependencies will ever be updated unless explicitly altered, first through **GOPATH** and then through Godep.\n\nShould your organization have a large number of common dependencies across different projects, you may want to look into using a forked dependency model. Godep provides a locally controlled, customizable dependency management system. When used with care, this system can support highly versioned and reproducible builds, especially in change resistive environments with few shared dependencies.\n\n\n","source":"_posts/2016-02-05-build-and-release-management-for-gogodep.md","raw":"---\ntitle: Build and release management for go(godep)\nslug: build-and-release-management-for-gogodep\ndate_published: 2016-02-05T05:51:16.879Z\ndate_updated:   2016-02-05T05:51:16.877Z\n---\n\n##Introduction\nIf you are using 3rd party packages, (packages that you don't own or control), you will want a way to create a reproducible build every time you build your projects. If you use 3rd party packages directly and the package authors change things, your projects could break. Even if things don't break, code changes could create inconsistent behavior and bugs.\n\n>**godep tool is a great step in the right direction for managing 3rd party dependencies and creating reproducible builds.**\n\n####Downloading Godep\nDownload godep using go get and make sure your $GOPATH/bin directory is in your PATH.\n\n\tgo get github.com/tools/godep\n\texport PATH=$PATH:$GOPATH/bin\n    \n####How Godep Works\nA **godep save** command will copy all imported packages in their entirety from your current **GOPATH** into a vendored workspace folder in **./Godeps/_workspace**. A list of those packages will be stored with relevant version information in a master file, **Godeps/Godeps.json**. This is done not just for the packages your project directly imports but also for any imported by your dependencies.\n\nUsing Godep is as simple as prepending your normal Go commands like go test or go build with the godep command. This uses a temporarily extended **GOPATH** which prioritizes the Godep vendor directory.\n\n>saves your GOPATH to the Godep folder \n>\n\t$ godep save ./  \n\n>builds using the Godep vendored dependencies\n>\n\t$ godep go build ./   \n\n>tests using the Godep vendored dependencies\n>\n\t$ godep go test ./\n\n\nFrom here, should you apply a change to your **GOPATH**, your project will be isolated.\n\n>update a dependency\n>\n\tgo get -u github.com/golang/protobuf/\n   \n>build using standard GOPATH\n>\n\t$ go build ./                         \n\n>build using Godep vendored version\n>\n\t$ godep go build ./     \n    \n    \n####godep update versus godep save\n**godep update** takes a specific dependency package and updates the vendored instance of that package with the version in your **GOPATH**. This will update files with changes, add new files, remove old ones, and update the version SHA listed in the **Godeps.json** file.\n\n\t$ go get -u github.com/golang/protobuf/\n\t$ godep update github.com/golang/protobuf/\n    \nThis will not add or remove sub-packages from dependency management, nor will it update any other dependencies recursively. Only previously imported packages are listed in the **Godeps.json** file and only those listed are updated.\n\nUpdating the entire package will update any references to sub-packages; however no new packages will be added, nor old ones removed. Similarly, if your dependency update is dependent upon another change elsewhere in your dependency stack, you may run into issues. **godep update** only touches the packages listed in Godeps.json, which match the provided package pattern.\n\nIn contrast, **godep save** applies the entire relevant GOPATH to the Godeps folder and will add/remove packages as needed. Because its based off of your **GOPATH, godep save** can also check for build errors and non-clean repositories before applying changes, enforcing dependency cohesion.\n\nGiven the dangers of using **godep update** (missing packages and dependencies), its much safer to use **godep save**. The only situation where its safe to use godep update are when both of these conditions are satisfied:\n\n>No dependencies of your target dependency need to be updated.\n\n>No imports were added to or removed from your target dependency.\n\nIf the dependency is external to your organization, it can be difficult to determine what changes are taking place, so it is safer to never use **godep update** on anything third-party.\n\n####When to Use Godep\nNot every project may require the broad dependency control as provided by Godep.\n\nUnlike import path-based vendoring, Godep vendors the entire set of dependencies regardless of a specific desire to version them. This does mean that no dependencies will ever be updated unless explicitly altered, first through **GOPATH** and then through Godep.\n\nShould your organization have a large number of common dependencies across different projects, you may want to look into using a forked dependency model. Godep provides a locally controlled, customizable dependency management system. When used with care, this system can support highly versioned and reproducible builds, especially in change resistive environments with few shared dependencies.\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaiso0013drgb50p1kl4a","content":"<p>##Introduction<br>If you are using 3rd party packages, (packages that you dont own or control), you will want a way to create a reproducible build every time you build your projects. If you use 3rd party packages directly and the package authors change things, your projects could break. Even if things dont break, code changes could create inconsistent behavior and bugs.</p>\n<blockquote>\n<p><strong>godep tool is a great step in the right direction for managing 3rd party dependencies and creating reproducible builds.</strong></p>\n</blockquote>\n<p>####Downloading Godep<br>Download godep using go get and make sure your $GOPATH/bin directory is in your PATH.</p>\n<pre><code>go get github.com/tools/godep\nexport PATH=$PATH:$GOPATH/bin\n</code></pre><p>####How Godep Works<br>A <strong>godep save</strong> command will copy all imported packages in their entirety from your current <strong>GOPATH</strong> into a vendored workspace folder in <strong>./Godeps/_workspace</strong>. A list of those packages will be stored with relevant version information in a master file, <strong>Godeps/Godeps.json</strong>. This is done not just for the packages your project directly imports but also for any imported by your dependencies.</p>\n<p>Using Godep is as simple as prepending your normal Go commands like go test or go build with the godep command. This uses a temporarily extended <strong>GOPATH</strong> which prioritizes the Godep vendor directory.</p>\n<blockquote>\n<p>saves your GOPATH to the Godep folder </p>\n<pre><code>$ godep save ./  \n</code></pre><p>builds using the Godep vendored dependencies</p>\n<pre><code>$ godep go build ./   \n</code></pre><p>tests using the Godep vendored dependencies</p>\n<pre><code>$ godep go test ./\n</code></pre></blockquote>\n<p>From here, should you apply a change to your <strong>GOPATH</strong>, your project will be isolated.</p>\n<blockquote>\n<p>update a dependency</p>\n<pre><code>go get -u github.com/golang/protobuf/\n</code></pre><p>build using standard GOPATH</p>\n<pre><code>$ go build ./                         \n</code></pre><p>build using Godep vendored version</p>\n<pre><code>$ godep go build ./     \n</code></pre></blockquote>\n<p>####godep update versus godep save<br><strong>godep update</strong> takes a specific dependency package and updates the vendored instance of that package with the version in your <strong>GOPATH</strong>. This will update files with changes, add new files, remove old ones, and update the version SHA listed in the <strong>Godeps.json</strong> file.</p>\n<pre><code>$ go get -u github.com/golang/protobuf/\n$ godep update github.com/golang/protobuf/\n</code></pre><p>This will not add or remove sub-packages from dependency management, nor will it update any other dependencies recursively. Only previously imported packages are listed in the <strong>Godeps.json</strong> file and only those listed are updated.</p>\n<p>Updating the entire package will update any references to sub-packages; however no new packages will be added, nor old ones removed. Similarly, if your dependency update is dependent upon another change elsewhere in your dependency stack, you may run into issues. <strong>godep update</strong> only touches the packages listed in Godeps.json, which match the provided package pattern.</p>\n<p>In contrast, <strong>godep save</strong> applies the entire relevant GOPATH to the Godeps folder and will add/remove packages as needed. Because its based off of your <strong>GOPATH, godep save</strong> can also check for build errors and non-clean repositories before applying changes, enforcing dependency cohesion.</p>\n<p>Given the dangers of using <strong>godep update</strong> (missing packages and dependencies), its much safer to use <strong>godep save</strong>. The only situation where its safe to use godep update are when both of these conditions are satisfied:</p>\n<blockquote>\n<p>No dependencies of your target dependency need to be updated.</p>\n<p>No imports were added to or removed from your target dependency.</p>\n</blockquote>\n<p>If the dependency is external to your organization, it can be difficult to determine what changes are taking place, so it is safer to never use <strong>godep update</strong> on anything third-party.</p>\n<p>####When to Use Godep<br>Not every project may require the broad dependency control as provided by Godep.</p>\n<p>Unlike import path-based vendoring, Godep vendors the entire set of dependencies regardless of a specific desire to version them. This does mean that no dependencies will ever be updated unless explicitly altered, first through <strong>GOPATH</strong> and then through Godep.</p>\n<p>Should your organization have a large number of common dependencies across different projects, you may want to look into using a forked dependency model. Godep provides a locally controlled, customizable dependency management system. When used with care, this system can support highly versioned and reproducible builds, especially in change resistive environments with few shared dependencies.</p>\n","excerpt":"","more":"<p>##Introduction<br>If you are using 3rd party packages, (packages that you dont own or control), you will want a way to create a reproducible build every time you build your projects. If you use 3rd party packages directly and the package authors change things, your projects could break. Even if things dont break, code changes could create inconsistent behavior and bugs.</p>\n<blockquote>\n<p><strong>godep tool is a great step in the right direction for managing 3rd party dependencies and creating reproducible builds.</strong></p>\n</blockquote>\n<p>####Downloading Godep<br>Download godep using go get and make sure your $GOPATH/bin directory is in your PATH.</p>\n<pre><code>go get github.com/tools/godep\nexport PATH=$PATH:$GOPATH/bin\n</code></pre><p>####How Godep Works<br>A <strong>godep save</strong> command will copy all imported packages in their entirety from your current <strong>GOPATH</strong> into a vendored workspace folder in <strong>./Godeps/_workspace</strong>. A list of those packages will be stored with relevant version information in a master file, <strong>Godeps/Godeps.json</strong>. This is done not just for the packages your project directly imports but also for any imported by your dependencies.</p>\n<p>Using Godep is as simple as prepending your normal Go commands like go test or go build with the godep command. This uses a temporarily extended <strong>GOPATH</strong> which prioritizes the Godep vendor directory.</p>\n<blockquote>\n<p>saves your GOPATH to the Godep folder </p>\n<pre><code>$ godep save ./  \n</code></pre><p>builds using the Godep vendored dependencies</p>\n<pre><code>$ godep go build ./   \n</code></pre><p>tests using the Godep vendored dependencies</p>\n<pre><code>$ godep go test ./\n</code></pre></blockquote>\n<p>From here, should you apply a change to your <strong>GOPATH</strong>, your project will be isolated.</p>\n<blockquote>\n<p>update a dependency</p>\n<pre><code>go get -u github.com/golang/protobuf/\n</code></pre><p>build using standard GOPATH</p>\n<pre><code>$ go build ./                         \n</code></pre><p>build using Godep vendored version</p>\n<pre><code>$ godep go build ./     \n</code></pre></blockquote>\n<p>####godep update versus godep save<br><strong>godep update</strong> takes a specific dependency package and updates the vendored instance of that package with the version in your <strong>GOPATH</strong>. This will update files with changes, add new files, remove old ones, and update the version SHA listed in the <strong>Godeps.json</strong> file.</p>\n<pre><code>$ go get -u github.com/golang/protobuf/\n$ godep update github.com/golang/protobuf/\n</code></pre><p>This will not add or remove sub-packages from dependency management, nor will it update any other dependencies recursively. Only previously imported packages are listed in the <strong>Godeps.json</strong> file and only those listed are updated.</p>\n<p>Updating the entire package will update any references to sub-packages; however no new packages will be added, nor old ones removed. Similarly, if your dependency update is dependent upon another change elsewhere in your dependency stack, you may run into issues. <strong>godep update</strong> only touches the packages listed in Godeps.json, which match the provided package pattern.</p>\n<p>In contrast, <strong>godep save</strong> applies the entire relevant GOPATH to the Godeps folder and will add/remove packages as needed. Because its based off of your <strong>GOPATH, godep save</strong> can also check for build errors and non-clean repositories before applying changes, enforcing dependency cohesion.</p>\n<p>Given the dangers of using <strong>godep update</strong> (missing packages and dependencies), its much safer to use <strong>godep save</strong>. The only situation where its safe to use godep update are when both of these conditions are satisfied:</p>\n<blockquote>\n<p>No dependencies of your target dependency need to be updated.</p>\n<p>No imports were added to or removed from your target dependency.</p>\n</blockquote>\n<p>If the dependency is external to your organization, it can be difficult to determine what changes are taking place, so it is safer to never use <strong>godep update</strong> on anything third-party.</p>\n<p>####When to Use Godep<br>Not every project may require the broad dependency control as provided by Godep.</p>\n<p>Unlike import path-based vendoring, Godep vendors the entire set of dependencies regardless of a specific desire to version them. This does mean that no dependencies will ever be updated unless explicitly altered, first through <strong>GOPATH</strong> and then through Godep.</p>\n<p>Should your organization have a large number of common dependencies across different projects, you may want to look into using a forked dependency model. Godep provides a locally controlled, customizable dependency management system. When used with care, this system can support highly versioned and reproducible builds, especially in change resistive environments with few shared dependencies.</p>\n"},{"title":"Getting more native, welcome scyllaDB","slug":"2016-02-05-getting-more-native-welcome-scylladb","date_published":"2016-02-05T04:00:12.675Z","date_updated":"2016-02-09T03:18:32.514Z","_content":"\nIs it not an uncommon fact that cassandra is the defacto NoSQL database that is being used in the bigdata world at the moment. It is known for its ease and performance, and the constant push that is being given by DataStax in building the community. But there is this new kid in town, a very powerful kid, he is like one of those kids from spykids. Yes, scyllaDB \n\nScylla is an open source NoSQL database which is apache cassandra compatible with performance 10x more than cassandra. scylla has been giving out promising results so far with very low latency. \n\nCurrently in the 0.16 version, and the GA coming out very soon, this is going to be really interesting to see how this works for a lot of bigdata usecases.\n\nIn this blog post we will focus on how to setup scylla and how the data modelling works. If you are already a cassandra expert, just head over to the google forums which is very active and ask your queries. But the documentation does not cover for a non-cassandra folks  and I am hoping this will be helpful for those people in particular.\n\n####1. Setting it up:\n\nThis article [here](http://www.scylladb.com/doc/getting-started-ubuntu/) gives the steps in downloading and setting it up.\n\nFew things to note is, all the configuration setups and changes should be done in the yaml file which is in `/var/lib/conf/scylla.yml'\n\n**Note: make sure you add `SCYLLA_ARGS=\"--developer-mode true\"` in your `scylla-server` file, it will by default look for XFS file system and we need ext**\n\nOnce you install scylla-server and scylla-jmx, \n\n    nodetool status\n    \n And it will display, \n \n     Datacenter: datacenter1\n     =======================\n    Status=Up/Down\n    |/ State=Normal/Leaving/Joining/Moving\n    --  Address       Load       Tokens  Owns    Host ID                               Rack\n    UN  103.56.92.54  211.48 KB  256     ?       6c78937a-2d1f-4dfa-ad47-98405fbd2eff  rack1\n\n    Note: Non-system keyspaces don't have the same replication settings, effective ownership information is meaningless\n \n \n* Change `listen_address` to public IP like the above example\n\n* Make sure you change the `rpc_address` if you want to communicate through the CQL native protocol remotely. Other wise you will get the `NoHostAvailableException`. \n\n* Change the `api_address` to the public ip to access the REST API server.(This is really cool and one of the reasons I really like riak)\n\nYou have the db all set, it is up and running. \n\n####2. Cassandra compatibility - cqlsh\n\nScylla has got good cassandra compatibility and there is a healthy set of driver support as well. ([Driver status](https://github.com/scylladb/scylla/wiki/Driver-Status))\n\nTo get the CQL shell, type `cqlsh` \tin your shell.\n\n\n######1. Creating a keyspace\n\n    CREATE KEYSPACE musiclibrary WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1 };\n\nThis creates a keyspace(database in RDBMS world) .\n\n**Note: Use RDBMS to compare only upto a point until you understand the data modelling concepts. For designing complex data models, it is good to grasp the cassandra-scylla way of thinking.**\n\n    USE \"musiclibrary\";\n    CREATE TABLE rockmusic(\n                band text,\n                genre text,\n                era int,\n                PRIMARY KEY (era)\n                );\n                \n    \n   This creates a table called rockmusic.Let us now insert data\n   \n      INSERT INTO rockmusic(band, genre, era) values ('rolling stones', 'rocknroll', 1960);\n      \n      INSERT INTO rockmusic(band, genre, era) values ('beatles', 'britpop', 1960);\n      \n      INSERT INTO TABLE rockmusic(band, genre, era) values ('thewho', 'rock', 1960);\n      \nThats it. Just do a `select * from rockmusic` and it will print it out. You can also set multiple primary key and do a Key -> Key -> Value search.\n\nIn the next article we will briefly look at data modelling in scyllaDB, we will look at\n\n* ColumnFamily & SuperColumnFamily\n* How to use [phantom](https://github.com/websudos/phantom) the scala-java driver. \n* Using apache spark with scyllaDB\n\nThats it for now.\n\n\n\n\n","source":"_posts/2016-02-05-getting-more-native-welcome-scylladb.md","raw":"---\ntitle: Getting more native, welcome scyllaDB\nslug: getting-more-native-welcome-scylladb\ndate_published: 2016-02-05T09:30:12.675Z\ndate_updated:   2016-02-09T08:48:32.514Z\ntags: scylla, scylladb, nosql, cassandra\n---\n\nIs it not an uncommon fact that cassandra is the defacto NoSQL database that is being used in the bigdata world at the moment. It is known for its ease and performance, and the constant push that is being given by DataStax in building the community. But there is this new kid in town, a very powerful kid, he is like one of those kids from spykids. Yes, scyllaDB \n\nScylla is an open source NoSQL database which is apache cassandra compatible with performance 10x more than cassandra. scylla has been giving out promising results so far with very low latency. \n\nCurrently in the 0.16 version, and the GA coming out very soon, this is going to be really interesting to see how this works for a lot of bigdata usecases.\n\nIn this blog post we will focus on how to setup scylla and how the data modelling works. If you are already a cassandra expert, just head over to the google forums which is very active and ask your queries. But the documentation does not cover for a non-cassandra folks  and I am hoping this will be helpful for those people in particular.\n\n####1. Setting it up:\n\nThis article [here](http://www.scylladb.com/doc/getting-started-ubuntu/) gives the steps in downloading and setting it up.\n\nFew things to note is, all the configuration setups and changes should be done in the yaml file which is in `/var/lib/conf/scylla.yml'\n\n**Note: make sure you add `SCYLLA_ARGS=\"--developer-mode true\"` in your `scylla-server` file, it will by default look for XFS file system and we need ext**\n\nOnce you install scylla-server and scylla-jmx, \n\n    nodetool status\n    \n And it will display, \n \n     Datacenter: datacenter1\n     =======================\n    Status=Up/Down\n    |/ State=Normal/Leaving/Joining/Moving\n    --  Address       Load       Tokens  Owns    Host ID                               Rack\n    UN  103.56.92.54  211.48 KB  256     ?       6c78937a-2d1f-4dfa-ad47-98405fbd2eff  rack1\n\n    Note: Non-system keyspaces don't have the same replication settings, effective ownership information is meaningless\n \n \n* Change `listen_address` to public IP like the above example\n\n* Make sure you change the `rpc_address` if you want to communicate through the CQL native protocol remotely. Other wise you will get the `NoHostAvailableException`. \n\n* Change the `api_address` to the public ip to access the REST API server.(This is really cool and one of the reasons I really like riak)\n\nYou have the db all set, it is up and running. \n\n####2. Cassandra compatibility - cqlsh\n\nScylla has got good cassandra compatibility and there is a healthy set of driver support as well. ([Driver status](https://github.com/scylladb/scylla/wiki/Driver-Status))\n\nTo get the CQL shell, type `cqlsh` \tin your shell.\n\n\n######1. Creating a keyspace\n\n    CREATE KEYSPACE musiclibrary WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1 };\n\nThis creates a keyspace(database in RDBMS world) .\n\n**Note: Use RDBMS to compare only upto a point until you understand the data modelling concepts. For designing complex data models, it is good to grasp the cassandra-scylla way of thinking.**\n\n    USE \"musiclibrary\";\n    CREATE TABLE rockmusic(\n                band text,\n                genre text,\n                era int,\n                PRIMARY KEY (era)\n                );\n                \n    \n   This creates a table called rockmusic.Let us now insert data\n   \n      INSERT INTO rockmusic(band, genre, era) values ('rolling stones', 'rocknroll', 1960);\n      \n      INSERT INTO rockmusic(band, genre, era) values ('beatles', 'britpop', 1960);\n      \n      INSERT INTO TABLE rockmusic(band, genre, era) values ('thewho', 'rock', 1960);\n      \nThats it. Just do a `select * from rockmusic` and it will print it out. You can also set multiple primary key and do a Key -> Key -> Value search.\n\nIn the next article we will briefly look at data modelling in scyllaDB, we will look at\n\n* ColumnFamily & SuperColumnFamily\n* How to use [phantom](https://github.com/websudos/phantom) the scala-java driver. \n* Using apache spark with scyllaDB\n\nThats it for now.\n\n\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaisp0014drgbs8d50kdz","content":"<p>Is it not an uncommon fact that cassandra is the defacto NoSQL database that is being used in the bigdata world at the moment. It is known for its ease and performance, and the constant push that is being given by DataStax in building the community. But there is this new kid in town, a very powerful kid, he is like one of those kids from spykids. Yes, scyllaDB </p>\n<p>Scylla is an open source NoSQL database which is apache cassandra compatible with performance 10x more than cassandra. scylla has been giving out promising results so far with very low latency. </p>\n<p>Currently in the 0.16 version, and the GA coming out very soon, this is going to be really interesting to see how this works for a lot of bigdata usecases.</p>\n<p>In this blog post we will focus on how to setup scylla and how the data modelling works. If you are already a cassandra expert, just head over to the google forums which is very active and ask your queries. But the documentation does not cover for a non-cassandra folks  and I am hoping this will be helpful for those people in particular.</p>\n<p>####1. Setting it up:</p>\n<p>This article <a href=\"http://www.scylladb.com/doc/getting-started-ubuntu/\" target=\"_blank\" rel=\"external\">here</a> gives the steps in downloading and setting it up.</p>\n<p>Few things to note is, all the configuration setups and changes should be done in the yaml file which is in `/var/lib/conf/scylla.yml</p>\n<p><strong>Note: make sure you add <code>SCYLLA_ARGS=&quot;--developer-mode true&quot;</code> in your <code>scylla-server</code> file, it will by default look for XFS file system and we need ext</strong></p>\n<p>Once you install scylla-server and scylla-jmx, </p>\n<pre><code>nodetool status\n</code></pre><p> And it will display, </p>\n<pre><code> Datacenter: datacenter1\n =======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address       Load       Tokens  Owns    Host ID                               Rack\nUN  103.56.92.54  211.48 KB  256     ?       6c78937a-2d1f-4dfa-ad47-98405fbd2eff  rack1\n\nNote: Non-system keyspaces don&apos;t have the same replication settings, effective ownership information is meaningless\n</code></pre><ul>\n<li><p>Change <code>listen_address</code> to public IP like the above example</p>\n</li>\n<li><p>Make sure you change the <code>rpc_address</code> if you want to communicate through the CQL native protocol remotely. Other wise you will get the <code>NoHostAvailableException</code>. </p>\n</li>\n<li><p>Change the <code>api_address</code> to the public ip to access the REST API server.(This is really cool and one of the reasons I really like riak)</p>\n</li>\n</ul>\n<p>You have the db all set, it is up and running. </p>\n<p>####2. Cassandra compatibility - cqlsh</p>\n<p>Scylla has got good cassandra compatibility and there is a healthy set of driver support as well. (<a href=\"https://github.com/scylladb/scylla/wiki/Driver-Status\" target=\"_blank\" rel=\"external\">Driver status</a>)</p>\n<p>To get the CQL shell, type <code>cqlsh</code>     in your shell.</p>\n<p>######1. Creating a keyspace</p>\n<pre><code>CREATE KEYSPACE musiclibrary WITH replication = {&apos;class&apos;: &apos;SimpleStrategy&apos;, &apos;replication_factor&apos;: 1 };\n</code></pre><p>This creates a keyspace(database in RDBMS world) .</p>\n<p><strong>Note: Use RDBMS to compare only upto a point until you understand the data modelling concepts. For designing complex data models, it is good to grasp the cassandra-scylla way of thinking.</strong></p>\n<pre><code>USE &quot;musiclibrary&quot;;\nCREATE TABLE rockmusic(\n            band text,\n            genre text,\n            era int,\n            PRIMARY KEY (era)\n            );\n</code></pre><p>   This creates a table called rockmusic.Let us now insert data</p>\n<pre><code>INSERT INTO rockmusic(band, genre, era) values (&apos;rolling stones&apos;, &apos;rocknroll&apos;, 1960);\n\nINSERT INTO rockmusic(band, genre, era) values (&apos;beatles&apos;, &apos;britpop&apos;, 1960);\n\nINSERT INTO TABLE rockmusic(band, genre, era) values (&apos;thewho&apos;, &apos;rock&apos;, 1960);\n</code></pre><p>Thats it. Just do a <code>select * from rockmusic</code> and it will print it out. You can also set multiple primary key and do a Key -&gt; Key -&gt; Value search.</p>\n<p>In the next article we will briefly look at data modelling in scyllaDB, we will look at</p>\n<ul>\n<li>ColumnFamily &amp; SuperColumnFamily</li>\n<li>How to use <a href=\"https://github.com/websudos/phantom\" target=\"_blank\" rel=\"external\">phantom</a> the scala-java driver. </li>\n<li>Using apache spark with scyllaDB</li>\n</ul>\n<p>Thats it for now.</p>\n","excerpt":"","more":"<p>Is it not an uncommon fact that cassandra is the defacto NoSQL database that is being used in the bigdata world at the moment. It is known for its ease and performance, and the constant push that is being given by DataStax in building the community. But there is this new kid in town, a very powerful kid, he is like one of those kids from spykids. Yes, scyllaDB </p>\n<p>Scylla is an open source NoSQL database which is apache cassandra compatible with performance 10x more than cassandra. scylla has been giving out promising results so far with very low latency. </p>\n<p>Currently in the 0.16 version, and the GA coming out very soon, this is going to be really interesting to see how this works for a lot of bigdata usecases.</p>\n<p>In this blog post we will focus on how to setup scylla and how the data modelling works. If you are already a cassandra expert, just head over to the google forums which is very active and ask your queries. But the documentation does not cover for a non-cassandra folks  and I am hoping this will be helpful for those people in particular.</p>\n<p>####1. Setting it up:</p>\n<p>This article <a href=\"http://www.scylladb.com/doc/getting-started-ubuntu/\">here</a> gives the steps in downloading and setting it up.</p>\n<p>Few things to note is, all the configuration setups and changes should be done in the yaml file which is in `/var/lib/conf/scylla.yml</p>\n<p><strong>Note: make sure you add <code>SCYLLA_ARGS=&quot;--developer-mode true&quot;</code> in your <code>scylla-server</code> file, it will by default look for XFS file system and we need ext</strong></p>\n<p>Once you install scylla-server and scylla-jmx, </p>\n<pre><code>nodetool status\n</code></pre><p> And it will display, </p>\n<pre><code> Datacenter: datacenter1\n =======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address       Load       Tokens  Owns    Host ID                               Rack\nUN  103.56.92.54  211.48 KB  256     ?       6c78937a-2d1f-4dfa-ad47-98405fbd2eff  rack1\n\nNote: Non-system keyspaces don&apos;t have the same replication settings, effective ownership information is meaningless\n</code></pre><ul>\n<li><p>Change <code>listen_address</code> to public IP like the above example</p>\n</li>\n<li><p>Make sure you change the <code>rpc_address</code> if you want to communicate through the CQL native protocol remotely. Other wise you will get the <code>NoHostAvailableException</code>. </p>\n</li>\n<li><p>Change the <code>api_address</code> to the public ip to access the REST API server.(This is really cool and one of the reasons I really like riak)</p>\n</li>\n</ul>\n<p>You have the db all set, it is up and running. </p>\n<p>####2. Cassandra compatibility - cqlsh</p>\n<p>Scylla has got good cassandra compatibility and there is a healthy set of driver support as well. (<a href=\"https://github.com/scylladb/scylla/wiki/Driver-Status\">Driver status</a>)</p>\n<p>To get the CQL shell, type <code>cqlsh</code>     in your shell.</p>\n<p>######1. Creating a keyspace</p>\n<pre><code>CREATE KEYSPACE musiclibrary WITH replication = {&apos;class&apos;: &apos;SimpleStrategy&apos;, &apos;replication_factor&apos;: 1 };\n</code></pre><p>This creates a keyspace(database in RDBMS world) .</p>\n<p><strong>Note: Use RDBMS to compare only upto a point until you understand the data modelling concepts. For designing complex data models, it is good to grasp the cassandra-scylla way of thinking.</strong></p>\n<pre><code>USE &quot;musiclibrary&quot;;\nCREATE TABLE rockmusic(\n            band text,\n            genre text,\n            era int,\n            PRIMARY KEY (era)\n            );\n</code></pre><p>   This creates a table called rockmusic.Let us now insert data</p>\n<pre><code>INSERT INTO rockmusic(band, genre, era) values (&apos;rolling stones&apos;, &apos;rocknroll&apos;, 1960);\n\nINSERT INTO rockmusic(band, genre, era) values (&apos;beatles&apos;, &apos;britpop&apos;, 1960);\n\nINSERT INTO TABLE rockmusic(band, genre, era) values (&apos;thewho&apos;, &apos;rock&apos;, 1960);\n</code></pre><p>Thats it. Just do a <code>select * from rockmusic</code> and it will print it out. You can also set multiple primary key and do a Key -&gt; Key -&gt; Value search.</p>\n<p>In the next article we will briefly look at data modelling in scyllaDB, we will look at</p>\n<ul>\n<li>ColumnFamily &amp; SuperColumnFamily</li>\n<li>How to use <a href=\"https://github.com/websudos/phantom\">phantom</a> the scala-java driver. </li>\n<li>Using apache spark with scyllaDB</li>\n</ul>\n<p>Thats it for now.</p>\n"},{"title":"Chef vs Urknall","slug":"2016-02-06-chef-vs-urknall","date_published":"2016-02-06T09:40:34.662Z","date_updated":"2016-02-06T09:40:35.993Z","_content":"\n####An Introduction to Urknall \n\nUrknall is Go based automation provising tools for the administration of complex infrastructure developed in Golang. Agentless tool that only relies on common UNIX tools and provides decent caching.\n\nIt provides template machanisms that helps us to reuseablity and Urknall provides some basic templates, but lets users modify those or add new ones to solve the specific problem at hand.\n\n\nIt provides the benefits of a compiler, helping to catch bugs early and making refactoring easy and single binary infrastructure management tools, having no dependencies.\n\nUrknall library part of urknall provides the core mechanisms to execute commands on a remote host.\n\n It provides four kind of interfaces to handle the commands. Commands in the sense of shell commands.\n\n#####About Urknall machanisms \n\n  \tCommands Interface  -  to run shell commands on target  \n    \n \tLogger Interface    - to simplify the logging outputs, to track commands which is executed.\n    \n\tRenderer Interface   - to use its properties in the command strings using gos templating. \n    \n\tValidator Interface  - to do more complex validations \n\n \tPackages - Packages are an strictly internal data-structure.\n    \n\tTasks - Tasks are ordered collections of commands.\n    \n\tTemplates -  to define the list of tasks that should be performed during provisioning.\n    \n\tTargets - where the commands are executed on remote host or local\n    \n\t\tRemote Target - uses SSH to connect to the remote machine \n\t\tLocal Target - to provision the local host.\n\t\tSudo Without Password - it is required that the user is allowed sudo without password. this done by \n        \n\techo \"username ALL=(ALL) NOPASSWD:ALL\" > /etc/sudoers.d/90-nopassword\n\n\n#####Urknall binary\n\n\n   Urknall binary helps managing projects that use the library. While the urknall library provides the handling of targets, tasks and caching.\n   \n   Its fully integrated with libraries i.e. the implementations of some basic commands and templates were part of the library itself.\n   \n   we can change the templates directly, but have to move the according code to our project manually. \n   \n######Chef vs Urknall\n     **Urknall**\n\t\tTies users to Golang.\n\t\tHelping to catch bugs early and making refactoring easy.\n\t\tUrknall supports for Linux.\n\t\tEasy to learn and deploy. \n\t\tGo is more flexible to use both YAML and JSON\n        No need any dependecies \n        \n \t**Chef**\n\t\tTies users to Ruby.\n\t\tLarger community, with a large collection of modules and configuration recipes.\n\t\tFull support for Linux, Unix, Windows.\n\t\tNot as easy to learn and deploy. and Documentation still needs a lot of work.\n\t\tRelies on JSON which is not as friendly as YAML.\n\n\n   \n   \n","source":"_posts/2016-02-06-chef-vs-urknall.md","raw":"---\ntitle: Chef vs Urknall\nslug: chef-vs-urknall\ndate_published: 2016-02-06T15:10:34.662Z\ndate_updated:   2016-02-06T15:10:35.993Z\n---\n\n####An Introduction to Urknall \n\nUrknall is Go based automation provising tools for the administration of complex infrastructure developed in Golang. Agentless tool that only relies on common UNIX tools and provides decent caching.\n\nIt provides template machanisms that helps us to reuseablity and Urknall provides some basic templates, but lets users modify those or add new ones to solve the specific problem at hand.\n\n\nIt provides the benefits of a compiler, helping to catch bugs early and making refactoring easy and single binary infrastructure management tools, having no dependencies.\n\nUrknall library part of urknall provides the core mechanisms to execute commands on a remote host.\n\n It provides four kind of interfaces to handle the commands. Commands in the sense of shell commands.\n\n#####About Urknall machanisms \n\n  \tCommands Interface  -  to run shell commands on target  \n    \n \tLogger Interface    - to simplify the logging outputs, to track commands which is executed.\n    \n\tRenderer Interface   - to use its properties in the command strings using gos templating. \n    \n\tValidator Interface  - to do more complex validations \n\n \tPackages - Packages are an strictly internal data-structure.\n    \n\tTasks - Tasks are ordered collections of commands.\n    \n\tTemplates -  to define the list of tasks that should be performed during provisioning.\n    \n\tTargets - where the commands are executed on remote host or local\n    \n\t\tRemote Target - uses SSH to connect to the remote machine \n\t\tLocal Target - to provision the local host.\n\t\tSudo Without Password - it is required that the user is allowed sudo without password. this done by \n        \n\techo \"username ALL=(ALL) NOPASSWD:ALL\" > /etc/sudoers.d/90-nopassword\n\n\n#####Urknall binary\n\n\n   Urknall binary helps managing projects that use the library. While the urknall library provides the handling of targets, tasks and caching.\n   \n   Its fully integrated with libraries i.e. the implementations of some basic commands and templates were part of the library itself.\n   \n   we can change the templates directly, but have to move the according code to our project manually. \n   \n######Chef vs Urknall\n     **Urknall**\n\t\tTies users to Golang.\n\t\tHelping to catch bugs early and making refactoring easy.\n\t\tUrknall supports for Linux.\n\t\tEasy to learn and deploy. \n\t\tGo is more flexible to use both YAML and JSON\n        No need any dependecies \n        \n \t**Chef**\n\t\tTies users to Ruby.\n\t\tLarger community, with a large collection of modules and configuration recipes.\n\t\tFull support for Linux, Unix, Windows.\n\t\tNot as easy to learn and deploy. and Documentation still needs a lot of work.\n\t\tRelies on JSON which is not as friendly as YAML.\n\n\n   \n   \n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaisq0015drgbi4nm7511","content":"<p>####An Introduction to Urknall </p>\n<p>Urknall is Go based automation provising tools for the administration of complex infrastructure developed in Golang. Agentless tool that only relies on common UNIX tools and provides decent caching.</p>\n<p>It provides template machanisms that helps us to reuseablity and Urknall provides some basic templates, but lets users modify those or add new ones to solve the specific problem at hand.</p>\n<p>It provides the benefits of a compiler, helping to catch bugs early and making refactoring easy and single binary infrastructure management tools, having no dependencies.</p>\n<p>Urknall library part of urknall provides the core mechanisms to execute commands on a remote host.</p>\n<p> It provides four kind of interfaces to handle the commands. Commands in the sense of shell commands.</p>\n<p>#####About Urknall machanisms </p>\n<pre><code>  Commands Interface  -  to run shell commands on target  \n\n Logger Interface    - to simplify the logging outputs, to track commands which is executed.\n\nRenderer Interface   - to use its properties in the command strings using gos templating. \n\nValidator Interface  - to do more complex validations \n\n Packages - Packages are an strictly internal data-structure.\n\nTasks - Tasks are ordered collections of commands.\n\nTemplates -  to define the list of tasks that should be performed during provisioning.\n\nTargets - where the commands are executed on remote host or local\n\n    Remote Target - uses SSH to connect to the remote machine \n    Local Target - to provision the local host.\n    Sudo Without Password - it is required that the user is allowed sudo without password. this done by \n\necho &quot;username ALL=(ALL) NOPASSWD:ALL&quot; &gt; /etc/sudoers.d/90-nopassword\n</code></pre><p>#####Urknall binary</p>\n<p>   Urknall binary helps managing projects that use the library. While the urknall library provides the handling of targets, tasks and caching.</p>\n<p>   Its fully integrated with libraries i.e. the implementations of some basic commands and templates were part of the library itself.</p>\n<p>   we can change the templates directly, but have to move the according code to our project manually. </p>\n<p>######Chef vs Urknall<br>     <strong>Urknall</strong><br>        Ties users to Golang.<br>        Helping to catch bugs early and making refactoring easy.<br>        Urknall supports for Linux.<br>        Easy to learn and deploy.<br>        Go is more flexible to use both YAML and JSON<br>        No need any dependecies </p>\n<pre><code>**Chef**\n   Ties users to Ruby.\n   Larger community, with a large collection of modules and configuration recipes.\n   Full support for Linux, Unix, Windows.\n   Not as easy to learn and deploy. and Documentation still needs a lot of work.\n   Relies on JSON which is not as friendly as YAML.\n</code></pre>","excerpt":"","more":"<p>####An Introduction to Urknall </p>\n<p>Urknall is Go based automation provising tools for the administration of complex infrastructure developed in Golang. Agentless tool that only relies on common UNIX tools and provides decent caching.</p>\n<p>It provides template machanisms that helps us to reuseablity and Urknall provides some basic templates, but lets users modify those or add new ones to solve the specific problem at hand.</p>\n<p>It provides the benefits of a compiler, helping to catch bugs early and making refactoring easy and single binary infrastructure management tools, having no dependencies.</p>\n<p>Urknall library part of urknall provides the core mechanisms to execute commands on a remote host.</p>\n<p> It provides four kind of interfaces to handle the commands. Commands in the sense of shell commands.</p>\n<p>#####About Urknall machanisms </p>\n<pre><code>  Commands Interface  -  to run shell commands on target  \n\n Logger Interface    - to simplify the logging outputs, to track commands which is executed.\n\nRenderer Interface   - to use its properties in the command strings using gos templating. \n\nValidator Interface  - to do more complex validations \n\n Packages - Packages are an strictly internal data-structure.\n\nTasks - Tasks are ordered collections of commands.\n\nTemplates -  to define the list of tasks that should be performed during provisioning.\n\nTargets - where the commands are executed on remote host or local\n\n    Remote Target - uses SSH to connect to the remote machine \n    Local Target - to provision the local host.\n    Sudo Without Password - it is required that the user is allowed sudo without password. this done by \n\necho &quot;username ALL=(ALL) NOPASSWD:ALL&quot; &gt; /etc/sudoers.d/90-nopassword\n</code></pre><p>#####Urknall binary</p>\n<p>   Urknall binary helps managing projects that use the library. While the urknall library provides the handling of targets, tasks and caching.</p>\n<p>   Its fully integrated with libraries i.e. the implementations of some basic commands and templates were part of the library itself.</p>\n<p>   we can change the templates directly, but have to move the according code to our project manually. </p>\n<p>######Chef vs Urknall<br>     <strong>Urknall</strong><br>        Ties users to Golang.<br>        Helping to catch bugs early and making refactoring easy.<br>        Urknall supports for Linux.<br>        Easy to learn and deploy.<br>        Go is more flexible to use both YAML and JSON<br>        No need any dependecies </p>\n<pre><code>**Chef**\n   Ties users to Ruby.\n   Larger community, with a large collection of modules and configuration recipes.\n   Full support for Linux, Unix, Windows.\n   Not as easy to learn and deploy. and Documentation still needs a lot of work.\n   Relies on JSON which is not as friendly as YAML.\n</code></pre>"},{"title":"Package Upgrading in Trusty","slug":"2016-02-06-package-upgrade-from-trusty-to-jessie","date_published":"2016-02-06T09:41:08.896Z","date_updated":"2016-02-06T09:41:08.894Z","_content":"\n Upgrading is new versioning of an existing model that add or modify the modules of an already defined package. Here we upgrading the Ubuntu Trusty to a newer version.\n\n\n**Upgrading**\n\n\"fpm\" is used for package management that build backage.\n\nthe fpm command is resides in a file\n\nSyntax for fpm\n\n fpm -s <source type> -t <target type> [options]\n \nthe option will deciede our package configuration \n\nOptions:\n\t \n     -t OUTPUT_TYPE \n     the type of package you want to create (deb, rpm, solaris, etc)\n    -s INPUT_TYPE \n    the package type to use as input (gem, rpm,python, etc)\n    \n    \n Check the Dependencies of upgrading version is it compactable with newer version.\n  \n  \t-d, --depends DEPENDENCY      \n    A dependency. This flag can be specified multiple times. Value is usually in the form of: -d 'name' or -d 'name > version'\n  \nfor example Ubuntu Trusty supports with ruby version 2.0, but the Ubuntu Jessie supports with ruby version 2.1. so we have to change of all dependencies.\n\nthen add the  beforeupgrade and afterupdgrade process script file.\n\n \t--after-upgrade FILE  --> \n    \n    A script to be run after package upgrade. If not specified, --before-install, --after-install, --before-remove, and --after-remove wil behave in a backwards-compatible manner(they will not be upgrade-case aware).\n    \n    --before-upgrade FILE  -->\n    \n    A script to be run before package upgrade. If not specified, --before-install, --after-install, --before-remove, and --after-remove wil behave in a backwards-compatible manner (they will not be upgrade-case aware).\n    \n    \n      Currently only supports deb and rpm packages.\n\nthe FILE contains the script for the pre upgrade and post upgrade configuration.\n\nbefore upgrade script does what are the processes to be perform before upgrading the package.\n\nbefore upgrading we have to ask to the user whether he/she continue with the existing configuration settings or change the new configuration settings.\n\nIf he allows to new configuration settings we have to copy the new configuration setting file to appropriate location.\n\nfor example the pre upgrade file has the blow scripts\n\n\n\t#!/bin/sh\n\tcount=\"0\";\n\tt=\"3\";\n\twhile [ \"$count\" -ne \"$t\" ];\n\t do \n\t  count=`expr $count + 1`\n\t  echo -n \"Do u want to continue the set new configuration file  [Y/N] :\"\n  \tread x\n  \t\tif [ $x = y ]; then\n   \tcp /your conf file path/conf-file  /var/lib//conf-file\n\t   echo \"new configureation file copied....\"\n\t   break\n\t  fi\n  \tif [ \"$count\" -eq \"3\" ]; then\n     \techo \"more than three attempt,so it keep the old configuration file\"\n     \tbreak\n  \telse \n    \t echo \"enter valid input \"\n  \tfi\n\tdone\n\nafter upgrade script does what are the processes to be perform after upgrading the package.\n\n after upgrading start your service .\n \n \tsystemctl enable servicefile.service \n\tsystemctl start servicefile.service\n    \n\n","source":"_posts/2016-02-06-package-upgrade-from-trusty-to-jessie.md","raw":"---\ntitle: Package Upgrading in Trusty\nslug: package-upgrade-from-trusty-to-jessie\ndate_published: 2016-02-06T15:11:08.896Z\ndate_updated:   2016-02-06T15:11:08.894Z\n---\n\n Upgrading is new versioning of an existing model that add or modify the modules of an already defined package. Here we upgrading the Ubuntu Trusty to a newer version.\n\n\n**Upgrading**\n\n\"fpm\" is used for package management that build backage.\n\nthe fpm command is resides in a file\n\nSyntax for fpm\n\n fpm -s <source type> -t <target type> [options]\n \nthe option will deciede our package configuration \n\nOptions:\n\t \n     -t OUTPUT_TYPE \n     the type of package you want to create (deb, rpm, solaris, etc)\n    -s INPUT_TYPE \n    the package type to use as input (gem, rpm,python, etc)\n    \n    \n Check the Dependencies of upgrading version is it compactable with newer version.\n  \n  \t-d, --depends DEPENDENCY      \n    A dependency. This flag can be specified multiple times. Value is usually in the form of: -d 'name' or -d 'name > version'\n  \nfor example Ubuntu Trusty supports with ruby version 2.0, but the Ubuntu Jessie supports with ruby version 2.1. so we have to change of all dependencies.\n\nthen add the  beforeupgrade and afterupdgrade process script file.\n\n \t--after-upgrade FILE  --> \n    \n    A script to be run after package upgrade. If not specified, --before-install, --after-install, --before-remove, and --after-remove wil behave in a backwards-compatible manner(they will not be upgrade-case aware).\n    \n    --before-upgrade FILE  -->\n    \n    A script to be run before package upgrade. If not specified, --before-install, --after-install, --before-remove, and --after-remove wil behave in a backwards-compatible manner (they will not be upgrade-case aware).\n    \n    \n      Currently only supports deb and rpm packages.\n\nthe FILE contains the script for the pre upgrade and post upgrade configuration.\n\nbefore upgrade script does what are the processes to be perform before upgrading the package.\n\nbefore upgrading we have to ask to the user whether he/she continue with the existing configuration settings or change the new configuration settings.\n\nIf he allows to new configuration settings we have to copy the new configuration setting file to appropriate location.\n\nfor example the pre upgrade file has the blow scripts\n\n\n\t#!/bin/sh\n\tcount=\"0\";\n\tt=\"3\";\n\twhile [ \"$count\" -ne \"$t\" ];\n\t do \n\t  count=`expr $count + 1`\n\t  echo -n \"Do u want to continue the set new configuration file  [Y/N] :\"\n  \tread x\n  \t\tif [ $x = y ]; then\n   \tcp /your conf file path/conf-file  /var/lib//conf-file\n\t   echo \"new configureation file copied....\"\n\t   break\n\t  fi\n  \tif [ \"$count\" -eq \"3\" ]; then\n     \techo \"more than three attempt,so it keep the old configuration file\"\n     \tbreak\n  \telse \n    \t echo \"enter valid input \"\n  \tfi\n\tdone\n\nafter upgrade script does what are the processes to be perform after upgrading the package.\n\n after upgrading start your service .\n \n \tsystemctl enable servicefile.service \n\tsystemctl start servicefile.service\n    \n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaiss0017drgbjkzclvaa","content":"<p> Upgrading is new versioning of an existing model that add or modify the modules of an already defined package. Here we upgrading the Ubuntu Trusty to a newer version.</p>\n<p><strong>Upgrading</strong></p>\n<p>fpm is used for package management that build backage.</p>\n<p>the fpm command is resides in a file</p>\n<p>Syntax for fpm</p>\n<p> fpm -s <source type=\"\"> -t <target type=\"\"> [options]</target></p>\n<p>the option will deciede our package configuration </p>\n<p>Options:</p>\n<pre><code> -t OUTPUT_TYPE \n the type of package you want to create (deb, rpm, solaris, etc)\n-s INPUT_TYPE \nthe package type to use as input (gem, rpm,python, etc)\n</code></pre><p> Check the Dependencies of upgrading version is it compactable with newer version.</p>\n<pre><code>  -d, --depends DEPENDENCY      \nA dependency. This flag can be specified multiple times. Value is usually in the form of: -d &apos;name&apos; or -d &apos;name &gt; version&apos;\n</code></pre><p>for example Ubuntu Trusty supports with ruby version 2.0, but the Ubuntu Jessie supports with ruby version 2.1. so we have to change of all dependencies.</p>\n<p>then add the  beforeupgrade and afterupdgrade process script file.</p>\n<pre><code> --after-upgrade FILE  --&gt; \n\nA script to be run after package upgrade. If not specified, --before-install, --after-install, --before-remove, and --after-remove wil behave in a backwards-compatible manner(they will not be upgrade-case aware).\n\n--before-upgrade FILE  --&gt;\n\nA script to be run before package upgrade. If not specified, --before-install, --after-install, --before-remove, and --after-remove wil behave in a backwards-compatible manner (they will not be upgrade-case aware).\n\n\n  Currently only supports deb and rpm packages.\n</code></pre><p>the FILE contains the script for the pre upgrade and post upgrade configuration.</p>\n<p>before upgrade script does what are the processes to be perform before upgrading the package.</p>\n<p>before upgrading we have to ask to the user whether he/she continue with the existing configuration settings or change the new configuration settings.</p>\n<p>If he allows to new configuration settings we have to copy the new configuration setting file to appropriate location.</p>\n<p>for example the pre upgrade file has the blow scripts</p>\n<pre><code>#!/bin/sh\ncount=&quot;0&quot;;\nt=&quot;3&quot;;\nwhile [ &quot;$count&quot; -ne &quot;$t&quot; ];\n do \n  count=`expr $count + 1`\n  echo -n &quot;Do u want to continue the set new configuration file  [Y/N] :&quot;\n  read x\n      if [ $x = y ]; then\n   cp /your conf file path/conf-file  /var/lib//conf-file\n   echo &quot;new configureation file copied....&quot;\n   break\n  fi\n  if [ &quot;$count&quot; -eq &quot;3&quot; ]; then\n     echo &quot;more than three attempt,so it keep the old configuration file&quot;\n     break\n  else \n     echo &quot;enter valid input &quot;\n  fi\ndone\n</code></pre><p>after upgrade script does what are the processes to be perform after upgrading the package.</p>\n<p> after upgrading start your service .</p>\n<pre><code> systemctl enable servicefile.service \nsystemctl start servicefile.service\n</code></pre>","excerpt":"","more":"<p> Upgrading is new versioning of an existing model that add or modify the modules of an already defined package. Here we upgrading the Ubuntu Trusty to a newer version.</p>\n<p><strong>Upgrading</strong></p>\n<p>fpm is used for package management that build backage.</p>\n<p>the fpm command is resides in a file</p>\n<p>Syntax for fpm</p>\n<p> fpm -s <source type> -t <target type> [options]</p>\n<p>the option will deciede our package configuration </p>\n<p>Options:</p>\n<pre><code> -t OUTPUT_TYPE \n the type of package you want to create (deb, rpm, solaris, etc)\n-s INPUT_TYPE \nthe package type to use as input (gem, rpm,python, etc)\n</code></pre><p> Check the Dependencies of upgrading version is it compactable with newer version.</p>\n<pre><code>  -d, --depends DEPENDENCY      \nA dependency. This flag can be specified multiple times. Value is usually in the form of: -d &apos;name&apos; or -d &apos;name &gt; version&apos;\n</code></pre><p>for example Ubuntu Trusty supports with ruby version 2.0, but the Ubuntu Jessie supports with ruby version 2.1. so we have to change of all dependencies.</p>\n<p>then add the  beforeupgrade and afterupdgrade process script file.</p>\n<pre><code> --after-upgrade FILE  --&gt; \n\nA script to be run after package upgrade. If not specified, --before-install, --after-install, --before-remove, and --after-remove wil behave in a backwards-compatible manner(they will not be upgrade-case aware).\n\n--before-upgrade FILE  --&gt;\n\nA script to be run before package upgrade. If not specified, --before-install, --after-install, --before-remove, and --after-remove wil behave in a backwards-compatible manner (they will not be upgrade-case aware).\n\n\n  Currently only supports deb and rpm packages.\n</code></pre><p>the FILE contains the script for the pre upgrade and post upgrade configuration.</p>\n<p>before upgrade script does what are the processes to be perform before upgrading the package.</p>\n<p>before upgrading we have to ask to the user whether he/she continue with the existing configuration settings or change the new configuration settings.</p>\n<p>If he allows to new configuration settings we have to copy the new configuration setting file to appropriate location.</p>\n<p>for example the pre upgrade file has the blow scripts</p>\n<pre><code>#!/bin/sh\ncount=&quot;0&quot;;\nt=&quot;3&quot;;\nwhile [ &quot;$count&quot; -ne &quot;$t&quot; ];\n do \n  count=`expr $count + 1`\n  echo -n &quot;Do u want to continue the set new configuration file  [Y/N] :&quot;\n  read x\n      if [ $x = y ]; then\n   cp /your conf file path/conf-file  /var/lib//conf-file\n   echo &quot;new configureation file copied....&quot;\n   break\n  fi\n  if [ &quot;$count&quot; -eq &quot;3&quot; ]; then\n     echo &quot;more than three attempt,so it keep the old configuration file&quot;\n     break\n  else \n     echo &quot;enter valid input &quot;\n  fi\ndone\n</code></pre><p>after upgrade script does what are the processes to be perform after upgrading the package.</p>\n<p> after upgrading start your service .</p>\n<pre><code> systemctl enable servicefile.service \nsystemctl start servicefile.service\n</code></pre>"},{"title":"Spark-Notebook For Developer","slug":"2016-02-08-spark-notebook-for-developer","date_published":"2016-02-08T00:28:49.397Z","date_updated":"2016-02-08T00:30:08.137Z","_content":"\n#Introduction\n Spark-notebook allows performing reproducible with scala,Apache Spark and more.\n      This is achieved through an interactive web-based editor that can combine Scala code, SQL queries, Markup or even JavaScript in a collaborative manner.\n\nThe Spark is available out of the box, and is simply accessed by the variable sparkContext.Spark Notebook offers these capabilities to anybody who needs to play with data, leveraging not only Spark for all data manipulation, but also the Typesafe Reactive Platform, to offer unique power to the user.\n    \n#Installation    \n   To get debian package install spark-notebook\n    \n    wget https://s3.eu-central-1.amazonaws.com/spark-notebook/zip/spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4.zip\n    \n  Unzip the package in spark-notebook\n  \n    unzip spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4.zip\n    \n To rename directory  spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4 into spark-notebook\n \n    mv spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4 spark-notebook\n     \n  \n####Running Spark-notebook\n  \n  To run the spark-notebook cd into spark-notebook\n  \n    ./bin/spark-notebook\n    \n  When the server has been started, fire up your browser and point it to localhost:9000 and you'll see something similar to: Notebook list\n  \n  From there you can either:\n  create a new notebook or\n  launch an existing notebook. \n  \n  In UI, You can see the following menu **files**, **Running**, **clusters** and **New**. To create a new notebook click New option.\n  \n  Click cluster tab, to create spark cluster open in another window. To write a program in the cell and click Run button.\n  For example in the cell\n  \n    In[]: import org.apache.spark._\n          import org.apache.spark.SparkContext._\n          import org.apache.spark.rdd._\n          \n Click run button.You will see the output in the cell.\n \n######Advantages \n\n  The construction of models on a full dataset, not just subsets\n \nThe generation of deployable products to Mesos clusters\nThe creation of Avro and Play/Akka HTTP powered web services that use the resulting dataset\n\nThe creation of repositories and indexes of the analyses and services\n\n   \n   \n  \n  \n\n  \n  \n  \n  \n  \n  \n      \n","source":"_posts/2016-02-08-spark-notebook-for-developer.md","raw":"---\ntitle: Spark-Notebook For Developer\nslug: spark-notebook-for-developer\ndate_published: 2016-02-08T05:58:49.397Z\ndate_updated:   2016-02-08T06:00:08.137Z\n---\n\n#Introduction\n Spark-notebook allows performing reproducible with scala,Apache Spark and more.\n      This is achieved through an interactive web-based editor that can combine Scala code, SQL queries, Markup or even JavaScript in a collaborative manner.\n\nThe Spark is available out of the box, and is simply accessed by the variable sparkContext.Spark Notebook offers these capabilities to anybody who needs to play with data, leveraging not only Spark for all data manipulation, but also the Typesafe Reactive Platform, to offer unique power to the user.\n    \n#Installation    \n   To get debian package install spark-notebook\n    \n    wget https://s3.eu-central-1.amazonaws.com/spark-notebook/zip/spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4.zip\n    \n  Unzip the package in spark-notebook\n  \n    unzip spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4.zip\n    \n To rename directory  spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4 into spark-notebook\n \n    mv spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4 spark-notebook\n     \n  \n####Running Spark-notebook\n  \n  To run the spark-notebook cd into spark-notebook\n  \n    ./bin/spark-notebook\n    \n  When the server has been started, fire up your browser and point it to localhost:9000 and you'll see something similar to: Notebook list\n  \n  From there you can either:\n  create a new notebook or\n  launch an existing notebook. \n  \n  In UI, You can see the following menu **files**, **Running**, **clusters** and **New**. To create a new notebook click New option.\n  \n  Click cluster tab, to create spark cluster open in another window. To write a program in the cell and click Run button.\n  For example in the cell\n  \n    In[]: import org.apache.spark._\n          import org.apache.spark.SparkContext._\n          import org.apache.spark.rdd._\n          \n Click run button.You will see the output in the cell.\n \n######Advantages \n\n  The construction of models on a full dataset, not just subsets\n \nThe generation of deployable products to Mesos clusters\nThe creation of Avro and Play/Akka HTTP powered web services that use the resulting dataset\n\nThe creation of repositories and indexes of the analyses and services\n\n   \n   \n  \n  \n\n  \n  \n  \n  \n  \n  \n      \n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaist0018drgbz5gwdwdw","content":"<p>#Introduction<br> Spark-notebook allows performing reproducible with scala,Apache Spark and more.<br>      This is achieved through an interactive web-based editor that can combine Scala code, SQL queries, Markup or even JavaScript in a collaborative manner.</p>\n<p>The Spark is available out of the box, and is simply accessed by the variable sparkContext.Spark Notebook offers these capabilities to anybody who needs to play with data, leveraging not only Spark for all data manipulation, but also the Typesafe Reactive Platform, to offer unique power to the user.</p>\n<p>#Installation<br>   To get debian package install spark-notebook</p>\n<pre><code>wget https://s3.eu-central-1.amazonaws.com/spark-notebook/zip/spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4.zip\n</code></pre><p>  Unzip the package in spark-notebook</p>\n<pre><code>unzip spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4.zip\n</code></pre><p> To rename directory  spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4 into spark-notebook</p>\n<pre><code>mv spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4 spark-notebook\n</code></pre><p>####Running Spark-notebook</p>\n<p>  To run the spark-notebook cd into spark-notebook</p>\n<pre><code>./bin/spark-notebook\n</code></pre><p>  When the server has been started, fire up your browser and point it to localhost:9000 and youll see something similar to: Notebook list</p>\n<p>  From there you can either:<br>  create a new notebook or<br>  launch an existing notebook. </p>\n<p>  In UI, You can see the following menu <strong>files</strong>, <strong>Running</strong>, <strong>clusters</strong> and <strong>New</strong>. To create a new notebook click New option.</p>\n<p>  Click cluster tab, to create spark cluster open in another window. To write a program in the cell and click Run button.<br>  For example in the cell</p>\n<pre><code>In[]: import org.apache.spark._\n      import org.apache.spark.SparkContext._\n      import org.apache.spark.rdd._\n</code></pre><p> Click run button.You will see the output in the cell.</p>\n<p>######Advantages </p>\n<p>  The construction of models on a full dataset, not just subsets</p>\n<p>The generation of deployable products to Mesos clusters<br>The creation of Avro and Play/Akka HTTP powered web services that use the resulting dataset</p>\n<p>The creation of repositories and indexes of the analyses and services</p>\n","excerpt":"","more":"<p>#Introduction<br> Spark-notebook allows performing reproducible with scala,Apache Spark and more.<br>      This is achieved through an interactive web-based editor that can combine Scala code, SQL queries, Markup or even JavaScript in a collaborative manner.</p>\n<p>The Spark is available out of the box, and is simply accessed by the variable sparkContext.Spark Notebook offers these capabilities to anybody who needs to play with data, leveraging not only Spark for all data manipulation, but also the Typesafe Reactive Platform, to offer unique power to the user.</p>\n<p>#Installation<br>   To get debian package install spark-notebook</p>\n<pre><code>wget https://s3.eu-central-1.amazonaws.com/spark-notebook/zip/spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4.zip\n</code></pre><p>  Unzip the package in spark-notebook</p>\n<pre><code>unzip spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4.zip\n</code></pre><p> To rename directory  spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4 into spark-notebook</p>\n<pre><code>mv spark-notebook-0.6.0-scala-2.10.4-spark-1.4.1-hadoop-1.0.4 spark-notebook\n</code></pre><p>####Running Spark-notebook</p>\n<p>  To run the spark-notebook cd into spark-notebook</p>\n<pre><code>./bin/spark-notebook\n</code></pre><p>  When the server has been started, fire up your browser and point it to localhost:9000 and youll see something similar to: Notebook list</p>\n<p>  From there you can either:<br>  create a new notebook or<br>  launch an existing notebook. </p>\n<p>  In UI, You can see the following menu <strong>files</strong>, <strong>Running</strong>, <strong>clusters</strong> and <strong>New</strong>. To create a new notebook click New option.</p>\n<p>  Click cluster tab, to create spark cluster open in another window. To write a program in the cell and click Run button.<br>  For example in the cell</p>\n<pre><code>In[]: import org.apache.spark._\n      import org.apache.spark.SparkContext._\n      import org.apache.spark.rdd._\n</code></pre><p> Click run button.You will see the output in the cell.</p>\n<p>######Advantages </p>\n<p>  The construction of models on a full dataset, not just subsets</p>\n<p>The generation of deployable products to Mesos clusters<br>The creation of Avro and Play/Akka HTTP powered web services that use the resulting dataset</p>\n<p>The creation of repositories and indexes of the analyses and services</p>\n"},{"title":"Packet.net networking for opennebula host","slug":"2016-03-01-packet-net-networking-for-opennebula-host","date_published":"2016-03-01T01:51:05.328Z","date_updated":"2016-04-16T09:48:39.205Z","_content":"\nOur need is to setup `opennebula in packet.net`, so we have a server for both opennebula-frontend and opennebula-host. \n\nWe have a local working server for opennbula-host with openvswitch. But in packet.net we tried normal linux bridge(brctl) and we face some problem in creating virtual machines, because of networking.\n\n\tOS \t\t\t   : Ubuntu-14.04(trusty)\n\tHost IP \t   : 192.168.1.100\n\tAdditional IPs : 192.168.2.96/29\n\nNOTE: Actually we have public ips, but for security issues i documented with local ips.\nUsually, when we create a server in packet.net, they will give you a single IP, then we need to request them for additional IPs.\n\nAfter trying many configuration, we succeed with the following configurations,\n\nNOTE: Use `chattr -i /etc/network/interfaces` to make the file writable.\n\nMy Host server network configuration\n\n\t#cat /etc/network/interfaces\n\tauto lo\n\tiface lo inet loopback\n\n\tauto bond0\n\tiface bond0 inet static\n\t   address 192.168.1.100\n\t   netmask 255.255.255.254\n\t   bond-slaves eth1 eth0\n\t   gateway 192.168.1.99\n\t   bond-lacp-rate 1\n\t   bond-xmit_hash_policy layer3+4\n\t   bond-downdelay 200\n\t   bond-updelay 200\n\t   bond-miimon 100\n\t   bond-mode 4\n\tiface bond0 inet6 static\n\t   address 2604:xxxx:x:xxxx::x\n\t   netmask 127\n\t   gateway 2604:xxxx:x:xxxx::\n\tauto bond0:0\n\tiface bond0:0 inet static\n\t   address 10.99.18.1\n\t   netmask 255.255.255.254\n\tauto eth1\n\tiface eth1 inet manual\n\t   pre-up sleep 4\n\t   bond-master bond0\n\t\tauto eth0\n\tiface eth0 inet manual\n\t   bond-master bond0\n\t   post-up route add -net 10.0.0.0/8 gw 10.99.18.0\n\t   post-down route del -net 10.0.0.0/8 gw 10.99.18.0\n       \n\tauto br0\n\tiface br0 inet static\n\t  address 192.168.2.97\n\t  netmask 255.255.255.248\n\t  bridge_ports none\n\t  bridge_stp off\n\t  bridge_fd 1\n\t  bridge_hello 2\n\t  bridge_maxage 12\n\nRouting table for host server\n\n\troot@5:~# route\n\tKernel IP routing table\n\tDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n\tdefault         192.168.1.99    0.0.0.0         UG    0      0        0 bond0\n\t10.0.0.0        10.99.18.0      255.0.0.0       UG    0      0        0 bond0\n\t10.99.18.0      *               255.255.255.254 U     0      0        0 bond0\n\t192.168.1.99    *               255.255.255.254 U     0      0        0 bond0\n\t192.168.2.96    *               255.255.255.248 U     0      0        0 br0\n\n\nIP routes\n\n\troot@5:~# ip route show\n\tdefault via 192.168.1.99 dev bond0 \n\t10.0.0.0/8 via 10.99.18.0 dev bond0 \n\t10.99.18.0/31 dev bond0  proto kernel  scope link  src 10.99.18.1 \n\t192.168.1.99/31 dev bond0  proto kernel  scope link  src 192.168.1.100 \n\t192.168.2.96/29 dev br0  proto kernel  scope link  src 192.168.2.97\n    \n\nopen /etc/sysctl.conf and uncomment these lines\n\n\tnet.ipv4.conf.all.rp_filter=1 \n\tnet.ipv4.ip_forward=1 \n\tnet.ipv6.conf.all.forwarding=1\n\nDelete default bridge virbr0\n\n\t$ virsh net-destroy default\n\t$ virsh net-undefine default\n\t$ service libvirtd restart\n\nAfter launching vm, our linux bridge status\n\n\troot@5:~# brctl show\n\tbridge name\tbridge id\t\tSTP enabled\tinterfaces\n\tbr0\t\t8000.fe00934bc462\tno\t\tvnet0\n\t\t\t\t\t\t\nHost network\n\n\troot@5:~# ifconfig\n\tbond0     Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n\t          inet addr:192.168.1.100  Bcast:255.255.255.255  Mask:255.255.255.254\n\t          inet6 addr: xxxx:xxxx:x:xxxx::x/127 Scope:Global\n\t          inet6 addr: fe80::e61d:2dff:fe54:2478/64 Scope:Link\n\t          UP BROADCAST RUNNING MASTER MULTICAST  MTU:1500  Metric:1\n\t          RX packets:844156 errors:0 dropped:2 overruns:0 frame:0\n\t          TX packets:798032 errors:0 dropped:7 overruns:0 carrier:0\n\t          collisions:0 txqueuelen:0 \n\t          RX bytes:106510529 (106.5 MB)  TX bytes:105652129 (105.6 MB)\n\n\tbond0:0   Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n\t          inet addr:10.99.18.1  Bcast:255.255.255.255  Mask:255.255.255.254\n        \t  UP BROADCAST RUNNING MASTER MULTICAST  MTU:1500  Metric:1\n\t\n\tbr0       Link encap:Ethernet  HWaddr fe:00:93:4b:c4:62  \n\t          inet addr:192.168.2.97  Bcast:192.168.2.103  Mask:255.255.255.248\n\t          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n\t          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n\t          RX packets:18701 errors:0 dropped:0 overruns:0 frame:0\n\t          TX packets:23053 errors:0 dropped:0 overruns:0 carrier:0\n\t          collisions:0 txqueuelen:0 \n\t          RX bytes:2995153 (2.9 MB)  TX bytes:7377649 (7.3 MB)\n\t\n\teth0      Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n\t          UP BROADCAST RUNNING SLAVE MULTICAST  MTU:1500  Metric:1\n\t          RX packets:395599 errors:0 dropped:1 overruns:0 frame:0\n\t          TX packets:393086 errors:0 dropped:0 overruns:0 carrier:0\n\t          collisions:0 txqueuelen:1000 \n\t          RX bytes:50710378 (50.7 MB)  TX bytes:52152210 (52.1 MB)\n\t\n\teth1      Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n\t          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n\t          UP BROADCAST RUNNING SLAVE MULTICAST  MTU:1500  Metric:1\n\t          RX packets:448557 errors:0 dropped:1 overruns:0 frame:0\n\t          TX packets:404946 errors:0 dropped:0 overruns:0 carrier:0\n\t          collisions:0 txqueuelen:1000 \n\t          RX bytes:55800151 (55.8 MB)  TX bytes:53499919 (53.4 MB)\n\t\n\tlo        Link encap:Local Loopback  \n\t          inet addr:127.0.0.1  Mask:255.0.0.0\n\t          inet6 addr: ::1/128 Scope:Host\n\t          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n\t          RX packets:7881551 errors:0 dropped:0 overruns:0 frame:0\n\t          TX packets:7881551 errors:0 dropped:0 overruns:0 carrier:0\n\t          collisions:0 txqueuelen:0 \n\t          RX bytes:8125571309 (8.1 GB)  TX bytes:8125571309 (8.1 GB)\n\t\n\tvnet0     Link encap:Ethernet  HWaddr fe:00:93:4b:c4:62  \n\t          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n\t          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          \t  RX packets:18428 errors:0 dropped:0 overruns:0 frame:0\n\t          TX packets:21459 errors:0 dropped:0 overruns:0 carrier:0\n          \t  collisions:0 txqueuelen:500 \n\t          RX bytes:3225260 (3.2 MB)  TX bytes:7307291 (7.3 MB)\n\t\t\t\nThats it for opennebula host server's network configuration.\n\nNow launch a vm from opennebula\n\nVM's network configuration\n\n\troot@t2:~# cat /etc/network/interfaces\n\tauto lo\n\tiface lo inet loopback\n\t\n\tauto eth0\n\tiface eth0 inet static\n\t  address 192.168.2.98\n\t  network 192.168.2.96\n\t  netmask 255.255.255.248\n\t  gateway 192.168.2.97\n\nVM's routing table\n\n\troot@t2:~# route\n\tKernel IP routing table\n\tDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n\tdefault         192.168.2.97   0.0.0.0         UG    0      0        0 eth0\n\t192.168.2.96   *               255.255.255.248 U     0      0        0 eth0\n\nip route\n\n\troot@t2:~# ip route show\n\tdefault via 192.168.2.97 dev eth0 \n\t192.168.2.96/29 dev eth0  proto kernel  scope link  src 192.168.2.98\n    \nNow i can connect with my vm from anywhere.\n\n","source":"_posts/2016-03-01-packet-net-networking-for-opennebula-host.md","raw":"---\ntitle: Packet.net networking for opennebula host\nslug: packet-net-networking-for-opennebula-host\ndate_published: 2016-03-01T07:21:05.328Z\ndate_updated:   2016-04-16T15:18:39.205Z\n---\n\nOur need is to setup `opennebula in packet.net`, so we have a server for both opennebula-frontend and opennebula-host. \n\nWe have a local working server for opennbula-host with openvswitch. But in packet.net we tried normal linux bridge(brctl) and we face some problem in creating virtual machines, because of networking.\n\n\tOS \t\t\t   : Ubuntu-14.04(trusty)\n\tHost IP \t   : 192.168.1.100\n\tAdditional IPs : 192.168.2.96/29\n\nNOTE: Actually we have public ips, but for security issues i documented with local ips.\nUsually, when we create a server in packet.net, they will give you a single IP, then we need to request them for additional IPs.\n\nAfter trying many configuration, we succeed with the following configurations,\n\nNOTE: Use `chattr -i /etc/network/interfaces` to make the file writable.\n\nMy Host server network configuration\n\n\t#cat /etc/network/interfaces\n\tauto lo\n\tiface lo inet loopback\n\n\tauto bond0\n\tiface bond0 inet static\n\t   address 192.168.1.100\n\t   netmask 255.255.255.254\n\t   bond-slaves eth1 eth0\n\t   gateway 192.168.1.99\n\t   bond-lacp-rate 1\n\t   bond-xmit_hash_policy layer3+4\n\t   bond-downdelay 200\n\t   bond-updelay 200\n\t   bond-miimon 100\n\t   bond-mode 4\n\tiface bond0 inet6 static\n\t   address 2604:xxxx:x:xxxx::x\n\t   netmask 127\n\t   gateway 2604:xxxx:x:xxxx::\n\tauto bond0:0\n\tiface bond0:0 inet static\n\t   address 10.99.18.1\n\t   netmask 255.255.255.254\n\tauto eth1\n\tiface eth1 inet manual\n\t   pre-up sleep 4\n\t   bond-master bond0\n\t\tauto eth0\n\tiface eth0 inet manual\n\t   bond-master bond0\n\t   post-up route add -net 10.0.0.0/8 gw 10.99.18.0\n\t   post-down route del -net 10.0.0.0/8 gw 10.99.18.0\n       \n\tauto br0\n\tiface br0 inet static\n\t  address 192.168.2.97\n\t  netmask 255.255.255.248\n\t  bridge_ports none\n\t  bridge_stp off\n\t  bridge_fd 1\n\t  bridge_hello 2\n\t  bridge_maxage 12\n\nRouting table for host server\n\n\troot@5:~# route\n\tKernel IP routing table\n\tDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n\tdefault         192.168.1.99    0.0.0.0         UG    0      0        0 bond0\n\t10.0.0.0        10.99.18.0      255.0.0.0       UG    0      0        0 bond0\n\t10.99.18.0      *               255.255.255.254 U     0      0        0 bond0\n\t192.168.1.99    *               255.255.255.254 U     0      0        0 bond0\n\t192.168.2.96    *               255.255.255.248 U     0      0        0 br0\n\n\nIP routes\n\n\troot@5:~# ip route show\n\tdefault via 192.168.1.99 dev bond0 \n\t10.0.0.0/8 via 10.99.18.0 dev bond0 \n\t10.99.18.0/31 dev bond0  proto kernel  scope link  src 10.99.18.1 \n\t192.168.1.99/31 dev bond0  proto kernel  scope link  src 192.168.1.100 \n\t192.168.2.96/29 dev br0  proto kernel  scope link  src 192.168.2.97\n    \n\nopen /etc/sysctl.conf and uncomment these lines\n\n\tnet.ipv4.conf.all.rp_filter=1 \n\tnet.ipv4.ip_forward=1 \n\tnet.ipv6.conf.all.forwarding=1\n\nDelete default bridge virbr0\n\n\t$ virsh net-destroy default\n\t$ virsh net-undefine default\n\t$ service libvirtd restart\n\nAfter launching vm, our linux bridge status\n\n\troot@5:~# brctl show\n\tbridge name\tbridge id\t\tSTP enabled\tinterfaces\n\tbr0\t\t8000.fe00934bc462\tno\t\tvnet0\n\t\t\t\t\t\t\nHost network\n\n\troot@5:~# ifconfig\n\tbond0     Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n\t          inet addr:192.168.1.100  Bcast:255.255.255.255  Mask:255.255.255.254\n\t          inet6 addr: xxxx:xxxx:x:xxxx::x/127 Scope:Global\n\t          inet6 addr: fe80::e61d:2dff:fe54:2478/64 Scope:Link\n\t          UP BROADCAST RUNNING MASTER MULTICAST  MTU:1500  Metric:1\n\t          RX packets:844156 errors:0 dropped:2 overruns:0 frame:0\n\t          TX packets:798032 errors:0 dropped:7 overruns:0 carrier:0\n\t          collisions:0 txqueuelen:0 \n\t          RX bytes:106510529 (106.5 MB)  TX bytes:105652129 (105.6 MB)\n\n\tbond0:0   Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n\t          inet addr:10.99.18.1  Bcast:255.255.255.255  Mask:255.255.255.254\n        \t  UP BROADCAST RUNNING MASTER MULTICAST  MTU:1500  Metric:1\n\t\n\tbr0       Link encap:Ethernet  HWaddr fe:00:93:4b:c4:62  \n\t          inet addr:192.168.2.97  Bcast:192.168.2.103  Mask:255.255.255.248\n\t          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n\t          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n\t          RX packets:18701 errors:0 dropped:0 overruns:0 frame:0\n\t          TX packets:23053 errors:0 dropped:0 overruns:0 carrier:0\n\t          collisions:0 txqueuelen:0 \n\t          RX bytes:2995153 (2.9 MB)  TX bytes:7377649 (7.3 MB)\n\t\n\teth0      Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n\t          UP BROADCAST RUNNING SLAVE MULTICAST  MTU:1500  Metric:1\n\t          RX packets:395599 errors:0 dropped:1 overruns:0 frame:0\n\t          TX packets:393086 errors:0 dropped:0 overruns:0 carrier:0\n\t          collisions:0 txqueuelen:1000 \n\t          RX bytes:50710378 (50.7 MB)  TX bytes:52152210 (52.1 MB)\n\t\n\teth1      Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n\t          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n\t          UP BROADCAST RUNNING SLAVE MULTICAST  MTU:1500  Metric:1\n\t          RX packets:448557 errors:0 dropped:1 overruns:0 frame:0\n\t          TX packets:404946 errors:0 dropped:0 overruns:0 carrier:0\n\t          collisions:0 txqueuelen:1000 \n\t          RX bytes:55800151 (55.8 MB)  TX bytes:53499919 (53.4 MB)\n\t\n\tlo        Link encap:Local Loopback  \n\t          inet addr:127.0.0.1  Mask:255.0.0.0\n\t          inet6 addr: ::1/128 Scope:Host\n\t          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n\t          RX packets:7881551 errors:0 dropped:0 overruns:0 frame:0\n\t          TX packets:7881551 errors:0 dropped:0 overruns:0 carrier:0\n\t          collisions:0 txqueuelen:0 \n\t          RX bytes:8125571309 (8.1 GB)  TX bytes:8125571309 (8.1 GB)\n\t\n\tvnet0     Link encap:Ethernet  HWaddr fe:00:93:4b:c4:62  \n\t          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n\t          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          \t  RX packets:18428 errors:0 dropped:0 overruns:0 frame:0\n\t          TX packets:21459 errors:0 dropped:0 overruns:0 carrier:0\n          \t  collisions:0 txqueuelen:500 \n\t          RX bytes:3225260 (3.2 MB)  TX bytes:7307291 (7.3 MB)\n\t\t\t\nThats it for opennebula host server's network configuration.\n\nNow launch a vm from opennebula\n\nVM's network configuration\n\n\troot@t2:~# cat /etc/network/interfaces\n\tauto lo\n\tiface lo inet loopback\n\t\n\tauto eth0\n\tiface eth0 inet static\n\t  address 192.168.2.98\n\t  network 192.168.2.96\n\t  netmask 255.255.255.248\n\t  gateway 192.168.2.97\n\nVM's routing table\n\n\troot@t2:~# route\n\tKernel IP routing table\n\tDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n\tdefault         192.168.2.97   0.0.0.0         UG    0      0        0 eth0\n\t192.168.2.96   *               255.255.255.248 U     0      0        0 eth0\n\nip route\n\n\troot@t2:~# ip route show\n\tdefault via 192.168.2.97 dev eth0 \n\t192.168.2.96/29 dev eth0  proto kernel  scope link  src 192.168.2.98\n    \nNow i can connect with my vm from anywhere.\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaisu0019drgbtlg164pn","content":"<p>Our need is to setup <code>opennebula in packet.net</code>, so we have a server for both opennebula-frontend and opennebula-host. </p>\n<p>We have a local working server for opennbula-host with openvswitch. But in packet.net we tried normal linux bridge(brctl) and we face some problem in creating virtual machines, because of networking.</p>\n<pre><code>OS                : Ubuntu-14.04(trusty)\nHost IP        : 192.168.1.100\nAdditional IPs : 192.168.2.96/29\n</code></pre><p>NOTE: Actually we have public ips, but for security issues i documented with local ips.<br>Usually, when we create a server in packet.net, they will give you a single IP, then we need to request them for additional IPs.</p>\n<p>After trying many configuration, we succeed with the following configurations,</p>\n<p>NOTE: Use <code>chattr -i /etc/network/interfaces</code> to make the file writable.</p>\n<p>My Host server network configuration</p>\n<pre><code>#cat /etc/network/interfaces\nauto lo\niface lo inet loopback\n\nauto bond0\niface bond0 inet static\n   address 192.168.1.100\n   netmask 255.255.255.254\n   bond-slaves eth1 eth0\n   gateway 192.168.1.99\n   bond-lacp-rate 1\n   bond-xmit_hash_policy layer3+4\n   bond-downdelay 200\n   bond-updelay 200\n   bond-miimon 100\n   bond-mode 4\niface bond0 inet6 static\n   address 2604:xxxx:x:xxxx::x\n   netmask 127\n   gateway 2604:xxxx:x:xxxx::\nauto bond0:0\niface bond0:0 inet static\n   address 10.99.18.1\n   netmask 255.255.255.254\nauto eth1\niface eth1 inet manual\n   pre-up sleep 4\n   bond-master bond0\n    auto eth0\niface eth0 inet manual\n   bond-master bond0\n   post-up route add -net 10.0.0.0/8 gw 10.99.18.0\n   post-down route del -net 10.0.0.0/8 gw 10.99.18.0\n\nauto br0\niface br0 inet static\n  address 192.168.2.97\n  netmask 255.255.255.248\n  bridge_ports none\n  bridge_stp off\n  bridge_fd 1\n  bridge_hello 2\n  bridge_maxage 12\n</code></pre><p>Routing table for host server</p>\n<pre><code>root@5:~# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\ndefault         192.168.1.99    0.0.0.0         UG    0      0        0 bond0\n10.0.0.0        10.99.18.0      255.0.0.0       UG    0      0        0 bond0\n10.99.18.0      *               255.255.255.254 U     0      0        0 bond0\n192.168.1.99    *               255.255.255.254 U     0      0        0 bond0\n192.168.2.96    *               255.255.255.248 U     0      0        0 br0\n</code></pre><p>IP routes</p>\n<pre><code>root@5:~# ip route show\ndefault via 192.168.1.99 dev bond0 \n10.0.0.0/8 via 10.99.18.0 dev bond0 \n10.99.18.0/31 dev bond0  proto kernel  scope link  src 10.99.18.1 \n192.168.1.99/31 dev bond0  proto kernel  scope link  src 192.168.1.100 \n192.168.2.96/29 dev br0  proto kernel  scope link  src 192.168.2.97\n</code></pre><p>open /etc/sysctl.conf and uncomment these lines</p>\n<pre><code>net.ipv4.conf.all.rp_filter=1 \nnet.ipv4.ip_forward=1 \nnet.ipv6.conf.all.forwarding=1\n</code></pre><p>Delete default bridge virbr0</p>\n<pre><code>$ virsh net-destroy default\n$ virsh net-undefine default\n$ service libvirtd restart\n</code></pre><p>After launching vm, our linux bridge status</p>\n<pre><code>root@5:~# brctl show\nbridge name    bridge id        STP enabled    interfaces\nbr0        8000.fe00934bc462    no        vnet0\n</code></pre><p>Host network</p>\n<pre><code>root@5:~# ifconfig\nbond0     Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n          inet addr:192.168.1.100  Bcast:255.255.255.255  Mask:255.255.255.254\n          inet6 addr: xxxx:xxxx:x:xxxx::x/127 Scope:Global\n          inet6 addr: fe80::e61d:2dff:fe54:2478/64 Scope:Link\n          UP BROADCAST RUNNING MASTER MULTICAST  MTU:1500  Metric:1\n          RX packets:844156 errors:0 dropped:2 overruns:0 frame:0\n          TX packets:798032 errors:0 dropped:7 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:106510529 (106.5 MB)  TX bytes:105652129 (105.6 MB)\n\nbond0:0   Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n          inet addr:10.99.18.1  Bcast:255.255.255.255  Mask:255.255.255.254\n          UP BROADCAST RUNNING MASTER MULTICAST  MTU:1500  Metric:1\n\nbr0       Link encap:Ethernet  HWaddr fe:00:93:4b:c4:62  \n          inet addr:192.168.2.97  Bcast:192.168.2.103  Mask:255.255.255.248\n          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:18701 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:23053 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:2995153 (2.9 MB)  TX bytes:7377649 (7.3 MB)\n\neth0      Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n          UP BROADCAST RUNNING SLAVE MULTICAST  MTU:1500  Metric:1\n          RX packets:395599 errors:0 dropped:1 overruns:0 frame:0\n          TX packets:393086 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:50710378 (50.7 MB)  TX bytes:52152210 (52.1 MB)\n\neth1      Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n          UP BROADCAST RUNNING SLAVE MULTICAST  MTU:1500  Metric:1\n          RX packets:448557 errors:0 dropped:1 overruns:0 frame:0\n          TX packets:404946 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:55800151 (55.8 MB)  TX bytes:53499919 (53.4 MB)\n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:7881551 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:7881551 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:8125571309 (8.1 GB)  TX bytes:8125571309 (8.1 GB)\n\nvnet0     Link encap:Ethernet  HWaddr fe:00:93:4b:c4:62  \n          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n            RX packets:18428 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:21459 errors:0 dropped:0 overruns:0 carrier:0\n            collisions:0 txqueuelen:500 \n          RX bytes:3225260 (3.2 MB)  TX bytes:7307291 (7.3 MB)\n</code></pre><p>Thats it for opennebula host servers network configuration.</p>\n<p>Now launch a vm from opennebula</p>\n<p>VMs network configuration</p>\n<pre><code>root@t2:~# cat /etc/network/interfaces\nauto lo\niface lo inet loopback\n\nauto eth0\niface eth0 inet static\n  address 192.168.2.98\n  network 192.168.2.96\n  netmask 255.255.255.248\n  gateway 192.168.2.97\n</code></pre><p>VMs routing table</p>\n<pre><code>root@t2:~# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\ndefault         192.168.2.97   0.0.0.0         UG    0      0        0 eth0\n192.168.2.96   *               255.255.255.248 U     0      0        0 eth0\n</code></pre><p>ip route</p>\n<pre><code>root@t2:~# ip route show\ndefault via 192.168.2.97 dev eth0 \n192.168.2.96/29 dev eth0  proto kernel  scope link  src 192.168.2.98\n</code></pre><p>Now i can connect with my vm from anywhere.</p>\n","excerpt":"","more":"<p>Our need is to setup <code>opennebula in packet.net</code>, so we have a server for both opennebula-frontend and opennebula-host. </p>\n<p>We have a local working server for opennbula-host with openvswitch. But in packet.net we tried normal linux bridge(brctl) and we face some problem in creating virtual machines, because of networking.</p>\n<pre><code>OS                : Ubuntu-14.04(trusty)\nHost IP        : 192.168.1.100\nAdditional IPs : 192.168.2.96/29\n</code></pre><p>NOTE: Actually we have public ips, but for security issues i documented with local ips.<br>Usually, when we create a server in packet.net, they will give you a single IP, then we need to request them for additional IPs.</p>\n<p>After trying many configuration, we succeed with the following configurations,</p>\n<p>NOTE: Use <code>chattr -i /etc/network/interfaces</code> to make the file writable.</p>\n<p>My Host server network configuration</p>\n<pre><code>#cat /etc/network/interfaces\nauto lo\niface lo inet loopback\n\nauto bond0\niface bond0 inet static\n   address 192.168.1.100\n   netmask 255.255.255.254\n   bond-slaves eth1 eth0\n   gateway 192.168.1.99\n   bond-lacp-rate 1\n   bond-xmit_hash_policy layer3+4\n   bond-downdelay 200\n   bond-updelay 200\n   bond-miimon 100\n   bond-mode 4\niface bond0 inet6 static\n   address 2604:xxxx:x:xxxx::x\n   netmask 127\n   gateway 2604:xxxx:x:xxxx::\nauto bond0:0\niface bond0:0 inet static\n   address 10.99.18.1\n   netmask 255.255.255.254\nauto eth1\niface eth1 inet manual\n   pre-up sleep 4\n   bond-master bond0\n    auto eth0\niface eth0 inet manual\n   bond-master bond0\n   post-up route add -net 10.0.0.0/8 gw 10.99.18.0\n   post-down route del -net 10.0.0.0/8 gw 10.99.18.0\n\nauto br0\niface br0 inet static\n  address 192.168.2.97\n  netmask 255.255.255.248\n  bridge_ports none\n  bridge_stp off\n  bridge_fd 1\n  bridge_hello 2\n  bridge_maxage 12\n</code></pre><p>Routing table for host server</p>\n<pre><code>root@5:~# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\ndefault         192.168.1.99    0.0.0.0         UG    0      0        0 bond0\n10.0.0.0        10.99.18.0      255.0.0.0       UG    0      0        0 bond0\n10.99.18.0      *               255.255.255.254 U     0      0        0 bond0\n192.168.1.99    *               255.255.255.254 U     0      0        0 bond0\n192.168.2.96    *               255.255.255.248 U     0      0        0 br0\n</code></pre><p>IP routes</p>\n<pre><code>root@5:~# ip route show\ndefault via 192.168.1.99 dev bond0 \n10.0.0.0/8 via 10.99.18.0 dev bond0 \n10.99.18.0/31 dev bond0  proto kernel  scope link  src 10.99.18.1 \n192.168.1.99/31 dev bond0  proto kernel  scope link  src 192.168.1.100 \n192.168.2.96/29 dev br0  proto kernel  scope link  src 192.168.2.97\n</code></pre><p>open /etc/sysctl.conf and uncomment these lines</p>\n<pre><code>net.ipv4.conf.all.rp_filter=1 \nnet.ipv4.ip_forward=1 \nnet.ipv6.conf.all.forwarding=1\n</code></pre><p>Delete default bridge virbr0</p>\n<pre><code>$ virsh net-destroy default\n$ virsh net-undefine default\n$ service libvirtd restart\n</code></pre><p>After launching vm, our linux bridge status</p>\n<pre><code>root@5:~# brctl show\nbridge name    bridge id        STP enabled    interfaces\nbr0        8000.fe00934bc462    no        vnet0\n</code></pre><p>Host network</p>\n<pre><code>root@5:~# ifconfig\nbond0     Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n          inet addr:192.168.1.100  Bcast:255.255.255.255  Mask:255.255.255.254\n          inet6 addr: xxxx:xxxx:x:xxxx::x/127 Scope:Global\n          inet6 addr: fe80::e61d:2dff:fe54:2478/64 Scope:Link\n          UP BROADCAST RUNNING MASTER MULTICAST  MTU:1500  Metric:1\n          RX packets:844156 errors:0 dropped:2 overruns:0 frame:0\n          TX packets:798032 errors:0 dropped:7 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:106510529 (106.5 MB)  TX bytes:105652129 (105.6 MB)\n\nbond0:0   Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n          inet addr:10.99.18.1  Bcast:255.255.255.255  Mask:255.255.255.254\n          UP BROADCAST RUNNING MASTER MULTICAST  MTU:1500  Metric:1\n\nbr0       Link encap:Ethernet  HWaddr fe:00:93:4b:c4:62  \n          inet addr:192.168.2.97  Bcast:192.168.2.103  Mask:255.255.255.248\n          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:18701 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:23053 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:2995153 (2.9 MB)  TX bytes:7377649 (7.3 MB)\n\neth0      Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n          UP BROADCAST RUNNING SLAVE MULTICAST  MTU:1500  Metric:1\n          RX packets:395599 errors:0 dropped:1 overruns:0 frame:0\n          TX packets:393086 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:50710378 (50.7 MB)  TX bytes:52152210 (52.1 MB)\n\neth1      Link encap:Ethernet  HWaddr e4:1d:2d:54:24:78  \n          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n          UP BROADCAST RUNNING SLAVE MULTICAST  MTU:1500  Metric:1\n          RX packets:448557 errors:0 dropped:1 overruns:0 frame:0\n          TX packets:404946 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:55800151 (55.8 MB)  TX bytes:53499919 (53.4 MB)\n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:7881551 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:7881551 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:8125571309 (8.1 GB)  TX bytes:8125571309 (8.1 GB)\n\nvnet0     Link encap:Ethernet  HWaddr fe:00:93:4b:c4:62  \n          inet6 addr: xxxx::xxxx:xxxx:xxxx:xxxx/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n            RX packets:18428 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:21459 errors:0 dropped:0 overruns:0 carrier:0\n            collisions:0 txqueuelen:500 \n          RX bytes:3225260 (3.2 MB)  TX bytes:7307291 (7.3 MB)\n</code></pre><p>Thats it for opennebula host servers network configuration.</p>\n<p>Now launch a vm from opennebula</p>\n<p>VMs network configuration</p>\n<pre><code>root@t2:~# cat /etc/network/interfaces\nauto lo\niface lo inet loopback\n\nauto eth0\niface eth0 inet static\n  address 192.168.2.98\n  network 192.168.2.96\n  netmask 255.255.255.248\n  gateway 192.168.2.97\n</code></pre><p>VMs routing table</p>\n<pre><code>root@t2:~# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\ndefault         192.168.2.97   0.0.0.0         UG    0      0        0 eth0\n192.168.2.96   *               255.255.255.248 U     0      0        0 eth0\n</code></pre><p>ip route</p>\n<pre><code>root@t2:~# ip route show\ndefault via 192.168.2.97 dev eth0 \n192.168.2.96/29 dev eth0  proto kernel  scope link  src 192.168.2.98\n</code></pre><p>Now i can connect with my vm from anywhere.</p>\n"},{"title":"How to Launch CentOS 7.2 in MegamAfrica","slug":"2016-05-09-how-to-launch-centos","date_published":"2016-05-09T07:03:50.780Z","date_updated":"2016-05-27T05:00:33.152Z","_content":"\n###Introduction\n\nThe CentOS Linux distribution is a stable, predictable, manageable and reproducible platform derived from the sources of Red Hat Enterprise Linux (RHEL). CentOS Linux is developed by a small but growing team of core developers. In turn the core developers are supported by an active user community including system administrators, network administrators, managers, core Linux contributors, and Linux enthusiasts from around the world.\n\nThis tutorial will guide you in setting up a CentOS VM in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* An account on GitHub, which is a Git repository host.\nTo follow this tutorial :\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\nYou have to install openssh-server for ssh access.\n\n\t$ sudo yum install openssh-server\n    \nTo check the ssh is properly installed in our system\n\n\t$ ps aux | grep sshd\n\n###Step - 1 Creating CentOS VM\n\nThis initial section contains everything you need to get CentOS and running on your server.\n\nFirst, ensure the user can login to https://console.megamafrica.com. \n\n* Go to the Market Places.\n\n* Select the CentOS, A window will pop up with for CPU, storage, RAM and SSHkey options.\n\n* You can choose the storage size, RAM capacity.\n\n* You can Create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* click the Create button. it will create the virtual machine.\n\n###Step - 2 Access the CentOS VM\n\nNext, Go to the Dashboard and click the domain name a new window will open.\n\n* It contains the CPU, RAM and Network tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and Network usage.\n\n* VM Logs shows all the running process in VM.\n\n* You need to access the Virtual Machine from a terminal. \n\n* You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,\n\n\t\t$ ssh -i path to/<private_key filename> root@<ipaddress>\n\n###Conclusion\n\nThese are the very simple steps to launch CentOS in virtual machine. This is a good head-start for launching  CentOS in MegamAfrica.\n\n###Deploy your CentOS VM now\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n","source":"_posts/2016-05-09-how-to-launch-centos.md","raw":"---\ntitle: How to Launch CentOS 7.2 in MegamAfrica\nslug: how-to-launch-centos\ndate_published: 2016-05-09T12:33:50.780Z\ndate_updated:   2016-05-27T10:30:33.152Z\n---\n\n###Introduction\n\nThe CentOS Linux distribution is a stable, predictable, manageable and reproducible platform derived from the sources of Red Hat Enterprise Linux (RHEL). CentOS Linux is developed by a small but growing team of core developers. In turn the core developers are supported by an active user community including system administrators, network administrators, managers, core Linux contributors, and Linux enthusiasts from around the world.\n\nThis tutorial will guide you in setting up a CentOS VM in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* An account on GitHub, which is a Git repository host.\nTo follow this tutorial :\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\nYou have to install openssh-server for ssh access.\n\n\t$ sudo yum install openssh-server\n    \nTo check the ssh is properly installed in our system\n\n\t$ ps aux | grep sshd\n\n###Step - 1 Creating CentOS VM\n\nThis initial section contains everything you need to get CentOS and running on your server.\n\nFirst, ensure the user can login to https://console.megamafrica.com. \n\n* Go to the Market Places.\n\n* Select the CentOS, A window will pop up with for CPU, storage, RAM and SSHkey options.\n\n* You can choose the storage size, RAM capacity.\n\n* You can Create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* click the Create button. it will create the virtual machine.\n\n###Step - 2 Access the CentOS VM\n\nNext, Go to the Dashboard and click the domain name a new window will open.\n\n* It contains the CPU, RAM and Network tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and Network usage.\n\n* VM Logs shows all the running process in VM.\n\n* You need to access the Virtual Machine from a terminal. \n\n* You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,\n\n\t\t$ ssh -i path to/<private_key filename> root@<ipaddress>\n\n###Conclusion\n\nThese are the very simple steps to launch CentOS in virtual machine. This is a good head-start for launching  CentOS in MegamAfrica.\n\n###Deploy your CentOS VM now\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaisv001bdrgbg88bi7xs","content":"<p>###Introduction</p>\n<p>The CentOS Linux distribution is a stable, predictable, manageable and reproducible platform derived from the sources of Red Hat Enterprise Linux (RHEL). CentOS Linux is developed by a small but growing team of core developers. In turn the core developers are supported by an active user community including system administrators, network administrators, managers, core Linux contributors, and Linux enthusiasts from around the world.</p>\n<p>This tutorial will guide you in setting up a CentOS VM in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\" target=\"_blank\" rel=\"external\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>An account on GitHub, which is a Git repository host.<br>To follow this tutorial :</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a></p>\n</li>\n</ul>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>$ sudo yum install openssh-server\n</code></pre><p>To check the ssh is properly installed in our system</p>\n<pre><code>$ ps aux | grep sshd\n</code></pre><p>###Step - 1 Creating CentOS VM</p>\n<p>This initial section contains everything you need to get CentOS and running on your server.</p>\n<p>First, ensure the user can login to <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. </p>\n<ul>\n<li><p>Go to the Market Places.</p>\n</li>\n<li><p>Select the CentOS, A window will pop up with for CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can choose the storage size, RAM capacity.</p>\n</li>\n<li><p>You can Create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>click the Create button. it will create the virtual machine.</p>\n</li>\n</ul>\n<p>###Step - 2 Access the CentOS VM</p>\n<p>Next, Go to the Dashboard and click the domain name a new window will open.</p>\n<ul>\n<li><p>It contains the CPU, RAM and Network tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and Network usage.</p>\n</li>\n<li><p>VM Logs shows all the running process in VM.</p>\n</li>\n<li><p>You need to access the Virtual Machine from a terminal. </p>\n</li>\n<li><p>You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,</p>\n<pre><code>$ ssh -i path to/&lt;private_key filename&gt; root@&lt;ipaddress&gt;\n</code></pre></li>\n</ul>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch CentOS in virtual machine. This is a good head-start for launching  CentOS in MegamAfrica.</p>\n<p>###Deploy your CentOS VM now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###Introduction</p>\n<p>The CentOS Linux distribution is a stable, predictable, manageable and reproducible platform derived from the sources of Red Hat Enterprise Linux (RHEL). CentOS Linux is developed by a small but growing team of core developers. In turn the core developers are supported by an active user community including system administrators, network administrators, managers, core Linux contributors, and Linux enthusiasts from around the world.</p>\n<p>This tutorial will guide you in setting up a CentOS VM in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>An account on GitHub, which is a Git repository host.<br>To follow this tutorial :</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a></p>\n</li>\n</ul>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>$ sudo yum install openssh-server\n</code></pre><p>To check the ssh is properly installed in our system</p>\n<pre><code>$ ps aux | grep sshd\n</code></pre><p>###Step - 1 Creating CentOS VM</p>\n<p>This initial section contains everything you need to get CentOS and running on your server.</p>\n<p>First, ensure the user can login to <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. </p>\n<ul>\n<li><p>Go to the Market Places.</p>\n</li>\n<li><p>Select the CentOS, A window will pop up with for CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can choose the storage size, RAM capacity.</p>\n</li>\n<li><p>You can Create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>click the Create button. it will create the virtual machine.</p>\n</li>\n</ul>\n<p>###Step - 2 Access the CentOS VM</p>\n<p>Next, Go to the Dashboard and click the domain name a new window will open.</p>\n<ul>\n<li><p>It contains the CPU, RAM and Network tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and Network usage.</p>\n</li>\n<li><p>VM Logs shows all the running process in VM.</p>\n</li>\n<li><p>You need to access the Virtual Machine from a terminal. </p>\n</li>\n<li><p>You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,</p>\n<pre><code>$ ssh -i path to/&lt;private_key filename&gt; root@&lt;ipaddress&gt;\n</code></pre></li>\n</ul>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch CentOS in virtual machine. This is a good head-start for launching  CentOS in MegamAfrica.</p>\n<p>###Deploy your CentOS VM now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"How to Launch Debian Jessie in MegamAfrica","slug":"2016-05-09-how-to-launch-debian-jessie","date_published":"2016-05-09T07:29:54.449Z","date_updated":"2016-05-27T05:00:15.537Z","_content":"\n###Introduction\n\nDebian is a Unix-like computer operating system that is composed entirely of free software, most of which is under the GNU General Public License, and packaged by a group of individuals known as the Debian. Three main branches are offered: Stable, Testing and Unstable.\n\nThis tutorial will guide you in launching Debian Jessie in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* An account on GitHub, which is a Git repository host.\nTo follow this tutorial :\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\nYou have to install openssh-server for ssh access.\n\n\t$ sudo apt-get install openssh-server\n\nTo check the ssh is properly installed in our system\n\n\t$ ps aux | grep sshd\n    \n###Step - 1 Creating Debian Jessie VM\n\nThis initial section contains everything you need to get Debian Jessie and running on your server.\n\nFirst, ensure the user can login to https://console.megamafrica.com.  \n\n* Go to the Market Place.\n\n* Select the Debian, A window will pop up with for CPU, storage, RAM and SSHkey options.\n\n* You can choose the storage size and RAM capacity.\n\n* You can create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* Click the create button. it will create the virtual machine.\n\n###Step - 2 Access the Debian Jessie VM Machine\n\nNext, Go to the Dashboard and click the domain name a new window will open.\n\n* It contains the CPU, RAM and Network tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and Network usage.\n\n* VM Logs shows all the running process in VM.\n\n* You need to access the Virtual Machine from a terminal. \n\n* You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,\n\n\t    $ ssh -i path to/<private_key filename> root@<ipaddress>\n    \n\n###Conclusion\n\nThese are the very simple steps to launch Debian Jessie virtual machine. This is a good head-start for launching a Debian Jessie in MegamAfrica.\n\n###Deploy debian jessie now\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n","source":"_posts/2016-05-09-how-to-launch-debian-jessie.md","raw":"---\ntitle: How to Launch Debian Jessie in MegamAfrica\nslug: how-to-launch-debian-jessie\ndate_published: 2016-05-09T12:59:54.449Z\ndate_updated:   2016-05-27T10:30:15.537Z\n---\n\n###Introduction\n\nDebian is a Unix-like computer operating system that is composed entirely of free software, most of which is under the GNU General Public License, and packaged by a group of individuals known as the Debian. Three main branches are offered: Stable, Testing and Unstable.\n\nThis tutorial will guide you in launching Debian Jessie in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* An account on GitHub, which is a Git repository host.\nTo follow this tutorial :\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\nYou have to install openssh-server for ssh access.\n\n\t$ sudo apt-get install openssh-server\n\nTo check the ssh is properly installed in our system\n\n\t$ ps aux | grep sshd\n    \n###Step - 1 Creating Debian Jessie VM\n\nThis initial section contains everything you need to get Debian Jessie and running on your server.\n\nFirst, ensure the user can login to https://console.megamafrica.com.  \n\n* Go to the Market Place.\n\n* Select the Debian, A window will pop up with for CPU, storage, RAM and SSHkey options.\n\n* You can choose the storage size and RAM capacity.\n\n* You can create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* Click the create button. it will create the virtual machine.\n\n###Step - 2 Access the Debian Jessie VM Machine\n\nNext, Go to the Dashboard and click the domain name a new window will open.\n\n* It contains the CPU, RAM and Network tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and Network usage.\n\n* VM Logs shows all the running process in VM.\n\n* You need to access the Virtual Machine from a terminal. \n\n* You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,\n\n\t    $ ssh -i path to/<private_key filename> root@<ipaddress>\n    \n\n###Conclusion\n\nThese are the very simple steps to launch Debian Jessie virtual machine. This is a good head-start for launching a Debian Jessie in MegamAfrica.\n\n###Deploy debian jessie now\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaisy001cdrgbx1ef08wu","content":"<p>###Introduction</p>\n<p>Debian is a Unix-like computer operating system that is composed entirely of free software, most of which is under the GNU General Public License, and packaged by a group of individuals known as the Debian. Three main branches are offered: Stable, Testing and Unstable.</p>\n<p>This tutorial will guide you in launching Debian Jessie in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\" target=\"_blank\" rel=\"external\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>An account on GitHub, which is a Git repository host.<br>To follow this tutorial :</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a></p>\n</li>\n</ul>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>$ sudo apt-get install openssh-server\n</code></pre><p>To check the ssh is properly installed in our system</p>\n<pre><code>$ ps aux | grep sshd\n</code></pre><p>###Step - 1 Creating Debian Jessie VM</p>\n<p>This initial section contains everything you need to get Debian Jessie and running on your server.</p>\n<p>First, ensure the user can login to <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>.  </p>\n<ul>\n<li><p>Go to the Market Place.</p>\n</li>\n<li><p>Select the Debian, A window will pop up with for CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can choose the storage size and RAM capacity.</p>\n</li>\n<li><p>You can create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>Click the create button. it will create the virtual machine.</p>\n</li>\n</ul>\n<p>###Step - 2 Access the Debian Jessie VM Machine</p>\n<p>Next, Go to the Dashboard and click the domain name a new window will open.</p>\n<ul>\n<li><p>It contains the CPU, RAM and Network tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and Network usage.</p>\n</li>\n<li><p>VM Logs shows all the running process in VM.</p>\n</li>\n<li><p>You need to access the Virtual Machine from a terminal. </p>\n</li>\n<li><p>You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,</p>\n<pre><code>$ ssh -i path to/&lt;private_key filename&gt; root@&lt;ipaddress&gt;\n</code></pre></li>\n</ul>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch Debian Jessie virtual machine. This is a good head-start for launching a Debian Jessie in MegamAfrica.</p>\n<p>###Deploy debian jessie now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###Introduction</p>\n<p>Debian is a Unix-like computer operating system that is composed entirely of free software, most of which is under the GNU General Public License, and packaged by a group of individuals known as the Debian. Three main branches are offered: Stable, Testing and Unstable.</p>\n<p>This tutorial will guide you in launching Debian Jessie in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>An account on GitHub, which is a Git repository host.<br>To follow this tutorial :</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a></p>\n</li>\n</ul>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>$ sudo apt-get install openssh-server\n</code></pre><p>To check the ssh is properly installed in our system</p>\n<pre><code>$ ps aux | grep sshd\n</code></pre><p>###Step - 1 Creating Debian Jessie VM</p>\n<p>This initial section contains everything you need to get Debian Jessie and running on your server.</p>\n<p>First, ensure the user can login to <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>.  </p>\n<ul>\n<li><p>Go to the Market Place.</p>\n</li>\n<li><p>Select the Debian, A window will pop up with for CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can choose the storage size and RAM capacity.</p>\n</li>\n<li><p>You can create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>Click the create button. it will create the virtual machine.</p>\n</li>\n</ul>\n<p>###Step - 2 Access the Debian Jessie VM Machine</p>\n<p>Next, Go to the Dashboard and click the domain name a new window will open.</p>\n<ul>\n<li><p>It contains the CPU, RAM and Network tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and Network usage.</p>\n</li>\n<li><p>VM Logs shows all the running process in VM.</p>\n</li>\n<li><p>You need to access the Virtual Machine from a terminal. </p>\n</li>\n<li><p>You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,</p>\n<pre><code>$ ssh -i path to/&lt;private_key filename&gt; root@&lt;ipaddress&gt;\n</code></pre></li>\n</ul>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch Debian Jessie virtual machine. This is a good head-start for launching a Debian Jessie in MegamAfrica.</p>\n<p>###Deploy debian jessie now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"How to launch Java - spring-webflow in MegamAfrica","slug":"2016-05-09-how-to-launch-spring-webflow","date_published":"2016-05-09T09:28:36.118Z","date_updated":"2016-05-27T07:57:33.453Z","_content":"\n###**Introduction**\nSpring Web Flow facilitates building the j2EE based web applications that require guided navigation -- e.g. a shopping cart, flight check-in, a loan application, and many others. In contrast to stateless, free-form navigation such use cases have a clear start and end point, one or more screens to go through in a specific order, and a set of changes that are not finalized to the end.\n\nThis tutorial will guide you in launching a J2EE web application (spring-webflow) in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n###**Prerequisites**\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\nYou have to install openssh-server for ssh access.\n\n\tsudo apt-get install openssh-server\nCheck SSH working properly\n\n\tps aux | grep sshd\nIn this tutorial you will see the steps to launch the J2EE using Spring-webflow application.\n\n###Step-1 Fork spring web-flow\n\n* To fork spring web-flow  https://github.com/verticeapps/java_springwebflow.git\n\n* You will be see the fork option in the top right corner of the git hub page.click the fork option.\n\n* The spring web-flow repository is forked into your git repository.\n\n###Step-2 Launch the app\n1. Go to MegamAfrica Dashboard\n\n2. Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n3. Click Java Icon.A window will pop up for your git repository selection. \n\n4. Pick a repository by choosing your repository.\n\n  Let us use Github: < mygithub >/java_springwebflow.git\n\n5. You can create new sshkey or use an existing sshkey or upload your own sshkeys too.\n\n6. To launch J2EE App.Click Create.\n\n* Voila ! Your App is up to date.\n\n* Now that you have launched your app, you might want to launch a service (database) and bind it\n\n*Rember that when you select memory its upto `2GB`\n\n####Buildpack for Java\n\nJava's default build pack get's going by kicking of maven. We plan to support `ant`, `gradle` in the future\n\n\t#!/bin/bash\n\t#Java builder WAR\n\n\t#megam_java_builder/build tomcat \n\n\tmegam_home=\"/var/lib/megam/gulp\"\n\tlocal_repo=\"/home/megam/tomcat/webapps\"\n\tremote_repo=\"https://github.com/vinomca-megam/spring-webflow-samples.git\"\n\n\tfilename=$(basename \"$remote_repo\")\n\textension=\"${filename##*.}\"\n\tfilename=\"${filename%.*}\"\n\n      rm $local_repo/*.war\n      cd $megam_home\n      rm -r $filename\n      git clone $remote_repo\n      cd $filename\n      mvn clean\n      mvn install -Dmaven.test.skip=true -U\n      \n\tstop java\n\tstart java\n    \n###**Step-3 Open Your Web browser**\n  You can access your web page using `http://IP_ADDRESS:8080`\n\nYou will show the below UI\n![](/content/images/2016/05/1-1.png)\n\nSelect the Manager App.It asks User Name and Password\n`Username and password is \"megam\"`\n\nThen the below UI will be open\n\nHere you will click the webflow show case link.\n\n![](/content/images/2016/05/2.png)\n\n![](/content/images/2016/05/3-1.png)\n   \n  \n\n###Conclusion\n\nThese are the very simple steps to launch a J2EE web app (spring-webflow) using github repository.\n\n###Deploy Java app now \n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n","source":"_posts/2016-05-09-how-to-launch-spring-webflow.md","raw":"---\ntitle: How to launch Java - spring-webflow in MegamAfrica\nslug: how-to-launch-spring-webflow\ndate_published: 2016-05-09T14:58:36.118Z\ndate_updated:   2016-05-27T13:27:33.453Z\n---\n\n###**Introduction**\nSpring Web Flow facilitates building the j2EE based web applications that require guided navigation -- e.g. a shopping cart, flight check-in, a loan application, and many others. In contrast to stateless, free-form navigation such use cases have a clear start and end point, one or more screens to go through in a specific order, and a set of changes that are not finalized to the end.\n\nThis tutorial will guide you in launching a J2EE web application (spring-webflow) in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n###**Prerequisites**\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\nYou have to install openssh-server for ssh access.\n\n\tsudo apt-get install openssh-server\nCheck SSH working properly\n\n\tps aux | grep sshd\nIn this tutorial you will see the steps to launch the J2EE using Spring-webflow application.\n\n###Step-1 Fork spring web-flow\n\n* To fork spring web-flow  https://github.com/verticeapps/java_springwebflow.git\n\n* You will be see the fork option in the top right corner of the git hub page.click the fork option.\n\n* The spring web-flow repository is forked into your git repository.\n\n###Step-2 Launch the app\n1. Go to MegamAfrica Dashboard\n\n2. Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n3. Click Java Icon.A window will pop up for your git repository selection. \n\n4. Pick a repository by choosing your repository.\n\n  Let us use Github: < mygithub >/java_springwebflow.git\n\n5. You can create new sshkey or use an existing sshkey or upload your own sshkeys too.\n\n6. To launch J2EE App.Click Create.\n\n* Voila ! Your App is up to date.\n\n* Now that you have launched your app, you might want to launch a service (database) and bind it\n\n*Rember that when you select memory its upto `2GB`\n\n####Buildpack for Java\n\nJava's default build pack get's going by kicking of maven. We plan to support `ant`, `gradle` in the future\n\n\t#!/bin/bash\n\t#Java builder WAR\n\n\t#megam_java_builder/build tomcat \n\n\tmegam_home=\"/var/lib/megam/gulp\"\n\tlocal_repo=\"/home/megam/tomcat/webapps\"\n\tremote_repo=\"https://github.com/vinomca-megam/spring-webflow-samples.git\"\n\n\tfilename=$(basename \"$remote_repo\")\n\textension=\"${filename##*.}\"\n\tfilename=\"${filename%.*}\"\n\n      rm $local_repo/*.war\n      cd $megam_home\n      rm -r $filename\n      git clone $remote_repo\n      cd $filename\n      mvn clean\n      mvn install -Dmaven.test.skip=true -U\n      \n\tstop java\n\tstart java\n    \n###**Step-3 Open Your Web browser**\n  You can access your web page using `http://IP_ADDRESS:8080`\n\nYou will show the below UI\n![](/content/images/2016/05/1-1.png)\n\nSelect the Manager App.It asks User Name and Password\n`Username and password is \"megam\"`\n\nThen the below UI will be open\n\nHere you will click the webflow show case link.\n\n![](/content/images/2016/05/2.png)\n\n![](/content/images/2016/05/3-1.png)\n   \n  \n\n###Conclusion\n\nThese are the very simple steps to launch a J2EE web app (spring-webflow) using github repository.\n\n###Deploy Java app now \n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaisz001ddrgb1j8ubcge","content":"<p>###<strong>Introduction</strong><br>Spring Web Flow facilitates building the j2EE based web applications that require guided navigation  e.g. a shopping cart, flight check-in, a loan application, and many others. In contrast to stateless, free-form navigation such use cases have a clear start and end point, one or more screens to go through in a specific order, and a set of changes that are not finalized to the end.</p>\n<p>This tutorial will guide you in launching a J2EE web application (spring-webflow) in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>###<strong>Prerequisites</strong></p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\" target=\"_blank\" rel=\"external\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a></p>\n</li>\n</ul>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre><p>Check SSH working properly</p>\n<pre><code>ps aux | grep sshd\n</code></pre><p>In this tutorial you will see the steps to launch the J2EE using Spring-webflow application.</p>\n<p>###Step-1 Fork spring web-flow</p>\n<ul>\n<li><p>To fork spring web-flow  <a href=\"https://github.com/verticeapps/java_springwebflow.git\" target=\"_blank\" rel=\"external\">https://github.com/verticeapps/java_springwebflow.git</a></p>\n</li>\n<li><p>You will be see the fork option in the top right corner of the git hub page.click the fork option.</p>\n</li>\n<li><p>The spring web-flow repository is forked into your git repository.</p>\n</li>\n</ul>\n<p>###Step-2 Launch the app</p>\n<ol>\n<li><p>Go to MegamAfrica Dashboard</p>\n</li>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click Java Icon.A window will pop up for your git repository selection. </p>\n</li>\n<li><p>Pick a repository by choosing your repository.</p>\n<p>Let us use Github: &lt; mygithub &gt;/java_springwebflow.git</p>\n</li>\n<li><p>You can create new sshkey or use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>To launch J2EE App.Click Create.</p>\n</li>\n</ol>\n<ul>\n<li><p>Voila ! Your App is up to date.</p>\n</li>\n<li><p>Now that you have launched your app, you might want to launch a service (database) and bind it</p>\n</li>\n</ul>\n<p>*Rember that when you select memory its upto <code>2GB</code></p>\n<p>####Buildpack for Java</p>\n<p>Javas default build pack gets going by kicking of maven. We plan to support <code>ant</code>, <code>gradle</code> in the future</p>\n<pre><code>#!/bin/bash\n#Java builder WAR\n\n#megam_java_builder/build tomcat \n\nmegam_home=&quot;/var/lib/megam/gulp&quot;\nlocal_repo=&quot;/home/megam/tomcat/webapps&quot;\nremote_repo=&quot;https://github.com/vinomca-megam/spring-webflow-samples.git&quot;\n\nfilename=$(basename &quot;$remote_repo&quot;)\nextension=&quot;${filename##*.}&quot;\nfilename=&quot;${filename%.*}&quot;\n\n  rm $local_repo/*.war\n  cd $megam_home\n  rm -r $filename\n  git clone $remote_repo\n  cd $filename\n  mvn clean\n  mvn install -Dmaven.test.skip=true -U\n\nstop java\nstart java\n</code></pre><p>###<strong>Step-3 Open Your Web browser</strong><br>  You can access your web page using <code>http://IP_ADDRESS:8080</code></p>\n<p>You will show the below UI<br><img src=\"/content/images/2016/05/1-1.png\" alt=\"\"></p>\n<p>Select the Manager App.It asks User Name and Password<br><code>Username and password is &quot;megam&quot;</code></p>\n<p>Then the below UI will be open</p>\n<p>Here you will click the webflow show case link.</p>\n<p><img src=\"/content/images/2016/05/2.png\" alt=\"\"></p>\n<p><img src=\"/content/images/2016/05/3-1.png\" alt=\"\"></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch a J2EE web app (spring-webflow) using github repository.</p>\n<p>###Deploy Java app now<br><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###<strong>Introduction</strong><br>Spring Web Flow facilitates building the j2EE based web applications that require guided navigation  e.g. a shopping cart, flight check-in, a loan application, and many others. In contrast to stateless, free-form navigation such use cases have a clear start and end point, one or more screens to go through in a specific order, and a set of changes that are not finalized to the end.</p>\n<p>This tutorial will guide you in launching a J2EE web application (spring-webflow) in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>###<strong>Prerequisites</strong></p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a></p>\n</li>\n</ul>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre><p>Check SSH working properly</p>\n<pre><code>ps aux | grep sshd\n</code></pre><p>In this tutorial you will see the steps to launch the J2EE using Spring-webflow application.</p>\n<p>###Step-1 Fork spring web-flow</p>\n<ul>\n<li><p>To fork spring web-flow  <a href=\"https://github.com/verticeapps/java_springwebflow.git\">https://github.com/verticeapps/java_springwebflow.git</a></p>\n</li>\n<li><p>You will be see the fork option in the top right corner of the git hub page.click the fork option.</p>\n</li>\n<li><p>The spring web-flow repository is forked into your git repository.</p>\n</li>\n</ul>\n<p>###Step-2 Launch the app</p>\n<ol>\n<li><p>Go to MegamAfrica Dashboard</p>\n</li>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click Java Icon.A window will pop up for your git repository selection. </p>\n</li>\n<li><p>Pick a repository by choosing your repository.</p>\n<p>Let us use Github: &lt; mygithub &gt;/java_springwebflow.git</p>\n</li>\n<li><p>You can create new sshkey or use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>To launch J2EE App.Click Create.</p>\n</li>\n</ol>\n<ul>\n<li><p>Voila ! Your App is up to date.</p>\n</li>\n<li><p>Now that you have launched your app, you might want to launch a service (database) and bind it</p>\n</li>\n</ul>\n<p>*Rember that when you select memory its upto <code>2GB</code></p>\n<p>####Buildpack for Java</p>\n<p>Javas default build pack gets going by kicking of maven. We plan to support <code>ant</code>, <code>gradle</code> in the future</p>\n<pre><code>#!/bin/bash\n#Java builder WAR\n\n#megam_java_builder/build tomcat \n\nmegam_home=&quot;/var/lib/megam/gulp&quot;\nlocal_repo=&quot;/home/megam/tomcat/webapps&quot;\nremote_repo=&quot;https://github.com/vinomca-megam/spring-webflow-samples.git&quot;\n\nfilename=$(basename &quot;$remote_repo&quot;)\nextension=&quot;${filename##*.}&quot;\nfilename=&quot;${filename%.*}&quot;\n\n  rm $local_repo/*.war\n  cd $megam_home\n  rm -r $filename\n  git clone $remote_repo\n  cd $filename\n  mvn clean\n  mvn install -Dmaven.test.skip=true -U\n\nstop java\nstart java\n</code></pre><p>###<strong>Step-3 Open Your Web browser</strong><br>  You can access your web page using <code>http://IP_ADDRESS:8080</code></p>\n<p>You will show the below UI<br><img src=\"/content/images/2016/05/1-1.png\" alt=\"\"></p>\n<p>Select the Manager App.It asks User Name and Password<br><code>Username and password is &quot;megam&quot;</code></p>\n<p>Then the below UI will be open</p>\n<p>Here you will click the webflow show case link.</p>\n<p><img src=\"/content/images/2016/05/2.png\" alt=\"\"></p>\n<p><img src=\"/content/images/2016/05/3-1.png\" alt=\"\"></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch a J2EE web app (spring-webflow) using github repository.</p>\n<p>###Deploy Java app now<br><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"How to Launch Ubuntu 14.04 in MegamAfrica","slug":"2016-05-09-launch-ubuntu","date_published":"2016-05-09T05:13:06.342Z","date_updated":"2016-05-27T06:04:25.986Z","_content":"\n###Introduction\n\nUbuntu is a Debian-based Linux operating system and distribution for personal computers, smartphones and network servers. It uses Unity as its default user interface. It is based on free software and named after the Southern African philosophy of ubuntu. \n\nThis tutorial will guide you in setting up a Ubuntu 14.04 VM in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* An account on GitHub, which is a Git repository host.\nTo follow this tutorial :\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\nYou have to install openssh-server for ssh access.\n\n\t$ sudo apt-get install openssh-server\n\nTo check the ssh is properly installed in our system\n\n\t$ ps aux | grep sshd\n    \n###Step - 1 Creating Ubuntu VM\n\nThis initial section contains everything you need to get Ubuntu and running on your server.\n\nFirst, ensure the user can login to https://console.megamafrica.com.  \n\n* Go to the Market Places.\n\n* Select the Ubuntu, A window will pop up with for CPU, storage, RAM and SSHkey options.\n\n* You can choose the storage size, RAM capacity.\n\n* You can Create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* click the Create button. it will create the virtual machine.\n\n###Step - 2 Access the Ubuntu VM\n\nNext, Go to the Dashboard and click the domain name a new window will open.\n\n* It contains the CPU, RAM and Network tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and Network usage.\n\n* VM Logs shows all the running process in VM.\n\n* You need to access the Virtual Machine from a terminal. \n\n* You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,\n\n\t\t$ ssh -i path to/<private_key filename> root@<ipaddress>\n\n###Conclusion\n\nThese are the very simple steps to launch Ubuntu virtual machine. This is a good head-start for launching a Ubuntu in MegamAfrica.\n\n###Deploy your Ubuntu VM now\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n","source":"_posts/2016-05-09-launch-ubuntu.md","raw":"---\ntitle: How to Launch Ubuntu 14.04 in MegamAfrica\nslug: launch-ubuntu\ndate_published: 2016-05-09T10:43:06.342Z\ndate_updated:   2016-05-27T11:34:25.986Z\n---\n\n###Introduction\n\nUbuntu is a Debian-based Linux operating system and distribution for personal computers, smartphones and network servers. It uses Unity as its default user interface. It is based on free software and named after the Southern African philosophy of ubuntu. \n\nThis tutorial will guide you in setting up a Ubuntu 14.04 VM in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* An account on GitHub, which is a Git repository host.\nTo follow this tutorial :\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\nYou have to install openssh-server for ssh access.\n\n\t$ sudo apt-get install openssh-server\n\nTo check the ssh is properly installed in our system\n\n\t$ ps aux | grep sshd\n    \n###Step - 1 Creating Ubuntu VM\n\nThis initial section contains everything you need to get Ubuntu and running on your server.\n\nFirst, ensure the user can login to https://console.megamafrica.com.  \n\n* Go to the Market Places.\n\n* Select the Ubuntu, A window will pop up with for CPU, storage, RAM and SSHkey options.\n\n* You can choose the storage size, RAM capacity.\n\n* You can Create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* click the Create button. it will create the virtual machine.\n\n###Step - 2 Access the Ubuntu VM\n\nNext, Go to the Dashboard and click the domain name a new window will open.\n\n* It contains the CPU, RAM and Network tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and Network usage.\n\n* VM Logs shows all the running process in VM.\n\n* You need to access the Virtual Machine from a terminal. \n\n* You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,\n\n\t\t$ ssh -i path to/<private_key filename> root@<ipaddress>\n\n###Conclusion\n\nThese are the very simple steps to launch Ubuntu virtual machine. This is a good head-start for launching a Ubuntu in MegamAfrica.\n\n###Deploy your Ubuntu VM now\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzait1001edrgb15t99moo","content":"<p>###Introduction</p>\n<p>Ubuntu is a Debian-based Linux operating system and distribution for personal computers, smartphones and network servers. It uses Unity as its default user interface. It is based on free software and named after the Southern African philosophy of ubuntu. </p>\n<p>This tutorial will guide you in setting up a Ubuntu 14.04 VM in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\" target=\"_blank\" rel=\"external\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>An account on GitHub, which is a Git repository host.<br>To follow this tutorial :</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a></p>\n</li>\n</ul>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>$ sudo apt-get install openssh-server\n</code></pre><p>To check the ssh is properly installed in our system</p>\n<pre><code>$ ps aux | grep sshd\n</code></pre><p>###Step - 1 Creating Ubuntu VM</p>\n<p>This initial section contains everything you need to get Ubuntu and running on your server.</p>\n<p>First, ensure the user can login to <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>.  </p>\n<ul>\n<li><p>Go to the Market Places.</p>\n</li>\n<li><p>Select the Ubuntu, A window will pop up with for CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can choose the storage size, RAM capacity.</p>\n</li>\n<li><p>You can Create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>click the Create button. it will create the virtual machine.</p>\n</li>\n</ul>\n<p>###Step - 2 Access the Ubuntu VM</p>\n<p>Next, Go to the Dashboard and click the domain name a new window will open.</p>\n<ul>\n<li><p>It contains the CPU, RAM and Network tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and Network usage.</p>\n</li>\n<li><p>VM Logs shows all the running process in VM.</p>\n</li>\n<li><p>You need to access the Virtual Machine from a terminal. </p>\n</li>\n<li><p>You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,</p>\n<pre><code>$ ssh -i path to/&lt;private_key filename&gt; root@&lt;ipaddress&gt;\n</code></pre></li>\n</ul>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch Ubuntu virtual machine. This is a good head-start for launching a Ubuntu in MegamAfrica.</p>\n<p>###Deploy your Ubuntu VM now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###Introduction</p>\n<p>Ubuntu is a Debian-based Linux operating system and distribution for personal computers, smartphones and network servers. It uses Unity as its default user interface. It is based on free software and named after the Southern African philosophy of ubuntu. </p>\n<p>This tutorial will guide you in setting up a Ubuntu 14.04 VM in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>An account on GitHub, which is a Git repository host.<br>To follow this tutorial :</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a></p>\n</li>\n</ul>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>$ sudo apt-get install openssh-server\n</code></pre><p>To check the ssh is properly installed in our system</p>\n<pre><code>$ ps aux | grep sshd\n</code></pre><p>###Step - 1 Creating Ubuntu VM</p>\n<p>This initial section contains everything you need to get Ubuntu and running on your server.</p>\n<p>First, ensure the user can login to <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>.  </p>\n<ul>\n<li><p>Go to the Market Places.</p>\n</li>\n<li><p>Select the Ubuntu, A window will pop up with for CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can choose the storage size, RAM capacity.</p>\n</li>\n<li><p>You can Create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>click the Create button. it will create the virtual machine.</p>\n</li>\n</ul>\n<p>###Step - 2 Access the Ubuntu VM</p>\n<p>Next, Go to the Dashboard and click the domain name a new window will open.</p>\n<ul>\n<li><p>It contains the CPU, RAM and Network tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and Network usage.</p>\n</li>\n<li><p>VM Logs shows all the running process in VM.</p>\n</li>\n<li><p>You need to access the Virtual Machine from a terminal. </p>\n</li>\n<li><p>You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,</p>\n<pre><code>$ ssh -i path to/&lt;private_key filename&gt; root@&lt;ipaddress&gt;\n</code></pre></li>\n</ul>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch Ubuntu virtual machine. This is a good head-start for launching a Ubuntu in MegamAfrica.</p>\n<p>###Deploy your Ubuntu VM now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"How to launch Java - continious integration jenkins in MegamAfrica","slug":"2016-05-09-launching-jenkins","date_published":"2016-05-09T07:54:25.010Z","date_updated":"2016-05-27T07:59:43.718Z","_content":"\n###**Introduction**\n\nJenkins is the leading open-source automation server. Built with Java, it provides over 1000 plugins to support automating virtually anything, so that humans can actually spend their time doing things machines cannot.\n\nThis tutorial will guide you in launching a J2EE web application () in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n###**Prerequisites**\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\nYou have to install openssh-server for ssh access.\n\n\tsudo apt-get install openssh-server\n    \nCheck SSH working properly \n\n\tps aux | grep sshd\n    \nIn this tutorial you will see the steps to launch the J2EE using jenkins\n\n###Step-1 Fork jenkins\n\n* Fork jenkins from https://github.com/verticeapps/java_jenkins.git\n\n* You will be see the fork option in the top right corner of the git hub page.click the fork option.\n\n* The jenkins repository is forked into your git repository\n\n\n###Step-2 Launch the app\n1. Go to MegamAfrica Dashboard\n\n2. Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n3. Click Java Icon.A window will pop up for your repository selection. \n\n4. Pick a repository by choosing your repository.\n\n  Let us use Github: < mygithub >/java_jenkins.git\n\n5. You can create new sshkey, use an existing sshkey or upload your own sshkeys too.\n\n6. Launch Java App.Click Create.\n\n* Voila ! Your App is up to date.\n\n* Now that you have launched your app, you might want to launch a service (database) and bind it\n\n*Rember that when you select memory its upto `2GB`\n\n\n####Buildpack for java\nJava's default build pack get's going by kicking of maven. We plan to support `ant`, `gradle` in the future\n\n\t#!/bin/bash\n\tmegam_home=\"/var/lib/megam/gulp\"\n\tlocal_repo=\"/home/megam/tomcat/webapps\"\n\tremote_repo=\"https://github.com/vinomca-megam/jenkins.git\"\n\tfilename=$(basename \"$remote_repo\")\n\textension=\"${filename##*.}\"\n\tfilename=\"${filename%.*}\"\n\n      rm $local_repo/*.war\n      cd $megam_home\n      rm -r $filename\n      git clone $remote_repo\n      cd $filename\n      mvn clean\n      mvn install -Dmaven.test.skip=true -U\n    stop java\n    start java\n\n\n\n###**Step-3 Open Your Web browser**\n  You can access your web page using `http://IP_ADDRESS:8080`\n\nThen the below UI will be open\n\n![](/content/images/2016/05/1-2.png)\n\nSelect the Manager App.It asks User Name and Password\n`Username and password is \"megam\"`\n\n![](/content/images/2016/05/j2.png)\n\nHere you will click the `jenkins` link.\n* (or) the url to launch jenkins\n`http://IP_ADDRESS:8080/jenkins`\n\n![](/content/images/2016/05/j3.png)\n\n  \n###Conclusion\n\nThese are the very simple steps to launch a J2EE web app (jenkins) using github repository.\n\n\n###Deploy Java app now \n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n\n\n\n\n\n","source":"_posts/2016-05-09-launching-jenkins.md","raw":"---\ntitle: How to launch Java - continious integration jenkins in MegamAfrica\nslug: launching-jenkins\ndate_published: 2016-05-09T13:24:25.010Z\ndate_updated:   2016-05-27T13:29:43.718Z\n---\n\n###**Introduction**\n\nJenkins is the leading open-source automation server. Built with Java, it provides over 1000 plugins to support automating virtually anything, so that humans can actually spend their time doing things machines cannot.\n\nThis tutorial will guide you in launching a J2EE web application () in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n###**Prerequisites**\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\nYou have to install openssh-server for ssh access.\n\n\tsudo apt-get install openssh-server\n    \nCheck SSH working properly \n\n\tps aux | grep sshd\n    \nIn this tutorial you will see the steps to launch the J2EE using jenkins\n\n###Step-1 Fork jenkins\n\n* Fork jenkins from https://github.com/verticeapps/java_jenkins.git\n\n* You will be see the fork option in the top right corner of the git hub page.click the fork option.\n\n* The jenkins repository is forked into your git repository\n\n\n###Step-2 Launch the app\n1. Go to MegamAfrica Dashboard\n\n2. Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n3. Click Java Icon.A window will pop up for your repository selection. \n\n4. Pick a repository by choosing your repository.\n\n  Let us use Github: < mygithub >/java_jenkins.git\n\n5. You can create new sshkey, use an existing sshkey or upload your own sshkeys too.\n\n6. Launch Java App.Click Create.\n\n* Voila ! Your App is up to date.\n\n* Now that you have launched your app, you might want to launch a service (database) and bind it\n\n*Rember that when you select memory its upto `2GB`\n\n\n####Buildpack for java\nJava's default build pack get's going by kicking of maven. We plan to support `ant`, `gradle` in the future\n\n\t#!/bin/bash\n\tmegam_home=\"/var/lib/megam/gulp\"\n\tlocal_repo=\"/home/megam/tomcat/webapps\"\n\tremote_repo=\"https://github.com/vinomca-megam/jenkins.git\"\n\tfilename=$(basename \"$remote_repo\")\n\textension=\"${filename##*.}\"\n\tfilename=\"${filename%.*}\"\n\n      rm $local_repo/*.war\n      cd $megam_home\n      rm -r $filename\n      git clone $remote_repo\n      cd $filename\n      mvn clean\n      mvn install -Dmaven.test.skip=true -U\n    stop java\n    start java\n\n\n\n###**Step-3 Open Your Web browser**\n  You can access your web page using `http://IP_ADDRESS:8080`\n\nThen the below UI will be open\n\n![](/content/images/2016/05/1-2.png)\n\nSelect the Manager App.It asks User Name and Password\n`Username and password is \"megam\"`\n\n![](/content/images/2016/05/j2.png)\n\nHere you will click the `jenkins` link.\n* (or) the url to launch jenkins\n`http://IP_ADDRESS:8080/jenkins`\n\n![](/content/images/2016/05/j3.png)\n\n  \n###Conclusion\n\nThese are the very simple steps to launch a J2EE web app (jenkins) using github repository.\n\n\n###Deploy Java app now \n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n\n\n\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzait2001fdrgbhg82k2gz","content":"<p>###<strong>Introduction</strong></p>\n<p>Jenkins is the leading open-source automation server. Built with Java, it provides over 1000 plugins to support automating virtually anything, so that humans can actually spend their time doing things machines cannot.</p>\n<p>This tutorial will guide you in launching a J2EE web application () in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>###<strong>Prerequisites</strong></p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\" target=\"_blank\" rel=\"external\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a></p>\n</li>\n</ul>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre><p>Check SSH working properly </p>\n<pre><code>ps aux | grep sshd\n</code></pre><p>In this tutorial you will see the steps to launch the J2EE using jenkins</p>\n<p>###Step-1 Fork jenkins</p>\n<ul>\n<li><p>Fork jenkins from <a href=\"https://github.com/verticeapps/java_jenkins.git\" target=\"_blank\" rel=\"external\">https://github.com/verticeapps/java_jenkins.git</a></p>\n</li>\n<li><p>You will be see the fork option in the top right corner of the git hub page.click the fork option.</p>\n</li>\n<li><p>The jenkins repository is forked into your git repository</p>\n</li>\n</ul>\n<p>###Step-2 Launch the app</p>\n<ol>\n<li><p>Go to MegamAfrica Dashboard</p>\n</li>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click Java Icon.A window will pop up for your repository selection. </p>\n</li>\n<li><p>Pick a repository by choosing your repository.</p>\n<p>Let us use Github: &lt; mygithub &gt;/java_jenkins.git</p>\n</li>\n<li><p>You can create new sshkey, use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>Launch Java App.Click Create.</p>\n</li>\n</ol>\n<ul>\n<li><p>Voila ! Your App is up to date.</p>\n</li>\n<li><p>Now that you have launched your app, you might want to launch a service (database) and bind it</p>\n</li>\n</ul>\n<p>*Rember that when you select memory its upto <code>2GB</code></p>\n<p>####Buildpack for java<br>Javas default build pack gets going by kicking of maven. We plan to support <code>ant</code>, <code>gradle</code> in the future</p>\n<pre><code>#!/bin/bash\nmegam_home=&quot;/var/lib/megam/gulp&quot;\nlocal_repo=&quot;/home/megam/tomcat/webapps&quot;\nremote_repo=&quot;https://github.com/vinomca-megam/jenkins.git&quot;\nfilename=$(basename &quot;$remote_repo&quot;)\nextension=&quot;${filename##*.}&quot;\nfilename=&quot;${filename%.*}&quot;\n\n  rm $local_repo/*.war\n  cd $megam_home\n  rm -r $filename\n  git clone $remote_repo\n  cd $filename\n  mvn clean\n  mvn install -Dmaven.test.skip=true -U\nstop java\nstart java\n</code></pre><p>###<strong>Step-3 Open Your Web browser</strong><br>  You can access your web page using <code>http://IP_ADDRESS:8080</code></p>\n<p>Then the below UI will be open</p>\n<p><img src=\"/content/images/2016/05/1-2.png\" alt=\"\"></p>\n<p>Select the Manager App.It asks User Name and Password<br><code>Username and password is &quot;megam&quot;</code></p>\n<p><img src=\"/content/images/2016/05/j2.png\" alt=\"\"></p>\n<p>Here you will click the <code>jenkins</code> link.</p>\n<ul>\n<li>(or) the url to launch jenkins<br><code>http://IP_ADDRESS:8080/jenkins</code></li>\n</ul>\n<p><img src=\"/content/images/2016/05/j3.png\" alt=\"\"></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch a J2EE web app (jenkins) using github repository.</p>\n<p>###Deploy Java app now<br><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###<strong>Introduction</strong></p>\n<p>Jenkins is the leading open-source automation server. Built with Java, it provides over 1000 plugins to support automating virtually anything, so that humans can actually spend their time doing things machines cannot.</p>\n<p>This tutorial will guide you in launching a J2EE web application () in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>###<strong>Prerequisites</strong></p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a></p>\n</li>\n</ul>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre><p>Check SSH working properly </p>\n<pre><code>ps aux | grep sshd\n</code></pre><p>In this tutorial you will see the steps to launch the J2EE using jenkins</p>\n<p>###Step-1 Fork jenkins</p>\n<ul>\n<li><p>Fork jenkins from <a href=\"https://github.com/verticeapps/java_jenkins.git\">https://github.com/verticeapps/java_jenkins.git</a></p>\n</li>\n<li><p>You will be see the fork option in the top right corner of the git hub page.click the fork option.</p>\n</li>\n<li><p>The jenkins repository is forked into your git repository</p>\n</li>\n</ul>\n<p>###Step-2 Launch the app</p>\n<ol>\n<li><p>Go to MegamAfrica Dashboard</p>\n</li>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click Java Icon.A window will pop up for your repository selection. </p>\n</li>\n<li><p>Pick a repository by choosing your repository.</p>\n<p>Let us use Github: &lt; mygithub &gt;/java_jenkins.git</p>\n</li>\n<li><p>You can create new sshkey, use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>Launch Java App.Click Create.</p>\n</li>\n</ol>\n<ul>\n<li><p>Voila ! Your App is up to date.</p>\n</li>\n<li><p>Now that you have launched your app, you might want to launch a service (database) and bind it</p>\n</li>\n</ul>\n<p>*Rember that when you select memory its upto <code>2GB</code></p>\n<p>####Buildpack for java<br>Javas default build pack gets going by kicking of maven. We plan to support <code>ant</code>, <code>gradle</code> in the future</p>\n<pre><code>#!/bin/bash\nmegam_home=&quot;/var/lib/megam/gulp&quot;\nlocal_repo=&quot;/home/megam/tomcat/webapps&quot;\nremote_repo=&quot;https://github.com/vinomca-megam/jenkins.git&quot;\nfilename=$(basename &quot;$remote_repo&quot;)\nextension=&quot;${filename##*.}&quot;\nfilename=&quot;${filename%.*}&quot;\n\n  rm $local_repo/*.war\n  cd $megam_home\n  rm -r $filename\n  git clone $remote_repo\n  cd $filename\n  mvn clean\n  mvn install -Dmaven.test.skip=true -U\nstop java\nstart java\n</code></pre><p>###<strong>Step-3 Open Your Web browser</strong><br>  You can access your web page using <code>http://IP_ADDRESS:8080</code></p>\n<p>Then the below UI will be open</p>\n<p><img src=\"/content/images/2016/05/1-2.png\" alt=\"\"></p>\n<p>Select the Manager App.It asks User Name and Password<br><code>Username and password is &quot;megam&quot;</code></p>\n<p><img src=\"/content/images/2016/05/j2.png\" alt=\"\"></p>\n<p>Here you will click the <code>jenkins</code> link.</p>\n<ul>\n<li>(or) the url to launch jenkins<br><code>http://IP_ADDRESS:8080/jenkins</code></li>\n</ul>\n<p><img src=\"/content/images/2016/05/j3.png\" alt=\"\"></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch a J2EE web app (jenkins) using github repository.</p>\n<p>###Deploy Java app now<br><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"How to launch PHP - PostageApp in MegamAfrica","slug":"2016-05-10-how-to-launch-postageapp-in-php","date_published":"2016-05-10T04:21:33.815Z","date_updated":"2016-05-27T07:09:33.982Z","_content":"\n####Introduction\n\n   The PostageApp is used in quick way to deliver the email. This application supports PHP.It optionally attachs it to the mail server.\n   \nThis tutorial will guide you in launching a php web application (PostageApp) in MegamAfrica.\n   \n   <a href=\"https://console.megamafrica.com\"target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png \" alt=\"wordpres button\" /></a>\n\n####Prerequisites\n \n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your workstation, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\n * You have to install openssh-server for ssh access in your local system.\n\n     \n         sudo apt-get install openssh-server\n   \n check SSH installed on your system\n \n        ps aux | grep sshd\n   \n###Step-1 Fork PostageApp\n* Fork PostageApp\nfrom https://github.com/verticeapps/php_postage.git\n\n* You will be see the fork option in the top right corner of the git hub page.click the fork option.\n\n* The php_postage repository is forked into your git repository\n\n####Step - 2 Launch PostageApp\n1. Go to MegamAfrica Dashboard\n\n2. Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n4. Click PHP Icon.A window will pop up for your repository selection. \n\n3. Pick a repository by choosing your repository.\n\n  Let us use Github: < mygithub >/php_postage.git\n\n5. You can create new sshkey, use an existing sshkey or upload your own sshkeys too.\n\n6. Launch PHP App.Click Create.\n\n* Voila ! Your App is up to date.\n\n* Now that you have launched your app, you might want to launch a service (database) and bind it\n####Step - 2 Buildpack for php\n\nWe use a default PHP build pack using our super cool chef-repo. \n\n      #!/bin/bash\n      #Php builder\n      #megam_php \n      local_repo=/var/www/html/current \n      remote_repo=https://github.com/verticeapps/php_postage.git\n      megam_home=/var/lib/megam/gulp\n      filename=$(basename \"$remote_repo\")\n      extension=\"${filename##*.}\"\n      project=\"${filename%.*}\"\n      cd $megam_home\n      rm -r $project\n      git clone $remote_repo\n      rm -r $local_repo/*\n      mv ./$project/* $local_repo\n      cd $project\n      if [  -f \"./$project/start\" ]; then\n      chmod 755 ./$project/start\n      ./$project/start\n      fi\n      service apache2 restart\n\n\n####Step - 3 Open Your Web Browser\n\nYou can access your web page using http://IP_ADDRESS/current\n\n![](/content/images/2016/05/postage4.png)\n\n\nVoila ! Your App is up to date.\n####Conclusion\nThese are the very simple steps to launch a php web app (PostageApp) using github repository.\n\n####Deploy PHP app now\n\n<a href=\"https://console.megamafrica.com\"target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png \" alt=\"wordpres button\" /></a>\n","source":"_posts/2016-05-10-how-to-launch-postageapp-in-php.md","raw":"---\ntitle: How to launch PHP - PostageApp in MegamAfrica\nslug: how-to-launch-postageapp-in-php\ndate_published: 2016-05-10T09:51:33.815Z\ndate_updated:   2016-05-27T12:39:33.982Z\n---\n\n####Introduction\n\n   The PostageApp is used in quick way to deliver the email. This application supports PHP.It optionally attachs it to the mail server.\n   \nThis tutorial will guide you in launching a php web application (PostageApp) in MegamAfrica.\n   \n   <a href=\"https://console.megamafrica.com\"target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png \" alt=\"wordpres button\" /></a>\n\n####Prerequisites\n \n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your workstation, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\n * You have to install openssh-server for ssh access in your local system.\n\n     \n         sudo apt-get install openssh-server\n   \n check SSH installed on your system\n \n        ps aux | grep sshd\n   \n###Step-1 Fork PostageApp\n* Fork PostageApp\nfrom https://github.com/verticeapps/php_postage.git\n\n* You will be see the fork option in the top right corner of the git hub page.click the fork option.\n\n* The php_postage repository is forked into your git repository\n\n####Step - 2 Launch PostageApp\n1. Go to MegamAfrica Dashboard\n\n2. Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n4. Click PHP Icon.A window will pop up for your repository selection. \n\n3. Pick a repository by choosing your repository.\n\n  Let us use Github: < mygithub >/php_postage.git\n\n5. You can create new sshkey, use an existing sshkey or upload your own sshkeys too.\n\n6. Launch PHP App.Click Create.\n\n* Voila ! Your App is up to date.\n\n* Now that you have launched your app, you might want to launch a service (database) and bind it\n####Step - 2 Buildpack for php\n\nWe use a default PHP build pack using our super cool chef-repo. \n\n      #!/bin/bash\n      #Php builder\n      #megam_php \n      local_repo=/var/www/html/current \n      remote_repo=https://github.com/verticeapps/php_postage.git\n      megam_home=/var/lib/megam/gulp\n      filename=$(basename \"$remote_repo\")\n      extension=\"${filename##*.}\"\n      project=\"${filename%.*}\"\n      cd $megam_home\n      rm -r $project\n      git clone $remote_repo\n      rm -r $local_repo/*\n      mv ./$project/* $local_repo\n      cd $project\n      if [  -f \"./$project/start\" ]; then\n      chmod 755 ./$project/start\n      ./$project/start\n      fi\n      service apache2 restart\n\n\n####Step - 3 Open Your Web Browser\n\nYou can access your web page using http://IP_ADDRESS/current\n\n![](/content/images/2016/05/postage4.png)\n\n\nVoila ! Your App is up to date.\n####Conclusion\nThese are the very simple steps to launch a php web app (PostageApp) using github repository.\n\n####Deploy PHP app now\n\n<a href=\"https://console.megamafrica.com\"target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png \" alt=\"wordpres button\" /></a>\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzait2001gdrgbkyok2vq6","content":"<p>####Introduction</p>\n<p>   The PostageApp is used in quick way to deliver the email. This application supports PHP.It optionally attachs it to the mail server.</p>\n<p>This tutorial will guide you in launching a php web application (PostageApp) in MegamAfrica.</p>\n<p>   <a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png \" alt=\"wordpres button\"></a></p>\n<p>####Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your workstation, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\" target=\"_blank\" rel=\"external\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a></p>\n<ul>\n<li>You have to install openssh-server for ssh access in your local system.</li>\n</ul>\n</li>\n</ul>\n<pre><code>sudo apt-get install openssh-server\n</code></pre><p> check SSH installed on your system</p>\n<pre><code>ps aux | grep sshd\n</code></pre><p>###Step-1 Fork PostageApp</p>\n<ul>\n<li><p>Fork PostageApp<br>from <a href=\"https://github.com/verticeapps/php_postage.git\" target=\"_blank\" rel=\"external\">https://github.com/verticeapps/php_postage.git</a></p>\n</li>\n<li><p>You will be see the fork option in the top right corner of the git hub page.click the fork option.</p>\n</li>\n<li><p>The php_postage repository is forked into your git repository</p>\n</li>\n</ul>\n<p>####Step - 2 Launch PostageApp</p>\n<ol>\n<li><p>Go to MegamAfrica Dashboard</p>\n</li>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click PHP Icon.A window will pop up for your repository selection. </p>\n</li>\n<li><p>Pick a repository by choosing your repository.</p>\n<p>Let us use Github: &lt; mygithub &gt;/php_postage.git</p>\n</li>\n<li><p>You can create new sshkey, use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>Launch PHP App.Click Create.</p>\n</li>\n</ol>\n<ul>\n<li><p>Voila ! Your App is up to date.</p>\n</li>\n<li><p>Now that you have launched your app, you might want to launch a service (database) and bind it<br>####Step - 2 Buildpack for php</p>\n</li>\n</ul>\n<p>We use a default PHP build pack using our super cool chef-repo. </p>\n<pre><code>#!/bin/bash\n#Php builder\n#megam_php \nlocal_repo=/var/www/html/current \nremote_repo=https://github.com/verticeapps/php_postage.git\nmegam_home=/var/lib/megam/gulp\nfilename=$(basename &quot;$remote_repo&quot;)\nextension=&quot;${filename##*.}&quot;\nproject=&quot;${filename%.*}&quot;\ncd $megam_home\nrm -r $project\ngit clone $remote_repo\nrm -r $local_repo/*\nmv ./$project/* $local_repo\ncd $project\nif [  -f &quot;./$project/start&quot; ]; then\nchmod 755 ./$project/start\n./$project/start\nfi\nservice apache2 restart\n</code></pre><p>####Step - 3 Open Your Web Browser</p>\n<p>You can access your web page using <a href=\"http://IP_ADDRESS/current\" target=\"_blank\" rel=\"external\">http://IP_ADDRESS/current</a></p>\n<p><img src=\"/content/images/2016/05/postage4.png\" alt=\"\"></p>\n<p>Voila ! Your App is up to date.</p>\n<p>####Conclusion<br>These are the very simple steps to launch a php web app (PostageApp) using github repository.</p>\n<p>####Deploy PHP app now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png \" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>####Introduction</p>\n<p>   The PostageApp is used in quick way to deliver the email. This application supports PHP.It optionally attachs it to the mail server.</p>\n<p>This tutorial will guide you in launching a php web application (PostageApp) in MegamAfrica.</p>\n<p>   <a href=\"https://console.megamafrica.com\"target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png \" alt=\"wordpres button\" /></a></p>\n<p>####Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your workstation, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a></p>\n<ul>\n<li>You have to install openssh-server for ssh access in your local system.</li>\n</ul>\n</li>\n</ul>\n<pre><code>sudo apt-get install openssh-server\n</code></pre><p> check SSH installed on your system</p>\n<pre><code>ps aux | grep sshd\n</code></pre><p>###Step-1 Fork PostageApp</p>\n<ul>\n<li><p>Fork PostageApp<br>from <a href=\"https://github.com/verticeapps/php_postage.git\">https://github.com/verticeapps/php_postage.git</a></p>\n</li>\n<li><p>You will be see the fork option in the top right corner of the git hub page.click the fork option.</p>\n</li>\n<li><p>The php_postage repository is forked into your git repository</p>\n</li>\n</ul>\n<p>####Step - 2 Launch PostageApp</p>\n<ol>\n<li><p>Go to MegamAfrica Dashboard</p>\n</li>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click PHP Icon.A window will pop up for your repository selection. </p>\n</li>\n<li><p>Pick a repository by choosing your repository.</p>\n<p>Let us use Github: &lt; mygithub &gt;/php_postage.git</p>\n</li>\n<li><p>You can create new sshkey, use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>Launch PHP App.Click Create.</p>\n</li>\n</ol>\n<ul>\n<li><p>Voila ! Your App is up to date.</p>\n</li>\n<li><p>Now that you have launched your app, you might want to launch a service (database) and bind it<br>####Step - 2 Buildpack for php</p>\n</li>\n</ul>\n<p>We use a default PHP build pack using our super cool chef-repo. </p>\n<pre><code>#!/bin/bash\n#Php builder\n#megam_php \nlocal_repo=/var/www/html/current \nremote_repo=https://github.com/verticeapps/php_postage.git\nmegam_home=/var/lib/megam/gulp\nfilename=$(basename &quot;$remote_repo&quot;)\nextension=&quot;${filename##*.}&quot;\nproject=&quot;${filename%.*}&quot;\ncd $megam_home\nrm -r $project\ngit clone $remote_repo\nrm -r $local_repo/*\nmv ./$project/* $local_repo\ncd $project\nif [  -f &quot;./$project/start&quot; ]; then\nchmod 755 ./$project/start\n./$project/start\nfi\nservice apache2 restart\n</code></pre><p>####Step - 3 Open Your Web Browser</p>\n<p>You can access your web page using <a href=\"http://IP_ADDRESS/current\">http://IP_ADDRESS/current</a></p>\n<p><img src=\"/content/images/2016/05/postage4.png\" alt=\"\"></p>\n<p>Voila ! Your App is up to date.</p>\n<p>####Conclusion<br>These are the very simple steps to launch a php web app (PostageApp) using github repository.</p>\n<p>####Deploy PHP app now</p>\n<p><a href=\"https://console.megamafrica.com\"target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png \" alt=\"wordpres button\" /></a></p>\n"},{"title":"How to launch SDK for C/C++/Python in MegamAfrica","slug":"2016-05-10-how-to-launch-sdk-using-cc-python","date_published":"2016-05-10T08:37:41.707Z","date_updated":"2016-05-27T07:18:43.597Z","_content":"\n####Introduction\n  A software development kit (SDK or \"devkit\") is typically a set of software development tools that allows the creation of applications for a certain software package, software framework, hardware platform, computer system, operating system, or similar development platform. \n  To create applications, you have to download a specific software development kit.\n  \n This tutorial will set up launching sdk using c/c++, python.\n \n <a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n \n####Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git is installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\n\nYou have to install openssh-server for ssh access.\n\n     sudo apt-get install openssh-server\n     \nTo check the ssh is properly installed in our system\n\n     ps aux | grep sshd\n     \n#### Launch SDK using c/c++\n\nThis initial section contains everything you need to get c/c++ running on your server.\n\n* First, ensure the user can login to https://console.megamafrica.com.\n\n* Go to the Market Places, click the C/C++. \n\n* Select the SDK option\n\n* You can create new sshkey or use an existing sshkey or upload your own sshkeys too.\n\n* Click the Create button. it will launch the C/C++ SDK.\n\n####Step - 1  C/C++ SDK\nNext, Go to your  Dashboard. Click the domain name of C/C++ SDK which opens a new window.\n\n* It contains the CPU, RAM and NETWORK tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and NETWORK usage.\n\n* You need to access the Virtual Machine from a terminal. \n\n* You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,\n\n        \n         ssh -i path to/example@email.com_os_key root@<ipaddress>\n\n####Step - 2 Running C program\n\n In the VM gcc 4.9 version in installed. To test it, create a file in **hello.c**\n \n open a file to write a hello world program in c,\n \n      #include <stdio.h>\n      main()\n      {\n      printf(\"hello World\");\n      }\n\nCompile the program\n\n    gcc-4.9 hello.c -o hello\n Run the program\n \n    ./hello\n    \n    \n####Step - 3 Running C++ program  \n  \n  In the VM g++ 4.9 version is installed. To test it, create a file in **hello.cc**.\n  \n  open a file to write a hello world program in c++,\n  \n    #include<iostream>\n    using namespace std;\n    main()\n    {\n    cout<<\"hello world\";\n    }\n \n Compile the program \n   \n    g++-4.9 hello.cc -o hello\n Run the program\n \n    ./hello\n    \n    \n    \n  \n#### Launch SDK for Python\n\nThis initial section contains everything you need to get Python and running on your server.\n\n* First, ensure the user to login our websites.\n\n* Go to the Market Places to click the Python apps. \n\n* Select the SDK option\n\n* You can create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* Click the create button. it will launch the Python app.\n\n####Step - 1  Access the Python SDK\nNext, Go to the Dashboard.click the domain name of python app and open a new window.\n\n* It contains the CPU, RAM and NETWORK tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and NETWORK usage.\n\n* VM Logs shows all the running process in VM.\n\n* You need to access the Virtual Machine from a terminal. \n\n* You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,\n\n        \n         ssh -i path to/example@email.com_os_key root@<ipaddress>\n\n####Step - 2 Running a python program\n\n After ssh into vm, check python version\n \n      python --version\n      \n Create a file in hello.py. \n \n open a file to Write a hello world program\n \n      #! /usr/bin/python\n      print 'hello world!'\n      \nChange the file permission into a file\n\n    chmod 755 hello.py\n\n Run the program\n \n    ./hello.py\n  \n  \n####Conclusion\n \nThese are the very simple steps to launch SDK  using C/C++/Python.\n\n####Deploy your C/C++/Python SDK now\n\n<a href=\"https://console.megamafrica.com\"target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png \" alt=\"wordpres button\" />\n","source":"_posts/2016-05-10-how-to-launch-sdk-using-cc-python.md","raw":"---\ntitle: How to launch SDK for C/C++/Python in MegamAfrica\nslug: how-to-launch-sdk-using-cc-python\ndate_published: 2016-05-10T14:07:41.707Z\ndate_updated:   2016-05-27T12:48:43.597Z\n---\n\n####Introduction\n  A software development kit (SDK or \"devkit\") is typically a set of software development tools that allows the creation of applications for a certain software package, software framework, hardware platform, computer system, operating system, or similar development platform. \n  To create applications, you have to download a specific software development kit.\n  \n This tutorial will set up launching sdk using c/c++, python.\n \n <a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n \n####Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git is installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\n\nYou have to install openssh-server for ssh access.\n\n     sudo apt-get install openssh-server\n     \nTo check the ssh is properly installed in our system\n\n     ps aux | grep sshd\n     \n#### Launch SDK using c/c++\n\nThis initial section contains everything you need to get c/c++ running on your server.\n\n* First, ensure the user can login to https://console.megamafrica.com.\n\n* Go to the Market Places, click the C/C++. \n\n* Select the SDK option\n\n* You can create new sshkey or use an existing sshkey or upload your own sshkeys too.\n\n* Click the Create button. it will launch the C/C++ SDK.\n\n####Step - 1  C/C++ SDK\nNext, Go to your  Dashboard. Click the domain name of C/C++ SDK which opens a new window.\n\n* It contains the CPU, RAM and NETWORK tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and NETWORK usage.\n\n* You need to access the Virtual Machine from a terminal. \n\n* You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,\n\n        \n         ssh -i path to/example@email.com_os_key root@<ipaddress>\n\n####Step - 2 Running C program\n\n In the VM gcc 4.9 version in installed. To test it, create a file in **hello.c**\n \n open a file to write a hello world program in c,\n \n      #include <stdio.h>\n      main()\n      {\n      printf(\"hello World\");\n      }\n\nCompile the program\n\n    gcc-4.9 hello.c -o hello\n Run the program\n \n    ./hello\n    \n    \n####Step - 3 Running C++ program  \n  \n  In the VM g++ 4.9 version is installed. To test it, create a file in **hello.cc**.\n  \n  open a file to write a hello world program in c++,\n  \n    #include<iostream>\n    using namespace std;\n    main()\n    {\n    cout<<\"hello world\";\n    }\n \n Compile the program \n   \n    g++-4.9 hello.cc -o hello\n Run the program\n \n    ./hello\n    \n    \n    \n  \n#### Launch SDK for Python\n\nThis initial section contains everything you need to get Python and running on your server.\n\n* First, ensure the user to login our websites.\n\n* Go to the Market Places to click the Python apps. \n\n* Select the SDK option\n\n* You can create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* Click the create button. it will launch the Python app.\n\n####Step - 1  Access the Python SDK\nNext, Go to the Dashboard.click the domain name of python app and open a new window.\n\n* It contains the CPU, RAM and NETWORK tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and NETWORK usage.\n\n* VM Logs shows all the running process in VM.\n\n* You need to access the Virtual Machine from a terminal. \n\n* You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,\n\n        \n         ssh -i path to/example@email.com_os_key root@<ipaddress>\n\n####Step - 2 Running a python program\n\n After ssh into vm, check python version\n \n      python --version\n      \n Create a file in hello.py. \n \n open a file to Write a hello world program\n \n      #! /usr/bin/python\n      print 'hello world!'\n      \nChange the file permission into a file\n\n    chmod 755 hello.py\n\n Run the program\n \n    ./hello.py\n  \n  \n####Conclusion\n \nThese are the very simple steps to launch SDK  using C/C++/Python.\n\n####Deploy your C/C++/Python SDK now\n\n<a href=\"https://console.megamafrica.com\"target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png \" alt=\"wordpres button\" />\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzait3001hdrgbqzo3js8e","content":"<p>####Introduction<br>  A software development kit (SDK or devkit) is typically a set of software development tools that allows the creation of applications for a certain software package, software framework, hardware platform, computer system, operating system, or similar development platform.<br>  To create applications, you have to download a specific software development kit.</p>\n<p> This tutorial will set up launching sdk using c/c++, python.</p>\n<p> <a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>####Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git is installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\" target=\"_blank\" rel=\"external\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a></p>\n</li>\n</ul>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre><p>To check the ssh is properly installed in our system</p>\n<pre><code>ps aux | grep sshd\n</code></pre><h4 id=\"Launch-SDK-using-c-c\"><a href=\"#Launch-SDK-using-c-c\" class=\"headerlink\" title=\"Launch SDK using c/c++\"></a>Launch SDK using c/c++</h4><p>This initial section contains everything you need to get c/c++ running on your server.</p>\n<ul>\n<li><p>First, ensure the user can login to <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>.</p>\n</li>\n<li><p>Go to the Market Places, click the C/C++. </p>\n</li>\n<li><p>Select the SDK option</p>\n</li>\n<li><p>You can create new sshkey or use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>Click the Create button. it will launch the C/C++ SDK.</p>\n</li>\n</ul>\n<p>####Step - 1  C/C++ SDK<br>Next, Go to your  Dashboard. Click the domain name of C/C++ SDK which opens a new window.</p>\n<ul>\n<li><p>It contains the CPU, RAM and NETWORK tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and NETWORK usage.</p>\n</li>\n<li><p>You need to access the Virtual Machine from a terminal. </p>\n</li>\n<li><p>You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,</p>\n</li>\n</ul>\n<pre><code>ssh -i path to/example@email.com_os_key root@&lt;ipaddress&gt;\n</code></pre><p>####Step - 2 Running C program</p>\n<p> In the VM gcc 4.9 version in installed. To test it, create a file in <strong>hello.c</strong></p>\n<p> open a file to write a hello world program in c,</p>\n<pre><code>#include &lt;stdio.h&gt;\nmain()\n{\nprintf(&quot;hello World&quot;);\n}\n</code></pre><p>Compile the program</p>\n<pre><code>gcc-4.9 hello.c -o hello\n</code></pre><p> Run the program</p>\n<pre><code>./hello\n</code></pre><p>####Step - 3 Running C++ program  </p>\n<p>  In the VM g++ 4.9 version is installed. To test it, create a file in <strong>hello.cc</strong>.</p>\n<p>  open a file to write a hello world program in c++,</p>\n<pre><code>#include&lt;iostream&gt;\nusing namespace std;\nmain()\n{\ncout&lt;&lt;&quot;hello world&quot;;\n}\n</code></pre><p> Compile the program </p>\n<pre><code>g++-4.9 hello.cc -o hello\n</code></pre><p> Run the program</p>\n<pre><code>./hello\n</code></pre><h4 id=\"Launch-SDK-for-Python\"><a href=\"#Launch-SDK-for-Python\" class=\"headerlink\" title=\"Launch SDK for Python\"></a>Launch SDK for Python</h4><p>This initial section contains everything you need to get Python and running on your server.</p>\n<ul>\n<li><p>First, ensure the user to login our websites.</p>\n</li>\n<li><p>Go to the Market Places to click the Python apps. </p>\n</li>\n<li><p>Select the SDK option</p>\n</li>\n<li><p>You can create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>Click the create button. it will launch the Python app.</p>\n</li>\n</ul>\n<p>####Step - 1  Access the Python SDK<br>Next, Go to the Dashboard.click the domain name of python app and open a new window.</p>\n<ul>\n<li><p>It contains the CPU, RAM and NETWORK tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and NETWORK usage.</p>\n</li>\n<li><p>VM Logs shows all the running process in VM.</p>\n</li>\n<li><p>You need to access the Virtual Machine from a terminal. </p>\n</li>\n<li><p>You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,</p>\n</li>\n</ul>\n<pre><code>ssh -i path to/example@email.com_os_key root@&lt;ipaddress&gt;\n</code></pre><p>####Step - 2 Running a python program</p>\n<p> After ssh into vm, check python version</p>\n<pre><code>python --version\n</code></pre><p> Create a file in hello.py. </p>\n<p> open a file to Write a hello world program</p>\n<pre><code>#! /usr/bin/python\nprint &apos;hello world!&apos;\n</code></pre><p>Change the file permission into a file</p>\n<pre><code>chmod 755 hello.py\n</code></pre><p> Run the program</p>\n<pre><code>./hello.py\n</code></pre><p>####Conclusion</p>\n<p>These are the very simple steps to launch SDK  using C/C++/Python.</p>\n<p>####Deploy your C/C++/Python SDK now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png \" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>####Introduction<br>  A software development kit (SDK or devkit) is typically a set of software development tools that allows the creation of applications for a certain software package, software framework, hardware platform, computer system, operating system, or similar development platform.<br>  To create applications, you have to download a specific software development kit.</p>\n<p> This tutorial will set up launching sdk using c/c++, python.</p>\n<p> <a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>####Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git is installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a></p>\n</li>\n</ul>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre><p>To check the ssh is properly installed in our system</p>\n<pre><code>ps aux | grep sshd\n</code></pre><h4 id=\"Launch-SDK-using-c-c\"><a href=\"#Launch-SDK-using-c-c\" class=\"headerlink\" title=\"Launch SDK using c/c++\"></a>Launch SDK using c/c++</h4><p>This initial section contains everything you need to get c/c++ running on your server.</p>\n<ul>\n<li><p>First, ensure the user can login to <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>.</p>\n</li>\n<li><p>Go to the Market Places, click the C/C++. </p>\n</li>\n<li><p>Select the SDK option</p>\n</li>\n<li><p>You can create new sshkey or use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>Click the Create button. it will launch the C/C++ SDK.</p>\n</li>\n</ul>\n<p>####Step - 1  C/C++ SDK<br>Next, Go to your  Dashboard. Click the domain name of C/C++ SDK which opens a new window.</p>\n<ul>\n<li><p>It contains the CPU, RAM and NETWORK tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and NETWORK usage.</p>\n</li>\n<li><p>You need to access the Virtual Machine from a terminal. </p>\n</li>\n<li><p>You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,</p>\n</li>\n</ul>\n<pre><code>ssh -i path to/example@email.com_os_key root@&lt;ipaddress&gt;\n</code></pre><p>####Step - 2 Running C program</p>\n<p> In the VM gcc 4.9 version in installed. To test it, create a file in <strong>hello.c</strong></p>\n<p> open a file to write a hello world program in c,</p>\n<pre><code>#include &lt;stdio.h&gt;\nmain()\n{\nprintf(&quot;hello World&quot;);\n}\n</code></pre><p>Compile the program</p>\n<pre><code>gcc-4.9 hello.c -o hello\n</code></pre><p> Run the program</p>\n<pre><code>./hello\n</code></pre><p>####Step - 3 Running C++ program  </p>\n<p>  In the VM g++ 4.9 version is installed. To test it, create a file in <strong>hello.cc</strong>.</p>\n<p>  open a file to write a hello world program in c++,</p>\n<pre><code>#include&lt;iostream&gt;\nusing namespace std;\nmain()\n{\ncout&lt;&lt;&quot;hello world&quot;;\n}\n</code></pre><p> Compile the program </p>\n<pre><code>g++-4.9 hello.cc -o hello\n</code></pre><p> Run the program</p>\n<pre><code>./hello\n</code></pre><h4 id=\"Launch-SDK-for-Python\"><a href=\"#Launch-SDK-for-Python\" class=\"headerlink\" title=\"Launch SDK for Python\"></a>Launch SDK for Python</h4><p>This initial section contains everything you need to get Python and running on your server.</p>\n<ul>\n<li><p>First, ensure the user to login our websites.</p>\n</li>\n<li><p>Go to the Market Places to click the Python apps. </p>\n</li>\n<li><p>Select the SDK option</p>\n</li>\n<li><p>You can create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>Click the create button. it will launch the Python app.</p>\n</li>\n</ul>\n<p>####Step - 1  Access the Python SDK<br>Next, Go to the Dashboard.click the domain name of python app and open a new window.</p>\n<ul>\n<li><p>It contains the CPU, RAM and NETWORK tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and NETWORK usage.</p>\n</li>\n<li><p>VM Logs shows all the running process in VM.</p>\n</li>\n<li><p>You need to access the Virtual Machine from a terminal. </p>\n</li>\n<li><p>You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,</p>\n</li>\n</ul>\n<pre><code>ssh -i path to/example@email.com_os_key root@&lt;ipaddress&gt;\n</code></pre><p>####Step - 2 Running a python program</p>\n<p> After ssh into vm, check python version</p>\n<pre><code>python --version\n</code></pre><p> Create a file in hello.py. </p>\n<p> open a file to Write a hello world program</p>\n<pre><code>#! /usr/bin/python\nprint &apos;hello world!&apos;\n</code></pre><p>Change the file permission into a file</p>\n<pre><code>chmod 755 hello.py\n</code></pre><p> Run the program</p>\n<pre><code>./hello.py\n</code></pre><p>####Conclusion</p>\n<p>These are the very simple steps to launch SDK  using C/C++/Python.</p>\n<p>####Deploy your C/C++/Python SDK now</p>\n<p><a href=\"https://console.megamafrica.com\"target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png \" alt=\"wordpres button\" /></p>\n"},{"title":"How to launch Nodejs - etherpad-lite in MegamAfrica","slug":"2016-05-11-how-to-launch-etherpad-lite","date_published":"2016-05-10T23:27:43.140Z","date_updated":"2016-05-27T07:54:30.004Z","_content":"\n###Introduction\n\nEtherpad is a really-real time collaborative editor maintained by the Etherpad Community.Etherpad is designed to be easily embeddable and provides a HTTP API that allows your web application to manage pads, users and groups. It is recommended to use the available client implementations in order to interact with this API.\n\nThis tutorial will guide you in launching a Nodejs web application (etherpad-lite) in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your workstation, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\n* You have to install openssh-server for ssh access in your worstation.\n\n\t\tsudo apt-get install openssh-server\n    \n* Check SSH working properly \n\n\t\tps aux | grep sshd\n\nThis initial section contains everything you need to get etherpad-lite running on your server.\n\n###Step-1 Fork etherpad-lite\n* Fork etherpad-lite\nfrom https://github.com/verticeapps/node_etherpad.git\n\n* You will be see the fork option in the top right corner of the git hub page.click the fork option.\n\n* The node_etherpad is forked into your git repository\n\n###Step-2 Launch the app\n1. Go to MegamAfrica Dashboard\n\n2. Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n3. Click Nodejs Icon.A window will pop up for your repository selection. \n\n4. Pick a repository by choosing your git repository.\n\n  Let us use Github: < mygithub >/node_etherpad\n\n5. You can create new sshkey or use an existing sshkey or upload your own sshkeys too.\n\n6. To Launch Nodejs App.Click Create.\n\n* Voila ! Your App is up to date.\n\n* Now that you have launched your app, you might want to launch a service (database) and bind it\n\n###Start Script\nMegamAfrica will look for a start script named `start`,  \nensure that your git repository have the start script file as follows.\n\n \t#!/bin/sh\n \t./bin/run.sh --root\n\n   \n###**Step-3 Open Your Web browser**\nYou can access your web page using http://IP_ADDRESS/9001\n\n\n![](/content/images/2016/05/node.png)\n\n###Conclusion\n\nThese are the very simple steps to launch a Nodejs web app (etherpad-lite) using github repository.\n\n###Deploy Nodejs app now \n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n\n","source":"_posts/2016-05-11-how-to-launch-etherpad-lite.md","raw":"---\ntitle: How to launch Nodejs - etherpad-lite in MegamAfrica\nslug: how-to-launch-etherpad-lite\ndate_published: 2016-05-11T04:57:43.140Z\ndate_updated:   2016-05-27T13:24:30.004Z\n---\n\n###Introduction\n\nEtherpad is a really-real time collaborative editor maintained by the Etherpad Community.Etherpad is designed to be easily embeddable and provides a HTTP API that allows your web application to manage pads, users and groups. It is recommended to use the available client implementations in order to interact with this API.\n\nThis tutorial will guide you in launching a Nodejs web application (etherpad-lite) in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your workstation, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\n* You have to install openssh-server for ssh access in your worstation.\n\n\t\tsudo apt-get install openssh-server\n    \n* Check SSH working properly \n\n\t\tps aux | grep sshd\n\nThis initial section contains everything you need to get etherpad-lite running on your server.\n\n###Step-1 Fork etherpad-lite\n* Fork etherpad-lite\nfrom https://github.com/verticeapps/node_etherpad.git\n\n* You will be see the fork option in the top right corner of the git hub page.click the fork option.\n\n* The node_etherpad is forked into your git repository\n\n###Step-2 Launch the app\n1. Go to MegamAfrica Dashboard\n\n2. Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n3. Click Nodejs Icon.A window will pop up for your repository selection. \n\n4. Pick a repository by choosing your git repository.\n\n  Let us use Github: < mygithub >/node_etherpad\n\n5. You can create new sshkey or use an existing sshkey or upload your own sshkeys too.\n\n6. To Launch Nodejs App.Click Create.\n\n* Voila ! Your App is up to date.\n\n* Now that you have launched your app, you might want to launch a service (database) and bind it\n\n###Start Script\nMegamAfrica will look for a start script named `start`,  \nensure that your git repository have the start script file as follows.\n\n \t#!/bin/sh\n \t./bin/run.sh --root\n\n   \n###**Step-3 Open Your Web browser**\nYou can access your web page using http://IP_ADDRESS/9001\n\n\n![](/content/images/2016/05/node.png)\n\n###Conclusion\n\nThese are the very simple steps to launch a Nodejs web app (etherpad-lite) using github repository.\n\n###Deploy Nodejs app now \n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzait5001idrgbx93aphgj","content":"<p>###Introduction</p>\n<p>Etherpad is a really-real time collaborative editor maintained by the Etherpad Community.Etherpad is designed to be easily embeddable and provides a HTTP API that allows your web application to manage pads, users and groups. It is recommended to use the available client implementations in order to interact with this API.</p>\n<p>This tutorial will guide you in launching a Nodejs web application (etherpad-lite) in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your workstation, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\" target=\"_blank\" rel=\"external\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a></p>\n</li>\n<li><p>You have to install openssh-server for ssh access in your worstation.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre></li>\n<li><p>Check SSH working properly </p>\n<pre><code>ps aux | grep sshd\n</code></pre></li>\n</ul>\n<p>This initial section contains everything you need to get etherpad-lite running on your server.</p>\n<p>###Step-1 Fork etherpad-lite</p>\n<ul>\n<li><p>Fork etherpad-lite<br>from <a href=\"https://github.com/verticeapps/node_etherpad.git\" target=\"_blank\" rel=\"external\">https://github.com/verticeapps/node_etherpad.git</a></p>\n</li>\n<li><p>You will be see the fork option in the top right corner of the git hub page.click the fork option.</p>\n</li>\n<li><p>The node_etherpad is forked into your git repository</p>\n</li>\n</ul>\n<p>###Step-2 Launch the app</p>\n<ol>\n<li><p>Go to MegamAfrica Dashboard</p>\n</li>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click Nodejs Icon.A window will pop up for your repository selection. </p>\n</li>\n<li><p>Pick a repository by choosing your git repository.</p>\n<p>Let us use Github: &lt; mygithub &gt;/node_etherpad</p>\n</li>\n<li><p>You can create new sshkey or use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>To Launch Nodejs App.Click Create.</p>\n</li>\n</ol>\n<ul>\n<li><p>Voila ! Your App is up to date.</p>\n</li>\n<li><p>Now that you have launched your app, you might want to launch a service (database) and bind it</p>\n</li>\n</ul>\n<p>###Start Script<br>MegamAfrica will look for a start script named <code>start</code>,<br>ensure that your git repository have the start script file as follows.</p>\n<pre><code>#!/bin/sh\n./bin/run.sh --root\n</code></pre><p>###<strong>Step-3 Open Your Web browser</strong><br>You can access your web page using <a href=\"http://IP_ADDRESS/9001\" target=\"_blank\" rel=\"external\">http://IP_ADDRESS/9001</a></p>\n<p><img src=\"/content/images/2016/05/node.png\" alt=\"\"></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch a Nodejs web app (etherpad-lite) using github repository.</p>\n<p>###Deploy Nodejs app now<br><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###Introduction</p>\n<p>Etherpad is a really-real time collaborative editor maintained by the Etherpad Community.Etherpad is designed to be easily embeddable and provides a HTTP API that allows your web application to manage pads, users and groups. It is recommended to use the available client implementations in order to interact with this API.</p>\n<p>This tutorial will guide you in launching a Nodejs web application (etherpad-lite) in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your workstation, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a></p>\n</li>\n<li><p>You have to install openssh-server for ssh access in your worstation.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre></li>\n<li><p>Check SSH working properly </p>\n<pre><code>ps aux | grep sshd\n</code></pre></li>\n</ul>\n<p>This initial section contains everything you need to get etherpad-lite running on your server.</p>\n<p>###Step-1 Fork etherpad-lite</p>\n<ul>\n<li><p>Fork etherpad-lite<br>from <a href=\"https://github.com/verticeapps/node_etherpad.git\">https://github.com/verticeapps/node_etherpad.git</a></p>\n</li>\n<li><p>You will be see the fork option in the top right corner of the git hub page.click the fork option.</p>\n</li>\n<li><p>The node_etherpad is forked into your git repository</p>\n</li>\n</ul>\n<p>###Step-2 Launch the app</p>\n<ol>\n<li><p>Go to MegamAfrica Dashboard</p>\n</li>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click Nodejs Icon.A window will pop up for your repository selection. </p>\n</li>\n<li><p>Pick a repository by choosing your git repository.</p>\n<p>Let us use Github: &lt; mygithub &gt;/node_etherpad</p>\n</li>\n<li><p>You can create new sshkey or use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>To Launch Nodejs App.Click Create.</p>\n</li>\n</ol>\n<ul>\n<li><p>Voila ! Your App is up to date.</p>\n</li>\n<li><p>Now that you have launched your app, you might want to launch a service (database) and bind it</p>\n</li>\n</ul>\n<p>###Start Script<br>MegamAfrica will look for a start script named <code>start</code>,<br>ensure that your git repository have the start script file as follows.</p>\n<pre><code>#!/bin/sh\n./bin/run.sh --root\n</code></pre><p>###<strong>Step-3 Open Your Web browser</strong><br>You can access your web page using <a href=\"http://IP_ADDRESS/9001\">http://IP_ADDRESS/9001</a></p>\n<p><img src=\"/content/images/2016/05/node.png\" alt=\"\"></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch a Nodejs web app (etherpad-lite) using github repository.</p>\n<p>###Deploy Nodejs app now<br><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"How to launch MySQL in MegamAfrica","slug":"2016-05-11-how-to-launch-mysql","date_published":"2016-05-10T23:21:29.770Z","date_updated":"2016-05-27T05:52:40.824Z","_content":"\n###Introduction\n\nMySQL is the world's most popular open source database. It runs on virtually all platforms, including Linux, UNIX, and Windows. Although it can be used in a wide range of applications, MySQL is most often associated with web-based applications and online publishing and is an important component of an open source enterprise stack called LAMP. It works very quickly and works well even with large data sets. MySQL uses a standard form of the well-known SQL data language.\n\nThis tutorial will guide you in launching MySQL.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n##Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* An account on GitHub, which is a Git repository host.\n\nYou have to create a valid credential access for https://console.megamafrica.com.\n\nYou have to install openssh-server for ssh access.\n\n\t$ sudo apt-get install openssh-server\n\nTo check the ssh is properly installed in our system\n\n\t$ ps aux | grep sshd\n\n###Step - 1 Creating MySQL Virtual Machine\n\nThis initial section contains everything you need to get MySQL and running on your server.\n\n* First, ensure the user can login to https://console.megamafrica.com. \n\n* Go to the Market Places.\n\n* Select the MySQL, A window will pop up with for CPU, storage, RAM and SSHkey options.\n\n* You can choose the storage size and RAM capacity.\n\n* You can create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* Click the create button. it will create the virtual machine.\n\n###Step - 2 Access the MySQL in the Virtual Machine\n\nNext, Go to the Dashboard and click the domain name a new window will open.\n\n* It contains the CPU, RAM and NETWORK tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and NETWORK  usage.\n\n* VM Logs shows all the running process in VM.\n\n* You need to access the virtual machine in terminal, you can download the SSH Keys from SSH Keys tab or Overview page. Use this keys to login the terminal in following command,\n\n \t\t$ ssh -i path to/<private_key filename> root@<ipaddress>\n\n* Now, you are login into vm then you need to access MySQL use the following command:\n\n\t\t$ mysql -h 127.0.0.1 --password=megam\n\nsuccessfully launched the vm and login into MySQL.\n\n###Conclusion\n\nThis is a good head-start for launching MySQL in MegamAfrica.\n\n###Deploy MySQL now\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n","source":"_posts/2016-05-11-how-to-launch-mysql.md","raw":"---\ntitle: How to launch MySQL in MegamAfrica\nslug: how-to-launch-mysql\ndate_published: 2016-05-11T04:51:29.770Z\ndate_updated:   2016-05-27T11:22:40.824Z\n---\n\n###Introduction\n\nMySQL is the world's most popular open source database. It runs on virtually all platforms, including Linux, UNIX, and Windows. Although it can be used in a wide range of applications, MySQL is most often associated with web-based applications and online publishing and is an important component of an open source enterprise stack called LAMP. It works very quickly and works well even with large data sets. MySQL uses a standard form of the well-known SQL data language.\n\nThis tutorial will guide you in launching MySQL.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n##Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* An account on GitHub, which is a Git repository host.\n\nYou have to create a valid credential access for https://console.megamafrica.com.\n\nYou have to install openssh-server for ssh access.\n\n\t$ sudo apt-get install openssh-server\n\nTo check the ssh is properly installed in our system\n\n\t$ ps aux | grep sshd\n\n###Step - 1 Creating MySQL Virtual Machine\n\nThis initial section contains everything you need to get MySQL and running on your server.\n\n* First, ensure the user can login to https://console.megamafrica.com. \n\n* Go to the Market Places.\n\n* Select the MySQL, A window will pop up with for CPU, storage, RAM and SSHkey options.\n\n* You can choose the storage size and RAM capacity.\n\n* You can create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* Click the create button. it will create the virtual machine.\n\n###Step - 2 Access the MySQL in the Virtual Machine\n\nNext, Go to the Dashboard and click the domain name a new window will open.\n\n* It contains the CPU, RAM and NETWORK tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and NETWORK  usage.\n\n* VM Logs shows all the running process in VM.\n\n* You need to access the virtual machine in terminal, you can download the SSH Keys from SSH Keys tab or Overview page. Use this keys to login the terminal in following command,\n\n \t\t$ ssh -i path to/<private_key filename> root@<ipaddress>\n\n* Now, you are login into vm then you need to access MySQL use the following command:\n\n\t\t$ mysql -h 127.0.0.1 --password=megam\n\nsuccessfully launched the vm and login into MySQL.\n\n###Conclusion\n\nThis is a good head-start for launching MySQL in MegamAfrica.\n\n###Deploy MySQL now\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzait7001jdrgb8629grzo","content":"<p>###Introduction</p>\n<p>MySQL is the worlds most popular open source database. It runs on virtually all platforms, including Linux, UNIX, and Windows. Although it can be used in a wide range of applications, MySQL is most often associated with web-based applications and online publishing and is an important component of an open source enterprise stack called LAMP. It works very quickly and works well even with large data sets. MySQL uses a standard form of the well-known SQL data language.</p>\n<p>This tutorial will guide you in launching MySQL.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>##Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\" target=\"_blank\" rel=\"external\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>An account on GitHub, which is a Git repository host.</p>\n</li>\n</ul>\n<p>You have to create a valid credential access for <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>.</p>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>$ sudo apt-get install openssh-server\n</code></pre><p>To check the ssh is properly installed in our system</p>\n<pre><code>$ ps aux | grep sshd\n</code></pre><p>###Step - 1 Creating MySQL Virtual Machine</p>\n<p>This initial section contains everything you need to get MySQL and running on your server.</p>\n<ul>\n<li><p>First, ensure the user can login to <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. </p>\n</li>\n<li><p>Go to the Market Places.</p>\n</li>\n<li><p>Select the MySQL, A window will pop up with for CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can choose the storage size and RAM capacity.</p>\n</li>\n<li><p>You can create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>Click the create button. it will create the virtual machine.</p>\n</li>\n</ul>\n<p>###Step - 2 Access the MySQL in the Virtual Machine</p>\n<p>Next, Go to the Dashboard and click the domain name a new window will open.</p>\n<ul>\n<li><p>It contains the CPU, RAM and NETWORK tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and NETWORK  usage.</p>\n</li>\n<li><p>VM Logs shows all the running process in VM.</p>\n</li>\n<li><p>You need to access the virtual machine in terminal, you can download the SSH Keys from SSH Keys tab or Overview page. Use this keys to login the terminal in following command,</p>\n<pre><code>$ ssh -i path to/&lt;private_key filename&gt; root@&lt;ipaddress&gt;\n</code></pre></li>\n<li><p>Now, you are login into vm then you need to access MySQL use the following command:</p>\n<pre><code>$ mysql -h 127.0.0.1 --password=megam\n</code></pre></li>\n</ul>\n<p>successfully launched the vm and login into MySQL.</p>\n<p>###Conclusion</p>\n<p>This is a good head-start for launching MySQL in MegamAfrica.</p>\n<p>###Deploy MySQL now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###Introduction</p>\n<p>MySQL is the worlds most popular open source database. It runs on virtually all platforms, including Linux, UNIX, and Windows. Although it can be used in a wide range of applications, MySQL is most often associated with web-based applications and online publishing and is an important component of an open source enterprise stack called LAMP. It works very quickly and works well even with large data sets. MySQL uses a standard form of the well-known SQL data language.</p>\n<p>This tutorial will guide you in launching MySQL.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>##Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>An account on GitHub, which is a Git repository host.</p>\n</li>\n</ul>\n<p>You have to create a valid credential access for <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>.</p>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>$ sudo apt-get install openssh-server\n</code></pre><p>To check the ssh is properly installed in our system</p>\n<pre><code>$ ps aux | grep sshd\n</code></pre><p>###Step - 1 Creating MySQL Virtual Machine</p>\n<p>This initial section contains everything you need to get MySQL and running on your server.</p>\n<ul>\n<li><p>First, ensure the user can login to <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. </p>\n</li>\n<li><p>Go to the Market Places.</p>\n</li>\n<li><p>Select the MySQL, A window will pop up with for CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can choose the storage size and RAM capacity.</p>\n</li>\n<li><p>You can create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>Click the create button. it will create the virtual machine.</p>\n</li>\n</ul>\n<p>###Step - 2 Access the MySQL in the Virtual Machine</p>\n<p>Next, Go to the Dashboard and click the domain name a new window will open.</p>\n<ul>\n<li><p>It contains the CPU, RAM and NETWORK tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and NETWORK  usage.</p>\n</li>\n<li><p>VM Logs shows all the running process in VM.</p>\n</li>\n<li><p>You need to access the virtual machine in terminal, you can download the SSH Keys from SSH Keys tab or Overview page. Use this keys to login the terminal in following command,</p>\n<pre><code>$ ssh -i path to/&lt;private_key filename&gt; root@&lt;ipaddress&gt;\n</code></pre></li>\n<li><p>Now, you are login into vm then you need to access MySQL use the following command:</p>\n<pre><code>$ mysql -h 127.0.0.1 --password=megam\n</code></pre></li>\n</ul>\n<p>successfully launched the vm and login into MySQL.</p>\n<p>###Conclusion</p>\n<p>This is a good head-start for launching MySQL in MegamAfrica.</p>\n<p>###Deploy MySQL now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"How to launch PHP - OpsWorks   in MegamAfrica","slug":"2016-05-11-how-to-launch-opsworks-php-simple-demo-app","date_published":"2016-05-10T23:29:07.423Z","date_updated":"2016-05-27T06:55:54.838Z","_content":"\n###Introduction\nAWS OpsWorks PHP is a simple demo app that can help you get started using your favourite PHP language. \n\nThis tutorial will guide you in launching a php web application (OpsWorks) in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a> \n\n###Prerequisites\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your workstation, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\n* You have to install openssh-server for ssh access.\n\n\t\tsudo apt-get install openssh-server\n    \n* Check SSH working properly \n\n\t\tps aux | grep sshd\n\nThis initial section contains everything you need to get OpsWorks PHP Simple Demo App and running on your server.\n\n###Step-1 Fork OpsWorks PHP Simple Demo App\n* Fork Open OpsWorks PHP Simple Demo App\nfrom https://github.com/verticeapps/php_simpleapp.git\n\n* You will be see the fork option in the top right corner of the git hub page.click the fork option.\n\n* The OpsWorks PHP Simple Demo App repository is forked into your git repository.\n\n###Step-2 Launch the app\n1. Go to MegamAfrica Dashboard\n\n2. Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n4. Click PHP Icon.A window will pop up for your repository selection. \n\n3. Pick a repository by choosing your git repository.\n\n  Let us use Github: < mygithub >/php_simpleapp.git\n\n5. You can create new sshkey or use an existing sshkey or upload your own sshkeys too.\n\n6. To launch PHP App.Click Create.\n\n* Voila ! Your App is up to date.\n\n* Now that you have launched your app, you might want to launch a service (database) and bind it\n\n###**Buildpack for php**\n\nWe use a PHP build pack using our super cool chef-repo. \n\nThe buildpack for PHP \n  \n\t#!/bin/bash\n\t#Php builder\n\t#megam_php \n\tlocal_repo=/var/www/html/currentremote_repo=https://github.com/megamsys/opsworks-demo-php-simple-app.git\n\tmegam_home=/var/lib/megam/gulp\n\tfilename=$(basename \"$remote_repo\")\n\textension=\"${filename##*.}\"\n\tproject=\"${filename%.*}\"\n\tcd $megam_home\n\trm -r $project\n    git clone $remote_repo\n    rm -r $local_repo/*\n    mv ./$project/* $local_repo\n    cd $project\n    if [  -f \"./$project/start\" ]; then\n    chmod 755 ./$project/start\n    ./$project/star\n    fi\n    service apache2 restart\n    \n\n       \n###**Step-3 Open Your Web browser**\nYou can access your web page using http://IP_ADDRESS/current\n\n\n{<1>}![](/content/images/2016/05/ops.png)\n\n###Conclusion\n\nThese are the very simple steps to launch a php web app (OpsWorks PHP Simple Demo App) using github repository. \n\n###Deploy PHP app now\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n","source":"_posts/2016-05-11-how-to-launch-opsworks-php-simple-demo-app.md","raw":"---\ntitle: How to launch PHP - OpsWorks   in MegamAfrica\nslug: how-to-launch-opsworks-php-simple-demo-app\ndate_published: 2016-05-11T04:59:07.423Z\ndate_updated:   2016-05-27T12:25:54.838Z\n---\n\n###Introduction\nAWS OpsWorks PHP is a simple demo app that can help you get started using your favourite PHP language. \n\nThis tutorial will guide you in launching a php web application (OpsWorks) in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a> \n\n###Prerequisites\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your workstation, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\n* You have to install openssh-server for ssh access.\n\n\t\tsudo apt-get install openssh-server\n    \n* Check SSH working properly \n\n\t\tps aux | grep sshd\n\nThis initial section contains everything you need to get OpsWorks PHP Simple Demo App and running on your server.\n\n###Step-1 Fork OpsWorks PHP Simple Demo App\n* Fork Open OpsWorks PHP Simple Demo App\nfrom https://github.com/verticeapps/php_simpleapp.git\n\n* You will be see the fork option in the top right corner of the git hub page.click the fork option.\n\n* The OpsWorks PHP Simple Demo App repository is forked into your git repository.\n\n###Step-2 Launch the app\n1. Go to MegamAfrica Dashboard\n\n2. Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n4. Click PHP Icon.A window will pop up for your repository selection. \n\n3. Pick a repository by choosing your git repository.\n\n  Let us use Github: < mygithub >/php_simpleapp.git\n\n5. You can create new sshkey or use an existing sshkey or upload your own sshkeys too.\n\n6. To launch PHP App.Click Create.\n\n* Voila ! Your App is up to date.\n\n* Now that you have launched your app, you might want to launch a service (database) and bind it\n\n###**Buildpack for php**\n\nWe use a PHP build pack using our super cool chef-repo. \n\nThe buildpack for PHP \n  \n\t#!/bin/bash\n\t#Php builder\n\t#megam_php \n\tlocal_repo=/var/www/html/currentremote_repo=https://github.com/megamsys/opsworks-demo-php-simple-app.git\n\tmegam_home=/var/lib/megam/gulp\n\tfilename=$(basename \"$remote_repo\")\n\textension=\"${filename##*.}\"\n\tproject=\"${filename%.*}\"\n\tcd $megam_home\n\trm -r $project\n    git clone $remote_repo\n    rm -r $local_repo/*\n    mv ./$project/* $local_repo\n    cd $project\n    if [  -f \"./$project/start\" ]; then\n    chmod 755 ./$project/start\n    ./$project/star\n    fi\n    service apache2 restart\n    \n\n       \n###**Step-3 Open Your Web browser**\nYou can access your web page using http://IP_ADDRESS/current\n\n\n{<1>}![](/content/images/2016/05/ops.png)\n\n###Conclusion\n\nThese are the very simple steps to launch a php web app (OpsWorks PHP Simple Demo App) using github repository. \n\n###Deploy PHP app now\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzait8001kdrgbcjf7xych","content":"<p>###Introduction<br>AWS OpsWorks PHP is a simple demo app that can help you get started using your favourite PHP language. </p>\n<p>This tutorial will guide you in launching a php web application (OpsWorks) in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a> </p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your workstation, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\" target=\"_blank\" rel=\"external\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a></p>\n</li>\n<li><p>You have to install openssh-server for ssh access.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre></li>\n<li><p>Check SSH working properly </p>\n<pre><code>ps aux | grep sshd\n</code></pre></li>\n</ul>\n<p>This initial section contains everything you need to get OpsWorks PHP Simple Demo App and running on your server.</p>\n<p>###Step-1 Fork OpsWorks PHP Simple Demo App</p>\n<ul>\n<li><p>Fork Open OpsWorks PHP Simple Demo App<br>from <a href=\"https://github.com/verticeapps/php_simpleapp.git\" target=\"_blank\" rel=\"external\">https://github.com/verticeapps/php_simpleapp.git</a></p>\n</li>\n<li><p>You will be see the fork option in the top right corner of the git hub page.click the fork option.</p>\n</li>\n<li><p>The OpsWorks PHP Simple Demo App repository is forked into your git repository.</p>\n</li>\n</ul>\n<p>###Step-2 Launch the app</p>\n<ol>\n<li><p>Go to MegamAfrica Dashboard</p>\n</li>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click PHP Icon.A window will pop up for your repository selection. </p>\n</li>\n<li><p>Pick a repository by choosing your git repository.</p>\n<p>Let us use Github: &lt; mygithub &gt;/php_simpleapp.git</p>\n</li>\n<li><p>You can create new sshkey or use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>To launch PHP App.Click Create.</p>\n</li>\n</ol>\n<ul>\n<li><p>Voila ! Your App is up to date.</p>\n</li>\n<li><p>Now that you have launched your app, you might want to launch a service (database) and bind it</p>\n</li>\n</ul>\n<p>###<strong>Buildpack for php</strong></p>\n<p>We use a PHP build pack using our super cool chef-repo. </p>\n<p>The buildpack for PHP </p>\n<pre><code>#!/bin/bash\n#Php builder\n#megam_php \nlocal_repo=/var/www/html/currentremote_repo=https://github.com/megamsys/opsworks-demo-php-simple-app.git\nmegam_home=/var/lib/megam/gulp\nfilename=$(basename &quot;$remote_repo&quot;)\nextension=&quot;${filename##*.}&quot;\nproject=&quot;${filename%.*}&quot;\ncd $megam_home\nrm -r $project\ngit clone $remote_repo\nrm -r $local_repo/*\nmv ./$project/* $local_repo\ncd $project\nif [  -f &quot;./$project/start&quot; ]; then\nchmod 755 ./$project/start\n./$project/star\nfi\nservice apache2 restart\n</code></pre><p>###<strong>Step-3 Open Your Web browser</strong><br>You can access your web page using <a href=\"http://IP_ADDRESS/current\" target=\"_blank\" rel=\"external\">http://IP_ADDRESS/current</a></p>\n<p>{<1>}<img src=\"/content/images/2016/05/ops.png\" alt=\"\"></1></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch a php web app (OpsWorks PHP Simple Demo App) using github repository. </p>\n<p>###Deploy PHP app now<br><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###Introduction<br>AWS OpsWorks PHP is a simple demo app that can help you get started using your favourite PHP language. </p>\n<p>This tutorial will guide you in launching a php web application (OpsWorks) in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a> </p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your workstation, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a></p>\n</li>\n<li><p>You have to install openssh-server for ssh access.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre></li>\n<li><p>Check SSH working properly </p>\n<pre><code>ps aux | grep sshd\n</code></pre></li>\n</ul>\n<p>This initial section contains everything you need to get OpsWorks PHP Simple Demo App and running on your server.</p>\n<p>###Step-1 Fork OpsWorks PHP Simple Demo App</p>\n<ul>\n<li><p>Fork Open OpsWorks PHP Simple Demo App<br>from <a href=\"https://github.com/verticeapps/php_simpleapp.git\">https://github.com/verticeapps/php_simpleapp.git</a></p>\n</li>\n<li><p>You will be see the fork option in the top right corner of the git hub page.click the fork option.</p>\n</li>\n<li><p>The OpsWorks PHP Simple Demo App repository is forked into your git repository.</p>\n</li>\n</ul>\n<p>###Step-2 Launch the app</p>\n<ol>\n<li><p>Go to MegamAfrica Dashboard</p>\n</li>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click PHP Icon.A window will pop up for your repository selection. </p>\n</li>\n<li><p>Pick a repository by choosing your git repository.</p>\n<p>Let us use Github: &lt; mygithub &gt;/php_simpleapp.git</p>\n</li>\n<li><p>You can create new sshkey or use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>To launch PHP App.Click Create.</p>\n</li>\n</ol>\n<ul>\n<li><p>Voila ! Your App is up to date.</p>\n</li>\n<li><p>Now that you have launched your app, you might want to launch a service (database) and bind it</p>\n</li>\n</ul>\n<p>###<strong>Buildpack for php</strong></p>\n<p>We use a PHP build pack using our super cool chef-repo. </p>\n<p>The buildpack for PHP </p>\n<pre><code>#!/bin/bash\n#Php builder\n#megam_php \nlocal_repo=/var/www/html/currentremote_repo=https://github.com/megamsys/opsworks-demo-php-simple-app.git\nmegam_home=/var/lib/megam/gulp\nfilename=$(basename &quot;$remote_repo&quot;)\nextension=&quot;${filename##*.}&quot;\nproject=&quot;${filename%.*}&quot;\ncd $megam_home\nrm -r $project\ngit clone $remote_repo\nrm -r $local_repo/*\nmv ./$project/* $local_repo\ncd $project\nif [  -f &quot;./$project/start&quot; ]; then\nchmod 755 ./$project/start\n./$project/star\nfi\nservice apache2 restart\n</code></pre><p>###<strong>Step-3 Open Your Web browser</strong><br>You can access your web page using <a href=\"http://IP_ADDRESS/current\">http://IP_ADDRESS/current</a></p>\n<p>{<1>}<img src=\"/content/images/2016/05/ops.png\" alt=\"\"></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch a php web app (OpsWorks PHP Simple Demo App) using github repository. </p>\n<p>###Deploy PHP app now<br><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"How to launch Redis in MegamAfrica","slug":"2016-05-11-how-to-launch-redis","date_published":"2016-05-10T23:42:20.685Z","date_updated":"2016-06-17T08:31:34.855Z","_content":"\n###Introduction\n\nRedis is an open source (BSD licensed), in-memory data structure store, used as database, cache and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs and geospatial indexes with radius queries. Redis has built-in replication, Lua scripting, LRU eviction, transactions and different levels of on-disk persistence, and provides high availability via Redis Sentinel and automatic partitioning with Redis Cluster.\n\nThis tutorial will guide you in launching Redis.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n###Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the How To Install Git with Apt.\n\n* An account on GitHub, which is a Git repository host.\n\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\nYou have to install openssh-server in your linux machine for ssh access.\n\n\t$ sudo apt-get install openssh-server\n\nTo check the ssh is properly installed in our system\n\n\t$ ps aux | grep sshd\n\n###Step - 1 Creating Redis \n\nThis initial section contains everything you need to get Redis and running on your server.\n\n* First, ensure the user can login to our console.megamafrica.com\n\n* Go to the Market Places.\n\n* Select the Redis, A window will pop up with for CPU, storage, RAM and SSHkey options.\n\n* You can choose the storage size and RAM capacity.\n\n* You can create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* Click the create button. it will create the virtual machine.\n\n###Step - 2 Accessing Redis\n\nNext, Go to the Dashboard and click the domain name a new window is open.\n\n* It contains the CPU, RAM and NETWORK tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and NETWORK usage.\n\n* VM Logs shows all the running process in VM.\n\n* You need to access the Virtual Machine from a terminal. \n\n* You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,\n\n \t\t$ ssh -i path to/<private_key filename> root@<ipaddress>\n \n* Now, you are login into vm then start the Redis use the following command\n\n\t\t$ redis-server\n    \n* Check if Redis is working properly is sending a PING command using redis-cli:\n\t\n    \t$ redis-cli ping\n\t\tPONG\n\nSuccessfully launched the vm and login into Redis.\n\n###Conclusion\n\nThese are the very simple steps to launch Redis in virtual machine.This is a good head-start for launching Redis in MegamAfrica.\n\n###Deploy Redis service\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n","source":"_posts/2016-05-11-how-to-launch-redis.md","raw":"---\ntitle: How to launch Redis in MegamAfrica\nslug: how-to-launch-redis\ndate_published: 2016-05-11T05:12:20.685Z\ndate_updated:   2016-06-17T14:01:34.855Z\n---\n\n###Introduction\n\nRedis is an open source (BSD licensed), in-memory data structure store, used as database, cache and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs and geospatial indexes with radius queries. Redis has built-in replication, Lua scripting, LRU eviction, transactions and different levels of on-disk persistence, and provides high availability via Redis Sentinel and automatic partitioning with Redis Cluster.\n\nThis tutorial will guide you in launching Redis.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n###Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the How To Install Git with Apt.\n\n* An account on GitHub, which is a Git repository host.\n\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\nYou have to install openssh-server in your linux machine for ssh access.\n\n\t$ sudo apt-get install openssh-server\n\nTo check the ssh is properly installed in our system\n\n\t$ ps aux | grep sshd\n\n###Step - 1 Creating Redis \n\nThis initial section contains everything you need to get Redis and running on your server.\n\n* First, ensure the user can login to our console.megamafrica.com\n\n* Go to the Market Places.\n\n* Select the Redis, A window will pop up with for CPU, storage, RAM and SSHkey options.\n\n* You can choose the storage size and RAM capacity.\n\n* You can create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* Click the create button. it will create the virtual machine.\n\n###Step - 2 Accessing Redis\n\nNext, Go to the Dashboard and click the domain name a new window is open.\n\n* It contains the CPU, RAM and NETWORK tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and NETWORK usage.\n\n* VM Logs shows all the running process in VM.\n\n* You need to access the Virtual Machine from a terminal. \n\n* You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,\n\n \t\t$ ssh -i path to/<private_key filename> root@<ipaddress>\n \n* Now, you are login into vm then start the Redis use the following command\n\n\t\t$ redis-server\n    \n* Check if Redis is working properly is sending a PING command using redis-cli:\n\t\n    \t$ redis-cli ping\n\t\tPONG\n\nSuccessfully launched the vm and login into Redis.\n\n###Conclusion\n\nThese are the very simple steps to launch Redis in virtual machine.This is a good head-start for launching Redis in MegamAfrica.\n\n###Deploy Redis service\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzait9001ldrgbcw5oss27","content":"<p>###Introduction</p>\n<p>Redis is an open source (BSD licensed), in-memory data structure store, used as database, cache and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs and geospatial indexes with radius queries. Redis has built-in replication, Lua scripting, LRU eviction, transactions and different levels of on-disk persistence, and provides high availability via Redis Sentinel and automatic partitioning with Redis Cluster.</p>\n<p>This tutorial will guide you in launching Redis.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the How To Install Git with Apt.</p>\n</li>\n<li><p>An account on GitHub, which is a Git repository host.</p>\n</li>\n</ul>\n<ul>\n<li>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a></li>\n</ul>\n<p>You have to install openssh-server in your linux machine for ssh access.</p>\n<pre><code>$ sudo apt-get install openssh-server\n</code></pre><p>To check the ssh is properly installed in our system</p>\n<pre><code>$ ps aux | grep sshd\n</code></pre><p>###Step - 1 Creating Redis </p>\n<p>This initial section contains everything you need to get Redis and running on your server.</p>\n<ul>\n<li><p>First, ensure the user can login to our console.megamafrica.com</p>\n</li>\n<li><p>Go to the Market Places.</p>\n</li>\n<li><p>Select the Redis, A window will pop up with for CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can choose the storage size and RAM capacity.</p>\n</li>\n<li><p>You can create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>Click the create button. it will create the virtual machine.</p>\n</li>\n</ul>\n<p>###Step - 2 Accessing Redis</p>\n<p>Next, Go to the Dashboard and click the domain name a new window is open.</p>\n<ul>\n<li><p>It contains the CPU, RAM and NETWORK tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and NETWORK usage.</p>\n</li>\n<li><p>VM Logs shows all the running process in VM.</p>\n</li>\n<li><p>You need to access the Virtual Machine from a terminal. </p>\n</li>\n<li><p>You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,</p>\n<pre><code>$ ssh -i path to/&lt;private_key filename&gt; root@&lt;ipaddress&gt;\n</code></pre></li>\n<li><p>Now, you are login into vm then start the Redis use the following command</p>\n<pre><code>$ redis-server\n</code></pre></li>\n<li><p>Check if Redis is working properly is sending a PING command using redis-cli:</p>\n<pre><code>$ redis-cli ping\nPONG\n</code></pre></li>\n</ul>\n<p>Successfully launched the vm and login into Redis.</p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch Redis in virtual machine.This is a good head-start for launching Redis in MegamAfrica.</p>\n<p>###Deploy Redis service</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###Introduction</p>\n<p>Redis is an open source (BSD licensed), in-memory data structure store, used as database, cache and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs and geospatial indexes with radius queries. Redis has built-in replication, Lua scripting, LRU eviction, transactions and different levels of on-disk persistence, and provides high availability via Redis Sentinel and automatic partitioning with Redis Cluster.</p>\n<p>This tutorial will guide you in launching Redis.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the How To Install Git with Apt.</p>\n</li>\n<li><p>An account on GitHub, which is a Git repository host.</p>\n</li>\n</ul>\n<ul>\n<li>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a></li>\n</ul>\n<p>You have to install openssh-server in your linux machine for ssh access.</p>\n<pre><code>$ sudo apt-get install openssh-server\n</code></pre><p>To check the ssh is properly installed in our system</p>\n<pre><code>$ ps aux | grep sshd\n</code></pre><p>###Step - 1 Creating Redis </p>\n<p>This initial section contains everything you need to get Redis and running on your server.</p>\n<ul>\n<li><p>First, ensure the user can login to our console.megamafrica.com</p>\n</li>\n<li><p>Go to the Market Places.</p>\n</li>\n<li><p>Select the Redis, A window will pop up with for CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can choose the storage size and RAM capacity.</p>\n</li>\n<li><p>You can create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>Click the create button. it will create the virtual machine.</p>\n</li>\n</ul>\n<p>###Step - 2 Accessing Redis</p>\n<p>Next, Go to the Dashboard and click the domain name a new window is open.</p>\n<ul>\n<li><p>It contains the CPU, RAM and NETWORK tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and NETWORK usage.</p>\n</li>\n<li><p>VM Logs shows all the running process in VM.</p>\n</li>\n<li><p>You need to access the Virtual Machine from a terminal. </p>\n</li>\n<li><p>You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,</p>\n<pre><code>$ ssh -i path to/&lt;private_key filename&gt; root@&lt;ipaddress&gt;\n</code></pre></li>\n<li><p>Now, you are login into vm then start the Redis use the following command</p>\n<pre><code>$ redis-server\n</code></pre></li>\n<li><p>Check if Redis is working properly is sending a PING command using redis-cli:</p>\n<pre><code>$ redis-cli ping\nPONG\n</code></pre></li>\n</ul>\n<p>Successfully launched the vm and login into Redis.</p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch Redis in virtual machine.This is a good head-start for launching Redis in MegamAfrica.</p>\n<p>###Deploy Redis service</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"How to launch travis-web in MegamAfrica","slug":"2016-05-11-how-to-launch-travis-web","date_published":"2016-05-11T00:53:09.991Z","date_updated":"2016-05-27T07:00:57.152Z","_content":"\n###Introduction\nIn software development, Travis-web is an open-source hosted, distributed continuous integration service used to build and test projects hosted at GitHub. Travis CI is configured by adding a file named .travis.yml, which is a YAML format text file, to the root directory of the GitHub repository.\n\n[![img](/content/images/2016/05/DEPLOY-TO-MEGAM-AFRICA-BIG1-4.png)](https://console.megamafrica.com)\n\n\n###Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* An account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential access for https://console.megamafrica.com.\n\n* You have to install openssh-server for ssh access.\n\n\t\tsudo apt-get install openssh-server\n    \n* Check SSH working properly \n\n\t\tps aux | grep sshd\nThis initial section contains everything you need to get etherpad-lite running on your server.\n\n###Step-1 Fork travis-web\n* Fork travis-web\nfrom [here](https://github.com/verticeapps/node_travisweb.git)\n\n* You will be see the fork option in the top right corner of the git hub page.click the fork option.\n\n* The travisweb is forked into your git repository\n\n###Step-2 create SSHKey and launch the app\n* Then go to your MegamAfrica Dashboard\n\n2. Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n3. Click Nodejs Icon.A window will pop up with for SSHkey options. You can create new sshkey, use an existing sshkey or upload your own sshkeys too.\n\n5. Pick a repository by Choose your public repository.\n\n  Let us use Github: <mygithubid>/travisweb\n\n6.\tTo launch Nodejs App.Click Create.\n\n* Voila ! Your App is up to date.\n\n* Now that you have launched your app, you might want to launch a service (database) and bind it\n\n###Start script\nMegamAfrica will look for a start script named `start as follows. \n\n\t#!/bin/sh\n \tsudo invoke-rc.d shellinabox stop\n    npm install -g ember-cli\n \tbower install --allow-root\n \tnpm install -g watchman`\n \tnpm rebuild node-sass\n \tnpm install\n \tember serve\n\n       \n###**Step-3 Open Your Web browser**\nYou can access your web page using http://IP_ADDRESS/4200\n\n![](/content/images/2016/05/Screenshot-from-2016-05-27-15-16-35.png)\n\n\n\n\n\n\n\n\n###Conclusion\n\nThese are the very simple steps to launch Nodejs using travis-web. Finally using github repository and launched the travis-web to run successfully.\n\n###To deploy your App \n[![img](/content/images/2016/05/DEPLOY-TO-MEGAM-AFRICA-BIG1-4.png)](https://console.megamafrica.com)\n\n\n\n\n","source":"_posts/2016-05-11-how-to-launch-travis-web.md","raw":"---\ntitle: How to launch travis-web in MegamAfrica\nslug: how-to-launch-travis-web\ndate_published: 2016-05-11T06:23:09.991Z\ndate_updated:   2016-05-27T12:30:57.152Z\n---\n\n###Introduction\nIn software development, Travis-web is an open-source hosted, distributed continuous integration service used to build and test projects hosted at GitHub. Travis CI is configured by adding a file named .travis.yml, which is a YAML format text file, to the root directory of the GitHub repository.\n\n[![img](/content/images/2016/05/DEPLOY-TO-MEGAM-AFRICA-BIG1-4.png)](https://console.megamafrica.com)\n\n\n###Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* An account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential access for https://console.megamafrica.com.\n\n* You have to install openssh-server for ssh access.\n\n\t\tsudo apt-get install openssh-server\n    \n* Check SSH working properly \n\n\t\tps aux | grep sshd\nThis initial section contains everything you need to get etherpad-lite running on your server.\n\n###Step-1 Fork travis-web\n* Fork travis-web\nfrom [here](https://github.com/verticeapps/node_travisweb.git)\n\n* You will be see the fork option in the top right corner of the git hub page.click the fork option.\n\n* The travisweb is forked into your git repository\n\n###Step-2 create SSHKey and launch the app\n* Then go to your MegamAfrica Dashboard\n\n2. Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n3. Click Nodejs Icon.A window will pop up with for SSHkey options. You can create new sshkey, use an existing sshkey or upload your own sshkeys too.\n\n5. Pick a repository by Choose your public repository.\n\n  Let us use Github: <mygithubid>/travisweb\n\n6.\tTo launch Nodejs App.Click Create.\n\n* Voila ! Your App is up to date.\n\n* Now that you have launched your app, you might want to launch a service (database) and bind it\n\n###Start script\nMegamAfrica will look for a start script named `start as follows. \n\n\t#!/bin/sh\n \tsudo invoke-rc.d shellinabox stop\n    npm install -g ember-cli\n \tbower install --allow-root\n \tnpm install -g watchman`\n \tnpm rebuild node-sass\n \tnpm install\n \tember serve\n\n       \n###**Step-3 Open Your Web browser**\nYou can access your web page using http://IP_ADDRESS/4200\n\n![](/content/images/2016/05/Screenshot-from-2016-05-27-15-16-35.png)\n\n\n\n\n\n\n\n\n###Conclusion\n\nThese are the very simple steps to launch Nodejs using travis-web. Finally using github repository and launched the travis-web to run successfully.\n\n###To deploy your App \n[![img](/content/images/2016/05/DEPLOY-TO-MEGAM-AFRICA-BIG1-4.png)](https://console.megamafrica.com)\n\n\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaita001mdrgbjln7y1uc","content":"<p>###Introduction<br>In software development, Travis-web is an open-source hosted, distributed continuous integration service used to build and test projects hosted at GitHub. Travis CI is configured by adding a file named .travis.yml, which is a YAML format text file, to the root directory of the GitHub repository.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\"><img src=\"/content/images/2016/05/DEPLOY-TO-MEGAM-AFRICA-BIG1-4.png\" alt=\"img\"></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\" target=\"_blank\" rel=\"external\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>An account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential access for <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>.</p>\n</li>\n<li><p>You have to install openssh-server for ssh access.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre></li>\n<li><p>Check SSH working properly </p>\n<pre><code>ps aux | grep sshd\n</code></pre><p>This initial section contains everything you need to get etherpad-lite running on your server.</p>\n</li>\n</ul>\n<p>###Step-1 Fork travis-web</p>\n<ul>\n<li><p>Fork travis-web<br>from <a href=\"https://github.com/verticeapps/node_travisweb.git\" target=\"_blank\" rel=\"external\">here</a></p>\n</li>\n<li><p>You will be see the fork option in the top right corner of the git hub page.click the fork option.</p>\n</li>\n<li><p>The travisweb is forked into your git repository</p>\n</li>\n</ul>\n<p>###Step-2 create SSHKey and launch the app</p>\n<ul>\n<li>Then go to your MegamAfrica Dashboard</li>\n</ul>\n<ol>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click Nodejs Icon.A window will pop up with for SSHkey options. You can create new sshkey, use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>Pick a repository by Choose your public repository.</p>\n<p>Let us use Github: <mygithubid>/travisweb</mygithubid></p>\n</li>\n<li><p>To launch Nodejs App.Click Create.</p>\n</li>\n</ol>\n<ul>\n<li><p>Voila ! Your App is up to date.</p>\n</li>\n<li><p>Now that you have launched your app, you might want to launch a service (database) and bind it</p>\n</li>\n</ul>\n<p>###Start script<br>MegamAfrica will look for a start script named `start as follows. </p>\n<pre><code>#!/bin/sh\n sudo invoke-rc.d shellinabox stop\nnpm install -g ember-cli\n bower install --allow-root\n npm install -g watchman`\n npm rebuild node-sass\n npm install\n ember serve\n</code></pre><p>###<strong>Step-3 Open Your Web browser</strong><br>You can access your web page using <a href=\"http://IP_ADDRESS/4200\" target=\"_blank\" rel=\"external\">http://IP_ADDRESS/4200</a></p>\n<p><img src=\"/content/images/2016/05/Screenshot-from-2016-05-27-15-16-35.png\" alt=\"\"></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch Nodejs using travis-web. Finally using github repository and launched the travis-web to run successfully.</p>\n<p>###To deploy your App<br><a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\"><img src=\"/content/images/2016/05/DEPLOY-TO-MEGAM-AFRICA-BIG1-4.png\" alt=\"img\"></a></p>\n","excerpt":"","more":"<p>###Introduction<br>In software development, Travis-web is an open-source hosted, distributed continuous integration service used to build and test projects hosted at GitHub. Travis CI is configured by adding a file named .travis.yml, which is a YAML format text file, to the root directory of the GitHub repository.</p>\n<p><a href=\"https://console.megamafrica.com\"><img src=\"/content/images/2016/05/DEPLOY-TO-MEGAM-AFRICA-BIG1-4.png\" alt=\"img\"></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>An account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential access for <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>.</p>\n</li>\n<li><p>You have to install openssh-server for ssh access.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre></li>\n<li><p>Check SSH working properly </p>\n<pre><code>ps aux | grep sshd\n</code></pre><p>This initial section contains everything you need to get etherpad-lite running on your server.</p>\n</li>\n</ul>\n<p>###Step-1 Fork travis-web</p>\n<ul>\n<li><p>Fork travis-web<br>from <a href=\"https://github.com/verticeapps/node_travisweb.git\">here</a></p>\n</li>\n<li><p>You will be see the fork option in the top right corner of the git hub page.click the fork option.</p>\n</li>\n<li><p>The travisweb is forked into your git repository</p>\n</li>\n</ul>\n<p>###Step-2 create SSHKey and launch the app</p>\n<ul>\n<li>Then go to your MegamAfrica Dashboard</li>\n</ul>\n<ol>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click Nodejs Icon.A window will pop up with for SSHkey options. You can create new sshkey, use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>Pick a repository by Choose your public repository.</p>\n<p>Let us use Github: <mygithubid>/travisweb</p>\n</li>\n<li><p>To launch Nodejs App.Click Create.</p>\n</li>\n</ol>\n<ul>\n<li><p>Voila ! Your App is up to date.</p>\n</li>\n<li><p>Now that you have launched your app, you might want to launch a service (database) and bind it</p>\n</li>\n</ul>\n<p>###Start script<br>MegamAfrica will look for a start script named `start as follows. </p>\n<pre><code>#!/bin/sh\n sudo invoke-rc.d shellinabox stop\nnpm install -g ember-cli\n bower install --allow-root\n npm install -g watchman`\n npm rebuild node-sass\n npm install\n ember serve\n</code></pre><p>###<strong>Step-3 Open Your Web browser</strong><br>You can access your web page using <a href=\"http://IP_ADDRESS/4200\">http://IP_ADDRESS/4200</a></p>\n<p><img src=\"/content/images/2016/05/Screenshot-from-2016-05-27-15-16-35.png\" alt=\"\"></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch Nodejs using travis-web. Finally using github repository and launched the travis-web to run successfully.</p>\n<p>###To deploy your App<br><a href=\"https://console.megamafrica.com\"><img src=\"/content/images/2016/05/DEPLOY-TO-MEGAM-AFRICA-BIG1-4.png\" alt=\"img\"></a></p>\n"},{"title":"How to launch PHP - Open Web Analytics  in MegamAfrica","slug":"2016-05-11-open-web-analytics-installer","date_published":"2016-05-10T23:30:16.046Z","date_updated":"2016-05-27T07:53:18.016Z","_content":"\n###**Introduction**\n\nOpen Web Analytics (OWA) is an open source web analytics framework written in PHP. OWA was born out of the need for an open source framework that could be used to easily add web analytics features to web sites and applications. The OWA framework also comes with built-in support for popular web applications such as WordPress and MediaWiki. As a generic web analytics framework, OWA can be extended to track and analyze any web application.\n\nThis tutorial will guide you in launching a php web application (Open Web Analytics) in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###**Prerequisites**\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git is installed on your workstation, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\n\n* You have to install openssh-server for ssh access in your worstation.\n\n\t\tsudo apt-get install openssh-server\n    \n* Check SSH working properly \n\n\t\tps aux | grep sshd\n\nThis initial section contains everything you need to get Open Web Analytics App and running on your server.\n\n###Step-1 Fork Open Web Analytics\n* Fork Open Web Analytics\nfrom https://github.com/verticeapps/php_webanalytics.git\n\n* You will be see the fork option in the top right corner of the git hub page.click the fork option.\n\n* The Open Web Analytics repository is forked into your git repository\n\n###Step-2 Launch the app\n1. Go to MegamAfrica Dashboard\n\n2. Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n4. Click PHP Icon.A window will pop up for your git repository selection. \n\n3. Pick a repository by choosing your repository.\n\n  Let us use Github: < mygithub >/php_webanalytics.git\n\n5. You can create new sshkey or use an existing sshkey or upload your own sshkeys too.\n\n6. To launch PHP App.Click Create.\n\n* Voila ! Your App is up to date.\n\n* Now that you have launched your app, you might want to launch a service (database) and bind it\n\n###**Buildpack for php**\n\nWe use a default PHP build pack using our super cool chef-repo. \n\nThe build pack for PHP\n  \n\t#!/bin/bash\n\t#Php builder\n\t#megam_php \n\tlocal_repo=/var/www/html/currentremote_repo=https://github.com/megamsys/Open-Web-Analytics.git\n\tmegam_home=/var/lib/megam/gulp\n\tfilename=$(basename \"$remote_repo\")\n\textension=\"${filename##*.}\"\n\tproject=\"${filename%.*}\"\n\tcd $megam_home\n\trm -r $project\n    git clone $remote_repo\n    rm -r $local_repo/*\n    mv ./$project/* $local_repo\n    cd $project\n    if [  -f \"./$project/start\" ]; then\n    chmod 755 ./$project/start\n    ./$project/star\n    fi\n    service apache2 restart\n    \n\n    \n   \n###**Step-3 Open Your Web browser**\nYou can access your web page using http://IP_ADDRESS/current\n\n\n{<1>}![](/content/images/2016/05/mmm.png)\n\n###Conclusion\n\nThese are the very simple steps to launch a PHP web app (Open Web Analytics) using your github repository.\n\n### Deploy PHP app now\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n   \n","source":"_posts/2016-05-11-open-web-analytics-installer.md","raw":"---\ntitle: How to launch PHP - Open Web Analytics  in MegamAfrica\nslug: open-web-analytics-installer\ndate_published: 2016-05-11T05:00:16.046Z\ndate_updated:   2016-05-27T13:23:18.016Z\n---\n\n###**Introduction**\n\nOpen Web Analytics (OWA) is an open source web analytics framework written in PHP. OWA was born out of the need for an open source framework that could be used to easily add web analytics features to web sites and applications. The OWA framework also comes with built-in support for popular web applications such as WordPress and MediaWiki. As a generic web analytics framework, OWA can be extended to track and analyze any web application.\n\nThis tutorial will guide you in launching a php web application (Open Web Analytics) in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###**Prerequisites**\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git is installed on your workstation, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n* You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\n\n* You have to install openssh-server for ssh access in your worstation.\n\n\t\tsudo apt-get install openssh-server\n    \n* Check SSH working properly \n\n\t\tps aux | grep sshd\n\nThis initial section contains everything you need to get Open Web Analytics App and running on your server.\n\n###Step-1 Fork Open Web Analytics\n* Fork Open Web Analytics\nfrom https://github.com/verticeapps/php_webanalytics.git\n\n* You will be see the fork option in the top right corner of the git hub page.click the fork option.\n\n* The Open Web Analytics repository is forked into your git repository\n\n###Step-2 Launch the app\n1. Go to MegamAfrica Dashboard\n\n2. Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n4. Click PHP Icon.A window will pop up for your git repository selection. \n\n3. Pick a repository by choosing your repository.\n\n  Let us use Github: < mygithub >/php_webanalytics.git\n\n5. You can create new sshkey or use an existing sshkey or upload your own sshkeys too.\n\n6. To launch PHP App.Click Create.\n\n* Voila ! Your App is up to date.\n\n* Now that you have launched your app, you might want to launch a service (database) and bind it\n\n###**Buildpack for php**\n\nWe use a default PHP build pack using our super cool chef-repo. \n\nThe build pack for PHP\n  \n\t#!/bin/bash\n\t#Php builder\n\t#megam_php \n\tlocal_repo=/var/www/html/currentremote_repo=https://github.com/megamsys/Open-Web-Analytics.git\n\tmegam_home=/var/lib/megam/gulp\n\tfilename=$(basename \"$remote_repo\")\n\textension=\"${filename##*.}\"\n\tproject=\"${filename%.*}\"\n\tcd $megam_home\n\trm -r $project\n    git clone $remote_repo\n    rm -r $local_repo/*\n    mv ./$project/* $local_repo\n    cd $project\n    if [  -f \"./$project/start\" ]; then\n    chmod 755 ./$project/start\n    ./$project/star\n    fi\n    service apache2 restart\n    \n\n    \n   \n###**Step-3 Open Your Web browser**\nYou can access your web page using http://IP_ADDRESS/current\n\n\n{<1>}![](/content/images/2016/05/mmm.png)\n\n###Conclusion\n\nThese are the very simple steps to launch a PHP web app (Open Web Analytics) using your github repository.\n\n### Deploy PHP app now\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n   \n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaitb001ndrgb6wjdpjtb","content":"<p>###<strong>Introduction</strong></p>\n<p>Open Web Analytics (OWA) is an open source web analytics framework written in PHP. OWA was born out of the need for an open source framework that could be used to easily add web analytics features to web sites and applications. The OWA framework also comes with built-in support for popular web applications such as WordPress and MediaWiki. As a generic web analytics framework, OWA can be extended to track and analyze any web application.</p>\n<p>This tutorial will guide you in launching a php web application (Open Web Analytics) in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>###<strong>Prerequisites</strong></p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git is installed on your workstation, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\" target=\"_blank\" rel=\"external\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a></p>\n</li>\n</ul>\n<ul>\n<li><p>You have to install openssh-server for ssh access in your worstation.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre></li>\n<li><p>Check SSH working properly </p>\n<pre><code>ps aux | grep sshd\n</code></pre></li>\n</ul>\n<p>This initial section contains everything you need to get Open Web Analytics App and running on your server.</p>\n<p>###Step-1 Fork Open Web Analytics</p>\n<ul>\n<li><p>Fork Open Web Analytics<br>from <a href=\"https://github.com/verticeapps/php_webanalytics.git\" target=\"_blank\" rel=\"external\">https://github.com/verticeapps/php_webanalytics.git</a></p>\n</li>\n<li><p>You will be see the fork option in the top right corner of the git hub page.click the fork option.</p>\n</li>\n<li><p>The Open Web Analytics repository is forked into your git repository</p>\n</li>\n</ul>\n<p>###Step-2 Launch the app</p>\n<ol>\n<li><p>Go to MegamAfrica Dashboard</p>\n</li>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click PHP Icon.A window will pop up for your git repository selection. </p>\n</li>\n<li><p>Pick a repository by choosing your repository.</p>\n<p>Let us use Github: &lt; mygithub &gt;/php_webanalytics.git</p>\n</li>\n<li><p>You can create new sshkey or use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>To launch PHP App.Click Create.</p>\n</li>\n</ol>\n<ul>\n<li><p>Voila ! Your App is up to date.</p>\n</li>\n<li><p>Now that you have launched your app, you might want to launch a service (database) and bind it</p>\n</li>\n</ul>\n<p>###<strong>Buildpack for php</strong></p>\n<p>We use a default PHP build pack using our super cool chef-repo. </p>\n<p>The build pack for PHP</p>\n<pre><code>#!/bin/bash\n#Php builder\n#megam_php \nlocal_repo=/var/www/html/currentremote_repo=https://github.com/megamsys/Open-Web-Analytics.git\nmegam_home=/var/lib/megam/gulp\nfilename=$(basename &quot;$remote_repo&quot;)\nextension=&quot;${filename##*.}&quot;\nproject=&quot;${filename%.*}&quot;\ncd $megam_home\nrm -r $project\ngit clone $remote_repo\nrm -r $local_repo/*\nmv ./$project/* $local_repo\ncd $project\nif [  -f &quot;./$project/start&quot; ]; then\nchmod 755 ./$project/start\n./$project/star\nfi\nservice apache2 restart\n</code></pre><p>###<strong>Step-3 Open Your Web browser</strong><br>You can access your web page using <a href=\"http://IP_ADDRESS/current\" target=\"_blank\" rel=\"external\">http://IP_ADDRESS/current</a></p>\n<p>{<1>}<img src=\"/content/images/2016/05/mmm.png\" alt=\"\"></1></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch a PHP web app (Open Web Analytics) using your github repository.</p>\n<h3 id=\"Deploy-PHP-app-now\"><a href=\"#Deploy-PHP-app-now\" class=\"headerlink\" title=\"Deploy PHP app now\"></a>Deploy PHP app now</h3><p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###<strong>Introduction</strong></p>\n<p>Open Web Analytics (OWA) is an open source web analytics framework written in PHP. OWA was born out of the need for an open source framework that could be used to easily add web analytics features to web sites and applications. The OWA framework also comes with built-in support for popular web applications such as WordPress and MediaWiki. As a generic web analytics framework, OWA can be extended to track and analyze any web application.</p>\n<p>This tutorial will guide you in launching a php web application (Open Web Analytics) in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>###<strong>Prerequisites</strong></p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git is installed on your workstation, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a></p>\n</li>\n</ul>\n<ul>\n<li><p>You have to install openssh-server for ssh access in your worstation.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre></li>\n<li><p>Check SSH working properly </p>\n<pre><code>ps aux | grep sshd\n</code></pre></li>\n</ul>\n<p>This initial section contains everything you need to get Open Web Analytics App and running on your server.</p>\n<p>###Step-1 Fork Open Web Analytics</p>\n<ul>\n<li><p>Fork Open Web Analytics<br>from <a href=\"https://github.com/verticeapps/php_webanalytics.git\">https://github.com/verticeapps/php_webanalytics.git</a></p>\n</li>\n<li><p>You will be see the fork option in the top right corner of the git hub page.click the fork option.</p>\n</li>\n<li><p>The Open Web Analytics repository is forked into your git repository</p>\n</li>\n</ul>\n<p>###Step-2 Launch the app</p>\n<ol>\n<li><p>Go to MegamAfrica Dashboard</p>\n</li>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click PHP Icon.A window will pop up for your git repository selection. </p>\n</li>\n<li><p>Pick a repository by choosing your repository.</p>\n<p>Let us use Github: &lt; mygithub &gt;/php_webanalytics.git</p>\n</li>\n<li><p>You can create new sshkey or use an existing sshkey or upload your own sshkeys too.</p>\n</li>\n<li><p>To launch PHP App.Click Create.</p>\n</li>\n</ol>\n<ul>\n<li><p>Voila ! Your App is up to date.</p>\n</li>\n<li><p>Now that you have launched your app, you might want to launch a service (database) and bind it</p>\n</li>\n</ul>\n<p>###<strong>Buildpack for php</strong></p>\n<p>We use a default PHP build pack using our super cool chef-repo. </p>\n<p>The build pack for PHP</p>\n<pre><code>#!/bin/bash\n#Php builder\n#megam_php \nlocal_repo=/var/www/html/currentremote_repo=https://github.com/megamsys/Open-Web-Analytics.git\nmegam_home=/var/lib/megam/gulp\nfilename=$(basename &quot;$remote_repo&quot;)\nextension=&quot;${filename##*.}&quot;\nproject=&quot;${filename%.*}&quot;\ncd $megam_home\nrm -r $project\ngit clone $remote_repo\nrm -r $local_repo/*\nmv ./$project/* $local_repo\ncd $project\nif [  -f &quot;./$project/start&quot; ]; then\nchmod 755 ./$project/start\n./$project/star\nfi\nservice apache2 restart\n</code></pre><p>###<strong>Step-3 Open Your Web browser</strong><br>You can access your web page using <a href=\"http://IP_ADDRESS/current\">http://IP_ADDRESS/current</a></p>\n<p>{<1>}<img src=\"/content/images/2016/05/mmm.png\" alt=\"\"></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch a PHP web app (Open Web Analytics) using your github repository.</p>\n<h3 id=\"Deploy-PHP-app-now\"><a href=\"#Deploy-PHP-app-now\" class=\"headerlink\" title=\"Deploy PHP app now\"></a>Deploy PHP app now</h3><p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"How to launch WordPress in MegamAfrica","slug":"2016-05-26-how-to-launch-wordpress","date_published":"2016-05-26T08:41:07.844Z","date_updated":"2016-05-27T02:40:50.163Z","_content":"\n#####Introduction\n\nWordPress is web software you can use to create a beautiful website, blog, or app. We like to say that WordPress is both free and priceless at the same time.\n\nAnd WordPress is a free and open-source content management system (CMS) based on PHP and MySQL. WordPress is installed on a web server, which either is part of an Internet hosting service or is a network host itself; the first case may be on a service like WordPress.com, for example, and the second case is a computer running the software package WordPress.org. [readmore](https://wordpress.org/news/category/documentation/)\n\n[![megamafrica](https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png)](https://console.megamafrica.com)\n\n#####Prerequisites\n\nYou have to create a valid credential access for https://console.megamafrica.com.\n\nYou have to install openssh-server for ssh access.\n\n\tsudo apt-get install openssh-server\n\nCheck SSH working properly\n\n\t\tps aux | grep sshd\n        \n######Step - 1 Lauch WordPress just by One Click \n\nThis initial section contains everything you need to get WordPress and running on your server.\n\nFirst, ensure the user to login our [site](https://console.megamafrica.com) .\n\nGo to the Market Places to click the create a new `WordPress on Collaboration`.\n\n* A window will pop up with the configurations of your server such CPU, storage, RAM and SSHkey options.\n\n* You can customize your HDD size,Core and RAM capacity.\n\n* You can create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* Click the create button. it will create the WordPress Machine.\n\n######Step - 2 Access the WordPress Machine\n* Next, Go to the Services it will show your services that you are lauched click the domain name of your wordpress and then a new window is open.\n\n* Now you can see your machine's CPU, RAM ,Storage IP address and SSH URL on Usage section.\n\n* And you can see your Metrics charts of CPU,RAM and Network of your machine.\n\n* Logs will show all the running process in the server.\n\n* You can access the virtual machine via SSH connection, you can download the your private and public keys from SSH Keys tab or Overview page. Use this keys to ssh like following command,\n\n\t$ ssh -i path to/private_key_filename root@ipaddress\n\n\n######Step - 3 Credentials of WordPress\n\nGet your server's IP from overview page \n\n* Go to your browser and type as follows\n\n\thttp://IP_ADDRESS/current \n    \n* Now you can see your WordPress welcome page and press Let's go! on that page.\n\n* Enter the credentials of database for WordPress. the below are default credentials. \n\nThe name of the database you want to use with WordPress.\n \n \t\tDatabase Name :\twordpress\n\nYour database username and password.\n\t\t\n        Username :  root\n\t\tPassword :\t<leave it blank>\n\nYou should be able to get this info from your web host, if localhost doesnt work.\n\n\t\tDatabase Host:\tlocalhost\n\nIf you want to run multiple WordPress installations in a single database, change this.\n\n\t\tTable Prefix : wp_\n\n* press submit, if the given credentials are valid it gets into next page \n\n* Press Run the install button shown in the page. \n\n* In this page you can choose your WordPress Login username, Password and your Site name.\n\nLogin with your user and password it will get to wordpress design page successfully.\n\n![](/content/images/2016/05/wordpress.png)\n\n\n#####Conclusion\n\nThese are the very simple steps to launch WordPress in virtual machine. Installing wordpress is faster, so it takes only less time. This is a good head-start for launching a WordPress in [MegamAfrica](https://console.megamafrica.com).\n\nTo Launch your WordPress Server click here\n\n\n[![megamafrica](https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png)](https://console.megamafrica.com)\n","source":"_posts/2016-05-26-how-to-launch-wordpress.md","raw":"---\ntitle: How to launch WordPress in MegamAfrica\nslug: how-to-launch-wordpress\ndate_published: 2016-05-26T14:11:07.844Z\ndate_updated:   2016-05-27T08:10:50.163Z\n---\n\n#####Introduction\n\nWordPress is web software you can use to create a beautiful website, blog, or app. We like to say that WordPress is both free and priceless at the same time.\n\nAnd WordPress is a free and open-source content management system (CMS) based on PHP and MySQL. WordPress is installed on a web server, which either is part of an Internet hosting service or is a network host itself; the first case may be on a service like WordPress.com, for example, and the second case is a computer running the software package WordPress.org. [readmore](https://wordpress.org/news/category/documentation/)\n\n[![megamafrica](https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png)](https://console.megamafrica.com)\n\n#####Prerequisites\n\nYou have to create a valid credential access for https://console.megamafrica.com.\n\nYou have to install openssh-server for ssh access.\n\n\tsudo apt-get install openssh-server\n\nCheck SSH working properly\n\n\t\tps aux | grep sshd\n        \n######Step - 1 Lauch WordPress just by One Click \n\nThis initial section contains everything you need to get WordPress and running on your server.\n\nFirst, ensure the user to login our [site](https://console.megamafrica.com) .\n\nGo to the Market Places to click the create a new `WordPress on Collaboration`.\n\n* A window will pop up with the configurations of your server such CPU, storage, RAM and SSHkey options.\n\n* You can customize your HDD size,Core and RAM capacity.\n\n* You can create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* Click the create button. it will create the WordPress Machine.\n\n######Step - 2 Access the WordPress Machine\n* Next, Go to the Services it will show your services that you are lauched click the domain name of your wordpress and then a new window is open.\n\n* Now you can see your machine's CPU, RAM ,Storage IP address and SSH URL on Usage section.\n\n* And you can see your Metrics charts of CPU,RAM and Network of your machine.\n\n* Logs will show all the running process in the server.\n\n* You can access the virtual machine via SSH connection, you can download the your private and public keys from SSH Keys tab or Overview page. Use this keys to ssh like following command,\n\n\t$ ssh -i path to/private_key_filename root@ipaddress\n\n\n######Step - 3 Credentials of WordPress\n\nGet your server's IP from overview page \n\n* Go to your browser and type as follows\n\n\thttp://IP_ADDRESS/current \n    \n* Now you can see your WordPress welcome page and press Let's go! on that page.\n\n* Enter the credentials of database for WordPress. the below are default credentials. \n\nThe name of the database you want to use with WordPress.\n \n \t\tDatabase Name :\twordpress\n\nYour database username and password.\n\t\t\n        Username :  root\n\t\tPassword :\t<leave it blank>\n\nYou should be able to get this info from your web host, if localhost doesnt work.\n\n\t\tDatabase Host:\tlocalhost\n\nIf you want to run multiple WordPress installations in a single database, change this.\n\n\t\tTable Prefix : wp_\n\n* press submit, if the given credentials are valid it gets into next page \n\n* Press Run the install button shown in the page. \n\n* In this page you can choose your WordPress Login username, Password and your Site name.\n\nLogin with your user and password it will get to wordpress design page successfully.\n\n![](/content/images/2016/05/wordpress.png)\n\n\n#####Conclusion\n\nThese are the very simple steps to launch WordPress in virtual machine. Installing wordpress is faster, so it takes only less time. This is a good head-start for launching a WordPress in [MegamAfrica](https://console.megamafrica.com).\n\nTo Launch your WordPress Server click here\n\n\n[![megamafrica](https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png)](https://console.megamafrica.com)\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:16.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaitc001odrgb2u3i57yq","content":"<p>#####Introduction</p>\n<p>WordPress is web software you can use to create a beautiful website, blog, or app. We like to say that WordPress is both free and priceless at the same time.</p>\n<p>And WordPress is a free and open-source content management system (CMS) based on PHP and MySQL. WordPress is installed on a web server, which either is part of an Internet hosting service or is a network host itself; the first case may be on a service like WordPress.com, for example, and the second case is a computer running the software package WordPress.org. <a href=\"https://wordpress.org/news/category/documentation/\" target=\"_blank\" rel=\"external\">readmore</a></p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\"><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"megamafrica\"></a></p>\n<p>#####Prerequisites</p>\n<p>You have to create a valid credential access for <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>.</p>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre><p>Check SSH working properly</p>\n<pre><code>ps aux | grep sshd\n</code></pre><p>######Step - 1 Lauch WordPress just by One Click </p>\n<p>This initial section contains everything you need to get WordPress and running on your server.</p>\n<p>First, ensure the user to login our <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">site</a> .</p>\n<p>Go to the Market Places to click the create a new <code>WordPress on Collaboration</code>.</p>\n<ul>\n<li><p>A window will pop up with the configurations of your server such CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can customize your HDD size,Core and RAM capacity.</p>\n</li>\n<li><p>You can create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>Click the create button. it will create the WordPress Machine.</p>\n</li>\n</ul>\n<p>######Step - 2 Access the WordPress Machine</p>\n<ul>\n<li><p>Next, Go to the Services it will show your services that you are lauched click the domain name of your wordpress and then a new window is open.</p>\n</li>\n<li><p>Now you can see your machines CPU, RAM ,Storage IP address and SSH URL on Usage section.</p>\n</li>\n<li><p>And you can see your Metrics charts of CPU,RAM and Network of your machine.</p>\n</li>\n<li><p>Logs will show all the running process in the server.</p>\n</li>\n<li><p>You can access the virtual machine via SSH connection, you can download the your private and public keys from SSH Keys tab or Overview page. Use this keys to ssh like following command,</p>\n<p>  $ ssh -i path to/private_key_filename root@ipaddress</p>\n</li>\n</ul>\n<p>######Step - 3 Credentials of WordPress</p>\n<p>Get your servers IP from overview page </p>\n<ul>\n<li><p>Go to your browser and type as follows</p>\n<p>  <a href=\"http://IP_ADDRESS/current\" target=\"_blank\" rel=\"external\">http://IP_ADDRESS/current</a> </p>\n</li>\n<li><p>Now you can see your WordPress welcome page and press Lets go! on that page.</p>\n</li>\n<li><p>Enter the credentials of database for WordPress. the below are default credentials. </p>\n</li>\n</ul>\n<p>The name of the database you want to use with WordPress.</p>\n<pre><code>Database Name :    wordpress\n</code></pre><p>Your database username and password.</p>\n<pre><code>Username :  root\nPassword :    &lt;leave it blank&gt;\n</code></pre><p>You should be able to get this info from your web host, if localhost doesnt work.</p>\n<pre><code>Database Host:    localhost\n</code></pre><p>If you want to run multiple WordPress installations in a single database, change this.</p>\n<pre><code>Table Prefix : wp_\n</code></pre><ul>\n<li><p>press submit, if the given credentials are valid it gets into next page </p>\n</li>\n<li><p>Press Run the install button shown in the page. </p>\n</li>\n<li><p>In this page you can choose your WordPress Login username, Password and your Site name.</p>\n</li>\n</ul>\n<p>Login with your user and password it will get to wordpress design page successfully.</p>\n<p><img src=\"/content/images/2016/05/wordpress.png\" alt=\"\"></p>\n<p>#####Conclusion</p>\n<p>These are the very simple steps to launch WordPress in virtual machine. Installing wordpress is faster, so it takes only less time. This is a good head-start for launching a WordPress in <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">MegamAfrica</a>.</p>\n<p>To Launch your WordPress Server click here</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\"><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"megamafrica\"></a></p>\n","excerpt":"","more":"<p>#####Introduction</p>\n<p>WordPress is web software you can use to create a beautiful website, blog, or app. We like to say that WordPress is both free and priceless at the same time.</p>\n<p>And WordPress is a free and open-source content management system (CMS) based on PHP and MySQL. WordPress is installed on a web server, which either is part of an Internet hosting service or is a network host itself; the first case may be on a service like WordPress.com, for example, and the second case is a computer running the software package WordPress.org. <a href=\"https://wordpress.org/news/category/documentation/\">readmore</a></p>\n<p><a href=\"https://console.megamafrica.com\"><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"megamafrica\"></a></p>\n<p>#####Prerequisites</p>\n<p>You have to create a valid credential access for <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>.</p>\n<p>You have to install openssh-server for ssh access.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre><p>Check SSH working properly</p>\n<pre><code>ps aux | grep sshd\n</code></pre><p>######Step - 1 Lauch WordPress just by One Click </p>\n<p>This initial section contains everything you need to get WordPress and running on your server.</p>\n<p>First, ensure the user to login our <a href=\"https://console.megamafrica.com\">site</a> .</p>\n<p>Go to the Market Places to click the create a new <code>WordPress on Collaboration</code>.</p>\n<ul>\n<li><p>A window will pop up with the configurations of your server such CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can customize your HDD size,Core and RAM capacity.</p>\n</li>\n<li><p>You can create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>Click the create button. it will create the WordPress Machine.</p>\n</li>\n</ul>\n<p>######Step - 2 Access the WordPress Machine</p>\n<ul>\n<li><p>Next, Go to the Services it will show your services that you are lauched click the domain name of your wordpress and then a new window is open.</p>\n</li>\n<li><p>Now you can see your machines CPU, RAM ,Storage IP address and SSH URL on Usage section.</p>\n</li>\n<li><p>And you can see your Metrics charts of CPU,RAM and Network of your machine.</p>\n</li>\n<li><p>Logs will show all the running process in the server.</p>\n</li>\n<li><p>You can access the virtual machine via SSH connection, you can download the your private and public keys from SSH Keys tab or Overview page. Use this keys to ssh like following command,</p>\n<p>  $ ssh -i path to/private_key_filename root@ipaddress</p>\n</li>\n</ul>\n<p>######Step - 3 Credentials of WordPress</p>\n<p>Get your servers IP from overview page </p>\n<ul>\n<li><p>Go to your browser and type as follows</p>\n<p>  <a href=\"http://IP_ADDRESS/current\">http://IP_ADDRESS/current</a> </p>\n</li>\n<li><p>Now you can see your WordPress welcome page and press Lets go! on that page.</p>\n</li>\n<li><p>Enter the credentials of database for WordPress. the below are default credentials. </p>\n</li>\n</ul>\n<p>The name of the database you want to use with WordPress.</p>\n<pre><code>Database Name :    wordpress\n</code></pre><p>Your database username and password.</p>\n<pre><code>Username :  root\nPassword :    &lt;leave it blank&gt;\n</code></pre><p>You should be able to get this info from your web host, if localhost doesnt work.</p>\n<pre><code>Database Host:    localhost\n</code></pre><p>If you want to run multiple WordPress installations in a single database, change this.</p>\n<pre><code>Table Prefix : wp_\n</code></pre><ul>\n<li><p>press submit, if the given credentials are valid it gets into next page </p>\n</li>\n<li><p>Press Run the install button shown in the page. </p>\n</li>\n<li><p>In this page you can choose your WordPress Login username, Password and your Site name.</p>\n</li>\n</ul>\n<p>Login with your user and password it will get to wordpress design page successfully.</p>\n<p><img src=\"/content/images/2016/05/wordpress.png\" alt=\"\"></p>\n<p>#####Conclusion</p>\n<p>These are the very simple steps to launch WordPress in virtual machine. Installing wordpress is faster, so it takes only less time. This is a good head-start for launching a WordPress in <a href=\"https://console.megamafrica.com\">MegamAfrica</a>.</p>\n<p>To Launch your WordPress Server click here</p>\n<p><a href=\"https://console.megamafrica.com\"><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"megamafrica\"></a></p>\n"},{"title":"How to setup docker container using vertice","slug":"2016-05-27-how-to-install-docker-container","date_published":"2016-05-27T04:36:53.327Z","date_updated":"2016-05-27T04:51:04.692Z","_content":"\n####Introduction\n\n  Docker containers wrap up a piece of software in a complete filesystem that contains everything it needs to run: code, runtime, system tools, system libraries  anything you can install on a server. This guarantees that it will always run the same, regardless of the environment it is running in.\n  \nThis tutorial we will need to setup the docker container.  \n\n####Prerequisites\n\n\n* You require atleast one swarm master and lots of node(s).\n\n* The nodes must have our package verticedocker installed with linux configured.\n\n* The linux bridge needs to configured in each of the hosts\n\n#### Swarm Install\n\n   Now, on your master which is soon going to be swarm master, install megamswarm\n   \n   \n    apt-add-repository \"deb [arch=amd64  http://get.megam.io/1.0/ubuntu/14.04/ trusty testing\"\n    \n    apt-key adv --keyserver keyserver.ubuntu.com --recv B3E0C1B7\n    \n    apt-get update\n    \n    apt-get install megamswarm \n    \n    start megamswarm\n    \n    \n####Install dockercontainer in node\n \n     echo 'deb https://apt.dockerproject.org/repo ubuntu-trusty main' >/etc/apt/sources.list.d/docker.list\n     \n      apt-get install apt-transport-https ca-certificates\n      \n      apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D\n     \n      apt-get install linux-image-generic-lts-trusty\n      \n      apt-get update\n      \n      apt-get install docker-engine\n      \n      apt-get install verticecommon verticegulpd verticedocker\n     \nedit your /usr/share/megam/verticegulpd/conf/gulpd.conf\n\n     ### Welcome to the Gulpd configuration file.\n     ###\n     ### [meta]\n     ###\n     ### Controls the parameters for the Raft consensus group that stores metadata\n     ### about the gulp.\n     ###\n     [meta]\n     user = \"root\"\n    nsqd = [\"xxx.xxx.xxx.xxx:4150\"]\n    scylla = [\"xxx.xxx.xxx.xxx\"]\n    scylla_keyspace = \"vertice\" \n    ###\n    ### [gulpd]\n    ###\n    ### Controls which assembly to be deployed into machine\n    ###\n    [gulpd]\n    enabled = false\n    name = \"disliked.megambox.com\"\n    assembly_id = \"ASM2593607080\"\n    assemblies_id = \"AMS253064546\"\n    provider = \"chefsolo\"\n  \tcookbook = \"apt\"\n  \tchefrepo = \"https://github.com/megamsys/chef-repo.git\"\n    chefrepo_tarball = \"https://github.com/megamsys/chef-repo/archive/0.94.tar.gz\"\n    ###\n    ### [http]\n    ###\n    ### Controls how the HTTP endpoints are configured. This a frill\n    ### mechanism for pinging gulpd (ping)\n    ###\n    [http]\n    enabled = true\n    bind_address = \"nodeip:6666\"\n    \n  start your node verticegulpd\n     \n      start verticegulpd\n     \n####Create Bridge  \n\n  To install bridge on your node\n  \n       apt-get install bridge-utils\n       \n   Edit your /etc/network/interface file\n   \n       auto megdock\n       iface megdock inet static\n       address   xxx.xxx.xxx.xxx\n       netmask   yyy.yyy.yyy.yyy\n       bridge_ports none\n       bridge_stp off\n       bridge_fd 1\n       bridge_hello 2\n       bridge_maxage 12\n       up ip route add zzz.zzz.zzz.zzz/27 dev megdock\n       \n     \n   \n  Then create megdock bridge  \n  \n     brctl add-br megdock\n     \n     \n  check if a linux bridge by name megdock exists\n  \n    brctl show\n   \n   \n start your docker daemon\n \n    docker daemon -D -H tcp://nodeip:2375\n####To join the nodes to the swarm master   \n \n We need a token to join the nodes to the swarm master.\n You should find this line following the command\n \n     ps -ef | grep swarm \n     \n     root     129993 129353  0 11:07 pts/0    00:00:01 swarm join --addr=xxx.xxx.xxx.xxx:2375 token://54c729c18d379721c9483c07e071b7e9\n \nCopy the token to join nodes to swarm master and paste the token. Then execute the below command on the master to join node to master\n\n    swarm join --addr=<node_ip>:2375 token://54c729c18d379721c9483c07e071b7e9\n    \nHopefully you have configured our engine vertice engine, if not this is needed for the launch\n\n    nano /usr/share/megam/megamd/megamd.conf\n    swarm:\n       host: http://<swarm_master_ip>:2375\n   \n Voila! Go ahead and launch multiple docker containers through  vertice. \n\n####Conclusion\n\n  Finally  swarm and dockernode installed setup on your host by docker container using vertice and successfully launched the docker container \n","source":"_posts/2016-05-27-how-to-install-docker-container.md","raw":"---\ntitle: How to setup docker container using vertice\nslug: how-to-install-docker-container\ndate_published: 2016-05-27T10:06:53.327Z\ndate_updated:   2016-05-27T10:21:04.692Z\n---\n\n####Introduction\n\n  Docker containers wrap up a piece of software in a complete filesystem that contains everything it needs to run: code, runtime, system tools, system libraries  anything you can install on a server. This guarantees that it will always run the same, regardless of the environment it is running in.\n  \nThis tutorial we will need to setup the docker container.  \n\n####Prerequisites\n\n\n* You require atleast one swarm master and lots of node(s).\n\n* The nodes must have our package verticedocker installed with linux configured.\n\n* The linux bridge needs to configured in each of the hosts\n\n#### Swarm Install\n\n   Now, on your master which is soon going to be swarm master, install megamswarm\n   \n   \n    apt-add-repository \"deb [arch=amd64  http://get.megam.io/1.0/ubuntu/14.04/ trusty testing\"\n    \n    apt-key adv --keyserver keyserver.ubuntu.com --recv B3E0C1B7\n    \n    apt-get update\n    \n    apt-get install megamswarm \n    \n    start megamswarm\n    \n    \n####Install dockercontainer in node\n \n     echo 'deb https://apt.dockerproject.org/repo ubuntu-trusty main' >/etc/apt/sources.list.d/docker.list\n     \n      apt-get install apt-transport-https ca-certificates\n      \n      apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D\n     \n      apt-get install linux-image-generic-lts-trusty\n      \n      apt-get update\n      \n      apt-get install docker-engine\n      \n      apt-get install verticecommon verticegulpd verticedocker\n     \nedit your /usr/share/megam/verticegulpd/conf/gulpd.conf\n\n     ### Welcome to the Gulpd configuration file.\n     ###\n     ### [meta]\n     ###\n     ### Controls the parameters for the Raft consensus group that stores metadata\n     ### about the gulp.\n     ###\n     [meta]\n     user = \"root\"\n    nsqd = [\"xxx.xxx.xxx.xxx:4150\"]\n    scylla = [\"xxx.xxx.xxx.xxx\"]\n    scylla_keyspace = \"vertice\" \n    ###\n    ### [gulpd]\n    ###\n    ### Controls which assembly to be deployed into machine\n    ###\n    [gulpd]\n    enabled = false\n    name = \"disliked.megambox.com\"\n    assembly_id = \"ASM2593607080\"\n    assemblies_id = \"AMS253064546\"\n    provider = \"chefsolo\"\n  \tcookbook = \"apt\"\n  \tchefrepo = \"https://github.com/megamsys/chef-repo.git\"\n    chefrepo_tarball = \"https://github.com/megamsys/chef-repo/archive/0.94.tar.gz\"\n    ###\n    ### [http]\n    ###\n    ### Controls how the HTTP endpoints are configured. This a frill\n    ### mechanism for pinging gulpd (ping)\n    ###\n    [http]\n    enabled = true\n    bind_address = \"nodeip:6666\"\n    \n  start your node verticegulpd\n     \n      start verticegulpd\n     \n####Create Bridge  \n\n  To install bridge on your node\n  \n       apt-get install bridge-utils\n       \n   Edit your /etc/network/interface file\n   \n       auto megdock\n       iface megdock inet static\n       address   xxx.xxx.xxx.xxx\n       netmask   yyy.yyy.yyy.yyy\n       bridge_ports none\n       bridge_stp off\n       bridge_fd 1\n       bridge_hello 2\n       bridge_maxage 12\n       up ip route add zzz.zzz.zzz.zzz/27 dev megdock\n       \n     \n   \n  Then create megdock bridge  \n  \n     brctl add-br megdock\n     \n     \n  check if a linux bridge by name megdock exists\n  \n    brctl show\n   \n   \n start your docker daemon\n \n    docker daemon -D -H tcp://nodeip:2375\n####To join the nodes to the swarm master   \n \n We need a token to join the nodes to the swarm master.\n You should find this line following the command\n \n     ps -ef | grep swarm \n     \n     root     129993 129353  0 11:07 pts/0    00:00:01 swarm join --addr=xxx.xxx.xxx.xxx:2375 token://54c729c18d379721c9483c07e071b7e9\n \nCopy the token to join nodes to swarm master and paste the token. Then execute the below command on the master to join node to master\n\n    swarm join --addr=<node_ip>:2375 token://54c729c18d379721c9483c07e071b7e9\n    \nHopefully you have configured our engine vertice engine, if not this is needed for the launch\n\n    nano /usr/share/megam/megamd/megamd.conf\n    swarm:\n       host: http://<swarm_master_ip>:2375\n   \n Voila! Go ahead and launch multiple docker containers through  vertice. \n\n####Conclusion\n\n  Finally  swarm and dockernode installed setup on your host by docker container using vertice and successfully launched the docker container \n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaitd001pdrgbrqsopd0b","content":"<p>####Introduction</p>\n<p>  Docker containers wrap up a piece of software in a complete filesystem that contains everything it needs to run: code, runtime, system tools, system libraries  anything you can install on a server. This guarantees that it will always run the same, regardless of the environment it is running in.</p>\n<p>This tutorial we will need to setup the docker container.  </p>\n<p>####Prerequisites</p>\n<ul>\n<li><p>You require atleast one swarm master and lots of node(s).</p>\n</li>\n<li><p>The nodes must have our package verticedocker installed with linux configured.</p>\n</li>\n<li><p>The linux bridge needs to configured in each of the hosts</p>\n</li>\n</ul>\n<h4 id=\"Swarm-Install\"><a href=\"#Swarm-Install\" class=\"headerlink\" title=\"Swarm Install\"></a>Swarm Install</h4><p>   Now, on your master which is soon going to be swarm master, install megamswarm</p>\n<pre><code>apt-add-repository &quot;deb [arch=amd64  http://get.megam.io/1.0/ubuntu/14.04/ trusty testing&quot;\n\napt-key adv --keyserver keyserver.ubuntu.com --recv B3E0C1B7\n\napt-get update\n\napt-get install megamswarm \n\nstart megamswarm\n</code></pre><p>####Install dockercontainer in node</p>\n<pre><code>echo &apos;deb https://apt.dockerproject.org/repo ubuntu-trusty main&apos; &gt;/etc/apt/sources.list.d/docker.list\n\n apt-get install apt-transport-https ca-certificates\n\n apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D\n\n apt-get install linux-image-generic-lts-trusty\n\n apt-get update\n\n apt-get install docker-engine\n\n apt-get install verticecommon verticegulpd verticedocker\n</code></pre><p>edit your /usr/share/megam/verticegulpd/conf/gulpd.conf</p>\n<pre><code> ### Welcome to the Gulpd configuration file.\n ###\n ### [meta]\n ###\n ### Controls the parameters for the Raft consensus group that stores metadata\n ### about the gulp.\n ###\n [meta]\n user = &quot;root&quot;\nnsqd = [&quot;xxx.xxx.xxx.xxx:4150&quot;]\nscylla = [&quot;xxx.xxx.xxx.xxx&quot;]\nscylla_keyspace = &quot;vertice&quot; \n###\n### [gulpd]\n###\n### Controls which assembly to be deployed into machine\n###\n[gulpd]\nenabled = false\nname = &quot;disliked.megambox.com&quot;\nassembly_id = &quot;ASM2593607080&quot;\nassemblies_id = &quot;AMS253064546&quot;\nprovider = &quot;chefsolo&quot;\n  cookbook = &quot;apt&quot;\n  chefrepo = &quot;https://github.com/megamsys/chef-repo.git&quot;\nchefrepo_tarball = &quot;https://github.com/megamsys/chef-repo/archive/0.94.tar.gz&quot;\n###\n### [http]\n###\n### Controls how the HTTP endpoints are configured. This a frill\n### mechanism for pinging gulpd (ping)\n###\n[http]\nenabled = true\nbind_address = &quot;nodeip:6666&quot;\n</code></pre><p>  start your node verticegulpd</p>\n<pre><code>start verticegulpd\n</code></pre><p>####Create Bridge  </p>\n<p>  To install bridge on your node</p>\n<pre><code>apt-get install bridge-utils\n</code></pre><p>   Edit your /etc/network/interface file</p>\n<pre><code>auto megdock\niface megdock inet static\naddress   xxx.xxx.xxx.xxx\nnetmask   yyy.yyy.yyy.yyy\nbridge_ports none\nbridge_stp off\nbridge_fd 1\nbridge_hello 2\nbridge_maxage 12\nup ip route add zzz.zzz.zzz.zzz/27 dev megdock\n</code></pre><p>  Then create megdock bridge  </p>\n<pre><code>brctl add-br megdock\n</code></pre><p>  check if a linux bridge by name megdock exists</p>\n<pre><code>brctl show\n</code></pre><p> start your docker daemon</p>\n<pre><code>docker daemon -D -H tcp://nodeip:2375\n</code></pre><p>####To join the nodes to the swarm master   </p>\n<p> We need a token to join the nodes to the swarm master.<br> You should find this line following the command</p>\n<pre><code>ps -ef | grep swarm \n\nroot     129993 129353  0 11:07 pts/0    00:00:01 swarm join --addr=xxx.xxx.xxx.xxx:2375 token://54c729c18d379721c9483c07e071b7e9\n</code></pre><p>Copy the token to join nodes to swarm master and paste the token. Then execute the below command on the master to join node to master</p>\n<pre><code>swarm join --addr=&lt;node_ip&gt;:2375 token://54c729c18d379721c9483c07e071b7e9\n</code></pre><p>Hopefully you have configured our engine vertice engine, if not this is needed for the launch</p>\n<pre><code>nano /usr/share/megam/megamd/megamd.conf\nswarm:\n   host: http://&lt;swarm_master_ip&gt;:2375\n</code></pre><p> Voila! Go ahead and launch multiple docker containers through  vertice. </p>\n<p>####Conclusion</p>\n<p>  Finally  swarm and dockernode installed setup on your host by docker container using vertice and successfully launched the docker container </p>\n","excerpt":"","more":"<p>####Introduction</p>\n<p>  Docker containers wrap up a piece of software in a complete filesystem that contains everything it needs to run: code, runtime, system tools, system libraries  anything you can install on a server. This guarantees that it will always run the same, regardless of the environment it is running in.</p>\n<p>This tutorial we will need to setup the docker container.  </p>\n<p>####Prerequisites</p>\n<ul>\n<li><p>You require atleast one swarm master and lots of node(s).</p>\n</li>\n<li><p>The nodes must have our package verticedocker installed with linux configured.</p>\n</li>\n<li><p>The linux bridge needs to configured in each of the hosts</p>\n</li>\n</ul>\n<h4 id=\"Swarm-Install\"><a href=\"#Swarm-Install\" class=\"headerlink\" title=\"Swarm Install\"></a>Swarm Install</h4><p>   Now, on your master which is soon going to be swarm master, install megamswarm</p>\n<pre><code>apt-add-repository &quot;deb [arch=amd64  http://get.megam.io/1.0/ubuntu/14.04/ trusty testing&quot;\n\napt-key adv --keyserver keyserver.ubuntu.com --recv B3E0C1B7\n\napt-get update\n\napt-get install megamswarm \n\nstart megamswarm\n</code></pre><p>####Install dockercontainer in node</p>\n<pre><code>echo &apos;deb https://apt.dockerproject.org/repo ubuntu-trusty main&apos; &gt;/etc/apt/sources.list.d/docker.list\n\n apt-get install apt-transport-https ca-certificates\n\n apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D\n\n apt-get install linux-image-generic-lts-trusty\n\n apt-get update\n\n apt-get install docker-engine\n\n apt-get install verticecommon verticegulpd verticedocker\n</code></pre><p>edit your /usr/share/megam/verticegulpd/conf/gulpd.conf</p>\n<pre><code> ### Welcome to the Gulpd configuration file.\n ###\n ### [meta]\n ###\n ### Controls the parameters for the Raft consensus group that stores metadata\n ### about the gulp.\n ###\n [meta]\n user = &quot;root&quot;\nnsqd = [&quot;xxx.xxx.xxx.xxx:4150&quot;]\nscylla = [&quot;xxx.xxx.xxx.xxx&quot;]\nscylla_keyspace = &quot;vertice&quot; \n###\n### [gulpd]\n###\n### Controls which assembly to be deployed into machine\n###\n[gulpd]\nenabled = false\nname = &quot;disliked.megambox.com&quot;\nassembly_id = &quot;ASM2593607080&quot;\nassemblies_id = &quot;AMS253064546&quot;\nprovider = &quot;chefsolo&quot;\n  cookbook = &quot;apt&quot;\n  chefrepo = &quot;https://github.com/megamsys/chef-repo.git&quot;\nchefrepo_tarball = &quot;https://github.com/megamsys/chef-repo/archive/0.94.tar.gz&quot;\n###\n### [http]\n###\n### Controls how the HTTP endpoints are configured. This a frill\n### mechanism for pinging gulpd (ping)\n###\n[http]\nenabled = true\nbind_address = &quot;nodeip:6666&quot;\n</code></pre><p>  start your node verticegulpd</p>\n<pre><code>start verticegulpd\n</code></pre><p>####Create Bridge  </p>\n<p>  To install bridge on your node</p>\n<pre><code>apt-get install bridge-utils\n</code></pre><p>   Edit your /etc/network/interface file</p>\n<pre><code>auto megdock\niface megdock inet static\naddress   xxx.xxx.xxx.xxx\nnetmask   yyy.yyy.yyy.yyy\nbridge_ports none\nbridge_stp off\nbridge_fd 1\nbridge_hello 2\nbridge_maxage 12\nup ip route add zzz.zzz.zzz.zzz/27 dev megdock\n</code></pre><p>  Then create megdock bridge  </p>\n<pre><code>brctl add-br megdock\n</code></pre><p>  check if a linux bridge by name megdock exists</p>\n<pre><code>brctl show\n</code></pre><p> start your docker daemon</p>\n<pre><code>docker daemon -D -H tcp://nodeip:2375\n</code></pre><p>####To join the nodes to the swarm master   </p>\n<p> We need a token to join the nodes to the swarm master.<br> You should find this line following the command</p>\n<pre><code>ps -ef | grep swarm \n\nroot     129993 129353  0 11:07 pts/0    00:00:01 swarm join --addr=xxx.xxx.xxx.xxx:2375 token://54c729c18d379721c9483c07e071b7e9\n</code></pre><p>Copy the token to join nodes to swarm master and paste the token. Then execute the below command on the master to join node to master</p>\n<pre><code>swarm join --addr=&lt;node_ip&gt;:2375 token://54c729c18d379721c9483c07e071b7e9\n</code></pre><p>Hopefully you have configured our engine vertice engine, if not this is needed for the launch</p>\n<pre><code>nano /usr/share/megam/megamd/megamd.conf\nswarm:\n   host: http://&lt;swarm_master_ip&gt;:2375\n</code></pre><p> Voila! Go ahead and launch multiple docker containers through  vertice. </p>\n<p>####Conclusion</p>\n<p>  Finally  swarm and dockernode installed setup on your host by docker container using vertice and successfully launched the docker container </p>\n"},{"title":"How to launch DockerContainer in MegamAfrica","slug":"2016-05-27-how-to-launch-dockercontainer-in-megamafrica","date_published":"2016-05-27T07:44:10.268Z","date_updated":"2016-05-27T07:46:17.482Z","_content":"\n####Introduction\nDocker containers wrap up a piece of software in a complete filesystem that contains everything it needs to run: code, runtime, system tools, system libraries  anything you can install on a server. This guarantees that it will always run the same, regardless of the environment it is running in.\n\nThis tutorial will guide you launching a Docker Container in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n####Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your workstation, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n*  You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\n* You have to install openssh-server for ssh access.\n\n    \tsudo apt-get install openssh-server\n    \n* To check the ssh is properly installed in our system\n\n      \tps aux | grep sshd\n\n####Step - 1  Launch DockerContainer\n\n This initial section contains everything you need to get  docker container and running on your server.\n\n * Go to your MegamAfrica Dashboard.\n\n * Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n * Click DockerContainer Icon.\n \n * Give the docker hub image name.\n      \n      For example jenkins\n\n * To launch DockerContainer Click Create button. \n \n * Now you have launched your dockercontainer.\n####Step - 2 Access the DockerContainer\n\nNext, Go to the Dashboard and click the domain name a new window will open.\n\nIt contains the CPU, RAM and Network tab.\n\nIt shows the Metrics, VM Logs, IP address and SSH URL.\n\nMetrics shows the CPU,RAM and Network usage.\n\nContainer Logs shows all the running process in DockerContainer.\n  \n####Step - 3 Open Your web browser\n\nYou can access your web page using http://IP_ADDRESS:8080\n\n       \n\n![](/content/images/2016/05/jenkins1.png)\n\n####Conclusion\n\nFinally These are the steps in launched the docker container in successfully. \n\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n","source":"_posts/2016-05-27-how-to-launch-dockercontainer-in-megamafrica.md","raw":"---\ntitle: How to launch DockerContainer in MegamAfrica\nslug: how-to-launch-dockercontainer-in-megamafrica\ndate_published: 2016-05-27T13:14:10.268Z\ndate_updated:   2016-05-27T13:16:17.482Z\n---\n\n####Introduction\nDocker containers wrap up a piece of software in a complete filesystem that contains everything it needs to run: code, runtime, system tools, system libraries  anything you can install on a server. This guarantees that it will always run the same, regardless of the environment it is running in.\n\nThis tutorial will guide you launching a Docker Container in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n####Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your workstation, which you can do by following the [How To Install Git with Apt.](https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04)\n\n*  You have an account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/)\n\n* You have to install openssh-server for ssh access.\n\n    \tsudo apt-get install openssh-server\n    \n* To check the ssh is properly installed in our system\n\n      \tps aux | grep sshd\n\n####Step - 1  Launch DockerContainer\n\n This initial section contains everything you need to get  docker container and running on your server.\n\n * Go to your MegamAfrica Dashboard.\n\n * Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.\n\n * Click DockerContainer Icon.\n \n * Give the docker hub image name.\n      \n      For example jenkins\n\n * To launch DockerContainer Click Create button. \n \n * Now you have launched your dockercontainer.\n####Step - 2 Access the DockerContainer\n\nNext, Go to the Dashboard and click the domain name a new window will open.\n\nIt contains the CPU, RAM and Network tab.\n\nIt shows the Metrics, VM Logs, IP address and SSH URL.\n\nMetrics shows the CPU,RAM and Network usage.\n\nContainer Logs shows all the running process in DockerContainer.\n  \n####Step - 3 Open Your web browser\n\nYou can access your web page using http://IP_ADDRESS:8080\n\n       \n\n![](/content/images/2016/05/jenkins1.png)\n\n####Conclusion\n\nFinally These are the steps in launched the docker container in successfully. \n\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaite001qdrgbpclehrzd","content":"<p>####Introduction<br>Docker containers wrap up a piece of software in a complete filesystem that contains everything it needs to run: code, runtime, system tools, system libraries  anything you can install on a server. This guarantees that it will always run the same, regardless of the environment it is running in.</p>\n<p>This tutorial will guide you launching a Docker Container in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>####Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your workstation, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\" target=\"_blank\" rel=\"external\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a></p>\n</li>\n<li><p>You have to install openssh-server for ssh access.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre></li>\n<li><p>To check the ssh is properly installed in our system</p>\n<pre><code>ps aux | grep sshd\n</code></pre></li>\n</ul>\n<p>####Step - 1  Launch DockerContainer</p>\n<p> This initial section contains everything you need to get  docker container and running on your server.</p>\n<ul>\n<li><p>Go to your MegamAfrica Dashboard.</p>\n</li>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click DockerContainer Icon.</p>\n</li>\n<li><p>Give the docker hub image name.</p>\n<p>   For example jenkins</p>\n</li>\n<li><p>To launch DockerContainer Click Create button. </p>\n</li>\n<li><p>Now you have launched your dockercontainer.<br>####Step - 2 Access the DockerContainer</p>\n</li>\n</ul>\n<p>Next, Go to the Dashboard and click the domain name a new window will open.</p>\n<p>It contains the CPU, RAM and Network tab.</p>\n<p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n<p>Metrics shows the CPU,RAM and Network usage.</p>\n<p>Container Logs shows all the running process in DockerContainer.</p>\n<p>####Step - 3 Open Your web browser</p>\n<p>You can access your web page using <a href=\"http://IP_ADDRESS:8080\" target=\"_blank\" rel=\"external\">http://IP_ADDRESS:8080</a></p>\n<p><img src=\"/content/images/2016/05/jenkins1.png\" alt=\"\"></p>\n<p>####Conclusion</p>\n<p>Finally These are the steps in launched the docker container in successfully. </p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>####Introduction<br>Docker containers wrap up a piece of software in a complete filesystem that contains everything it needs to run: code, runtime, system tools, system libraries  anything you can install on a server. This guarantees that it will always run the same, regardless of the environment it is running in.</p>\n<p>This tutorial will guide you launching a Docker Container in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>####Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your workstation, which you can do by following the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-git-on-ubuntu-14-04\">How To Install Git with Apt.</a></p>\n</li>\n<li><p>You have an account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a></p>\n</li>\n<li><p>You have to install openssh-server for ssh access.</p>\n<pre><code>sudo apt-get install openssh-server\n</code></pre></li>\n<li><p>To check the ssh is properly installed in our system</p>\n<pre><code>ps aux | grep sshd\n</code></pre></li>\n</ul>\n<p>####Step - 1  Launch DockerContainer</p>\n<p> This initial section contains everything you need to get  docker container and running on your server.</p>\n<ul>\n<li><p>Go to your MegamAfrica Dashboard.</p>\n</li>\n<li><p>Click Marketplace on the top bar.Marketplace contains all the linux distros, applications, services and microservices which megamafrica supports.</p>\n</li>\n<li><p>Click DockerContainer Icon.</p>\n</li>\n<li><p>Give the docker hub image name.</p>\n<p>   For example jenkins</p>\n</li>\n<li><p>To launch DockerContainer Click Create button. </p>\n</li>\n<li><p>Now you have launched your dockercontainer.<br>####Step - 2 Access the DockerContainer</p>\n</li>\n</ul>\n<p>Next, Go to the Dashboard and click the domain name a new window will open.</p>\n<p>It contains the CPU, RAM and Network tab.</p>\n<p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n<p>Metrics shows the CPU,RAM and Network usage.</p>\n<p>Container Logs shows all the running process in DockerContainer.</p>\n<p>####Step - 3 Open Your web browser</p>\n<p>You can access your web page using <a href=\"http://IP_ADDRESS:8080\">http://IP_ADDRESS:8080</a></p>\n<p><img src=\"/content/images/2016/05/jenkins1.png\" alt=\"\"></p>\n<p>####Conclusion</p>\n<p>Finally These are the steps in launched the docker container in successfully. </p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"Getting started in MegamAfrica - Open source cloud hosting","slug":"2016-05-27-how-to-launch-ubuntu","date_published":"2016-05-27T01:55:48.653Z","date_updated":"2016-05-27T06:06:40.129Z","_content":"\n###Introduction\n\nMegamAfrica is an end-to-end open source cloud management platform offered as a bundled offering with IaaS and can run apps, services, micro services (Docker), Analytics on hybrid cloud.\n\nThis tutorial will guide you in creating an account with MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\nYou can access MegamAfrica by clicking on https://console.megamafrica.com.\n\n![](/content/images/2016/05/s1-1.png)\n\n####1. Create an account\n\n* Create an new account in MegamAfrica\n\nClick the `create new account` link, it shows like below.\n\n![](/content/images/2016/05/s2.png)\n\nEnter your email-id, password, and mobile number then click verify button the `OTP` will be sent to your mobile.\n\n![](/content/images/2016/05/s3.png)\n\nPop-up window will be open enter the `OTP` then click the verify button.\n\nIt will verify your OTP.\n![](/content/images/2016/05/s5.png)\n\nFinally click the Create Account. You have successfully created an account. Now, you will see the dashboard page. \n\n![](/content/images/2016/05/s6.png)\n\n#### 2. Use OAuth - Facebook\n\nYou will be see the facebook icon at the bottom of the page. click that icon it shows like below\n\n![](/content/images/2016/05/s1-1-1-1.png)\n\nEnter your credentials and then click the login button. \n\nNow, you have successfully created an account in MegamAfrica. \n\nWe are create an default password \n\n\t`MegamAfrica` \n    \n for your account, hence reset it.\n \n You have to reset your password. \n![](/content/images/2016/05/profile.jpg)\n\nClick the `Profile` link in MegamAfrica a pop-up window will open, there you can change your password. \n\n#### 3. Use OAuth - Google+\n\nYou wiil be see the google+ icon at the bottom of the page in our website. click that icon it shows like below\n\n![](/content/images/2016/05/signin.jpg)\n\nEnter your credentials and then click the login button. \n\nNow, you have successfully created an account in MegamAfrica. \n\nWe are create an default password \n\n\t`MegamAfrica` \n    \n for your account, hence reset it.\n \n You have to reset your password. \n \n Click the `Profile` link in MegamAfrica a pop-up window will open, there you can change your password. \n\n####4.Use OAuth - Github\n\nYou wiil be see the github icon at the bottom of the page in our website. click that icon it shows like below\n\n![](/content/images/2016/05/s1-3.png)\n\nEnter your credentials and then click the login button. \n\nNow, you have successfully created an account in MegamAfrica. \n\nWe are create an default password \n\n\t`MegamAfrica` \n    \n for your account, hence reset it.\n \n You have to reset your password. \n \n Click the `Profile` link in MegamAfrica a pop-up window will open, there you can change your password. \n\n\n###Conclusion\n\nThese are the very simple steps to create an account with MegamAfrica. MegamAfrica website contain lot of feature - very easy to launch Virtual Machines, Apps, Services in MegamAfrica.\n\n######Deploy a VM or Container now\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n","source":"_posts/2016-05-27-how-to-launch-ubuntu.md","raw":"---\ntitle: Getting started in MegamAfrica - Open source cloud hosting\nslug: how-to-launch-ubuntu\ndate_published: 2016-05-27T07:25:48.653Z\ndate_updated:   2016-05-27T11:36:40.129Z\n---\n\n###Introduction\n\nMegamAfrica is an end-to-end open source cloud management platform offered as a bundled offering with IaaS and can run apps, services, micro services (Docker), Analytics on hybrid cloud.\n\nThis tutorial will guide you in creating an account with MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\nYou can access MegamAfrica by clicking on https://console.megamafrica.com.\n\n![](/content/images/2016/05/s1-1.png)\n\n####1. Create an account\n\n* Create an new account in MegamAfrica\n\nClick the `create new account` link, it shows like below.\n\n![](/content/images/2016/05/s2.png)\n\nEnter your email-id, password, and mobile number then click verify button the `OTP` will be sent to your mobile.\n\n![](/content/images/2016/05/s3.png)\n\nPop-up window will be open enter the `OTP` then click the verify button.\n\nIt will verify your OTP.\n![](/content/images/2016/05/s5.png)\n\nFinally click the Create Account. You have successfully created an account. Now, you will see the dashboard page. \n\n![](/content/images/2016/05/s6.png)\n\n#### 2. Use OAuth - Facebook\n\nYou will be see the facebook icon at the bottom of the page. click that icon it shows like below\n\n![](/content/images/2016/05/s1-1-1-1.png)\n\nEnter your credentials and then click the login button. \n\nNow, you have successfully created an account in MegamAfrica. \n\nWe are create an default password \n\n\t`MegamAfrica` \n    \n for your account, hence reset it.\n \n You have to reset your password. \n![](/content/images/2016/05/profile.jpg)\n\nClick the `Profile` link in MegamAfrica a pop-up window will open, there you can change your password. \n\n#### 3. Use OAuth - Google+\n\nYou wiil be see the google+ icon at the bottom of the page in our website. click that icon it shows like below\n\n![](/content/images/2016/05/signin.jpg)\n\nEnter your credentials and then click the login button. \n\nNow, you have successfully created an account in MegamAfrica. \n\nWe are create an default password \n\n\t`MegamAfrica` \n    \n for your account, hence reset it.\n \n You have to reset your password. \n \n Click the `Profile` link in MegamAfrica a pop-up window will open, there you can change your password. \n\n####4.Use OAuth - Github\n\nYou wiil be see the github icon at the bottom of the page in our website. click that icon it shows like below\n\n![](/content/images/2016/05/s1-3.png)\n\nEnter your credentials and then click the login button. \n\nNow, you have successfully created an account in MegamAfrica. \n\nWe are create an default password \n\n\t`MegamAfrica` \n    \n for your account, hence reset it.\n \n You have to reset your password. \n \n Click the `Profile` link in MegamAfrica a pop-up window will open, there you can change your password. \n\n\n###Conclusion\n\nThese are the very simple steps to create an account with MegamAfrica. MegamAfrica website contain lot of feature - very easy to launch Virtual Machines, Apps, Services in MegamAfrica.\n\n######Deploy a VM or Container now\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaitn001rdrgbg7t9jj8g","content":"<p>###Introduction</p>\n<p>MegamAfrica is an end-to-end open source cloud management platform offered as a bundled offering with IaaS and can run apps, services, micro services (Docker), Analytics on hybrid cloud.</p>\n<p>This tutorial will guide you in creating an account with MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>You can access MegamAfrica by clicking on <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>.</p>\n<p><img src=\"/content/images/2016/05/s1-1.png\" alt=\"\"></p>\n<p>####1. Create an account</p>\n<ul>\n<li>Create an new account in MegamAfrica</li>\n</ul>\n<p>Click the <code>create new account</code> link, it shows like below.</p>\n<p><img src=\"/content/images/2016/05/s2.png\" alt=\"\"></p>\n<p>Enter your email-id, password, and mobile number then click verify button the <code>OTP</code> will be sent to your mobile.</p>\n<p><img src=\"/content/images/2016/05/s3.png\" alt=\"\"></p>\n<p>Pop-up window will be open enter the <code>OTP</code> then click the verify button.</p>\n<p>It will verify your OTP.<br><img src=\"/content/images/2016/05/s5.png\" alt=\"\"></p>\n<p>Finally click the Create Account. You have successfully created an account. Now, you will see the dashboard page. </p>\n<p><img src=\"/content/images/2016/05/s6.png\" alt=\"\"></p>\n<h4 id=\"2-Use-OAuth-Facebook\"><a href=\"#2-Use-OAuth-Facebook\" class=\"headerlink\" title=\"2. Use OAuth - Facebook\"></a>2. Use OAuth - Facebook</h4><p>You will be see the facebook icon at the bottom of the page. click that icon it shows like below</p>\n<p><img src=\"/content/images/2016/05/s1-1-1-1.png\" alt=\"\"></p>\n<p>Enter your credentials and then click the login button. </p>\n<p>Now, you have successfully created an account in MegamAfrica. </p>\n<p>We are create an default password </p>\n<pre><code>`MegamAfrica` \n</code></pre><p> for your account, hence reset it.</p>\n<p> You have to reset your password.<br><img src=\"/content/images/2016/05/profile.jpg\" alt=\"\"></p>\n<p>Click the <code>Profile</code> link in MegamAfrica a pop-up window will open, there you can change your password. </p>\n<h4 id=\"3-Use-OAuth-Google\"><a href=\"#3-Use-OAuth-Google\" class=\"headerlink\" title=\"3. Use OAuth - Google+\"></a>3. Use OAuth - Google+</h4><p>You wiil be see the google+ icon at the bottom of the page in our website. click that icon it shows like below</p>\n<p><img src=\"/content/images/2016/05/signin.jpg\" alt=\"\"></p>\n<p>Enter your credentials and then click the login button. </p>\n<p>Now, you have successfully created an account in MegamAfrica. </p>\n<p>We are create an default password </p>\n<pre><code>`MegamAfrica` \n</code></pre><p> for your account, hence reset it.</p>\n<p> You have to reset your password. </p>\n<p> Click the <code>Profile</code> link in MegamAfrica a pop-up window will open, there you can change your password. </p>\n<p>####4.Use OAuth - Github</p>\n<p>You wiil be see the github icon at the bottom of the page in our website. click that icon it shows like below</p>\n<p><img src=\"/content/images/2016/05/s1-3.png\" alt=\"\"></p>\n<p>Enter your credentials and then click the login button. </p>\n<p>Now, you have successfully created an account in MegamAfrica. </p>\n<p>We are create an default password </p>\n<pre><code>`MegamAfrica` \n</code></pre><p> for your account, hence reset it.</p>\n<p> You have to reset your password. </p>\n<p> Click the <code>Profile</code> link in MegamAfrica a pop-up window will open, there you can change your password. </p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to create an account with MegamAfrica. MegamAfrica website contain lot of feature - very easy to launch Virtual Machines, Apps, Services in MegamAfrica.</p>\n<p>######Deploy a VM or Container now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###Introduction</p>\n<p>MegamAfrica is an end-to-end open source cloud management platform offered as a bundled offering with IaaS and can run apps, services, micro services (Docker), Analytics on hybrid cloud.</p>\n<p>This tutorial will guide you in creating an account with MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>You can access MegamAfrica by clicking on <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>.</p>\n<p><img src=\"/content/images/2016/05/s1-1.png\" alt=\"\"></p>\n<p>####1. Create an account</p>\n<ul>\n<li>Create an new account in MegamAfrica</li>\n</ul>\n<p>Click the <code>create new account</code> link, it shows like below.</p>\n<p><img src=\"/content/images/2016/05/s2.png\" alt=\"\"></p>\n<p>Enter your email-id, password, and mobile number then click verify button the <code>OTP</code> will be sent to your mobile.</p>\n<p><img src=\"/content/images/2016/05/s3.png\" alt=\"\"></p>\n<p>Pop-up window will be open enter the <code>OTP</code> then click the verify button.</p>\n<p>It will verify your OTP.<br><img src=\"/content/images/2016/05/s5.png\" alt=\"\"></p>\n<p>Finally click the Create Account. You have successfully created an account. Now, you will see the dashboard page. </p>\n<p><img src=\"/content/images/2016/05/s6.png\" alt=\"\"></p>\n<h4 id=\"2-Use-OAuth-Facebook\"><a href=\"#2-Use-OAuth-Facebook\" class=\"headerlink\" title=\"2. Use OAuth - Facebook\"></a>2. Use OAuth - Facebook</h4><p>You will be see the facebook icon at the bottom of the page. click that icon it shows like below</p>\n<p><img src=\"/content/images/2016/05/s1-1-1-1.png\" alt=\"\"></p>\n<p>Enter your credentials and then click the login button. </p>\n<p>Now, you have successfully created an account in MegamAfrica. </p>\n<p>We are create an default password </p>\n<pre><code>`MegamAfrica` \n</code></pre><p> for your account, hence reset it.</p>\n<p> You have to reset your password.<br><img src=\"/content/images/2016/05/profile.jpg\" alt=\"\"></p>\n<p>Click the <code>Profile</code> link in MegamAfrica a pop-up window will open, there you can change your password. </p>\n<h4 id=\"3-Use-OAuth-Google\"><a href=\"#3-Use-OAuth-Google\" class=\"headerlink\" title=\"3. Use OAuth - Google+\"></a>3. Use OAuth - Google+</h4><p>You wiil be see the google+ icon at the bottom of the page in our website. click that icon it shows like below</p>\n<p><img src=\"/content/images/2016/05/signin.jpg\" alt=\"\"></p>\n<p>Enter your credentials and then click the login button. </p>\n<p>Now, you have successfully created an account in MegamAfrica. </p>\n<p>We are create an default password </p>\n<pre><code>`MegamAfrica` \n</code></pre><p> for your account, hence reset it.</p>\n<p> You have to reset your password. </p>\n<p> Click the <code>Profile</code> link in MegamAfrica a pop-up window will open, there you can change your password. </p>\n<p>####4.Use OAuth - Github</p>\n<p>You wiil be see the github icon at the bottom of the page in our website. click that icon it shows like below</p>\n<p><img src=\"/content/images/2016/05/s1-3.png\" alt=\"\"></p>\n<p>Enter your credentials and then click the login button. </p>\n<p>Now, you have successfully created an account in MegamAfrica. </p>\n<p>We are create an default password </p>\n<pre><code>`MegamAfrica` \n</code></pre><p> for your account, hence reset it.</p>\n<p> You have to reset your password. </p>\n<p> Click the <code>Profile</code> link in MegamAfrica a pop-up window will open, there you can change your password. </p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to create an account with MegamAfrica. MegamAfrica website contain lot of feature - very easy to launch Virtual Machines, Apps, Services in MegamAfrica.</p>\n<p>######Deploy a VM or Container now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"How to launch CouchDB in megamafrica.com","slug":"2016-05-27-how-to-launch","date_published":"2016-05-27T04:18:10.730Z","date_updated":"2016-05-27T04:24:02.182Z","_content":"\n###Introduction\n\nApache CouchDB, commonly referred to as CouchDB, is open source database software that focuses on ease of use and having an architecture that \"completely embraces the Web\". It has a document-oriented NoSQL database architecture and is implemented in the concurrency-oriented language Erlang; it uses JSON to store data, JavaScript as its query language using MapReduce, and HTTP for an API.\n\nThis tutorial will set up launching CouchDB.\n\n[![img](https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png)](https://console.megamafrica.com)\n\n###Prerequisites\n\nTo follow this tutorial :\n\nYou have to create a valid credential for access https://console.megamafrica.com.\n\nYou have to install openssh-server in your linux machine for ssh access.\n\n\t$ sudo apt-get install openssh-server\n\nTo check the ssh is properly installed in our system\n\n\t$ ps aux | grep sshd\n\n###Step - 1 Creating CouchDB \n\nThis initial section contains everything you need to get CouchDB and running on your server.\n\n* First, ensure the user can login to our console.megamafrica.com\n\n* Go to the Market Places.\n\n* Select the CouchDB, A window will pop up with for CPU, storage, RAM and SSHkey options.\n\n* You can choose the storage size and RAM capacity.\n\n* You can create a new sshkey, or  use an existing sshkey or import your own sshkeys too.\n\n* Click the create button. it will create the virtual machine.\n\n###Step - 2 Accessing CouchDB\n\nNext, Go to the Dashboard and click the domain name a new window is open.\n\n* It contains the CPU, RAM and Storage tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and storage usage.\n\n* VM Logs shows all the running process in VM.\n\n* You need to access the virtual machine in terminal, you can download the SSH Keys from SSH Keys tab or Overview page. Use this keys to login the terminal in following command,\n\n \t\t$ ssh -i path to/<private_key filename> root@<ipaddress>\n \nsuccessfully launched the vm.\n\n###Step-3 Open Your Web browser\n\nYou can access your web page using http://localhost:5984/\n\n![](/content/images/2016/05/s2-2.jpg)\n\n###Conclusion\n\nThese are the very simple steps to launch CouchDB in virtual machine. Creating vm is faster, so it takes only less time. This is a good head-start for launching CouchDB in MegamAfrica.\n\n###To Deploy your app\n\n\n[![img](https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png)](https://console.megamafrica.com)\n\n\n","source":"_posts/2016-05-27-how-to-launch.md","raw":"---\ntitle: How to launch CouchDB in megamafrica.com\nslug: how-to-launch\ndate_published: 2016-05-27T09:48:10.730Z\ndate_updated:   2016-05-27T09:54:02.182Z\n---\n\n###Introduction\n\nApache CouchDB, commonly referred to as CouchDB, is open source database software that focuses on ease of use and having an architecture that \"completely embraces the Web\". It has a document-oriented NoSQL database architecture and is implemented in the concurrency-oriented language Erlang; it uses JSON to store data, JavaScript as its query language using MapReduce, and HTTP for an API.\n\nThis tutorial will set up launching CouchDB.\n\n[![img](https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png)](https://console.megamafrica.com)\n\n###Prerequisites\n\nTo follow this tutorial :\n\nYou have to create a valid credential for access https://console.megamafrica.com.\n\nYou have to install openssh-server in your linux machine for ssh access.\n\n\t$ sudo apt-get install openssh-server\n\nTo check the ssh is properly installed in our system\n\n\t$ ps aux | grep sshd\n\n###Step - 1 Creating CouchDB \n\nThis initial section contains everything you need to get CouchDB and running on your server.\n\n* First, ensure the user can login to our console.megamafrica.com\n\n* Go to the Market Places.\n\n* Select the CouchDB, A window will pop up with for CPU, storage, RAM and SSHkey options.\n\n* You can choose the storage size and RAM capacity.\n\n* You can create a new sshkey, or  use an existing sshkey or import your own sshkeys too.\n\n* Click the create button. it will create the virtual machine.\n\n###Step - 2 Accessing CouchDB\n\nNext, Go to the Dashboard and click the domain name a new window is open.\n\n* It contains the CPU, RAM and Storage tab.\n\n* It shows the Metrics, VM Logs, IP address and SSH URL.\n\n* Metrics shows the CPU,RAM and storage usage.\n\n* VM Logs shows all the running process in VM.\n\n* You need to access the virtual machine in terminal, you can download the SSH Keys from SSH Keys tab or Overview page. Use this keys to login the terminal in following command,\n\n \t\t$ ssh -i path to/<private_key filename> root@<ipaddress>\n \nsuccessfully launched the vm.\n\n###Step-3 Open Your Web browser\n\nYou can access your web page using http://localhost:5984/\n\n![](/content/images/2016/05/s2-2.jpg)\n\n###Conclusion\n\nThese are the very simple steps to launch CouchDB in virtual machine. Creating vm is faster, so it takes only less time. This is a good head-start for launching CouchDB in MegamAfrica.\n\n###To Deploy your app\n\n\n[![img](https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png)](https://console.megamafrica.com)\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaito001sdrgbmm3ymxws","content":"<p>###Introduction</p>\n<p>Apache CouchDB, commonly referred to as CouchDB, is open source database software that focuses on ease of use and having an architecture that completely embraces the Web. It has a document-oriented NoSQL database architecture and is implemented in the concurrency-oriented language Erlang; it uses JSON to store data, JavaScript as its query language using MapReduce, and HTTP for an API.</p>\n<p>This tutorial will set up launching CouchDB.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\"><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"img\"></a></p>\n<p>###Prerequisites</p>\n<p>To follow this tutorial :</p>\n<p>You have to create a valid credential for access <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>.</p>\n<p>You have to install openssh-server in your linux machine for ssh access.</p>\n<pre><code>$ sudo apt-get install openssh-server\n</code></pre><p>To check the ssh is properly installed in our system</p>\n<pre><code>$ ps aux | grep sshd\n</code></pre><p>###Step - 1 Creating CouchDB </p>\n<p>This initial section contains everything you need to get CouchDB and running on your server.</p>\n<ul>\n<li><p>First, ensure the user can login to our console.megamafrica.com</p>\n</li>\n<li><p>Go to the Market Places.</p>\n</li>\n<li><p>Select the CouchDB, A window will pop up with for CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can choose the storage size and RAM capacity.</p>\n</li>\n<li><p>You can create a new sshkey, or  use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>Click the create button. it will create the virtual machine.</p>\n</li>\n</ul>\n<p>###Step - 2 Accessing CouchDB</p>\n<p>Next, Go to the Dashboard and click the domain name a new window is open.</p>\n<ul>\n<li><p>It contains the CPU, RAM and Storage tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and storage usage.</p>\n</li>\n<li><p>VM Logs shows all the running process in VM.</p>\n</li>\n<li><p>You need to access the virtual machine in terminal, you can download the SSH Keys from SSH Keys tab or Overview page. Use this keys to login the terminal in following command,</p>\n<pre><code>$ ssh -i path to/&lt;private_key filename&gt; root@&lt;ipaddress&gt;\n</code></pre></li>\n</ul>\n<p>successfully launched the vm.</p>\n<p>###Step-3 Open Your Web browser</p>\n<p>You can access your web page using <a href=\"http://localhost:5984/\" target=\"_blank\" rel=\"external\">http://localhost:5984/</a></p>\n<p><img src=\"/content/images/2016/05/s2-2.jpg\" alt=\"\"></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch CouchDB in virtual machine. Creating vm is faster, so it takes only less time. This is a good head-start for launching CouchDB in MegamAfrica.</p>\n<p>###To Deploy your app</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\"><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"img\"></a></p>\n","excerpt":"","more":"<p>###Introduction</p>\n<p>Apache CouchDB, commonly referred to as CouchDB, is open source database software that focuses on ease of use and having an architecture that completely embraces the Web. It has a document-oriented NoSQL database architecture and is implemented in the concurrency-oriented language Erlang; it uses JSON to store data, JavaScript as its query language using MapReduce, and HTTP for an API.</p>\n<p>This tutorial will set up launching CouchDB.</p>\n<p><a href=\"https://console.megamafrica.com\"><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"img\"></a></p>\n<p>###Prerequisites</p>\n<p>To follow this tutorial :</p>\n<p>You have to create a valid credential for access <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>.</p>\n<p>You have to install openssh-server in your linux machine for ssh access.</p>\n<pre><code>$ sudo apt-get install openssh-server\n</code></pre><p>To check the ssh is properly installed in our system</p>\n<pre><code>$ ps aux | grep sshd\n</code></pre><p>###Step - 1 Creating CouchDB </p>\n<p>This initial section contains everything you need to get CouchDB and running on your server.</p>\n<ul>\n<li><p>First, ensure the user can login to our console.megamafrica.com</p>\n</li>\n<li><p>Go to the Market Places.</p>\n</li>\n<li><p>Select the CouchDB, A window will pop up with for CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can choose the storage size and RAM capacity.</p>\n</li>\n<li><p>You can create a new sshkey, or  use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>Click the create button. it will create the virtual machine.</p>\n</li>\n</ul>\n<p>###Step - 2 Accessing CouchDB</p>\n<p>Next, Go to the Dashboard and click the domain name a new window is open.</p>\n<ul>\n<li><p>It contains the CPU, RAM and Storage tab.</p>\n</li>\n<li><p>It shows the Metrics, VM Logs, IP address and SSH URL.</p>\n</li>\n<li><p>Metrics shows the CPU,RAM and storage usage.</p>\n</li>\n<li><p>VM Logs shows all the running process in VM.</p>\n</li>\n<li><p>You need to access the virtual machine in terminal, you can download the SSH Keys from SSH Keys tab or Overview page. Use this keys to login the terminal in following command,</p>\n<pre><code>$ ssh -i path to/&lt;private_key filename&gt; root@&lt;ipaddress&gt;\n</code></pre></li>\n</ul>\n<p>successfully launched the vm.</p>\n<p>###Step-3 Open Your Web browser</p>\n<p>You can access your web page using <a href=\"http://localhost:5984/\">http://localhost:5984/</a></p>\n<p><img src=\"/content/images/2016/05/s2-2.jpg\" alt=\"\"></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to launch CouchDB in virtual machine. Creating vm is faster, so it takes only less time. This is a good head-start for launching CouchDB in MegamAfrica.</p>\n<p>###To Deploy your app</p>\n<p><a href=\"https://console.megamafrica.com\"><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"img\"></a></p>\n"},{"title":"Ceph Object Gateway using Ceph-deploy","slug":"2016-06-02-ceph-object-gateway-using-jewel","date_published":"2016-06-02T08:37:30.823Z","date_updated":"2016-06-02T08:39:27.176Z","_content":"\n**Ceph Object Gateway** is an object storage interface built on top of librados to provide applications with a RESTful gateway to Ceph Storage Clusters. Ceph Object Storage supports two interfaces:\n\n***S3-compatible:*** Provides object storage functionality with an interface that is compatible with a large subset of the Amazon S3 RESTful API.\n\n**Swift-compatible:** Provides object storage functionality with an interface that is compatible with a large subset of the OpenStack Swift API.\n\n**My ceph cluster setup**\n\t\n    ceph version  : (10.2.1) Jewel\n    \n    mon, osd1 and osd2 - mon-server(192.168.1.10)\n    osd3 and osd4 \t - node2(192.168.1.11)\n    gateway node       - gateway(192.168.1.12)\n    OS\t\t\t\t - Ubuntu Trusty(14.04.2 LTS)\n    User \t\t\t  - megamsys (with sudoer permission)\n\nTo run the Ceph object gateway service on Ubuntu 14.04 (Trusty), you should have a running Ceph cluster and the gateway host should have access to storage and public networks.\n\n\n\tIn my case, I've done the follwing in mon-server(192.168.1.10)\n\n\n**INSTALL CEPH OBJECT GATEWAY DAEMON USING CEPH-DEPLOY**\n\nCeph-deploy tool is reduced the effort to setup gateway. \n\nAnd make sure you have password less access for ceph cluster mon and gateway for the apropriate user.\n\nRun the below commands on `admin node`\n\n\n\t$ su megamsys\n    \n    $ cd /home/megamsys/ceph-cluster\n    \n\t$ ceph-deploy install --rgw gateway\n    \n\t$ ceph-deploy admin gateway\n    \n\t$ ceph-deploy rgw create gateway\n\nCivetweb runs on port 7480 by default.\n\nTo change the default port (e.g., to port 80), modify your Ceph configuration file in the working directory of your `admin node`. Add a section entitled `[client.rgw.< gateway-node >]`, replacing < gateway-node > with the short node name of your Ceph Object Gateway node (i.e., hostname -s).\n\nappend the following after the [global] section: \n\n\t[client.rgw.gateway]\n\trgw_frontends = \"civetweb port=80\"\n\nPush the updated configuration file to your Ceph Object Gateway node (and other Ceph nodes):\n\n\n\t$ ceph-deploy --overwrite-conf config push mon-server gatway node2 \n\nRun the below command on `gateway-node`\n\n\t$ sudo service radosgw restart id=rgw.gateway\n\n**CREATE POOLS**\n\nIf pools already exist, no problem. If not, create all the pools listed below\n\n\t$ ceph osd pool create .rgw.buckets 128 128\n    \n\t.rgw\n\t.rgw.root\n\t.rgw.control\n\t.rgw.gc\n\t.rgw.buckets\n\t.rgw.buckets.index\n\t.log\n\t.intent-log\n\t.usage\n\t.users\n\t.users.email\n\t.users.swift\n\t.users.uid\n\ncalculate you pg_num using\n\nmax(128, Nearest power of 2 (No. of OSDs * 100 / No. of Replications / 10))\n\nfor example \n\n\tmax(128 ,Nearest Power of 2 (4 * 100 / 2 /10))\n    \n    \n`NOTE`\nif write permission is given, Ceph Object Gateway will create pools automatically.\n\nTo increase your pg_num \n\n\tceph osd pool set < pool name > pg_num 128\n    ceph osd pool set < pool name > pgp_num 128\n    \n\n**USING THE GATEWAY**\n\nCREATE A RADOSGW USER FOR S3 ACCESS\n\n\t$ sudo radosgw-admin user create --uid=\"testuser\" --display-name=\"First User\"\n\nThe output of the command will be something like the following:\n\n\t{\"user_id\": \"testuser\",\n\t\"display_name\": \"First User\",\n\t\"email\": \"\",\n\t\"suspended\": 0,\n\t\"max_buckets\": 1000,\n\t\"auid\": 0,\n\t\"subusers\": [],\n\t\"keys\": [\n\t{ \"user\": \"testuser\",\n\t\"access_key\": \"I0PJDPCIYZ665MW88W9R\",\n\t\"secret_key\": \t\"dxaXZ8U90SXydYzyS5ivamEP20hkLSUViiaR+ZDA\"}],\n\t\"swift_keys\": [],\n\t\"caps\": [],\n\t\"op_mask\": \"read, write, delete\",\n\t\"default_placement\": \"\",\n\t\"placement_tags\": [],\n\t\"bucket_quota\": { \"enabled\": false,\n\t\"max_size_kb\": -1,\n\t\"max_objects\": -1},\n\t\"user_quota\": { \"enabled\": false,\n\t\"max_size_kb\": -1,\n\t\"max_objects\": -1},\n\t\"temp_url_keys\": []}\n\n`NOTE` The values of keys->access_key and keys->secret_key are needed for access validation.\n\n**ACCESS VERIFICATION**\n\ninstall the python-boto package\n\n\t$ sudo apt-get install python-boto\n\nCreate the Python script:\n\n\t$ nano s3.py\n   \n\timport boto\n\timport boto.s3.connection\n\taccess_key = 'YOUR_ACCESS_KEY'\n\tsecret_key = 'YOUR_SECRET_KEY'\n\tconn = boto.connect_s3(\n\taws_access_key_id = access_key,\n\taws_secret_access_key = secret_key,\n\thost = '{FQDN}',\n\tis_secure=False,\n\tcalling_format = boto.s3.connection.OrdinaryCallingFormat(),)\n    bucket = conn.create_bucket('my-new-bucket')\n\tfor bucket in conn.get_all_buckets():\n\t\tprint \"{name}\\t{created}\".format(\n\t\t\tname = bucket.name,\n\t\t\tcreated = bucket.creation_date,\n\t)\n\t\nRun the script:\n\n\t$ python s3.py   \n    \nThe output will be something like the following:\n\n\tmy-new-bucket 2016-05-21T17:09:10.000Z\n    \n\n**Test in ruby language**\n\nTo test ceph-gateway, we have use rubygem `s3`. Source code is in https://github.com/megamsys/radosgw-s3\n\n\n######Revert installation\n\nThere are useful commands to purge the Ceph gateway nstallation and configuration from every node so that one can start over again from a clean state.\n\nThis will remove Ceph configuration and keys\n\n\tceph-deploy purgedata gateway\n\nThis will also remove Ceph packages\n\n\tceph-deploy purge gateway\n\nIF you received the below error when you attempt to install radosgw again\n\tclient.rgw.gateway exists but key does not match\n \nExecute this to fix the error \n    ceph auth del client.rgw.gateway\n\n\n \n","source":"_posts/2016-06-02-ceph-object-gateway-using-jewel.md","raw":"---\ntitle: Ceph Object Gateway using Ceph-deploy\nslug: ceph-object-gateway-using-jewel\ndate_published: 2016-06-02T14:07:30.823Z\ndate_updated:   2016-06-02T14:09:27.176Z\n---\n\n**Ceph Object Gateway** is an object storage interface built on top of librados to provide applications with a RESTful gateway to Ceph Storage Clusters. Ceph Object Storage supports two interfaces:\n\n***S3-compatible:*** Provides object storage functionality with an interface that is compatible with a large subset of the Amazon S3 RESTful API.\n\n**Swift-compatible:** Provides object storage functionality with an interface that is compatible with a large subset of the OpenStack Swift API.\n\n**My ceph cluster setup**\n\t\n    ceph version  : (10.2.1) Jewel\n    \n    mon, osd1 and osd2 - mon-server(192.168.1.10)\n    osd3 and osd4 \t - node2(192.168.1.11)\n    gateway node       - gateway(192.168.1.12)\n    OS\t\t\t\t - Ubuntu Trusty(14.04.2 LTS)\n    User \t\t\t  - megamsys (with sudoer permission)\n\nTo run the Ceph object gateway service on Ubuntu 14.04 (Trusty), you should have a running Ceph cluster and the gateway host should have access to storage and public networks.\n\n\n\tIn my case, I've done the follwing in mon-server(192.168.1.10)\n\n\n**INSTALL CEPH OBJECT GATEWAY DAEMON USING CEPH-DEPLOY**\n\nCeph-deploy tool is reduced the effort to setup gateway. \n\nAnd make sure you have password less access for ceph cluster mon and gateway for the apropriate user.\n\nRun the below commands on `admin node`\n\n\n\t$ su megamsys\n    \n    $ cd /home/megamsys/ceph-cluster\n    \n\t$ ceph-deploy install --rgw gateway\n    \n\t$ ceph-deploy admin gateway\n    \n\t$ ceph-deploy rgw create gateway\n\nCivetweb runs on port 7480 by default.\n\nTo change the default port (e.g., to port 80), modify your Ceph configuration file in the working directory of your `admin node`. Add a section entitled `[client.rgw.< gateway-node >]`, replacing < gateway-node > with the short node name of your Ceph Object Gateway node (i.e., hostname -s).\n\nappend the following after the [global] section: \n\n\t[client.rgw.gateway]\n\trgw_frontends = \"civetweb port=80\"\n\nPush the updated configuration file to your Ceph Object Gateway node (and other Ceph nodes):\n\n\n\t$ ceph-deploy --overwrite-conf config push mon-server gatway node2 \n\nRun the below command on `gateway-node`\n\n\t$ sudo service radosgw restart id=rgw.gateway\n\n**CREATE POOLS**\n\nIf pools already exist, no problem. If not, create all the pools listed below\n\n\t$ ceph osd pool create .rgw.buckets 128 128\n    \n\t.rgw\n\t.rgw.root\n\t.rgw.control\n\t.rgw.gc\n\t.rgw.buckets\n\t.rgw.buckets.index\n\t.log\n\t.intent-log\n\t.usage\n\t.users\n\t.users.email\n\t.users.swift\n\t.users.uid\n\ncalculate you pg_num using\n\nmax(128, Nearest power of 2 (No. of OSDs * 100 / No. of Replications / 10))\n\nfor example \n\n\tmax(128 ,Nearest Power of 2 (4 * 100 / 2 /10))\n    \n    \n`NOTE`\nif write permission is given, Ceph Object Gateway will create pools automatically.\n\nTo increase your pg_num \n\n\tceph osd pool set < pool name > pg_num 128\n    ceph osd pool set < pool name > pgp_num 128\n    \n\n**USING THE GATEWAY**\n\nCREATE A RADOSGW USER FOR S3 ACCESS\n\n\t$ sudo radosgw-admin user create --uid=\"testuser\" --display-name=\"First User\"\n\nThe output of the command will be something like the following:\n\n\t{\"user_id\": \"testuser\",\n\t\"display_name\": \"First User\",\n\t\"email\": \"\",\n\t\"suspended\": 0,\n\t\"max_buckets\": 1000,\n\t\"auid\": 0,\n\t\"subusers\": [],\n\t\"keys\": [\n\t{ \"user\": \"testuser\",\n\t\"access_key\": \"I0PJDPCIYZ665MW88W9R\",\n\t\"secret_key\": \t\"dxaXZ8U90SXydYzyS5ivamEP20hkLSUViiaR+ZDA\"}],\n\t\"swift_keys\": [],\n\t\"caps\": [],\n\t\"op_mask\": \"read, write, delete\",\n\t\"default_placement\": \"\",\n\t\"placement_tags\": [],\n\t\"bucket_quota\": { \"enabled\": false,\n\t\"max_size_kb\": -1,\n\t\"max_objects\": -1},\n\t\"user_quota\": { \"enabled\": false,\n\t\"max_size_kb\": -1,\n\t\"max_objects\": -1},\n\t\"temp_url_keys\": []}\n\n`NOTE` The values of keys->access_key and keys->secret_key are needed for access validation.\n\n**ACCESS VERIFICATION**\n\ninstall the python-boto package\n\n\t$ sudo apt-get install python-boto\n\nCreate the Python script:\n\n\t$ nano s3.py\n   \n\timport boto\n\timport boto.s3.connection\n\taccess_key = 'YOUR_ACCESS_KEY'\n\tsecret_key = 'YOUR_SECRET_KEY'\n\tconn = boto.connect_s3(\n\taws_access_key_id = access_key,\n\taws_secret_access_key = secret_key,\n\thost = '{FQDN}',\n\tis_secure=False,\n\tcalling_format = boto.s3.connection.OrdinaryCallingFormat(),)\n    bucket = conn.create_bucket('my-new-bucket')\n\tfor bucket in conn.get_all_buckets():\n\t\tprint \"{name}\\t{created}\".format(\n\t\t\tname = bucket.name,\n\t\t\tcreated = bucket.creation_date,\n\t)\n\t\nRun the script:\n\n\t$ python s3.py   \n    \nThe output will be something like the following:\n\n\tmy-new-bucket 2016-05-21T17:09:10.000Z\n    \n\n**Test in ruby language**\n\nTo test ceph-gateway, we have use rubygem `s3`. Source code is in https://github.com/megamsys/radosgw-s3\n\n\n######Revert installation\n\nThere are useful commands to purge the Ceph gateway nstallation and configuration from every node so that one can start over again from a clean state.\n\nThis will remove Ceph configuration and keys\n\n\tceph-deploy purgedata gateway\n\nThis will also remove Ceph packages\n\n\tceph-deploy purge gateway\n\nIF you received the below error when you attempt to install radosgw again\n\tclient.rgw.gateway exists but key does not match\n \nExecute this to fix the error \n    ceph auth del client.rgw.gateway\n\n\n \n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaitq001tdrgbd60byfb1","content":"<p><strong>Ceph Object Gateway</strong> is an object storage interface built on top of librados to provide applications with a RESTful gateway to Ceph Storage Clusters. Ceph Object Storage supports two interfaces:</p>\n<p><strong><em>S3-compatible:</em></strong> Provides object storage functionality with an interface that is compatible with a large subset of the Amazon S3 RESTful API.</p>\n<p><strong>Swift-compatible:</strong> Provides object storage functionality with an interface that is compatible with a large subset of the OpenStack Swift API.</p>\n<p><strong>My ceph cluster setup</strong></p>\n<pre><code>ceph version  : (10.2.1) Jewel\n\nmon, osd1 and osd2 - mon-server(192.168.1.10)\nosd3 and osd4      - node2(192.168.1.11)\ngateway node       - gateway(192.168.1.12)\nOS                 - Ubuntu Trusty(14.04.2 LTS)\nUser               - megamsys (with sudoer permission)\n</code></pre><p>To run the Ceph object gateway service on Ubuntu 14.04 (Trusty), you should have a running Ceph cluster and the gateway host should have access to storage and public networks.</p>\n<pre><code>In my case, I&apos;ve done the follwing in mon-server(192.168.1.10)\n</code></pre><p><strong>INSTALL CEPH OBJECT GATEWAY DAEMON USING CEPH-DEPLOY</strong></p>\n<p>Ceph-deploy tool is reduced the effort to setup gateway. </p>\n<p>And make sure you have password less access for ceph cluster mon and gateway for the apropriate user.</p>\n<p>Run the below commands on <code>admin node</code></p>\n<pre><code>$ su megamsys\n\n$ cd /home/megamsys/ceph-cluster\n\n$ ceph-deploy install --rgw gateway\n\n$ ceph-deploy admin gateway\n\n$ ceph-deploy rgw create gateway\n</code></pre><p>Civetweb runs on port 7480 by default.</p>\n<p>To change the default port (e.g., to port 80), modify your Ceph configuration file in the working directory of your <code>admin node</code>. Add a section entitled <code>[client.rgw.&lt; gateway-node &gt;]</code>, replacing &lt; gateway-node &gt; with the short node name of your Ceph Object Gateway node (i.e., hostname -s).</p>\n<p>append the following after the [global] section: </p>\n<pre><code>[client.rgw.gateway]\nrgw_frontends = &quot;civetweb port=80&quot;\n</code></pre><p>Push the updated configuration file to your Ceph Object Gateway node (and other Ceph nodes):</p>\n<pre><code>$ ceph-deploy --overwrite-conf config push mon-server gatway node2 \n</code></pre><p>Run the below command on <code>gateway-node</code></p>\n<pre><code>$ sudo service radosgw restart id=rgw.gateway\n</code></pre><p><strong>CREATE POOLS</strong></p>\n<p>If pools already exist, no problem. If not, create all the pools listed below</p>\n<pre><code>$ ceph osd pool create .rgw.buckets 128 128\n\n.rgw\n.rgw.root\n.rgw.control\n.rgw.gc\n.rgw.buckets\n.rgw.buckets.index\n.log\n.intent-log\n.usage\n.users\n.users.email\n.users.swift\n.users.uid\n</code></pre><p>calculate you pg_num using</p>\n<p>max(128, Nearest power of 2 (No. of OSDs * 100 / No. of Replications / 10))</p>\n<p>for example </p>\n<pre><code>max(128 ,Nearest Power of 2 (4 * 100 / 2 /10))\n</code></pre><p><code>NOTE</code><br>if write permission is given, Ceph Object Gateway will create pools automatically.</p>\n<p>To increase your pg_num </p>\n<pre><code>ceph osd pool set &lt; pool name &gt; pg_num 128\nceph osd pool set &lt; pool name &gt; pgp_num 128\n</code></pre><p><strong>USING THE GATEWAY</strong></p>\n<p>CREATE A RADOSGW USER FOR S3 ACCESS</p>\n<pre><code>$ sudo radosgw-admin user create --uid=&quot;testuser&quot; --display-name=&quot;First User&quot;\n</code></pre><p>The output of the command will be something like the following:</p>\n<pre><code>{&quot;user_id&quot;: &quot;testuser&quot;,\n&quot;display_name&quot;: &quot;First User&quot;,\n&quot;email&quot;: &quot;&quot;,\n&quot;suspended&quot;: 0,\n&quot;max_buckets&quot;: 1000,\n&quot;auid&quot;: 0,\n&quot;subusers&quot;: [],\n&quot;keys&quot;: [\n{ &quot;user&quot;: &quot;testuser&quot;,\n&quot;access_key&quot;: &quot;I0PJDPCIYZ665MW88W9R&quot;,\n&quot;secret_key&quot;:     &quot;dxaXZ8U90SXydYzyS5ivamEP20hkLSUViiaR+ZDA&quot;}],\n&quot;swift_keys&quot;: [],\n&quot;caps&quot;: [],\n&quot;op_mask&quot;: &quot;read, write, delete&quot;,\n&quot;default_placement&quot;: &quot;&quot;,\n&quot;placement_tags&quot;: [],\n&quot;bucket_quota&quot;: { &quot;enabled&quot;: false,\n&quot;max_size_kb&quot;: -1,\n&quot;max_objects&quot;: -1},\n&quot;user_quota&quot;: { &quot;enabled&quot;: false,\n&quot;max_size_kb&quot;: -1,\n&quot;max_objects&quot;: -1},\n&quot;temp_url_keys&quot;: []}\n</code></pre><p><code>NOTE</code> The values of keys-&gt;access_key and keys-&gt;secret_key are needed for access validation.</p>\n<p><strong>ACCESS VERIFICATION</strong></p>\n<p>install the python-boto package</p>\n<pre><code>$ sudo apt-get install python-boto\n</code></pre><p>Create the Python script:</p>\n<pre><code>$ nano s3.py\n\nimport boto\nimport boto.s3.connection\naccess_key = &apos;YOUR_ACCESS_KEY&apos;\nsecret_key = &apos;YOUR_SECRET_KEY&apos;\nconn = boto.connect_s3(\naws_access_key_id = access_key,\naws_secret_access_key = secret_key,\nhost = &apos;{FQDN}&apos;,\nis_secure=False,\ncalling_format = boto.s3.connection.OrdinaryCallingFormat(),)\nbucket = conn.create_bucket(&apos;my-new-bucket&apos;)\nfor bucket in conn.get_all_buckets():\n    print &quot;{name}\\t{created}&quot;.format(\n        name = bucket.name,\n        created = bucket.creation_date,\n)\n</code></pre><p>Run the script:</p>\n<pre><code>$ python s3.py   \n</code></pre><p>The output will be something like the following:</p>\n<pre><code>my-new-bucket 2016-05-21T17:09:10.000Z\n</code></pre><p><strong>Test in ruby language</strong></p>\n<p>To test ceph-gateway, we have use rubygem <code>s3</code>. Source code is in <a href=\"https://github.com/megamsys/radosgw-s3\" target=\"_blank\" rel=\"external\">https://github.com/megamsys/radosgw-s3</a></p>\n<p>######Revert installation</p>\n<p>There are useful commands to purge the Ceph gateway nstallation and configuration from every node so that one can start over again from a clean state.</p>\n<p>This will remove Ceph configuration and keys</p>\n<pre><code>ceph-deploy purgedata gateway\n</code></pre><p>This will also remove Ceph packages</p>\n<pre><code>ceph-deploy purge gateway\n</code></pre><p>IF you received the below error when you attempt to install radosgw again<br>    client.rgw.gateway exists but key does not match</p>\n<p>Execute this to fix the error<br>    ceph auth del client.rgw.gateway</p>\n","excerpt":"","more":"<p><strong>Ceph Object Gateway</strong> is an object storage interface built on top of librados to provide applications with a RESTful gateway to Ceph Storage Clusters. Ceph Object Storage supports two interfaces:</p>\n<p><strong><em>S3-compatible:</em></strong> Provides object storage functionality with an interface that is compatible with a large subset of the Amazon S3 RESTful API.</p>\n<p><strong>Swift-compatible:</strong> Provides object storage functionality with an interface that is compatible with a large subset of the OpenStack Swift API.</p>\n<p><strong>My ceph cluster setup</strong></p>\n<pre><code>ceph version  : (10.2.1) Jewel\n\nmon, osd1 and osd2 - mon-server(192.168.1.10)\nosd3 and osd4      - node2(192.168.1.11)\ngateway node       - gateway(192.168.1.12)\nOS                 - Ubuntu Trusty(14.04.2 LTS)\nUser               - megamsys (with sudoer permission)\n</code></pre><p>To run the Ceph object gateway service on Ubuntu 14.04 (Trusty), you should have a running Ceph cluster and the gateway host should have access to storage and public networks.</p>\n<pre><code>In my case, I&apos;ve done the follwing in mon-server(192.168.1.10)\n</code></pre><p><strong>INSTALL CEPH OBJECT GATEWAY DAEMON USING CEPH-DEPLOY</strong></p>\n<p>Ceph-deploy tool is reduced the effort to setup gateway. </p>\n<p>And make sure you have password less access for ceph cluster mon and gateway for the apropriate user.</p>\n<p>Run the below commands on <code>admin node</code></p>\n<pre><code>$ su megamsys\n\n$ cd /home/megamsys/ceph-cluster\n\n$ ceph-deploy install --rgw gateway\n\n$ ceph-deploy admin gateway\n\n$ ceph-deploy rgw create gateway\n</code></pre><p>Civetweb runs on port 7480 by default.</p>\n<p>To change the default port (e.g., to port 80), modify your Ceph configuration file in the working directory of your <code>admin node</code>. Add a section entitled <code>[client.rgw.&lt; gateway-node &gt;]</code>, replacing &lt; gateway-node &gt; with the short node name of your Ceph Object Gateway node (i.e., hostname -s).</p>\n<p>append the following after the [global] section: </p>\n<pre><code>[client.rgw.gateway]\nrgw_frontends = &quot;civetweb port=80&quot;\n</code></pre><p>Push the updated configuration file to your Ceph Object Gateway node (and other Ceph nodes):</p>\n<pre><code>$ ceph-deploy --overwrite-conf config push mon-server gatway node2 \n</code></pre><p>Run the below command on <code>gateway-node</code></p>\n<pre><code>$ sudo service radosgw restart id=rgw.gateway\n</code></pre><p><strong>CREATE POOLS</strong></p>\n<p>If pools already exist, no problem. If not, create all the pools listed below</p>\n<pre><code>$ ceph osd pool create .rgw.buckets 128 128\n\n.rgw\n.rgw.root\n.rgw.control\n.rgw.gc\n.rgw.buckets\n.rgw.buckets.index\n.log\n.intent-log\n.usage\n.users\n.users.email\n.users.swift\n.users.uid\n</code></pre><p>calculate you pg_num using</p>\n<p>max(128, Nearest power of 2 (No. of OSDs * 100 / No. of Replications / 10))</p>\n<p>for example </p>\n<pre><code>max(128 ,Nearest Power of 2 (4 * 100 / 2 /10))\n</code></pre><p><code>NOTE</code><br>if write permission is given, Ceph Object Gateway will create pools automatically.</p>\n<p>To increase your pg_num </p>\n<pre><code>ceph osd pool set &lt; pool name &gt; pg_num 128\nceph osd pool set &lt; pool name &gt; pgp_num 128\n</code></pre><p><strong>USING THE GATEWAY</strong></p>\n<p>CREATE A RADOSGW USER FOR S3 ACCESS</p>\n<pre><code>$ sudo radosgw-admin user create --uid=&quot;testuser&quot; --display-name=&quot;First User&quot;\n</code></pre><p>The output of the command will be something like the following:</p>\n<pre><code>{&quot;user_id&quot;: &quot;testuser&quot;,\n&quot;display_name&quot;: &quot;First User&quot;,\n&quot;email&quot;: &quot;&quot;,\n&quot;suspended&quot;: 0,\n&quot;max_buckets&quot;: 1000,\n&quot;auid&quot;: 0,\n&quot;subusers&quot;: [],\n&quot;keys&quot;: [\n{ &quot;user&quot;: &quot;testuser&quot;,\n&quot;access_key&quot;: &quot;I0PJDPCIYZ665MW88W9R&quot;,\n&quot;secret_key&quot;:     &quot;dxaXZ8U90SXydYzyS5ivamEP20hkLSUViiaR+ZDA&quot;}],\n&quot;swift_keys&quot;: [],\n&quot;caps&quot;: [],\n&quot;op_mask&quot;: &quot;read, write, delete&quot;,\n&quot;default_placement&quot;: &quot;&quot;,\n&quot;placement_tags&quot;: [],\n&quot;bucket_quota&quot;: { &quot;enabled&quot;: false,\n&quot;max_size_kb&quot;: -1,\n&quot;max_objects&quot;: -1},\n&quot;user_quota&quot;: { &quot;enabled&quot;: false,\n&quot;max_size_kb&quot;: -1,\n&quot;max_objects&quot;: -1},\n&quot;temp_url_keys&quot;: []}\n</code></pre><p><code>NOTE</code> The values of keys-&gt;access_key and keys-&gt;secret_key are needed for access validation.</p>\n<p><strong>ACCESS VERIFICATION</strong></p>\n<p>install the python-boto package</p>\n<pre><code>$ sudo apt-get install python-boto\n</code></pre><p>Create the Python script:</p>\n<pre><code>$ nano s3.py\n\nimport boto\nimport boto.s3.connection\naccess_key = &apos;YOUR_ACCESS_KEY&apos;\nsecret_key = &apos;YOUR_SECRET_KEY&apos;\nconn = boto.connect_s3(\naws_access_key_id = access_key,\naws_secret_access_key = secret_key,\nhost = &apos;{FQDN}&apos;,\nis_secure=False,\ncalling_format = boto.s3.connection.OrdinaryCallingFormat(),)\nbucket = conn.create_bucket(&apos;my-new-bucket&apos;)\nfor bucket in conn.get_all_buckets():\n    print &quot;{name}\\t{created}&quot;.format(\n        name = bucket.name,\n        created = bucket.creation_date,\n)\n</code></pre><p>Run the script:</p>\n<pre><code>$ python s3.py   \n</code></pre><p>The output will be something like the following:</p>\n<pre><code>my-new-bucket 2016-05-21T17:09:10.000Z\n</code></pre><p><strong>Test in ruby language</strong></p>\n<p>To test ceph-gateway, we have use rubygem <code>s3</code>. Source code is in <a href=\"https://github.com/megamsys/radosgw-s3\">https://github.com/megamsys/radosgw-s3</a></p>\n<p>######Revert installation</p>\n<p>There are useful commands to purge the Ceph gateway nstallation and configuration from every node so that one can start over again from a clean state.</p>\n<p>This will remove Ceph configuration and keys</p>\n<pre><code>ceph-deploy purgedata gateway\n</code></pre><p>This will also remove Ceph packages</p>\n<pre><code>ceph-deploy purge gateway\n</code></pre><p>IF you received the below error when you attempt to install radosgw again<br>    client.rgw.gateway exists but key does not match</p>\n<p>Execute this to fix the error<br>    ceph auth del client.rgw.gateway</p>\n"},{"title":"How to deploy Private Docker Registry in MegamAfrica","slug":"2016-06-10-private-registry-along-with-ceph","date_published":"2016-06-10T00:06:36.604Z","date_updated":"2016-06-16T21:34:38.092Z","_content":"\n###Introduction\n\nA Docker registry serves to manage Docker images in your organization, whether created internally or downloaded from remote Docker resources such as <a href=\"https://hub.docker.com/\" target=\"_blank\">Docker Hub</a>. \n\nThe Registry is a stateless, highly scalable server side application that stores and lets you distribute Docker images. \n\n#### Why use it\nYou should use the Registry if you want to:\n\n- tightly control where your images are being stored\n- fully own your images distribution pipeline\n- integrate image storage and distribution tightly into your in-house development workflow\n\nThis tutorial will guide you in setting up a **Private docker registry** in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the How To Install Git with Apt.\n\n* An account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com.[How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/).\n\n#### Introducing Atharva Storage - MegamAfrica\n\n**Atharva Storage** - MegamAfrica is a \"Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel.\".\n\nUpon successful signin to https://console.megamafrica.com, look for the icon \n![](/content/images/2016/06/storage-1.jpg)\n at the top right hand corner named `Storage`\n![](/content/images/2016/06/atharva-1.jpg)\n\n###To Deploy Private Docker Registry\n\nThis initial section contains everything you need to set private registry on your server.\n\n#####Step-1 Creating Ubuntu VM\n\n* First, ensure you can login to https://console.megamafrica.com.\n\n*  Go to the Market Places.\n\n* select the Ubuntu, A window will pop up with for CPU, storage, RAM and SSHkey options.\n\n* You can choose the storage size, RAM capacity.\n\n* You can Create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* Click the Create button. it will create the virtual machine.\n \n#####Step-2 Creating a Bucket in our Storage\n\n* Go to the Storage.\n\n* Click the create storage button. it will open one pop-up window. You can create a bucket. \n\n* Let us provide our bucket name as `docker-registry`.\n![](/content/images/2016/06/one.jpg)\n\n#####Step-3 Installing Docker\n\n* You need to access the launched Virtual Machine from `step-1` via a terminal. \n\n* You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,\n\n\t\t ssh -i path to/<private_key filename> root@<ipaddress>\n       \n* Update your apt sources\n\n        echo 'deb https://apt.dockerproject.org/repo ubuntu-trusty main' >/etc/apt/sources.list.d/docker.list\n\t\tsudo apt-get install apt-transport-https ca-certificates\n\t\tsudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D\n\t\tsudo apt-get install linux-image-generic-lts-trusty\n        \n* Update your APT package index.\n\n\t\tsudo apt-get update\n* Install Docker.\n\t\t\n        sudo apt-get install docker-engine\n* Start the docker daemon.\n\n\t\tsudo service docker start\n\n#####Step-4 Run the Docker Registry\n\n* Inside the virtual machine, Use the following command to run the docker registry.\n\nAdd an extra STORAGE_PATH=/registry  to create a child folder under `docker-registry` bucket. Apparently this didn't work for us. \n\n\t\tdocker run \\\n         -e SETTINGS_FLAVOR=ceph-s3 \\\n         -e AWS_BUCKET=docker-registry \\\n         -e STORAGE_PATH=/registry \\\n         -e AWS_REGION=default \\\n         -e AWS_KEY=<access-key> \\\n         -e AWS_SECRET=<secret-key> \\\n         -e AWS_CALLING_FORMAT=boto.s3.connection.OrdinaryCallingFormat \\\n         -e AWS_PORT=80 \\\n         -e AWS_HOST=88.198.139.81 \\\n         -p 5000:5000 \\\n         registry\n         \n         /* enter your bucket-name here.that you are created in step-2.\n        You can see your Access-key and Secret-key from your profile page in MegamAfrica(https://console.megamafrica.com) */\n   \n* Create a docker images by running the following command\n\nEnter this command in your virtual machine\n\n\t\tsudo docker pull <imagename>\n        eg: sudo docker pull hello-world\n![](/content/images/2016/06/p1-1.jpg)\n\n*  Check if the image is downloaded in the VM\n\n\t\tdocker images\n        \n\n![](/content/images/2016/06/p3.jpg)\n\n* Push downloaded docker image to your private registry.\n\nAs you are inside the VM, the private registry is running under `127.0.0.1:5000`\n\n\tsudo docker tag hello-world 127.0.0.1:5000/hello-world\n\tsudo docker push 127.0.0.1:5000/hello-world\n        \n    \n![](/content/images/2016/06/p2-1.jpg)\n\n* Let us verify if the image is stored\n\nLogon https://console.megamafrica.com goto storage place. You can see the docker images in file structure order.\n\n![](/content/images/2016/06/docker-1.jpg)\n\n* Grab the private regitry's ipaddress \n\t\n    \tifconfig\n        \n\n![](/content/images/2016/06/p4.jpg)\n\nIn our case the docker registry is running at 138.201.98.3.\n\n#####Step-5 Pull a docker images\n\n* Goto your workstation, Open the /etc/default/docker file\n\n* Edit or add the DOCKER_OPTS line and add the `--insecure-registry flag`.\n\n\t\tDOCKER_OPTS=\"--insecure-registry <vm-ipaddress>:5000\"\n \n* Close and save the configuration file.\n \n* Restart your Docker daemon\n\n\t\t\tservice docker stop\n    \t\tservice docker start\n\n* To run the pull command, make sure docker is running \n\n    \tdocker pull 138.201.98.3:5000/hello-world\n \n![](/content/images/2016/06/p5.jpg)\n###Conclusion\n\nThese are the very simple steps to create vm, utilize our atharva storage. \n\nThis is a good head-start for deploy a private docker-registry in MegamAfrica.\n\n###Deploy your Private Docker Registry now\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n\n","source":"_posts/2016-06-10-private-registry-along-with-ceph.md","raw":"---\ntitle: How to deploy Private Docker Registry in MegamAfrica\nslug: private-registry-along-with-ceph\ndate_published: 2016-06-10T05:36:36.604Z\ndate_updated:   2016-06-17T03:04:38.092Z\n---\n\n###Introduction\n\nA Docker registry serves to manage Docker images in your organization, whether created internally or downloaded from remote Docker resources such as <a href=\"https://hub.docker.com/\" target=\"_blank\">Docker Hub</a>. \n\nThe Registry is a stateless, highly scalable server side application that stores and lets you distribute Docker images. \n\n#### Why use it\nYou should use the Registry if you want to:\n\n- tightly control where your images are being stored\n- fully own your images distribution pipeline\n- integrate image storage and distribution tightly into your in-house development workflow\n\nThis tutorial will guide you in setting up a **Private docker registry** in MegamAfrica.\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n* You are running Ubuntu 14.04 or Linux workstation.\n\n* Git installed on your server, which you can do by following the How To Install Git with Apt.\n\n* An account on GitHub, which is a Git repository host.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com.[How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/).\n\n#### Introducing Atharva Storage - MegamAfrica\n\n**Atharva Storage** - MegamAfrica is a \"Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel.\".\n\nUpon successful signin to https://console.megamafrica.com, look for the icon \n![](/content/images/2016/06/storage-1.jpg)\n at the top right hand corner named `Storage`\n![](/content/images/2016/06/atharva-1.jpg)\n\n###To Deploy Private Docker Registry\n\nThis initial section contains everything you need to set private registry on your server.\n\n#####Step-1 Creating Ubuntu VM\n\n* First, ensure you can login to https://console.megamafrica.com.\n\n*  Go to the Market Places.\n\n* select the Ubuntu, A window will pop up with for CPU, storage, RAM and SSHkey options.\n\n* You can choose the storage size, RAM capacity.\n\n* You can Create a new sshkey, use an existing sshkey or import your own sshkeys too.\n\n* Click the Create button. it will create the virtual machine.\n \n#####Step-2 Creating a Bucket in our Storage\n\n* Go to the Storage.\n\n* Click the create storage button. it will open one pop-up window. You can create a bucket. \n\n* Let us provide our bucket name as `docker-registry`.\n![](/content/images/2016/06/one.jpg)\n\n#####Step-3 Installing Docker\n\n* You need to access the launched Virtual Machine from `step-1` via a terminal. \n\n* You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,\n\n\t\t ssh -i path to/<private_key filename> root@<ipaddress>\n       \n* Update your apt sources\n\n        echo 'deb https://apt.dockerproject.org/repo ubuntu-trusty main' >/etc/apt/sources.list.d/docker.list\n\t\tsudo apt-get install apt-transport-https ca-certificates\n\t\tsudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D\n\t\tsudo apt-get install linux-image-generic-lts-trusty\n        \n* Update your APT package index.\n\n\t\tsudo apt-get update\n* Install Docker.\n\t\t\n        sudo apt-get install docker-engine\n* Start the docker daemon.\n\n\t\tsudo service docker start\n\n#####Step-4 Run the Docker Registry\n\n* Inside the virtual machine, Use the following command to run the docker registry.\n\nAdd an extra STORAGE_PATH=/registry  to create a child folder under `docker-registry` bucket. Apparently this didn't work for us. \n\n\t\tdocker run \\\n         -e SETTINGS_FLAVOR=ceph-s3 \\\n         -e AWS_BUCKET=docker-registry \\\n         -e STORAGE_PATH=/registry \\\n         -e AWS_REGION=default \\\n         -e AWS_KEY=<access-key> \\\n         -e AWS_SECRET=<secret-key> \\\n         -e AWS_CALLING_FORMAT=boto.s3.connection.OrdinaryCallingFormat \\\n         -e AWS_PORT=80 \\\n         -e AWS_HOST=88.198.139.81 \\\n         -p 5000:5000 \\\n         registry\n         \n         /* enter your bucket-name here.that you are created in step-2.\n        You can see your Access-key and Secret-key from your profile page in MegamAfrica(https://console.megamafrica.com) */\n   \n* Create a docker images by running the following command\n\nEnter this command in your virtual machine\n\n\t\tsudo docker pull <imagename>\n        eg: sudo docker pull hello-world\n![](/content/images/2016/06/p1-1.jpg)\n\n*  Check if the image is downloaded in the VM\n\n\t\tdocker images\n        \n\n![](/content/images/2016/06/p3.jpg)\n\n* Push downloaded docker image to your private registry.\n\nAs you are inside the VM, the private registry is running under `127.0.0.1:5000`\n\n\tsudo docker tag hello-world 127.0.0.1:5000/hello-world\n\tsudo docker push 127.0.0.1:5000/hello-world\n        \n    \n![](/content/images/2016/06/p2-1.jpg)\n\n* Let us verify if the image is stored\n\nLogon https://console.megamafrica.com goto storage place. You can see the docker images in file structure order.\n\n![](/content/images/2016/06/docker-1.jpg)\n\n* Grab the private regitry's ipaddress \n\t\n    \tifconfig\n        \n\n![](/content/images/2016/06/p4.jpg)\n\nIn our case the docker registry is running at 138.201.98.3.\n\n#####Step-5 Pull a docker images\n\n* Goto your workstation, Open the /etc/default/docker file\n\n* Edit or add the DOCKER_OPTS line and add the `--insecure-registry flag`.\n\n\t\tDOCKER_OPTS=\"--insecure-registry <vm-ipaddress>:5000\"\n \n* Close and save the configuration file.\n \n* Restart your Docker daemon\n\n\t\t\tservice docker stop\n    \t\tservice docker start\n\n* To run the pull command, make sure docker is running \n\n    \tdocker pull 138.201.98.3:5000/hello-world\n \n![](/content/images/2016/06/p5.jpg)\n###Conclusion\n\nThese are the very simple steps to create vm, utilize our atharva storage. \n\nThis is a good head-start for deploy a private docker-registry in MegamAfrica.\n\n###Deploy your Private Docker Registry now\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaitu001udrgbqhuuxz4u","content":"<p>###Introduction</p>\n<p>A Docker registry serves to manage Docker images in your organization, whether created internally or downloaded from remote Docker resources such as <a href=\"https://hub.docker.com/\" target=\"_blank\">Docker Hub</a>. </p>\n<p>The Registry is a stateless, highly scalable server side application that stores and lets you distribute Docker images. </p>\n<h4 id=\"Why-use-it\"><a href=\"#Why-use-it\" class=\"headerlink\" title=\"Why use it\"></a>Why use it</h4><p>You should use the Registry if you want to:</p>\n<ul>\n<li>tightly control where your images are being stored</li>\n<li>fully own your images distribution pipeline</li>\n<li>integrate image storage and distribution tightly into your in-house development workflow</li>\n</ul>\n<p>This tutorial will guide you in setting up a <strong>Private docker registry</strong> in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the How To Install Git with Apt.</p>\n</li>\n<li><p>An account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com.[How\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com.[How</a> to create an account with MegamAfrica](<a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/</a>).</p>\n</li>\n</ul>\n<h4 id=\"Introducing-Atharva-Storage-MegamAfrica\"><a href=\"#Introducing-Atharva-Storage-MegamAfrica\" class=\"headerlink\" title=\"Introducing Atharva Storage - MegamAfrica\"></a>Introducing Atharva Storage - MegamAfrica</h4><p><strong>Atharva Storage</strong> - MegamAfrica is a Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel..</p>\n<p>Upon successful signin to <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>, look for the icon<br><img src=\"/content/images/2016/06/storage-1.jpg\" alt=\"\"><br> at the top right hand corner named <code>Storage</code><br><img src=\"/content/images/2016/06/atharva-1.jpg\" alt=\"\"></p>\n<p>###To Deploy Private Docker Registry</p>\n<p>This initial section contains everything you need to set private registry on your server.</p>\n<p>#####Step-1 Creating Ubuntu VM</p>\n<ul>\n<li><p>First, ensure you can login to <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>.</p>\n</li>\n<li><p>Go to the Market Places.</p>\n</li>\n<li><p>select the Ubuntu, A window will pop up with for CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can choose the storage size, RAM capacity.</p>\n</li>\n<li><p>You can Create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>Click the Create button. it will create the virtual machine.</p>\n</li>\n</ul>\n<p>#####Step-2 Creating a Bucket in our Storage</p>\n<ul>\n<li><p>Go to the Storage.</p>\n</li>\n<li><p>Click the create storage button. it will open one pop-up window. You can create a bucket. </p>\n</li>\n<li><p>Let us provide our bucket name as <code>docker-registry</code>.<br><img src=\"/content/images/2016/06/one.jpg\" alt=\"\"></p>\n</li>\n</ul>\n<p>#####Step-3 Installing Docker</p>\n<ul>\n<li><p>You need to access the launched Virtual Machine from <code>step-1</code> via a terminal. </p>\n</li>\n<li><p>You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,</p>\n<pre><code>ssh -i path to/&lt;private_key filename&gt; root@&lt;ipaddress&gt;\n</code></pre></li>\n<li><p>Update your apt sources</p>\n<pre><code>echo &apos;deb https://apt.dockerproject.org/repo ubuntu-trusty main&apos; &gt;/etc/apt/sources.list.d/docker.list\nsudo apt-get install apt-transport-https ca-certificates\nsudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D\nsudo apt-get install linux-image-generic-lts-trusty\n</code></pre></li>\n<li><p>Update your APT package index.</p>\n<pre><code>sudo apt-get update\n</code></pre></li>\n<li><p>Install Docker.</p>\n<pre><code>sudo apt-get install docker-engine\n</code></pre></li>\n<li><p>Start the docker daemon.</p>\n<pre><code>sudo service docker start\n</code></pre></li>\n</ul>\n<p>#####Step-4 Run the Docker Registry</p>\n<ul>\n<li>Inside the virtual machine, Use the following command to run the docker registry.</li>\n</ul>\n<p>Add an extra STORAGE_PATH=/registry  to create a child folder under <code>docker-registry</code> bucket. Apparently this didnt work for us. </p>\n<pre><code>docker run \\\n -e SETTINGS_FLAVOR=ceph-s3 \\\n -e AWS_BUCKET=docker-registry \\\n -e STORAGE_PATH=/registry \\\n -e AWS_REGION=default \\\n -e AWS_KEY=&lt;access-key&gt; \\\n -e AWS_SECRET=&lt;secret-key&gt; \\\n -e AWS_CALLING_FORMAT=boto.s3.connection.OrdinaryCallingFormat \\\n -e AWS_PORT=80 \\\n -e AWS_HOST=88.198.139.81 \\\n -p 5000:5000 \\\n registry\n\n /* enter your bucket-name here.that you are created in step-2.\nYou can see your Access-key and Secret-key from your profile page in MegamAfrica(https://console.megamafrica.com) */\n</code></pre><ul>\n<li>Create a docker images by running the following command</li>\n</ul>\n<p>Enter this command in your virtual machine</p>\n<pre><code>sudo docker pull &lt;imagename&gt;\neg: sudo docker pull hello-world\n</code></pre><p><img src=\"/content/images/2016/06/p1-1.jpg\" alt=\"\"></p>\n<ul>\n<li><p>Check if the image is downloaded in the VM</p>\n<pre><code>docker images\n</code></pre></li>\n</ul>\n<p><img src=\"/content/images/2016/06/p3.jpg\" alt=\"\"></p>\n<ul>\n<li>Push downloaded docker image to your private registry.</li>\n</ul>\n<p>As you are inside the VM, the private registry is running under <code>127.0.0.1:5000</code></p>\n<pre><code>sudo docker tag hello-world 127.0.0.1:5000/hello-world\nsudo docker push 127.0.0.1:5000/hello-world\n</code></pre><p><img src=\"/content/images/2016/06/p2-1.jpg\" alt=\"\"></p>\n<ul>\n<li>Let us verify if the image is stored</li>\n</ul>\n<p>Logon <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a> goto storage place. You can see the docker images in file structure order.</p>\n<p><img src=\"/content/images/2016/06/docker-1.jpg\" alt=\"\"></p>\n<ul>\n<li><p>Grab the private regitrys ipaddress </p>\n<pre><code>ifconfig\n</code></pre></li>\n</ul>\n<p><img src=\"/content/images/2016/06/p4.jpg\" alt=\"\"></p>\n<p>In our case the docker registry is running at 138.201.98.3.</p>\n<p>#####Step-5 Pull a docker images</p>\n<ul>\n<li><p>Goto your workstation, Open the /etc/default/docker file</p>\n</li>\n<li><p>Edit or add the DOCKER_OPTS line and add the <code>--insecure-registry flag</code>.</p>\n<pre><code>DOCKER_OPTS=&quot;--insecure-registry &lt;vm-ipaddress&gt;:5000&quot;\n</code></pre></li>\n<li><p>Close and save the configuration file.</p>\n</li>\n<li><p>Restart your Docker daemon</p>\n<pre><code>service docker stop\nservice docker start\n</code></pre></li>\n<li><p>To run the pull command, make sure docker is running </p>\n<pre><code>docker pull 138.201.98.3:5000/hello-world\n</code></pre></li>\n</ul>\n<p><img src=\"/content/images/2016/06/p5.jpg\" alt=\"\"></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to create vm, utilize our atharva storage. </p>\n<p>This is a good head-start for deploy a private docker-registry in MegamAfrica.</p>\n<p>###Deploy your Private Docker Registry now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###Introduction</p>\n<p>A Docker registry serves to manage Docker images in your organization, whether created internally or downloaded from remote Docker resources such as <a href=\"https://hub.docker.com/\" target=\"_blank\">Docker Hub</a>. </p>\n<p>The Registry is a stateless, highly scalable server side application that stores and lets you distribute Docker images. </p>\n<h4 id=\"Why-use-it\"><a href=\"#Why-use-it\" class=\"headerlink\" title=\"Why use it\"></a>Why use it</h4><p>You should use the Registry if you want to:</p>\n<ul>\n<li>tightly control where your images are being stored</li>\n<li>fully own your images distribution pipeline</li>\n<li>integrate image storage and distribution tightly into your in-house development workflow</li>\n</ul>\n<p>This tutorial will guide you in setting up a <strong>Private docker registry</strong> in MegamAfrica.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Ubuntu 14.04 or Linux workstation.</p>\n</li>\n<li><p>Git installed on your server, which you can do by following the How To Install Git with Apt.</p>\n</li>\n<li><p>An account on GitHub, which is a Git repository host.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com.[How\">https://console.megamafrica.com.[How</a> to create an account with MegamAfrica](<a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/</a>).</p>\n</li>\n</ul>\n<h4 id=\"Introducing-Atharva-Storage-MegamAfrica\"><a href=\"#Introducing-Atharva-Storage-MegamAfrica\" class=\"headerlink\" title=\"Introducing Atharva Storage - MegamAfrica\"></a>Introducing Atharva Storage - MegamAfrica</h4><p><strong>Atharva Storage</strong> - MegamAfrica is a Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel..</p>\n<p>Upon successful signin to <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>, look for the icon<br><img src=\"/content/images/2016/06/storage-1.jpg\" alt=\"\"><br> at the top right hand corner named <code>Storage</code><br><img src=\"/content/images/2016/06/atharva-1.jpg\" alt=\"\"></p>\n<p>###To Deploy Private Docker Registry</p>\n<p>This initial section contains everything you need to set private registry on your server.</p>\n<p>#####Step-1 Creating Ubuntu VM</p>\n<ul>\n<li><p>First, ensure you can login to <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>.</p>\n</li>\n<li><p>Go to the Market Places.</p>\n</li>\n<li><p>select the Ubuntu, A window will pop up with for CPU, storage, RAM and SSHkey options.</p>\n</li>\n<li><p>You can choose the storage size, RAM capacity.</p>\n</li>\n<li><p>You can Create a new sshkey, use an existing sshkey or import your own sshkeys too.</p>\n</li>\n<li><p>Click the Create button. it will create the virtual machine.</p>\n</li>\n</ul>\n<p>#####Step-2 Creating a Bucket in our Storage</p>\n<ul>\n<li><p>Go to the Storage.</p>\n</li>\n<li><p>Click the create storage button. it will open one pop-up window. You can create a bucket. </p>\n</li>\n<li><p>Let us provide our bucket name as <code>docker-registry</code>.<br><img src=\"/content/images/2016/06/one.jpg\" alt=\"\"></p>\n</li>\n</ul>\n<p>#####Step-3 Installing Docker</p>\n<ul>\n<li><p>You need to access the launched Virtual Machine from <code>step-1</code> via a terminal. </p>\n</li>\n<li><p>You can download the SSH Keys from SSH Keys tab or Overview page. Use this key to login to your virtual machine using the following command,</p>\n<pre><code>ssh -i path to/&lt;private_key filename&gt; root@&lt;ipaddress&gt;\n</code></pre></li>\n<li><p>Update your apt sources</p>\n<pre><code>echo &apos;deb https://apt.dockerproject.org/repo ubuntu-trusty main&apos; &gt;/etc/apt/sources.list.d/docker.list\nsudo apt-get install apt-transport-https ca-certificates\nsudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D\nsudo apt-get install linux-image-generic-lts-trusty\n</code></pre></li>\n<li><p>Update your APT package index.</p>\n<pre><code>sudo apt-get update\n</code></pre></li>\n<li><p>Install Docker.</p>\n<pre><code>sudo apt-get install docker-engine\n</code></pre></li>\n<li><p>Start the docker daemon.</p>\n<pre><code>sudo service docker start\n</code></pre></li>\n</ul>\n<p>#####Step-4 Run the Docker Registry</p>\n<ul>\n<li>Inside the virtual machine, Use the following command to run the docker registry.</li>\n</ul>\n<p>Add an extra STORAGE_PATH=/registry  to create a child folder under <code>docker-registry</code> bucket. Apparently this didnt work for us. </p>\n<pre><code>docker run \\\n -e SETTINGS_FLAVOR=ceph-s3 \\\n -e AWS_BUCKET=docker-registry \\\n -e STORAGE_PATH=/registry \\\n -e AWS_REGION=default \\\n -e AWS_KEY=&lt;access-key&gt; \\\n -e AWS_SECRET=&lt;secret-key&gt; \\\n -e AWS_CALLING_FORMAT=boto.s3.connection.OrdinaryCallingFormat \\\n -e AWS_PORT=80 \\\n -e AWS_HOST=88.198.139.81 \\\n -p 5000:5000 \\\n registry\n\n /* enter your bucket-name here.that you are created in step-2.\nYou can see your Access-key and Secret-key from your profile page in MegamAfrica(https://console.megamafrica.com) */\n</code></pre><ul>\n<li>Create a docker images by running the following command</li>\n</ul>\n<p>Enter this command in your virtual machine</p>\n<pre><code>sudo docker pull &lt;imagename&gt;\neg: sudo docker pull hello-world\n</code></pre><p><img src=\"/content/images/2016/06/p1-1.jpg\" alt=\"\"></p>\n<ul>\n<li><p>Check if the image is downloaded in the VM</p>\n<pre><code>docker images\n</code></pre></li>\n</ul>\n<p><img src=\"/content/images/2016/06/p3.jpg\" alt=\"\"></p>\n<ul>\n<li>Push downloaded docker image to your private registry.</li>\n</ul>\n<p>As you are inside the VM, the private registry is running under <code>127.0.0.1:5000</code></p>\n<pre><code>sudo docker tag hello-world 127.0.0.1:5000/hello-world\nsudo docker push 127.0.0.1:5000/hello-world\n</code></pre><p><img src=\"/content/images/2016/06/p2-1.jpg\" alt=\"\"></p>\n<ul>\n<li>Let us verify if the image is stored</li>\n</ul>\n<p>Logon <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a> goto storage place. You can see the docker images in file structure order.</p>\n<p><img src=\"/content/images/2016/06/docker-1.jpg\" alt=\"\"></p>\n<ul>\n<li><p>Grab the private regitrys ipaddress </p>\n<pre><code>ifconfig\n</code></pre></li>\n</ul>\n<p><img src=\"/content/images/2016/06/p4.jpg\" alt=\"\"></p>\n<p>In our case the docker registry is running at 138.201.98.3.</p>\n<p>#####Step-5 Pull a docker images</p>\n<ul>\n<li><p>Goto your workstation, Open the /etc/default/docker file</p>\n</li>\n<li><p>Edit or add the DOCKER_OPTS line and add the <code>--insecure-registry flag</code>.</p>\n<pre><code>DOCKER_OPTS=&quot;--insecure-registry &lt;vm-ipaddress&gt;:5000&quot;\n</code></pre></li>\n<li><p>Close and save the configuration file.</p>\n</li>\n<li><p>Restart your Docker daemon</p>\n<pre><code>service docker stop\nservice docker start\n</code></pre></li>\n<li><p>To run the pull command, make sure docker is running </p>\n<pre><code>docker pull 138.201.98.3:5000/hello-world\n</code></pre></li>\n</ul>\n<p><img src=\"/content/images/2016/06/p5.jpg\" alt=\"\"></p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to create vm, utilize our atharva storage. </p>\n<p>This is a good head-start for deploy a private docker-registry in MegamAfrica.</p>\n<p>###Deploy your Private Docker Registry now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"Use Windows client  S3 Browser to connect with MegamAfrica Storage (ceph)","slug":"2016-06-16-atharva-ceph-windows","date_published":"2016-06-15T23:29:56.264Z","date_updated":"2016-06-17T09:14:49.501Z","_content":"\n###Introduction\n\nS3 Browser is a freeware Windows client for Amazon S3. Amazon S3 provides a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web.\n\n\n#### Introducing Atharva Storage - MegamAfrica\n\n**Atharva Storage** - MegamAfrica is a \"Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel.\".\n\nUpon successful signin to https://console.megamafrica.com, look for the icon \n![](/content/images/2016/06/storage-1.jpg)\n at the top right hand corner named `Storage`\n![](/content/images/2016/06/atharva-1.jpg)\n\n\nThis tutorial will guide you in setting up a **S3 Browser windows client on your windows 7+/10 workstation** and connecting it to manage your atharva storage account in MegamAfrica.\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n* You are running Windows 7 or later version. This was tested on Windows 10.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/).\n\n* You have to create an atharva storage account with MegamAfrica. [How to create an atharva account with MegamAfrica](http://devcenter.megam.io/2016/06/17/getting-started-atharva-storage-in-megamafrica/).\n\n\n### Connecting  S3 Browser  with Atharva (Ceph object storage) MegamAfrica\n\nThis initial section contains everything you need to setup S3 Browser windows native client on your server.\n\n##### Step-1 Download S3 Browser for windows\n\n* Go to this link. <a href=\"http://s3browser.com/\" target=\"_blank\">S3 browser</a>. \n\n* Click `Download S3 Browser` in <a href=\"http://s3browser.com/\" target=\"_blank\">www.s3browser.com</a> to start your download.\n\n* Right-click the download file and install it in your windows system.\n\n###### Step-2 Create the storage setting with MegamAfrica\n\n* Open the S3 Browser. \n\n* Click the `Accounts -> Create New Account` button in S3 browser. it will open the pop-up window.\n\n* Choose `S3 Compatible Storage` as a storage type and specify REST endpoint as `88.198.139.81`.\n\n* Enter the other details.\n\t\n    \tAccount Name : Type a name for the account\n\t\tAccess key   \n\t\tSecret key   \n \nYou can see your `Access-key` and `Secret-key` from your `profile page` in MegamAfrica(https://console.megamafrica.com)\n\n* Click the Add new account button the account is created and  it display the bucket already created in megamafrica.\n\n##### Step-3 Create new bucket \n\n* Click the `Bucket -> Create New Bucket` button it will open the pop-up window.\n\n* Ask for the bucket name, you can assign your bucket name.\n\n* Click the  `Create new bucket` button the bucket it created.\n\n##### Upload a file from S3 Browser to MegamAfrica\n\n* Click the Upload button.\n\n* Choose the one or multiple files to upload/choose an upload folder if you want to upload a whole folder or whole drive.\n\n![](/content/images/2016/06/upload-folder-button.png)\n\n*  Select the files you want to upload or select the folder to upload. The upload process will begin. You can track the progress on the Tasks tab.\n\n* Let us verify if the files is uploaded\n\nLogon https://console.megamafrica.com goto `storage` place. You can see your bucket, and the uploaded files are displayed.\n\n###Conclusion\n\nThese are the very simple steps to create bucket and upload files using Windows native client using S3 Browser to Atharva - MegamAfrica.\n\nThis is a good head-start for using S3 Browser & our Athava ceph based object storage in MegamAfrica.\n\n###Start uploading to our storage - MegamAfrica\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n","source":"_posts/2016-06-16-atharva-ceph-windows.md","raw":"---\ntitle: Use Windows client  S3 Browser to connect with MegamAfrica Storage (ceph)\nslug: atharva-ceph-windows\ndate_published: 2016-06-16T04:59:56.264Z\ndate_updated:   2016-06-17T14:44:49.501Z\n---\n\n###Introduction\n\nS3 Browser is a freeware Windows client for Amazon S3. Amazon S3 provides a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web.\n\n\n#### Introducing Atharva Storage - MegamAfrica\n\n**Atharva Storage** - MegamAfrica is a \"Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel.\".\n\nUpon successful signin to https://console.megamafrica.com, look for the icon \n![](/content/images/2016/06/storage-1.jpg)\n at the top right hand corner named `Storage`\n![](/content/images/2016/06/atharva-1.jpg)\n\n\nThis tutorial will guide you in setting up a **S3 Browser windows client on your windows 7+/10 workstation** and connecting it to manage your atharva storage account in MegamAfrica.\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n* You are running Windows 7 or later version. This was tested on Windows 10.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/).\n\n* You have to create an atharva storage account with MegamAfrica. [How to create an atharva account with MegamAfrica](http://devcenter.megam.io/2016/06/17/getting-started-atharva-storage-in-megamafrica/).\n\n\n### Connecting  S3 Browser  with Atharva (Ceph object storage) MegamAfrica\n\nThis initial section contains everything you need to setup S3 Browser windows native client on your server.\n\n##### Step-1 Download S3 Browser for windows\n\n* Go to this link. <a href=\"http://s3browser.com/\" target=\"_blank\">S3 browser</a>. \n\n* Click `Download S3 Browser` in <a href=\"http://s3browser.com/\" target=\"_blank\">www.s3browser.com</a> to start your download.\n\n* Right-click the download file and install it in your windows system.\n\n###### Step-2 Create the storage setting with MegamAfrica\n\n* Open the S3 Browser. \n\n* Click the `Accounts -> Create New Account` button in S3 browser. it will open the pop-up window.\n\n* Choose `S3 Compatible Storage` as a storage type and specify REST endpoint as `88.198.139.81`.\n\n* Enter the other details.\n\t\n    \tAccount Name : Type a name for the account\n\t\tAccess key   \n\t\tSecret key   \n \nYou can see your `Access-key` and `Secret-key` from your `profile page` in MegamAfrica(https://console.megamafrica.com)\n\n* Click the Add new account button the account is created and  it display the bucket already created in megamafrica.\n\n##### Step-3 Create new bucket \n\n* Click the `Bucket -> Create New Bucket` button it will open the pop-up window.\n\n* Ask for the bucket name, you can assign your bucket name.\n\n* Click the  `Create new bucket` button the bucket it created.\n\n##### Upload a file from S3 Browser to MegamAfrica\n\n* Click the Upload button.\n\n* Choose the one or multiple files to upload/choose an upload folder if you want to upload a whole folder or whole drive.\n\n![](/content/images/2016/06/upload-folder-button.png)\n\n*  Select the files you want to upload or select the folder to upload. The upload process will begin. You can track the progress on the Tasks tab.\n\n* Let us verify if the files is uploaded\n\nLogon https://console.megamafrica.com goto `storage` place. You can see your bucket, and the uploaded files are displayed.\n\n###Conclusion\n\nThese are the very simple steps to create bucket and upload files using Windows native client using S3 Browser to Atharva - MegamAfrica.\n\nThis is a good head-start for using S3 Browser & our Athava ceph based object storage in MegamAfrica.\n\n###Start uploading to our storage - MegamAfrica\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaitv001vdrgbhszwhrpx","content":"<p>###Introduction</p>\n<p>S3 Browser is a freeware Windows client for Amazon S3. Amazon S3 provides a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web.</p>\n<h4 id=\"Introducing-Atharva-Storage-MegamAfrica\"><a href=\"#Introducing-Atharva-Storage-MegamAfrica\" class=\"headerlink\" title=\"Introducing Atharva Storage - MegamAfrica\"></a>Introducing Atharva Storage - MegamAfrica</h4><p><strong>Atharva Storage</strong> - MegamAfrica is a Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel..</p>\n<p>Upon successful signin to <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>, look for the icon<br><img src=\"/content/images/2016/06/storage-1.jpg\" alt=\"\"><br> at the top right hand corner named <code>Storage</code><br><img src=\"/content/images/2016/06/atharva-1.jpg\" alt=\"\"></p>\n<p>This tutorial will guide you in setting up a <strong>S3 Browser windows client on your windows 7+/10 workstation</strong> and connecting it to manage your atharva storage account in MegamAfrica.<br><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Windows 7 or later version. This was tested on Windows 10.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a>.</p>\n</li>\n<li><p>You have to create an atharva storage account with MegamAfrica. <a href=\"http://devcenter.megam.io/2016/06/17/getting-started-atharva-storage-in-megamafrica/\" target=\"_blank\" rel=\"external\">How to create an atharva account with MegamAfrica</a>.</p>\n</li>\n</ul>\n<h3 id=\"Connecting-S3-Browser-with-Atharva-Ceph-object-storage-MegamAfrica\"><a href=\"#Connecting-S3-Browser-with-Atharva-Ceph-object-storage-MegamAfrica\" class=\"headerlink\" title=\"Connecting  S3 Browser  with Atharva (Ceph object storage) MegamAfrica\"></a>Connecting  S3 Browser  with Atharva (Ceph object storage) MegamAfrica</h3><p>This initial section contains everything you need to setup S3 Browser windows native client on your server.</p>\n<h5 id=\"Step-1-Download-S3-Browser-for-windows\"><a href=\"#Step-1-Download-S3-Browser-for-windows\" class=\"headerlink\" title=\"Step-1 Download S3 Browser for windows\"></a>Step-1 Download S3 Browser for windows</h5><ul>\n<li><p>Go to this link. <a href=\"http://s3browser.com/\" target=\"_blank\">S3 browser</a>. </p>\n</li>\n<li><p>Click <code>Download S3 Browser</code> in <a href=\"http://s3browser.com/\" target=\"_blank\">www.s3browser.com</a> to start your download.</p>\n</li>\n<li><p>Right-click the download file and install it in your windows system.</p>\n</li>\n</ul>\n<h6 id=\"Step-2-Create-the-storage-setting-with-MegamAfrica\"><a href=\"#Step-2-Create-the-storage-setting-with-MegamAfrica\" class=\"headerlink\" title=\"Step-2 Create the storage setting with MegamAfrica\"></a>Step-2 Create the storage setting with MegamAfrica</h6><ul>\n<li><p>Open the S3 Browser. </p>\n</li>\n<li><p>Click the <code>Accounts -&gt; Create New Account</code> button in S3 browser. it will open the pop-up window.</p>\n</li>\n<li><p>Choose <code>S3 Compatible Storage</code> as a storage type and specify REST endpoint as <code>88.198.139.81</code>.</p>\n</li>\n<li><p>Enter the other details.</p>\n<pre><code>Account Name : Type a name for the account\nAccess key   \nSecret key   \n</code></pre></li>\n</ul>\n<p>You can see your <code>Access-key</code> and <code>Secret-key</code> from your <code>profile page</code> in MegamAfrica(<a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>)</p>\n<ul>\n<li>Click the Add new account button the account is created and  it display the bucket already created in megamafrica.</li>\n</ul>\n<h5 id=\"Step-3-Create-new-bucket\"><a href=\"#Step-3-Create-new-bucket\" class=\"headerlink\" title=\"Step-3 Create new bucket\"></a>Step-3 Create new bucket</h5><ul>\n<li><p>Click the <code>Bucket -&gt; Create New Bucket</code> button it will open the pop-up window.</p>\n</li>\n<li><p>Ask for the bucket name, you can assign your bucket name.</p>\n</li>\n<li><p>Click the  <code>Create new bucket</code> button the bucket it created.</p>\n</li>\n</ul>\n<h5 id=\"Upload-a-file-from-S3-Browser-to-MegamAfrica\"><a href=\"#Upload-a-file-from-S3-Browser-to-MegamAfrica\" class=\"headerlink\" title=\"Upload a file from S3 Browser to MegamAfrica\"></a>Upload a file from S3 Browser to MegamAfrica</h5><ul>\n<li><p>Click the Upload button.</p>\n</li>\n<li><p>Choose the one or multiple files to upload/choose an upload folder if you want to upload a whole folder or whole drive.</p>\n</li>\n</ul>\n<p><img src=\"/content/images/2016/06/upload-folder-button.png\" alt=\"\"></p>\n<ul>\n<li><p>Select the files you want to upload or select the folder to upload. The upload process will begin. You can track the progress on the Tasks tab.</p>\n</li>\n<li><p>Let us verify if the files is uploaded</p>\n</li>\n</ul>\n<p>Logon <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a> goto <code>storage</code> place. You can see your bucket, and the uploaded files are displayed.</p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to create bucket and upload files using Windows native client using S3 Browser to Atharva - MegamAfrica.</p>\n<p>This is a good head-start for using S3 Browser &amp; our Athava ceph based object storage in MegamAfrica.</p>\n<p>###Start uploading to our storage - MegamAfrica</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###Introduction</p>\n<p>S3 Browser is a freeware Windows client for Amazon S3. Amazon S3 provides a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web.</p>\n<h4 id=\"Introducing-Atharva-Storage-MegamAfrica\"><a href=\"#Introducing-Atharva-Storage-MegamAfrica\" class=\"headerlink\" title=\"Introducing Atharva Storage - MegamAfrica\"></a>Introducing Atharva Storage - MegamAfrica</h4><p><strong>Atharva Storage</strong> - MegamAfrica is a Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel..</p>\n<p>Upon successful signin to <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>, look for the icon<br><img src=\"/content/images/2016/06/storage-1.jpg\" alt=\"\"><br> at the top right hand corner named <code>Storage</code><br><img src=\"/content/images/2016/06/atharva-1.jpg\" alt=\"\"></p>\n<p>This tutorial will guide you in setting up a <strong>S3 Browser windows client on your windows 7+/10 workstation</strong> and connecting it to manage your atharva storage account in MegamAfrica.<br><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Windows 7 or later version. This was tested on Windows 10.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a>.</p>\n</li>\n<li><p>You have to create an atharva storage account with MegamAfrica. <a href=\"http://devcenter.megam.io/2016/06/17/getting-started-atharva-storage-in-megamafrica/\">How to create an atharva account with MegamAfrica</a>.</p>\n</li>\n</ul>\n<h3 id=\"Connecting-S3-Browser-with-Atharva-Ceph-object-storage-MegamAfrica\"><a href=\"#Connecting-S3-Browser-with-Atharva-Ceph-object-storage-MegamAfrica\" class=\"headerlink\" title=\"Connecting  S3 Browser  with Atharva (Ceph object storage) MegamAfrica\"></a>Connecting  S3 Browser  with Atharva (Ceph object storage) MegamAfrica</h3><p>This initial section contains everything you need to setup S3 Browser windows native client on your server.</p>\n<h5 id=\"Step-1-Download-S3-Browser-for-windows\"><a href=\"#Step-1-Download-S3-Browser-for-windows\" class=\"headerlink\" title=\"Step-1 Download S3 Browser for windows\"></a>Step-1 Download S3 Browser for windows</h5><ul>\n<li><p>Go to this link. <a href=\"http://s3browser.com/\" target=\"_blank\">S3 browser</a>. </p>\n</li>\n<li><p>Click <code>Download S3 Browser</code> in <a href=\"http://s3browser.com/\" target=\"_blank\">www.s3browser.com</a> to start your download.</p>\n</li>\n<li><p>Right-click the download file and install it in your windows system.</p>\n</li>\n</ul>\n<h6 id=\"Step-2-Create-the-storage-setting-with-MegamAfrica\"><a href=\"#Step-2-Create-the-storage-setting-with-MegamAfrica\" class=\"headerlink\" title=\"Step-2 Create the storage setting with MegamAfrica\"></a>Step-2 Create the storage setting with MegamAfrica</h6><ul>\n<li><p>Open the S3 Browser. </p>\n</li>\n<li><p>Click the <code>Accounts -&gt; Create New Account</code> button in S3 browser. it will open the pop-up window.</p>\n</li>\n<li><p>Choose <code>S3 Compatible Storage</code> as a storage type and specify REST endpoint as <code>88.198.139.81</code>.</p>\n</li>\n<li><p>Enter the other details.</p>\n<pre><code>Account Name : Type a name for the account\nAccess key   \nSecret key   \n</code></pre></li>\n</ul>\n<p>You can see your <code>Access-key</code> and <code>Secret-key</code> from your <code>profile page</code> in MegamAfrica(<a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>)</p>\n<ul>\n<li>Click the Add new account button the account is created and  it display the bucket already created in megamafrica.</li>\n</ul>\n<h5 id=\"Step-3-Create-new-bucket\"><a href=\"#Step-3-Create-new-bucket\" class=\"headerlink\" title=\"Step-3 Create new bucket\"></a>Step-3 Create new bucket</h5><ul>\n<li><p>Click the <code>Bucket -&gt; Create New Bucket</code> button it will open the pop-up window.</p>\n</li>\n<li><p>Ask for the bucket name, you can assign your bucket name.</p>\n</li>\n<li><p>Click the  <code>Create new bucket</code> button the bucket it created.</p>\n</li>\n</ul>\n<h5 id=\"Upload-a-file-from-S3-Browser-to-MegamAfrica\"><a href=\"#Upload-a-file-from-S3-Browser-to-MegamAfrica\" class=\"headerlink\" title=\"Upload a file from S3 Browser to MegamAfrica\"></a>Upload a file from S3 Browser to MegamAfrica</h5><ul>\n<li><p>Click the Upload button.</p>\n</li>\n<li><p>Choose the one or multiple files to upload/choose an upload folder if you want to upload a whole folder or whole drive.</p>\n</li>\n</ul>\n<p><img src=\"/content/images/2016/06/upload-folder-button.png\" alt=\"\"></p>\n<ul>\n<li><p>Select the files you want to upload or select the folder to upload. The upload process will begin. You can track the progress on the Tasks tab.</p>\n</li>\n<li><p>Let us verify if the files is uploaded</p>\n</li>\n</ul>\n<p>Logon <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a> goto <code>storage</code> place. You can see your bucket, and the uploaded files are displayed.</p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to create bucket and upload files using Windows native client using S3 Browser to Atharva - MegamAfrica.</p>\n<p>This is a good head-start for using S3 Browser &amp; our Athava ceph based object storage in MegamAfrica.</p>\n<p>###Start uploading to our storage - MegamAfrica</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"Getting started Atharva storage in MegamAfrica","slug":"2016-06-17-getting-started-atharva-storage-in-megamafrica","date_published":"2016-06-17T09:12:05.788Z","date_updated":"2016-06-17T09:13:54.393Z","_content":"\n###Introduction\n**Atharva Storage** - MegamAfrica is a \"Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel.\".\n\nThis tutorial will guide you creating atharva storage  in MegamAfrica.\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/).\n\n###Create Atharva storage in MegamAfrica\n\n* First, ensure the user can login to https://console.megamafrica.com.\n\n* Upon successful signin, look for the icon \n![](/content/images/2016/06/storage-1.jpg)\n at the top right hand corner named `Storage`\n![](/content/images/2016/06/atharva-1.jpg)\n\n* Click the `create storage` box. A window will pop up and ask for Bucket Name. You can type a name for the bucket.\n\n* Bucket is successfully created and also its created the `access-key` and `secret-key` for your account.\n\n* You can see your Access-key and Secret-key from your profile page in MegamAfrica (https://console.megamafrica.com).\n![](/content/images/2016/06/storage-keys.jpg)\n\n* Now, You can upload a files in `Atharva Storage` using your Access-key and Secret-key.\n\n* Upload a files using windows and ubuntu using following guide.\n\n[How to upload a files from windows to MegamAfrica](http://devcenter.megam.io/2016/06/16/atharva-ceph-windows/).\n\n[How to deploy private docker registry in MegamAfrica](http://devcenter.megam.io/2016/06/10/private-registry-along-with-ceph/).\n\n* Let us verify if the files is uploaded\n\nLogon https://console.megamafrica.com goto `storage` place. You can see your bucket, and the uploaded files are displayed.\n\n###Conclusion\n\nThese are the very simple steps to create an atharva storage in MegamAfrica. MegamAfrica website contain lot of feature - very easy to launch Virtual Machines, Apps, Services,and providing atharva storage in MegamAfrica.\n\n######Deploy a Atharva storage now\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n","source":"_posts/2016-06-17-getting-started-atharva-storage-in-megamafrica.md","raw":"---\ntitle: Getting started Atharva storage in MegamAfrica\nslug: getting-started-atharva-storage-in-megamafrica\ndate_published: 2016-06-17T14:42:05.788Z\ndate_updated:   2016-06-17T14:43:54.393Z\n---\n\n###Introduction\n**Atharva Storage** - MegamAfrica is a \"Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel.\".\n\nThis tutorial will guide you creating atharva storage  in MegamAfrica.\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/).\n\n###Create Atharva storage in MegamAfrica\n\n* First, ensure the user can login to https://console.megamafrica.com.\n\n* Upon successful signin, look for the icon \n![](/content/images/2016/06/storage-1.jpg)\n at the top right hand corner named `Storage`\n![](/content/images/2016/06/atharva-1.jpg)\n\n* Click the `create storage` box. A window will pop up and ask for Bucket Name. You can type a name for the bucket.\n\n* Bucket is successfully created and also its created the `access-key` and `secret-key` for your account.\n\n* You can see your Access-key and Secret-key from your profile page in MegamAfrica (https://console.megamafrica.com).\n![](/content/images/2016/06/storage-keys.jpg)\n\n* Now, You can upload a files in `Atharva Storage` using your Access-key and Secret-key.\n\n* Upload a files using windows and ubuntu using following guide.\n\n[How to upload a files from windows to MegamAfrica](http://devcenter.megam.io/2016/06/16/atharva-ceph-windows/).\n\n[How to deploy private docker registry in MegamAfrica](http://devcenter.megam.io/2016/06/10/private-registry-along-with-ceph/).\n\n* Let us verify if the files is uploaded\n\nLogon https://console.megamafrica.com goto `storage` place. You can see your bucket, and the uploaded files are displayed.\n\n###Conclusion\n\nThese are the very simple steps to create an atharva storage in MegamAfrica. MegamAfrica website contain lot of feature - very easy to launch Virtual Machines, Apps, Services,and providing atharva storage in MegamAfrica.\n\n######Deploy a Atharva storage now\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaitw001wdrgbhdq6g73i","content":"<p>###Introduction<br><strong>Atharva Storage</strong> - MegamAfrica is a Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel..</p>\n<p>This tutorial will guide you creating atharva storage  in MegamAfrica.<br><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a>.</li>\n</ul>\n<p>###Create Atharva storage in MegamAfrica</p>\n<ul>\n<li><p>First, ensure the user can login to <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>.</p>\n</li>\n<li><p>Upon successful signin, look for the icon<br><img src=\"/content/images/2016/06/storage-1.jpg\" alt=\"\"><br>at the top right hand corner named <code>Storage</code><br><img src=\"/content/images/2016/06/atharva-1.jpg\" alt=\"\"></p>\n</li>\n<li><p>Click the <code>create storage</code> box. A window will pop up and ask for Bucket Name. You can type a name for the bucket.</p>\n</li>\n<li><p>Bucket is successfully created and also its created the <code>access-key</code> and <code>secret-key</code> for your account.</p>\n</li>\n<li><p>You can see your Access-key and Secret-key from your profile page in MegamAfrica (<a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>).<br><img src=\"/content/images/2016/06/storage-keys.jpg\" alt=\"\"></p>\n</li>\n<li><p>Now, You can upload a files in <code>Atharva Storage</code> using your Access-key and Secret-key.</p>\n</li>\n<li><p>Upload a files using windows and ubuntu using following guide.</p>\n</li>\n</ul>\n<p><a href=\"http://devcenter.megam.io/2016/06/16/atharva-ceph-windows/\" target=\"_blank\" rel=\"external\">How to upload a files from windows to MegamAfrica</a>.</p>\n<p><a href=\"http://devcenter.megam.io/2016/06/10/private-registry-along-with-ceph/\" target=\"_blank\" rel=\"external\">How to deploy private docker registry in MegamAfrica</a>.</p>\n<ul>\n<li>Let us verify if the files is uploaded</li>\n</ul>\n<p>Logon <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a> goto <code>storage</code> place. You can see your bucket, and the uploaded files are displayed.</p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to create an atharva storage in MegamAfrica. MegamAfrica website contain lot of feature - very easy to launch Virtual Machines, Apps, Services,and providing atharva storage in MegamAfrica.</p>\n<p>######Deploy a Atharva storage now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###Introduction<br><strong>Atharva Storage</strong> - MegamAfrica is a Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel..</p>\n<p>This tutorial will guide you creating atharva storage  in MegamAfrica.<br><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a>.</li>\n</ul>\n<p>###Create Atharva storage in MegamAfrica</p>\n<ul>\n<li><p>First, ensure the user can login to <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>.</p>\n</li>\n<li><p>Upon successful signin, look for the icon<br><img src=\"/content/images/2016/06/storage-1.jpg\" alt=\"\"><br>at the top right hand corner named <code>Storage</code><br><img src=\"/content/images/2016/06/atharva-1.jpg\" alt=\"\"></p>\n</li>\n<li><p>Click the <code>create storage</code> box. A window will pop up and ask for Bucket Name. You can type a name for the bucket.</p>\n</li>\n<li><p>Bucket is successfully created and also its created the <code>access-key</code> and <code>secret-key</code> for your account.</p>\n</li>\n<li><p>You can see your Access-key and Secret-key from your profile page in MegamAfrica (<a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>).<br><img src=\"/content/images/2016/06/storage-keys.jpg\" alt=\"\"></p>\n</li>\n<li><p>Now, You can upload a files in <code>Atharva Storage</code> using your Access-key and Secret-key.</p>\n</li>\n<li><p>Upload a files using windows and ubuntu using following guide.</p>\n</li>\n</ul>\n<p><a href=\"http://devcenter.megam.io/2016/06/16/atharva-ceph-windows/\">How to upload a files from windows to MegamAfrica</a>.</p>\n<p><a href=\"http://devcenter.megam.io/2016/06/10/private-registry-along-with-ceph/\">How to deploy private docker registry in MegamAfrica</a>.</p>\n<ul>\n<li>Let us verify if the files is uploaded</li>\n</ul>\n<p>Logon <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a> goto <code>storage</code> place. You can see your bucket, and the uploaded files are displayed.</p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to create an atharva storage in MegamAfrica. MegamAfrica website contain lot of feature - very easy to launch Virtual Machines, Apps, Services,and providing atharva storage in MegamAfrica.</p>\n<p>######Deploy a Atharva storage now</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"Backup your data in a Cloud Storage - MegamAfrica","slug":"2016-06-27-cloud-backup-megamafrica","date_published":"2016-06-27T05:35:38.803Z","date_updated":"2016-06-27T07:42:02.994Z","_content":"\n###Introduction\nYou want to backup your data in cloud and access it on need. \nCloudberry backup desktop client can be used to backups files and folders on your Windows machine to our cloud storage - Atharva MegamAfrica.\n\n#### Introducing Atharva Storage - MegamAfrica\n\n**Atharva Storage** - MegamAfrica is a \"Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel.\".\n\nUpon successful signin to https://console.megamafrica.com, look for the icon \n![](/content/images/2016/06/storage-1.jpg)\n at the top right hand corner named `Storage`\n![](/content/images/2016/06/atharva-1.jpg)\n\nThis tutorial will guide you in setting up a **Cloudberry backup tool for windows client on your windows 7+/10 workstation** and connecting it to manage your atharva storage account in MegamAfrica.\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n* You are running Windows 7 or later version. This was tested on Windows 10.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/).\n\n* You have to create an atharva storage account with MegamAfrica. [How to create an atharva account with MegamAfrica](http://devcenter.megam.io/2016/06/17/getting-started-atharva-storage-in-megamafrica/).\n\n### Connecting Cloudberry Backup Desktop client with Atharva (Ceph object storage) MegamAfrica\n\nThis initial section contains everything you need to setup cloudberry backup tool for windows native client on your server.\n\n##### Step-1 Download Cloudberry Backup Desktop client for windows\n\n* Go to this link. <a href=\"http://www.cloudberrylab.com/download-thanks.aspx?prod=cbbackup\" target=\"_blank\">Cloudberry backup</a>. \n\n* Click `Download` button to start your download.\n\n* Right-click the download file and install it in your windows system.\n\n###### Step-2 Create the storage setting with MegamAfrica\n\n* Once you successfully install CloudBerry, start up the application to display the`Welcome` screen.\n\n* click the`Setup Backup Plan` button in the middle of the page\n\n* CloudBerry has many options for backup targets. In this tutorial were focusing on `Amazons s3 compatible` cloud storage offerings. \n\n* On the `S3 Compatible Storage` tab specify Servie point as `88.198.139.81`.\n\n* Enter the other details.\n\t\n    \tDisplay Name : Type a name for the account\n\t\tAccess key   \n\t\tSecret key   \n* You can see your `Access-key` and `Secret-key` from your `profile page` in MegamAfrica. (https://console.megamafrica.com)\n![](/content/images/2016/06/cloudberry-aws-s3-account-info.png)\n\n* Click the \"Advance Settings\" and uncheck `Use SSL` link. Now you can see your bucket in `Bucket name` box. choose one of the bucket  you want to backup.\n\n* Next youll want to select your `backup mode` as Simple. \n\n* On the next page youll want to select your `Backup Source`. Select your folder to connect with MegamAfrica storage \n![](/content/images/2016/06/cloudberry-backup-wizard-backup-source.png)\n\n* Once you see that your `Backup Plan` is successfully created, press \"Finish\" leaving the \"Run backup now\" box checked, to test your newly configured backup.\n\n* From the Welcome screen youll be able to see that your backup is currently running, and some live summary information about the backup job.\n\n##### Upload a file from cloudberry backup tool to MegamAfrica\n\n* Copy the one or multiple files to upload/copy an upload folder if you want to upload a whole folder.\n\n* Paste into `Backup source` folder. The upload process will begin. \n\n* Let us verify if the files is uploaded\n\nLogon https://console.megamafrica.com goto `storage` place. You can see your bucket, and the uploaded files are displayed.\n\n###Conclusion\n\nThese are the very simple steps to create a sync tool for an upload files using Windows native client using cloudberry backup to Atharva - MegamAfrica.\n\nThis is a good head-start for using Cloudberry  & our Athava ceph based object storage in MegamAfrica.\n\n###Start uploading to our storage - MegamAfrica\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n\n\n\n\n","source":"_posts/2016-06-27-cloud-backup-megamafrica.md","raw":"---\ntitle: Backup your data in a Cloud Storage - MegamAfrica\nslug: cloud-backup-megamafrica\ndate_published: 2016-06-27T11:05:38.803Z\ndate_updated:   2016-06-27T13:12:02.994Z\n---\n\n###Introduction\nYou want to backup your data in cloud and access it on need. \nCloudberry backup desktop client can be used to backups files and folders on your Windows machine to our cloud storage - Atharva MegamAfrica.\n\n#### Introducing Atharva Storage - MegamAfrica\n\n**Atharva Storage** - MegamAfrica is a \"Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel.\".\n\nUpon successful signin to https://console.megamafrica.com, look for the icon \n![](/content/images/2016/06/storage-1.jpg)\n at the top right hand corner named `Storage`\n![](/content/images/2016/06/atharva-1.jpg)\n\nThis tutorial will guide you in setting up a **Cloudberry backup tool for windows client on your windows 7+/10 workstation** and connecting it to manage your atharva storage account in MegamAfrica.\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n###Prerequisites\n\n* You are running Windows 7 or later version. This was tested on Windows 10.\n\n* You have to create a valid credential for accessing https://console.megamafrica.com. [How to create an account with MegamAfrica](http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/).\n\n* You have to create an atharva storage account with MegamAfrica. [How to create an atharva account with MegamAfrica](http://devcenter.megam.io/2016/06/17/getting-started-atharva-storage-in-megamafrica/).\n\n### Connecting Cloudberry Backup Desktop client with Atharva (Ceph object storage) MegamAfrica\n\nThis initial section contains everything you need to setup cloudberry backup tool for windows native client on your server.\n\n##### Step-1 Download Cloudberry Backup Desktop client for windows\n\n* Go to this link. <a href=\"http://www.cloudberrylab.com/download-thanks.aspx?prod=cbbackup\" target=\"_blank\">Cloudberry backup</a>. \n\n* Click `Download` button to start your download.\n\n* Right-click the download file and install it in your windows system.\n\n###### Step-2 Create the storage setting with MegamAfrica\n\n* Once you successfully install CloudBerry, start up the application to display the`Welcome` screen.\n\n* click the`Setup Backup Plan` button in the middle of the page\n\n* CloudBerry has many options for backup targets. In this tutorial were focusing on `Amazons s3 compatible` cloud storage offerings. \n\n* On the `S3 Compatible Storage` tab specify Servie point as `88.198.139.81`.\n\n* Enter the other details.\n\t\n    \tDisplay Name : Type a name for the account\n\t\tAccess key   \n\t\tSecret key   \n* You can see your `Access-key` and `Secret-key` from your `profile page` in MegamAfrica. (https://console.megamafrica.com)\n![](/content/images/2016/06/cloudberry-aws-s3-account-info.png)\n\n* Click the \"Advance Settings\" and uncheck `Use SSL` link. Now you can see your bucket in `Bucket name` box. choose one of the bucket  you want to backup.\n\n* Next youll want to select your `backup mode` as Simple. \n\n* On the next page youll want to select your `Backup Source`. Select your folder to connect with MegamAfrica storage \n![](/content/images/2016/06/cloudberry-backup-wizard-backup-source.png)\n\n* Once you see that your `Backup Plan` is successfully created, press \"Finish\" leaving the \"Run backup now\" box checked, to test your newly configured backup.\n\n* From the Welcome screen youll be able to see that your backup is currently running, and some live summary information about the backup job.\n\n##### Upload a file from cloudberry backup tool to MegamAfrica\n\n* Copy the one or multiple files to upload/copy an upload folder if you want to upload a whole folder.\n\n* Paste into `Backup source` folder. The upload process will begin. \n\n* Let us verify if the files is uploaded\n\nLogon https://console.megamafrica.com goto `storage` place. You can see your bucket, and the uploaded files are displayed.\n\n###Conclusion\n\nThese are the very simple steps to create a sync tool for an upload files using Windows native client using cloudberry backup to Atharva - MegamAfrica.\n\nThis is a good head-start for using Cloudberry  & our Athava ceph based object storage in MegamAfrica.\n\n###Start uploading to our storage - MegamAfrica\n\n<a href=\"https://console.megamafrica.com\" target=\"_blank\">\n<img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a>\n\n\n\n\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaitx001xdrgbgvmweh17","content":"<p>###Introduction<br>You want to backup your data in cloud and access it on need.<br>Cloudberry backup desktop client can be used to backups files and folders on your Windows machine to our cloud storage - Atharva MegamAfrica.</p>\n<h4 id=\"Introducing-Atharva-Storage-MegamAfrica\"><a href=\"#Introducing-Atharva-Storage-MegamAfrica\" class=\"headerlink\" title=\"Introducing Atharva Storage - MegamAfrica\"></a>Introducing Atharva Storage - MegamAfrica</h4><p><strong>Atharva Storage</strong> - MegamAfrica is a Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel..</p>\n<p>Upon successful signin to <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>, look for the icon<br><img src=\"/content/images/2016/06/storage-1.jpg\" alt=\"\"><br> at the top right hand corner named <code>Storage</code><br><img src=\"/content/images/2016/06/atharva-1.jpg\" alt=\"\"></p>\n<p>This tutorial will guide you in setting up a <strong>Cloudberry backup tool for windows client on your windows 7+/10 workstation</strong> and connecting it to manage your atharva storage account in MegamAfrica.<br><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Windows 7 or later version. This was tested on Windows 10.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\" target=\"_blank\" rel=\"external\">How to create an account with MegamAfrica</a>.</p>\n</li>\n<li><p>You have to create an atharva storage account with MegamAfrica. <a href=\"http://devcenter.megam.io/2016/06/17/getting-started-atharva-storage-in-megamafrica/\" target=\"_blank\" rel=\"external\">How to create an atharva account with MegamAfrica</a>.</p>\n</li>\n</ul>\n<h3 id=\"Connecting-Cloudberry-Backup-Desktop-client-with-Atharva-Ceph-object-storage-MegamAfrica\"><a href=\"#Connecting-Cloudberry-Backup-Desktop-client-with-Atharva-Ceph-object-storage-MegamAfrica\" class=\"headerlink\" title=\"Connecting Cloudberry Backup Desktop client with Atharva (Ceph object storage) MegamAfrica\"></a>Connecting Cloudberry Backup Desktop client with Atharva (Ceph object storage) MegamAfrica</h3><p>This initial section contains everything you need to setup cloudberry backup tool for windows native client on your server.</p>\n<h5 id=\"Step-1-Download-Cloudberry-Backup-Desktop-client-for-windows\"><a href=\"#Step-1-Download-Cloudberry-Backup-Desktop-client-for-windows\" class=\"headerlink\" title=\"Step-1 Download Cloudberry Backup Desktop client for windows\"></a>Step-1 Download Cloudberry Backup Desktop client for windows</h5><ul>\n<li><p>Go to this link. <a href=\"http://www.cloudberrylab.com/download-thanks.aspx?prod=cbbackup\" target=\"_blank\">Cloudberry backup</a>. </p>\n</li>\n<li><p>Click <code>Download</code> button to start your download.</p>\n</li>\n<li><p>Right-click the download file and install it in your windows system.</p>\n</li>\n</ul>\n<h6 id=\"Step-2-Create-the-storage-setting-with-MegamAfrica\"><a href=\"#Step-2-Create-the-storage-setting-with-MegamAfrica\" class=\"headerlink\" title=\"Step-2 Create the storage setting with MegamAfrica\"></a>Step-2 Create the storage setting with MegamAfrica</h6><ul>\n<li><p>Once you successfully install CloudBerry, start up the application to display the<code>Welcome</code> screen.</p>\n</li>\n<li><p>click the<code>Setup Backup Plan</code> button in the middle of the page</p>\n</li>\n<li><p>CloudBerry has many options for backup targets. In this tutorial were focusing on <code>Amazons s3 compatible</code> cloud storage offerings. </p>\n</li>\n<li><p>On the <code>S3 Compatible Storage</code> tab specify Servie point as <code>88.198.139.81</code>.</p>\n</li>\n<li><p>Enter the other details.</p>\n<pre><code>Display Name : Type a name for the account\nAccess key   \nSecret key   \n</code></pre></li>\n<li><p>You can see your <code>Access-key</code> and <code>Secret-key</code> from your <code>profile page</code> in MegamAfrica. (<a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a>)<br><img src=\"/content/images/2016/06/cloudberry-aws-s3-account-info.png\" alt=\"\"></p>\n</li>\n<li><p>Click the Advance Settings and uncheck <code>Use SSL</code> link. Now you can see your bucket in <code>Bucket name</code> box. choose one of the bucket  you want to backup.</p>\n</li>\n<li><p>Next youll want to select your <code>backup mode</code> as Simple. </p>\n</li>\n<li><p>On the next page youll want to select your <code>Backup Source</code>. Select your folder to connect with MegamAfrica storage<br><img src=\"/content/images/2016/06/cloudberry-backup-wizard-backup-source.png\" alt=\"\"></p>\n</li>\n<li><p>Once you see that your <code>Backup Plan</code> is successfully created, press Finish leaving the Run backup now box checked, to test your newly configured backup.</p>\n</li>\n<li><p>From the Welcome screen youll be able to see that your backup is currently running, and some live summary information about the backup job.</p>\n</li>\n</ul>\n<h5 id=\"Upload-a-file-from-cloudberry-backup-tool-to-MegamAfrica\"><a href=\"#Upload-a-file-from-cloudberry-backup-tool-to-MegamAfrica\" class=\"headerlink\" title=\"Upload a file from cloudberry backup tool to MegamAfrica\"></a>Upload a file from cloudberry backup tool to MegamAfrica</h5><ul>\n<li><p>Copy the one or multiple files to upload/copy an upload folder if you want to upload a whole folder.</p>\n</li>\n<li><p>Paste into <code>Backup source</code> folder. The upload process will begin. </p>\n</li>\n<li><p>Let us verify if the files is uploaded</p>\n</li>\n</ul>\n<p>Logon <a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\">https://console.megamafrica.com</a> goto <code>storage</code> place. You can see your bucket, and the uploaded files are displayed.</p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to create a sync tool for an upload files using Windows native client using cloudberry backup to Atharva - MegamAfrica.</p>\n<p>This is a good head-start for using Cloudberry  &amp; our Athava ceph based object storage in MegamAfrica.</p>\n<p>###Start uploading to our storage - MegamAfrica</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\"></a></p>\n","excerpt":"","more":"<p>###Introduction<br>You want to backup your data in cloud and access it on need.<br>Cloudberry backup desktop client can be used to backups files and folders on your Windows machine to our cloud storage - Atharva MegamAfrica.</p>\n<h4 id=\"Introducing-Atharva-Storage-MegamAfrica\"><a href=\"#Introducing-Atharva-Storage-MegamAfrica\" class=\"headerlink\" title=\"Introducing Atharva Storage - MegamAfrica\"></a>Introducing Atharva Storage - MegamAfrica</h4><p><strong>Atharva Storage</strong> - MegamAfrica is a Cloud object storage, low latency and (S3 - AWS Signature v2) compatible API  built on top of ceph - jewel..</p>\n<p>Upon successful signin to <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>, look for the icon<br><img src=\"/content/images/2016/06/storage-1.jpg\" alt=\"\"><br> at the top right hand corner named <code>Storage</code><br><img src=\"/content/images/2016/06/atharva-1.jpg\" alt=\"\"></p>\n<p>This tutorial will guide you in setting up a <strong>Cloudberry backup tool for windows client on your windows 7+/10 workstation</strong> and connecting it to manage your atharva storage account in MegamAfrica.<br><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n<p>###Prerequisites</p>\n<ul>\n<li><p>You are running Windows 7 or later version. This was tested on Windows 10.</p>\n</li>\n<li><p>You have to create a valid credential for accessing <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>. <a href=\"http://devcenter.megam.io/2016/05/27/how-to-launch-ubuntu/\">How to create an account with MegamAfrica</a>.</p>\n</li>\n<li><p>You have to create an atharva storage account with MegamAfrica. <a href=\"http://devcenter.megam.io/2016/06/17/getting-started-atharva-storage-in-megamafrica/\">How to create an atharva account with MegamAfrica</a>.</p>\n</li>\n</ul>\n<h3 id=\"Connecting-Cloudberry-Backup-Desktop-client-with-Atharva-Ceph-object-storage-MegamAfrica\"><a href=\"#Connecting-Cloudberry-Backup-Desktop-client-with-Atharva-Ceph-object-storage-MegamAfrica\" class=\"headerlink\" title=\"Connecting Cloudberry Backup Desktop client with Atharva (Ceph object storage) MegamAfrica\"></a>Connecting Cloudberry Backup Desktop client with Atharva (Ceph object storage) MegamAfrica</h3><p>This initial section contains everything you need to setup cloudberry backup tool for windows native client on your server.</p>\n<h5 id=\"Step-1-Download-Cloudberry-Backup-Desktop-client-for-windows\"><a href=\"#Step-1-Download-Cloudberry-Backup-Desktop-client-for-windows\" class=\"headerlink\" title=\"Step-1 Download Cloudberry Backup Desktop client for windows\"></a>Step-1 Download Cloudberry Backup Desktop client for windows</h5><ul>\n<li><p>Go to this link. <a href=\"http://www.cloudberrylab.com/download-thanks.aspx?prod=cbbackup\" target=\"_blank\">Cloudberry backup</a>. </p>\n</li>\n<li><p>Click <code>Download</code> button to start your download.</p>\n</li>\n<li><p>Right-click the download file and install it in your windows system.</p>\n</li>\n</ul>\n<h6 id=\"Step-2-Create-the-storage-setting-with-MegamAfrica\"><a href=\"#Step-2-Create-the-storage-setting-with-MegamAfrica\" class=\"headerlink\" title=\"Step-2 Create the storage setting with MegamAfrica\"></a>Step-2 Create the storage setting with MegamAfrica</h6><ul>\n<li><p>Once you successfully install CloudBerry, start up the application to display the<code>Welcome</code> screen.</p>\n</li>\n<li><p>click the<code>Setup Backup Plan</code> button in the middle of the page</p>\n</li>\n<li><p>CloudBerry has many options for backup targets. In this tutorial were focusing on <code>Amazons s3 compatible</code> cloud storage offerings. </p>\n</li>\n<li><p>On the <code>S3 Compatible Storage</code> tab specify Servie point as <code>88.198.139.81</code>.</p>\n</li>\n<li><p>Enter the other details.</p>\n<pre><code>Display Name : Type a name for the account\nAccess key   \nSecret key   \n</code></pre></li>\n<li><p>You can see your <code>Access-key</code> and <code>Secret-key</code> from your <code>profile page</code> in MegamAfrica. (<a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a>)<br><img src=\"/content/images/2016/06/cloudberry-aws-s3-account-info.png\" alt=\"\"></p>\n</li>\n<li><p>Click the Advance Settings and uncheck <code>Use SSL</code> link. Now you can see your bucket in <code>Bucket name</code> box. choose one of the bucket  you want to backup.</p>\n</li>\n<li><p>Next youll want to select your <code>backup mode</code> as Simple. </p>\n</li>\n<li><p>On the next page youll want to select your <code>Backup Source</code>. Select your folder to connect with MegamAfrica storage<br><img src=\"/content/images/2016/06/cloudberry-backup-wizard-backup-source.png\" alt=\"\"></p>\n</li>\n<li><p>Once you see that your <code>Backup Plan</code> is successfully created, press Finish leaving the Run backup now box checked, to test your newly configured backup.</p>\n</li>\n<li><p>From the Welcome screen youll be able to see that your backup is currently running, and some live summary information about the backup job.</p>\n</li>\n</ul>\n<h5 id=\"Upload-a-file-from-cloudberry-backup-tool-to-MegamAfrica\"><a href=\"#Upload-a-file-from-cloudberry-backup-tool-to-MegamAfrica\" class=\"headerlink\" title=\"Upload a file from cloudberry backup tool to MegamAfrica\"></a>Upload a file from cloudberry backup tool to MegamAfrica</h5><ul>\n<li><p>Copy the one or multiple files to upload/copy an upload folder if you want to upload a whole folder.</p>\n</li>\n<li><p>Paste into <code>Backup source</code> folder. The upload process will begin. </p>\n</li>\n<li><p>Let us verify if the files is uploaded</p>\n</li>\n</ul>\n<p>Logon <a href=\"https://console.megamafrica.com\">https://console.megamafrica.com</a> goto <code>storage</code> place. You can see your bucket, and the uploaded files are displayed.</p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to create a sync tool for an upload files using Windows native client using cloudberry backup to Atharva - MegamAfrica.</p>\n<p>This is a good head-start for using Cloudberry  &amp; our Athava ceph based object storage in MegamAfrica.</p>\n<p>###Start uploading to our storage - MegamAfrica</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\"><br><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"wordpres button\" /></a></p>\n"},{"title":"Hyperizing Docker Containers with rock solid security","slug":"2016-06-30-secure-docker-container-using-kvm","date_published":"2016-06-30T08:41:54.807Z","date_updated":"2016-06-30T23:53:11.387Z","_content":"\n####Introduction\n\n   One of the questions we have been asked is what is the secret sauce in our enterprise edition as all our stuff is opensource. \n   \n Hence this is one of our secret sauce. Yes if you want to run secure docker containers by using a hypervisor like KVM, contact us @info@megam.io. If you are from the hosting industry we will put you in touch with our partner DET.io (jonathan@det.io).\n   \nIn this article we will provide the opensource way of doing stuff on your own. \n\nLets get started too launch the docker container in \nsecure isolated with a very fast launch using hypercontainers.\n\n####Introducing HyperContainer\n   HyperContainer is a Hypervisor-agnostic Docker Runtime that allows you to run Docker images on any hypervisor (KVM, Xen, etc.).\n\n \n     HyperContainer = Hypervisor + Kernel + Docker Image\n     \nBy containing applications within **separate VM instances** and kernel spaces, HyperContainer is able to offer an excellent **Hardware-enforced Isolation**, which is much needed in multi-tenant environments.\n\nHyperContainer also promises  **Immutable** Infrastructure by eliminating the middle layer of Guest OS, along with the hassle to configure and manage them.\n\n####Setup HyperContainer\n \n This initial section contains everything you need to setup the hypercontainer on one of your baremental server. \n \nNow if your have a several servers, you can contact us, the enterprise edition is a lifesaver.\n \n#####Step - 1 Install HyperContainer\n\nThe Prerequisites are,\n\nHypervisor: at least one of\n\n[Linux] **QEMU KVM** 2.0 or later\n[Linux] **Xen** 4.5 or later (for Xen support)\n\nWe will use KVM here. Supose your server doesn't have the any hypervisor you need to install the following\n\n      sudo apt-get install qemu-system\n\nNow the install hypercontainer on your server,\n\n     wget http://hyper-install.s3.amazonaws.com/hyper-latest.tgz \n     tar -xvzf hyper-latest.tgz \n     \n     \n  Then cd into the hyper-pkg directory\n  \n    ./bootstrap.sh \n    ./install.sh\n      \n      \n   Next we start the hyperd service\n   \n    sudo service hyperd start\n      \n#####Step - 2 Pull  Docker Images\n\nTo pull the docker images from docker registry by using these command\n\n    hyper pull tutum/hello-world\n    \nNow the container pulled in sub-millseconds.\n\nTo list the docker images\n   \n  \n    hyper images\n    \n    REPOSITORY            TAG   IMAGE ID     CREATED        VIRTUAL SIZE\n    tutum/hello-world   latest  4b95f40f2f4d   2015-12-14 16:16:44   17.0 MB\n\n#####Step -3 Network  setup\n\nBy default the hypercontainer uses `hyper0` bridge but we wil have to use our own subnet (own bridge)\n\nLets setup a bridge named `one` in your server.\n\n    brctl addbr one\n\n    \nOnce you have created a bridge  you need to change the configuration file under in /etc/hyper/config\n \n    Kernel=/var/lib/hyper/kernel\n    Initrd=/var/lib/hyper/hyper-initrd.img\n    Bios=/var/lib/hyper/bios-qboot.bin\n    Cbfs=/var/lib/hyper/cbfs-qboot.rom\n    Bridge=one\n    BridgeIP=xxx.xxx.x.x/24\n    \n Then restart the hyperd service\n \n    service hyperd restart\n\n#####Step - 4 Run the HyperContainer\n\n    hyper run --name test -d tutum/hello-world \n \n The hypercontainer runs in an isolated space in an independent kernal.\n\nTo list the running hypercontainers\n \n    hyper list\n    POD ID            POD Name           VM name                 Status\n    pod-IlLsHBTYGQ      tutum1       vm-FXBRjvEgJY              running\n\n\n#### Conclusion\n\nThese are the very simple steps to successfully launch a docker container in a secure isolated space.\n\nAgain if you have a lot os server rack, we have the solution. Contact us @info@megam.io\n\n\n\n\n\n","source":"_posts/2016-06-30-secure-docker-container-using-kvm.md","raw":"---\ntitle: Hyperizing Docker Containers with rock solid security\nslug: secure-docker-container-using-kvm\ndate_published: 2016-06-30T14:11:54.807Z\ndate_updated:   2016-07-01T05:23:11.387Z\n---\n\n####Introduction\n\n   One of the questions we have been asked is what is the secret sauce in our enterprise edition as all our stuff is opensource. \n   \n Hence this is one of our secret sauce. Yes if you want to run secure docker containers by using a hypervisor like KVM, contact us @info@megam.io. If you are from the hosting industry we will put you in touch with our partner DET.io (jonathan@det.io).\n   \nIn this article we will provide the opensource way of doing stuff on your own. \n\nLets get started too launch the docker container in \nsecure isolated with a very fast launch using hypercontainers.\n\n####Introducing HyperContainer\n   HyperContainer is a Hypervisor-agnostic Docker Runtime that allows you to run Docker images on any hypervisor (KVM, Xen, etc.).\n\n \n     HyperContainer = Hypervisor + Kernel + Docker Image\n     \nBy containing applications within **separate VM instances** and kernel spaces, HyperContainer is able to offer an excellent **Hardware-enforced Isolation**, which is much needed in multi-tenant environments.\n\nHyperContainer also promises  **Immutable** Infrastructure by eliminating the middle layer of Guest OS, along with the hassle to configure and manage them.\n\n####Setup HyperContainer\n \n This initial section contains everything you need to setup the hypercontainer on one of your baremental server. \n \nNow if your have a several servers, you can contact us, the enterprise edition is a lifesaver.\n \n#####Step - 1 Install HyperContainer\n\nThe Prerequisites are,\n\nHypervisor: at least one of\n\n[Linux] **QEMU KVM** 2.0 or later\n[Linux] **Xen** 4.5 or later (for Xen support)\n\nWe will use KVM here. Supose your server doesn't have the any hypervisor you need to install the following\n\n      sudo apt-get install qemu-system\n\nNow the install hypercontainer on your server,\n\n     wget http://hyper-install.s3.amazonaws.com/hyper-latest.tgz \n     tar -xvzf hyper-latest.tgz \n     \n     \n  Then cd into the hyper-pkg directory\n  \n    ./bootstrap.sh \n    ./install.sh\n      \n      \n   Next we start the hyperd service\n   \n    sudo service hyperd start\n      \n#####Step - 2 Pull  Docker Images\n\nTo pull the docker images from docker registry by using these command\n\n    hyper pull tutum/hello-world\n    \nNow the container pulled in sub-millseconds.\n\nTo list the docker images\n   \n  \n    hyper images\n    \n    REPOSITORY            TAG   IMAGE ID     CREATED        VIRTUAL SIZE\n    tutum/hello-world   latest  4b95f40f2f4d   2015-12-14 16:16:44   17.0 MB\n\n#####Step -3 Network  setup\n\nBy default the hypercontainer uses `hyper0` bridge but we wil have to use our own subnet (own bridge)\n\nLets setup a bridge named `one` in your server.\n\n    brctl addbr one\n\n    \nOnce you have created a bridge  you need to change the configuration file under in /etc/hyper/config\n \n    Kernel=/var/lib/hyper/kernel\n    Initrd=/var/lib/hyper/hyper-initrd.img\n    Bios=/var/lib/hyper/bios-qboot.bin\n    Cbfs=/var/lib/hyper/cbfs-qboot.rom\n    Bridge=one\n    BridgeIP=xxx.xxx.x.x/24\n    \n Then restart the hyperd service\n \n    service hyperd restart\n\n#####Step - 4 Run the HyperContainer\n\n    hyper run --name test -d tutum/hello-world \n \n The hypercontainer runs in an isolated space in an independent kernal.\n\nTo list the running hypercontainers\n \n    hyper list\n    POD ID            POD Name           VM name                 Status\n    pod-IlLsHBTYGQ      tutum1       vm-FXBRjvEgJY              running\n\n\n#### Conclusion\n\nThese are the very simple steps to successfully launch a docker container in a secure isolated space.\n\nAgain if you have a lot os server rack, we have the solution. Contact us @info@megam.io\n\n\n\n\n\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaity001ydrgbc9h6am25","content":"<p>####Introduction</p>\n<p>   One of the questions we have been asked is what is the secret sauce in our enterprise edition as all our stuff is opensource. </p>\n<p> Hence this is one of our secret sauce. Yes if you want to run secure docker containers by using a hypervisor like KVM, contact us @info@megam.io. If you are from the hosting industry we will put you in touch with our partner DET.io (jonathan@det.io).</p>\n<p>In this article we will provide the opensource way of doing stuff on your own. </p>\n<p>Lets get started too launch the docker container in<br>secure isolated with a very fast launch using hypercontainers.</p>\n<p>####Introducing HyperContainer<br>   HyperContainer is a Hypervisor-agnostic Docker Runtime that allows you to run Docker images on any hypervisor (KVM, Xen, etc.).</p>\n<pre><code>HyperContainer = Hypervisor + Kernel + Docker Image\n</code></pre><p>By containing applications within <strong>separate VM instances</strong> and kernel spaces, HyperContainer is able to offer an excellent <strong>Hardware-enforced Isolation</strong>, which is much needed in multi-tenant environments.</p>\n<p>HyperContainer also promises  <strong>Immutable</strong> Infrastructure by eliminating the middle layer of Guest OS, along with the hassle to configure and manage them.</p>\n<p>####Setup HyperContainer</p>\n<p> This initial section contains everything you need to setup the hypercontainer on one of your baremental server. </p>\n<p>Now if your have a several servers, you can contact us, the enterprise edition is a lifesaver.</p>\n<p>#####Step - 1 Install HyperContainer</p>\n<p>The Prerequisites are,</p>\n<p>Hypervisor: at least one of</p>\n<p>[Linux] <strong>QEMU KVM</strong> 2.0 or later<br>[Linux] <strong>Xen</strong> 4.5 or later (for Xen support)</p>\n<p>We will use KVM here. Supose your server doesnt have the any hypervisor you need to install the following</p>\n<pre><code>sudo apt-get install qemu-system\n</code></pre><p>Now the install hypercontainer on your server,</p>\n<pre><code>wget http://hyper-install.s3.amazonaws.com/hyper-latest.tgz \ntar -xvzf hyper-latest.tgz \n</code></pre><p>  Then cd into the hyper-pkg directory</p>\n<pre><code>./bootstrap.sh \n./install.sh\n</code></pre><p>   Next we start the hyperd service</p>\n<pre><code>sudo service hyperd start\n</code></pre><p>#####Step - 2 Pull  Docker Images</p>\n<p>To pull the docker images from docker registry by using these command</p>\n<pre><code>hyper pull tutum/hello-world\n</code></pre><p>Now the container pulled in sub-millseconds.</p>\n<p>To list the docker images</p>\n<pre><code>hyper images\n\nREPOSITORY            TAG   IMAGE ID     CREATED        VIRTUAL SIZE\ntutum/hello-world   latest  4b95f40f2f4d   2015-12-14 16:16:44   17.0 MB\n</code></pre><p>#####Step -3 Network  setup</p>\n<p>By default the hypercontainer uses <code>hyper0</code> bridge but we wil have to use our own subnet (own bridge)</p>\n<p>Lets setup a bridge named <code>one</code> in your server.</p>\n<pre><code>brctl addbr one\n</code></pre><p>Once you have created a bridge  you need to change the configuration file under in /etc/hyper/config</p>\n<pre><code>Kernel=/var/lib/hyper/kernel\nInitrd=/var/lib/hyper/hyper-initrd.img\nBios=/var/lib/hyper/bios-qboot.bin\nCbfs=/var/lib/hyper/cbfs-qboot.rom\nBridge=one\nBridgeIP=xxx.xxx.x.x/24\n</code></pre><p> Then restart the hyperd service</p>\n<pre><code>service hyperd restart\n</code></pre><p>#####Step - 4 Run the HyperContainer</p>\n<pre><code>hyper run --name test -d tutum/hello-world \n</code></pre><p> The hypercontainer runs in an isolated space in an independent kernal.</p>\n<p>To list the running hypercontainers</p>\n<pre><code>hyper list\nPOD ID            POD Name           VM name                 Status\npod-IlLsHBTYGQ      tutum1       vm-FXBRjvEgJY              running\n</code></pre><h4 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h4><p>These are the very simple steps to successfully launch a docker container in a secure isolated space.</p>\n<p>Again if you have a lot os server rack, we have the solution. Contact us @info@megam.io</p>\n","excerpt":"","more":"<p>####Introduction</p>\n<p>   One of the questions we have been asked is what is the secret sauce in our enterprise edition as all our stuff is opensource. </p>\n<p> Hence this is one of our secret sauce. Yes if you want to run secure docker containers by using a hypervisor like KVM, contact us @info@megam.io. If you are from the hosting industry we will put you in touch with our partner DET.io (jonathan@det.io).</p>\n<p>In this article we will provide the opensource way of doing stuff on your own. </p>\n<p>Lets get started too launch the docker container in<br>secure isolated with a very fast launch using hypercontainers.</p>\n<p>####Introducing HyperContainer<br>   HyperContainer is a Hypervisor-agnostic Docker Runtime that allows you to run Docker images on any hypervisor (KVM, Xen, etc.).</p>\n<pre><code>HyperContainer = Hypervisor + Kernel + Docker Image\n</code></pre><p>By containing applications within <strong>separate VM instances</strong> and kernel spaces, HyperContainer is able to offer an excellent <strong>Hardware-enforced Isolation</strong>, which is much needed in multi-tenant environments.</p>\n<p>HyperContainer also promises  <strong>Immutable</strong> Infrastructure by eliminating the middle layer of Guest OS, along with the hassle to configure and manage them.</p>\n<p>####Setup HyperContainer</p>\n<p> This initial section contains everything you need to setup the hypercontainer on one of your baremental server. </p>\n<p>Now if your have a several servers, you can contact us, the enterprise edition is a lifesaver.</p>\n<p>#####Step - 1 Install HyperContainer</p>\n<p>The Prerequisites are,</p>\n<p>Hypervisor: at least one of</p>\n<p>[Linux] <strong>QEMU KVM</strong> 2.0 or later<br>[Linux] <strong>Xen</strong> 4.5 or later (for Xen support)</p>\n<p>We will use KVM here. Supose your server doesnt have the any hypervisor you need to install the following</p>\n<pre><code>sudo apt-get install qemu-system\n</code></pre><p>Now the install hypercontainer on your server,</p>\n<pre><code>wget http://hyper-install.s3.amazonaws.com/hyper-latest.tgz \ntar -xvzf hyper-latest.tgz \n</code></pre><p>  Then cd into the hyper-pkg directory</p>\n<pre><code>./bootstrap.sh \n./install.sh\n</code></pre><p>   Next we start the hyperd service</p>\n<pre><code>sudo service hyperd start\n</code></pre><p>#####Step - 2 Pull  Docker Images</p>\n<p>To pull the docker images from docker registry by using these command</p>\n<pre><code>hyper pull tutum/hello-world\n</code></pre><p>Now the container pulled in sub-millseconds.</p>\n<p>To list the docker images</p>\n<pre><code>hyper images\n\nREPOSITORY            TAG   IMAGE ID     CREATED        VIRTUAL SIZE\ntutum/hello-world   latest  4b95f40f2f4d   2015-12-14 16:16:44   17.0 MB\n</code></pre><p>#####Step -3 Network  setup</p>\n<p>By default the hypercontainer uses <code>hyper0</code> bridge but we wil have to use our own subnet (own bridge)</p>\n<p>Lets setup a bridge named <code>one</code> in your server.</p>\n<pre><code>brctl addbr one\n</code></pre><p>Once you have created a bridge  you need to change the configuration file under in /etc/hyper/config</p>\n<pre><code>Kernel=/var/lib/hyper/kernel\nInitrd=/var/lib/hyper/hyper-initrd.img\nBios=/var/lib/hyper/bios-qboot.bin\nCbfs=/var/lib/hyper/cbfs-qboot.rom\nBridge=one\nBridgeIP=xxx.xxx.x.x/24\n</code></pre><p> Then restart the hyperd service</p>\n<pre><code>service hyperd restart\n</code></pre><p>#####Step - 4 Run the HyperContainer</p>\n<pre><code>hyper run --name test -d tutum/hello-world \n</code></pre><p> The hypercontainer runs in an isolated space in an independent kernal.</p>\n<p>To list the running hypercontainers</p>\n<pre><code>hyper list\nPOD ID            POD Name           VM name                 Status\npod-IlLsHBTYGQ      tutum1       vm-FXBRjvEgJY              running\n</code></pre><h4 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h4><p>These are the very simple steps to successfully launch a docker container in a secure isolated space.</p>\n<p>Again if you have a lot os server rack, we have the solution. Contact us @info@megam.io</p>\n"},{"title":"Cassandra Replication - HA","slug":"2016-07-14-how-to-create-a-cassandra-replication","date_published":"2016-07-14T07:23:53.177Z","date_updated":"2016-07-18T00:29:22.028Z","_content":"\n###Introduction \n\nCassandra stores replicas on multiple nodes to ensure reliability and fault tolerance. A replication strategy determines the nodes where replicas are placed. The total number of replicas across the cluster is referred to as the replication factor. \n\nA replication factor of 1 means that there is only one copy of each row in the cluster. A replication factor of 2 means two copies of each row, where each copy is on a different node. As a general rule, the replication factor should not exceed the number of nodes in the cluster. However, you can increase the replication factor and then add the desired number of nodes.\n\n[![img](https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png)](https://console.megamafrica.com)\n\n###Prerequisites\n\nTo follow this tutorial :\n\n* You need atleast two nodes. \n\n* You need to install cassandra in all the nodes.\n\n### Step 1 - Create a Keyspace in cql\n\n* login into cqlsh\n\n\t\tcqlsh `ipaddress1`\n    \n* Creating a keyspace\n\n\t\tCREATE KEYSPACE IF NOT EXISTS `keyspacename` WITH REPLICATION = { 'class' : 'NetworkTopologyStrategy', 'dc1' : 2 , 'dc2' : 2 };\n\n* Two replication strategies of class are available:\n\n* `SimpleStrategy` Use only for a single data center and one rack. If you ever intend more than one data center, use the NetworkTopologyStrategy.\n\n* `NetworkTopologyStrategy` Highly recommended for most deployments because it is much easier to expand to multiple data centers when required by future expansion.\n\n* Here, we are testing in multiple datacenter so we used NetworkTopologyStrategy class.\n\n\n\n### Step 2 - Configure cassandra.yaml in dc1\n\n* Its assumed that you have installed cassandra in the two nodes (dc1, dc2).\n\n* Once you installed cassandra in your machine, then you need to change the cassandra yaml file in (dc1).\n\n* Open the file `/etc/cassandra/cassandra.yaml` and change the following settings\n\n\t\tlisten_address : `ipaddress`\n        rpc_address    : `ipaddress` \n\t\tendpoint_snitch: GossipingPropertyFileSnitch\n \t\t\n`Note` listen_address and rpc_address default is set localhost you need to change it to the private or public ipaddress (eg: 192.168.1.249).\n\n`endpoint_snitch` by default is set for `SimpleSnitch` which works only for SimpleStrategy so you can changed the snitch to `GossipingPropertyFileSnitch`\n\n* As we have used `GossipingPropertyFileSnitch` we need to change the file `/etc/cassandra/cassandra-rackdc.properties` with the datacenter and rack information.\n\t\t\n* `cassandra-rackdc.properties` it used to tell we are using GossipingPropertyFileSnitch as endpoint. \n\n* Define the Data Center and Rack that this node run on. The default settings:\n\t\t\n        dc=DC1\n\t\track=RAC1\n* Here, we are using two machines so change the file based on our setup.\n\t\t\n        dc=DC1\n\t\track=RAC1\n\t\tdc=DC2\n\t\track=RAC1\n\n* Add the above datacenter and rack in the `/etc/cassandra/cassandra-topology.properties`\n\n* It look like this\n\n\t\tData Center One\n\t\t175.56.12.105=DC1:RAC1\n\t\t175.50.13.200=DC1:RAC1\n\t\t175.54.35.197=DC1:RAC1\n\n\t\t120.53.24.101=DC1:RAC2\n\t\t120.55.16.200=DC1:RAC2\n\t\t120.57.102.103=DC1:RAC2\n\n* Change the datacenter and rack into your ipaddress in that file.\n\n\t\tipaddress1=DC1:RAC1\n\t\tipaddress2=DC2:RAC1\n        \n* Use this command to check the data center name, and rack is set into your machine.\n\t\n\t\tnodetool status.\n![](/content/images/2016/07/cassandra.png)\n* Its show the status of the node. \n\t\t\n        `UN` - define your node in up status.\n        `DN` - define your node in down status.\n \n\n### Step 3- Configure cassandra.yaml in dc2\n\n* Its assumed that you have installed cassandra in the two nodes (dc1, dc2).\n\n* Once you installed cassandra in your machine, then you need to change the cassandra yaml file in (dc2 as well).\n\nRepeat the process in as many racks/datacenters.\n\n###Conclusion\n\nThese are the very simple steps to setup cassandra replications in several nodes.\n\n###To Deploy your app\n\n[![img](https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png)](https://console.megamafrica.com)\n","source":"_posts/2016-07-14-how-to-create-a-cassandra-replication.md","raw":"---\ntitle: Cassandra Replication - HA\nslug: how-to-create-a-cassandra-replication\ndate_published: 2016-07-14T12:53:53.177Z\ndate_updated:   2016-07-18T05:59:22.028Z\n---\n\n###Introduction \n\nCassandra stores replicas on multiple nodes to ensure reliability and fault tolerance. A replication strategy determines the nodes where replicas are placed. The total number of replicas across the cluster is referred to as the replication factor. \n\nA replication factor of 1 means that there is only one copy of each row in the cluster. A replication factor of 2 means two copies of each row, where each copy is on a different node. As a general rule, the replication factor should not exceed the number of nodes in the cluster. However, you can increase the replication factor and then add the desired number of nodes.\n\n[![img](https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png)](https://console.megamafrica.com)\n\n###Prerequisites\n\nTo follow this tutorial :\n\n* You need atleast two nodes. \n\n* You need to install cassandra in all the nodes.\n\n### Step 1 - Create a Keyspace in cql\n\n* login into cqlsh\n\n\t\tcqlsh `ipaddress1`\n    \n* Creating a keyspace\n\n\t\tCREATE KEYSPACE IF NOT EXISTS `keyspacename` WITH REPLICATION = { 'class' : 'NetworkTopologyStrategy', 'dc1' : 2 , 'dc2' : 2 };\n\n* Two replication strategies of class are available:\n\n* `SimpleStrategy` Use only for a single data center and one rack. If you ever intend more than one data center, use the NetworkTopologyStrategy.\n\n* `NetworkTopologyStrategy` Highly recommended for most deployments because it is much easier to expand to multiple data centers when required by future expansion.\n\n* Here, we are testing in multiple datacenter so we used NetworkTopologyStrategy class.\n\n\n\n### Step 2 - Configure cassandra.yaml in dc1\n\n* Its assumed that you have installed cassandra in the two nodes (dc1, dc2).\n\n* Once you installed cassandra in your machine, then you need to change the cassandra yaml file in (dc1).\n\n* Open the file `/etc/cassandra/cassandra.yaml` and change the following settings\n\n\t\tlisten_address : `ipaddress`\n        rpc_address    : `ipaddress` \n\t\tendpoint_snitch: GossipingPropertyFileSnitch\n \t\t\n`Note` listen_address and rpc_address default is set localhost you need to change it to the private or public ipaddress (eg: 192.168.1.249).\n\n`endpoint_snitch` by default is set for `SimpleSnitch` which works only for SimpleStrategy so you can changed the snitch to `GossipingPropertyFileSnitch`\n\n* As we have used `GossipingPropertyFileSnitch` we need to change the file `/etc/cassandra/cassandra-rackdc.properties` with the datacenter and rack information.\n\t\t\n* `cassandra-rackdc.properties` it used to tell we are using GossipingPropertyFileSnitch as endpoint. \n\n* Define the Data Center and Rack that this node run on. The default settings:\n\t\t\n        dc=DC1\n\t\track=RAC1\n* Here, we are using two machines so change the file based on our setup.\n\t\t\n        dc=DC1\n\t\track=RAC1\n\t\tdc=DC2\n\t\track=RAC1\n\n* Add the above datacenter and rack in the `/etc/cassandra/cassandra-topology.properties`\n\n* It look like this\n\n\t\tData Center One\n\t\t175.56.12.105=DC1:RAC1\n\t\t175.50.13.200=DC1:RAC1\n\t\t175.54.35.197=DC1:RAC1\n\n\t\t120.53.24.101=DC1:RAC2\n\t\t120.55.16.200=DC1:RAC2\n\t\t120.57.102.103=DC1:RAC2\n\n* Change the datacenter and rack into your ipaddress in that file.\n\n\t\tipaddress1=DC1:RAC1\n\t\tipaddress2=DC2:RAC1\n        \n* Use this command to check the data center name, and rack is set into your machine.\n\t\n\t\tnodetool status.\n![](/content/images/2016/07/cassandra.png)\n* Its show the status of the node. \n\t\t\n        `UN` - define your node in up status.\n        `DN` - define your node in down status.\n \n\n### Step 3- Configure cassandra.yaml in dc2\n\n* Its assumed that you have installed cassandra in the two nodes (dc1, dc2).\n\n* Once you installed cassandra in your machine, then you need to change the cassandra yaml file in (dc2 as well).\n\nRepeat the process in as many racks/datacenters.\n\n###Conclusion\n\nThese are the very simple steps to setup cassandra replications in several nodes.\n\n###To Deploy your app\n\n[![img](https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png)](https://console.megamafrica.com)\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:14:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaitz001zdrgbluycagge","content":"<p>###Introduction </p>\n<p>Cassandra stores replicas on multiple nodes to ensure reliability and fault tolerance. A replication strategy determines the nodes where replicas are placed. The total number of replicas across the cluster is referred to as the replication factor. </p>\n<p>A replication factor of 1 means that there is only one copy of each row in the cluster. A replication factor of 2 means two copies of each row, where each copy is on a different node. As a general rule, the replication factor should not exceed the number of nodes in the cluster. However, you can increase the replication factor and then add the desired number of nodes.</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\"><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"img\"></a></p>\n<p>###Prerequisites</p>\n<p>To follow this tutorial :</p>\n<ul>\n<li><p>You need atleast two nodes. </p>\n</li>\n<li><p>You need to install cassandra in all the nodes.</p>\n</li>\n</ul>\n<h3 id=\"Step-1-Create-a-Keyspace-in-cql\"><a href=\"#Step-1-Create-a-Keyspace-in-cql\" class=\"headerlink\" title=\"Step 1 - Create a Keyspace in cql\"></a>Step 1 - Create a Keyspace in cql</h3><ul>\n<li><p>login into cqlsh</p>\n<pre><code>cqlsh `ipaddress1`\n</code></pre></li>\n<li><p>Creating a keyspace</p>\n<pre><code>CREATE KEYSPACE IF NOT EXISTS `keyspacename` WITH REPLICATION = { &apos;class&apos; : &apos;NetworkTopologyStrategy&apos;, &apos;dc1&apos; : 2 , &apos;dc2&apos; : 2 };\n</code></pre></li>\n<li><p>Two replication strategies of class are available:</p>\n</li>\n<li><p><code>SimpleStrategy</code> Use only for a single data center and one rack. If you ever intend more than one data center, use the NetworkTopologyStrategy.</p>\n</li>\n<li><p><code>NetworkTopologyStrategy</code> Highly recommended for most deployments because it is much easier to expand to multiple data centers when required by future expansion.</p>\n</li>\n<li><p>Here, we are testing in multiple datacenter so we used NetworkTopologyStrategy class.</p>\n</li>\n</ul>\n<h3 id=\"Step-2-Configure-cassandra-yaml-in-dc1\"><a href=\"#Step-2-Configure-cassandra-yaml-in-dc1\" class=\"headerlink\" title=\"Step 2 - Configure cassandra.yaml in dc1\"></a>Step 2 - Configure cassandra.yaml in dc1</h3><ul>\n<li><p>Its assumed that you have installed cassandra in the two nodes (dc1, dc2).</p>\n</li>\n<li><p>Once you installed cassandra in your machine, then you need to change the cassandra yaml file in (dc1).</p>\n</li>\n<li><p>Open the file <code>/etc/cassandra/cassandra.yaml</code> and change the following settings</p>\n<pre><code>listen_address : `ipaddress`\nrpc_address    : `ipaddress` \nendpoint_snitch: GossipingPropertyFileSnitch\n</code></pre></li>\n</ul>\n<p><code>Note</code> listen_address and rpc_address default is set localhost you need to change it to the private or public ipaddress (eg: 192.168.1.249).</p>\n<p><code>endpoint_snitch</code> by default is set for <code>SimpleSnitch</code> which works only for SimpleStrategy so you can changed the snitch to <code>GossipingPropertyFileSnitch</code></p>\n<ul>\n<li><p>As we have used <code>GossipingPropertyFileSnitch</code> we need to change the file <code>/etc/cassandra/cassandra-rackdc.properties</code> with the datacenter and rack information.</p>\n</li>\n<li><p><code>cassandra-rackdc.properties</code> it used to tell we are using GossipingPropertyFileSnitch as endpoint. </p>\n</li>\n<li><p>Define the Data Center and Rack that this node run on. The default settings:</p>\n<pre><code>dc=DC1\nrack=RAC1\n</code></pre></li>\n<li><p>Here, we are using two machines so change the file based on our setup.</p>\n<pre><code>dc=DC1\nrack=RAC1\ndc=DC2\nrack=RAC1\n</code></pre></li>\n<li><p>Add the above datacenter and rack in the <code>/etc/cassandra/cassandra-topology.properties</code></p>\n</li>\n<li><p>It look like this</p>\n<pre><code>Data Center One\n175.56.12.105=DC1:RAC1\n175.50.13.200=DC1:RAC1\n175.54.35.197=DC1:RAC1\n\n120.53.24.101=DC1:RAC2\n120.55.16.200=DC1:RAC2\n120.57.102.103=DC1:RAC2\n</code></pre></li>\n<li><p>Change the datacenter and rack into your ipaddress in that file.</p>\n<pre><code>ipaddress1=DC1:RAC1\nipaddress2=DC2:RAC1\n</code></pre></li>\n<li><p>Use this command to check the data center name, and rack is set into your machine.</p>\n<pre><code>nodetool status.\n</code></pre><p><img src=\"/content/images/2016/07/cassandra.png\" alt=\"\"></p>\n</li>\n<li><p>Its show the status of the node. </p>\n<pre><code>`UN` - define your node in up status.\n`DN` - define your node in down status.\n</code></pre></li>\n</ul>\n<h3 id=\"Step-3-Configure-cassandra-yaml-in-dc2\"><a href=\"#Step-3-Configure-cassandra-yaml-in-dc2\" class=\"headerlink\" title=\"Step 3- Configure cassandra.yaml in dc2\"></a>Step 3- Configure cassandra.yaml in dc2</h3><ul>\n<li><p>Its assumed that you have installed cassandra in the two nodes (dc1, dc2).</p>\n</li>\n<li><p>Once you installed cassandra in your machine, then you need to change the cassandra yaml file in (dc2 as well).</p>\n</li>\n</ul>\n<p>Repeat the process in as many racks/datacenters.</p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to setup cassandra replications in several nodes.</p>\n<p>###To Deploy your app</p>\n<p><a href=\"https://console.megamafrica.com\" target=\"_blank\" rel=\"external\"><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"img\"></a></p>\n","excerpt":"","more":"<p>###Introduction </p>\n<p>Cassandra stores replicas on multiple nodes to ensure reliability and fault tolerance. A replication strategy determines the nodes where replicas are placed. The total number of replicas across the cluster is referred to as the replication factor. </p>\n<p>A replication factor of 1 means that there is only one copy of each row in the cluster. A replication factor of 2 means two copies of each row, where each copy is on a different node. As a general rule, the replication factor should not exceed the number of nodes in the cluster. However, you can increase the replication factor and then add the desired number of nodes.</p>\n<p><a href=\"https://console.megamafrica.com\"><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"img\"></a></p>\n<p>###Prerequisites</p>\n<p>To follow this tutorial :</p>\n<ul>\n<li><p>You need atleast two nodes. </p>\n</li>\n<li><p>You need to install cassandra in all the nodes.</p>\n</li>\n</ul>\n<h3 id=\"Step-1-Create-a-Keyspace-in-cql\"><a href=\"#Step-1-Create-a-Keyspace-in-cql\" class=\"headerlink\" title=\"Step 1 - Create a Keyspace in cql\"></a>Step 1 - Create a Keyspace in cql</h3><ul>\n<li><p>login into cqlsh</p>\n<pre><code>cqlsh `ipaddress1`\n</code></pre></li>\n<li><p>Creating a keyspace</p>\n<pre><code>CREATE KEYSPACE IF NOT EXISTS `keyspacename` WITH REPLICATION = { &apos;class&apos; : &apos;NetworkTopologyStrategy&apos;, &apos;dc1&apos; : 2 , &apos;dc2&apos; : 2 };\n</code></pre></li>\n<li><p>Two replication strategies of class are available:</p>\n</li>\n<li><p><code>SimpleStrategy</code> Use only for a single data center and one rack. If you ever intend more than one data center, use the NetworkTopologyStrategy.</p>\n</li>\n<li><p><code>NetworkTopologyStrategy</code> Highly recommended for most deployments because it is much easier to expand to multiple data centers when required by future expansion.</p>\n</li>\n<li><p>Here, we are testing in multiple datacenter so we used NetworkTopologyStrategy class.</p>\n</li>\n</ul>\n<h3 id=\"Step-2-Configure-cassandra-yaml-in-dc1\"><a href=\"#Step-2-Configure-cassandra-yaml-in-dc1\" class=\"headerlink\" title=\"Step 2 - Configure cassandra.yaml in dc1\"></a>Step 2 - Configure cassandra.yaml in dc1</h3><ul>\n<li><p>Its assumed that you have installed cassandra in the two nodes (dc1, dc2).</p>\n</li>\n<li><p>Once you installed cassandra in your machine, then you need to change the cassandra yaml file in (dc1).</p>\n</li>\n<li><p>Open the file <code>/etc/cassandra/cassandra.yaml</code> and change the following settings</p>\n<pre><code>listen_address : `ipaddress`\nrpc_address    : `ipaddress` \nendpoint_snitch: GossipingPropertyFileSnitch\n</code></pre></li>\n</ul>\n<p><code>Note</code> listen_address and rpc_address default is set localhost you need to change it to the private or public ipaddress (eg: 192.168.1.249).</p>\n<p><code>endpoint_snitch</code> by default is set for <code>SimpleSnitch</code> which works only for SimpleStrategy so you can changed the snitch to <code>GossipingPropertyFileSnitch</code></p>\n<ul>\n<li><p>As we have used <code>GossipingPropertyFileSnitch</code> we need to change the file <code>/etc/cassandra/cassandra-rackdc.properties</code> with the datacenter and rack information.</p>\n</li>\n<li><p><code>cassandra-rackdc.properties</code> it used to tell we are using GossipingPropertyFileSnitch as endpoint. </p>\n</li>\n<li><p>Define the Data Center and Rack that this node run on. The default settings:</p>\n<pre><code>dc=DC1\nrack=RAC1\n</code></pre></li>\n<li><p>Here, we are using two machines so change the file based on our setup.</p>\n<pre><code>dc=DC1\nrack=RAC1\ndc=DC2\nrack=RAC1\n</code></pre></li>\n<li><p>Add the above datacenter and rack in the <code>/etc/cassandra/cassandra-topology.properties</code></p>\n</li>\n<li><p>It look like this</p>\n<pre><code>Data Center One\n175.56.12.105=DC1:RAC1\n175.50.13.200=DC1:RAC1\n175.54.35.197=DC1:RAC1\n\n120.53.24.101=DC1:RAC2\n120.55.16.200=DC1:RAC2\n120.57.102.103=DC1:RAC2\n</code></pre></li>\n<li><p>Change the datacenter and rack into your ipaddress in that file.</p>\n<pre><code>ipaddress1=DC1:RAC1\nipaddress2=DC2:RAC1\n</code></pre></li>\n<li><p>Use this command to check the data center name, and rack is set into your machine.</p>\n<pre><code>nodetool status.\n</code></pre><p><img src=\"/content/images/2016/07/cassandra.png\" alt=\"\"></p>\n</li>\n<li><p>Its show the status of the node. </p>\n<pre><code>`UN` - define your node in up status.\n`DN` - define your node in down status.\n</code></pre></li>\n</ul>\n<h3 id=\"Step-3-Configure-cassandra-yaml-in-dc2\"><a href=\"#Step-3-Configure-cassandra-yaml-in-dc2\" class=\"headerlink\" title=\"Step 3- Configure cassandra.yaml in dc2\"></a>Step 3- Configure cassandra.yaml in dc2</h3><ul>\n<li><p>Its assumed that you have installed cassandra in the two nodes (dc1, dc2).</p>\n</li>\n<li><p>Once you installed cassandra in your machine, then you need to change the cassandra yaml file in (dc2 as well).</p>\n</li>\n</ul>\n<p>Repeat the process in as many racks/datacenters.</p>\n<p>###Conclusion</p>\n<p>These are the very simple steps to setup cassandra replications in several nodes.</p>\n<p>###To Deploy your app</p>\n<p><a href=\"https://console.megamafrica.com\"><img src=\"https://s3-ap-southeast-1.amazonaws.com/megampub/images/megamafrica/DEPLOY-TO-MEGAM-AFRICA-BIG1.png\" alt=\"img\"></a></p>\n"},{"title":"All articles","slug":"page-index","date_published":"2015-03-27T06:13:17.328Z","date_updated":"2015-03-27T06:13:17.326Z","_content":"\nBeginner\n\n[Hadoop](http://devcenter.megam.io/2015/03/25/haddop_spark_multinode_setup/)\n","source":"_posts/page-index.md","raw":"---\ntitle: All articles\nslug: index\ndate_published: 2015-03-27T11:43:17.328Z\ndate_updated:   2015-03-27T11:43:17.326Z\n---\n\nBeginner\n\n[Hadoop](http://devcenter.megam.io/2015/03/25/haddop_spark_multinode_setup/)\n","published":1,"date":"2016-09-30T16:20:39.331Z","updated":"2016-09-27T17:13:44.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citpzaiu00020drgbzht6gudb","content":"<p>Beginner</p>\n<p><a href=\"http://devcenter.megam.io/2015/03/25/haddop_spark_multinode_setup/\" target=\"_blank\" rel=\"external\">Hadoop</a></p>\n","excerpt":"","more":"<p>Beginner</p>\n<p><a href=\"http://devcenter.megam.io/2015/03/25/haddop_spark_multinode_setup/\">Hadoop</a></p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"citpzaiqu0002drgbefooftgx","tag_id":"citpzaiqx0004drgbs71i96gv","_id":"citpzairg0009drgb29c7hy3b"},{"post_id":"citpzairb0006drgbho24hq3x","tag_id":"citpzairf0008drgb9gm5mukt","_id":"citpzairl000ddrgbgz4okcr0"},{"post_id":"citpzairp000fdrgbmz5c76gp","tag_id":"citpzairt000hdrgb4lagy00y","_id":"citpzairy000mdrgbxdozzilg"},{"post_id":"citpzairw000jdrgbpwu4cm59","tag_id":"citpzairy000ldrgb81a8fz1x","_id":"citpzais4000qdrgb69ovzd2m"},{"post_id":"citpzaisp0014drgbs8d50kdz","tag_id":"citpzaiss0016drgbxz2abv97","_id":"citpzaisv001adrgb5qhzuqog"}],"Tag":[{"name":"ruby","_id":"citpzaiqx0004drgbs71i96gv"},{"name":"expert, Ruby on Rails, oauth","_id":"citpzairf0008drgb9gm5mukt"},{"name":"ceph","_id":"citpzairt000hdrgb4lagy00y"},{"name":"docker, containers, containerization, LXCs, linux","_id":"citpzairy000ldrgb81a8fz1x"},{"name":"scylla, scylladb, nosql, cassandra","_id":"citpzaiss0016drgbxz2abv97"}]}}